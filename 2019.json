[{"title": "On multi-device use: Using technological modality profiles to explain differences in students' learning", "pages": "1-10", "doi": "10.1145/3303772.3303790", "abstract": "With increasing abundance and ubiquity of mobile phones, desktop PCs, and tablets in the last decade, we are seeing students intermixing these modalities to learn and regulate their learning. However, the role of these modalities in educational settings is still largely under-researched. Similarly, little attention has been paid to the research on the extension of learning analytics to analyze the learning processes of students adopting various modalities during a learning activity. Traditionally, research on how modalities affect the way in which activities are completed has mainly relied upon self-reported data or mere counts of access from each modality. We explore the use of technological modalities in regulating learning via learning management systems (LMS) in the context of blended courses. We used data mining techniques to analyze patterns in sequences of actions performed by learners (n = 120) across different modalities in order to identify technological modality profiles of sequences. These profiles were used to detect the technological modality strategies adopted by students. We found a moderate effect size (\u22082 = 0.12) of students' adopted strategies on the final course grade. Furthermore, when looking specifically at online discussion engagement and performance, students' adopted technological modality strategies explained a large amount of variance (\u03b72 = 0.68) in their engagement and quality of contributions. The result implications and further research are discussed.", "authors": ["Varshita Sher", "Marek Hatala", "Dragan Ga\u0161evi\u0107"], "session": "SESSION: Novel Devices"}, {"title": "Technologies for automated analysis of co-located, real-life, physical learning spaces: Where are we now?", "pages": "11-20", "doi": "10.1145/3303772.3303811", "abstract": "The motivation for this paper is derived from the fact that there has been increasing interest among researchers and practitioners in developing technologies that capture, model and analyze learning and teaching experiences that take place beyond computer-based learning environments. In this paper, we review case studies of tools and technologies developed to collect and analyze data in educational settings, quantify learning and teaching processes and support assessment of learning and teaching in an automated fashion. We focus on pipelines that leverage information and data harnessed from physical spaces and/or integrates collected data across physical and digital spaces. Our review reveals a promising field of physical classroom analysis. We describe some trends and suggest potential future directions. Specifically, more research should be geared towards a) deployable and sustainable data collection set-ups in physical learning environments, b) teacher assessment, c) developing feedback and visualization systems and d) promoting inclusivity and generalizability of models across populations.", "authors": ["Yi Han Victoria Chua", "Justin Dauwels", "Seng Chee Tan"], "session": "SESSION: Novel Devices"}, {"title": "\"I Spent More Time with that Team\": Making Spatial Pedagogy Visible Using Positioning Sensors", "pages": "21-25", "doi": "10.1145/3303772.3303818", "abstract": "Teachers are often encouraged to adopt different positioning strategies at various stages of a classroom lesson as each can influence learners in different ways. However, little work has been done to make evidence of the use of classrooms visible to teachers and students. As sensors drop in price, it is becoming more viable to capture traces of the use of the physical classroom space automatically. In this paper, we build on the notion of spatial pedagogy to propose an approach to visualise digital traces of teacher positioning in the classroom. We illustrate our approach through an authentic case study of a teacher enacting three distinctive learning designs. We document the teacher's and students' reactions to visual representations of positioning data to explore their potential as proxies of spatial pedagogy.", "authors": ["Roberto Martinez-Maldonado"], "session": "SESSION: Novel Devices"}, {"title": "A Study on Curriculum Planning and Its Relationship with Graduation GPA and Time To Degree", "pages": "26-35", "doi": "10.1145/3303772.3303783", "abstract": "In recent years, several data-driven methods have been developed to help undergraduate students during course selection and sequencing. These methods tend to utilize the whole set of past course registration data, regardless of the past students' graduation GPA and time to degree (TTD). Though some previous work has shown through the results of their developed models that students of different GPA tend to take courses in different sequence, the actual analysis of the degree plans and how/if they relate to the students' graduation GPA and time-to-degree has not received much attention. This study analyzes how the student's academic level when they take different courses, as well as the pairwise degree similarity between pairs of students relate to the students' graduation GPA and TTD. Our study uses a large-scale dataset that contains 25 majors from different colleges at the University of Minnesota and spans 16 years. The analysis shows that TTD is highly correlated with both the timing and ordering of courses that students follow in their degree plans, while the correlation between graduation GPA and the course timing and ordering is not as high. We also perform a case study that uses course timing and ordering features to predict whether the student at each semester will graduate on-time or overtime. The results show that careful curriculum planning is needed to improve graduation rates in universities.", "authors": ["Sara Morsy", "George Karypis"], "session": "SESSION: Curriculum"}, {"title": "Goal-based Course Recommendation", "pages": "36-45", "doi": "10.1145/3303772.3303814", "abstract": "With cross-disciplinary academic interests increasing and academic advising resources over capacity, the importance of exploring data-assisted methods to support student decision making has never been higher. We build on the findings and methodologies of a quickly developing literature around prediction and recommendation in higher education and develop a novel recurrent neural network-based recommendation system for suggesting courses to help students prepare for target courses of interest, personalized to their estimated prior knowledge background and zone of proximal development. We validate the model using tests of grade prediction and the ability to recover prerequisite relationships articulated by the university. In the third validation, we run the fully personalized recommendation for students the semester before taking a historically difficult course and observe differential overlap with our would-be suggestions. While not proof of causal effectiveness, these three evaluation perspectives on the performance of the goal-based model build confidence and bring us one step closer to deployment of this personalized course preparation affordance in the wild.", "authors": ["Weijie Jiang", "Zachary A. Pardos", "Qiang Wei"], "session": "SESSION: Curriculum"}, {"title": "Semi-Automatic Generation of Intelligent Curricula to Facilitate Learning Analytics", "pages": "46-50", "doi": "10.1145/3303772.3303834", "abstract": "Several Learning Analytics applications are limited by the cost of generating a computer understandable description of the course domain, what is called an Intelligent Curriculum. The following work contributes a novel approach to (semi-)automatically generate Intelligent Curriculum through ontologies extracted from existing learning materials such as digital books or web content. Through a series of natural language processing steps, the semi-structured information present in existing content is transformed into a concept-graph. This work also evaluates the proposed methodology by applying it to learning content for two different courses and measuring the quality of the extracted ontologies against manually generated ones. The results obtained suggest that the technique can be readily used to provide domain information to other Learning Analytics tools.", "authors": ["Angel Fiallos", "Xavier Ochoa"], "session": "SESSION: Curriculum"}, {"title": "Read Between the Lines: An Annotation Tool for Multimodal Data for Learning", "pages": "51-60", "doi": "10.1145/3303772.3303776", "abstract": "This paper introduces the Visual Inspection Tool (VIT) which supports researchers in the annotation of multimodal data as well as the processing and exploitation for learning purposes. While most of the existing Multimodal Learning Analytics (MMLA) solutions are tailor-made for specific learning tasks and sensors, the VIT addresses the data annotation for different types of learning tasks that can be captured with a customisable set of sensors in a flexible way. The VIT supports MMLA researchers in 1) triangulating multimodal data with video recordings; 2) segmenting the multimodal data into time-intervals and adding annotations to the time-intervals; 3) downloading the annotated dataset and using it for multimodal data analysis. The VIT is a crucial component that was so far missing in the available tools for MMLA research. By filling this gap we also identified an integrated workflow that characterises current MMLA research. We call this workflow the Multimodal Learning Analytics Pipeline, a toolkit for orchestration, the use and application of various MMLA tools.", "authors": ["Daniele Di Mitri", "Jan Schneider", "Roland Klemke", "Marcus Specht", "Hendrik Drachsler"], "session": "SESSION: Multimodal Analytics"}, {"title": "Multichannel data for understanding cognitive affordances during complex problem solving", "pages": "61-70", "doi": "10.1145/3303772.3303778", "abstract": "This exploratory study challenges the current practices in cognitive load measurement by using multichannel data to investigate cognitive load affordances during online complex problem solving. Moreover, it is an attempt to investigate how cognitive load is related to strategy use. Accordingly, in the current study a well- and an ill-structured problem were developed in a virtual learning environment. Online support was provided. Participants were 15 students from the teacher training program. This study incorporated subjective measurements of students' cognitive load (i.e., intrinsic, extraneous, germane load and their mental effort) combined with physiological data containing galvanic skin response (GSR) and skin temperature (ST). A first aim was to investigate whether there was a significant difference for the subjective measurements, physiological data and consultation of support between the well-and ill-structured problem. Secondly this study investigated how individual differences of subjective measurements are related to individual differences of physiological data and consultation of support. Results reveal significant differences for intrinsic load, mental effort between a well- and ill-structured problem. Moreover, when investigating individual differences, findings reveal that GSR might be related to mental effort. Additionally, results indicate that cognitive load influences strategy use. Future research with larger sample sizes should verify these findings in order to have more insight into how we can measure cognitive load and how its related to self-directed learning. These insights should allow us to provide adaptive support in virtual learning environments.", "authors": ["Charlotte Larmuseau", "Pieter Vanneste", "Piet Desmet", "Fien Depaepe"], "session": "SESSION: Multimodal Analytics"}, {"title": "Cross-Platform Analytics: A step towards Personalization and Adaptation in Education", "pages": "71-75", "doi": "10.1145/3303772.3303825", "abstract": "Learning analytics are used to track learners' progress and empower educators and learners to make well-informed data-driven decisions. However, due to the distributed nature of the learning process, analytics need to be combined to offer broader insights into learner's behavior and experiences. Consequently, this paper presents an architecture of a learning ecosystem, that integrates and utilizes cross-platform analytics. The proposed cross-platform architecture has been put into practice via a Java programming course. After a series of studies, a proof of concept was derived that shows how cross-platform analytics amplify the relevant analytics for the learning process. Such analytics could improve educators' and learners' understanding of their own actions and the environments in which learning occurs.", "authors": ["Katerina Mangaroska", "Boban Vesin", "Michail Giannakos"], "session": "SESSION: Multimodal Analytics"}, {"title": "Reliable Deep Grade Prediction with Uncertainty Estimation", "pages": "76-85", "doi": "10.1145/3303772.3303802", "abstract": "Currently, college-going students are taking longer to graduate than their parental generations. Further, in the United States, the six-year graduation rate has been 59% for decades. Improving the educational quality by training better-prepared students who can successfully graduate in a timely manner is critical. Accurately predicting students' grades in future courses has attracted much attention as it can help identify at-risk students early so that personalized feedback can be provided to them on time by advisors. Prior research on students' grade prediction include shallow linear models; however, students' learning is a highly complex process that involves the accumulation of knowledge across a sequence of courses that can not be sufficiently modeled by these linear models. In addition to that, prior approaches focus on prediction accuracy without considering prediction uncertainty, which is essential for advising and decision making. In this work, we present two types of Bayesian deep learning models for grade prediction under a course-specific framework: i)Multilayer Perceptron (MLP) and ii) Recurrent Neural Network (RNN). These course-specific models are based on the assumption that prior courses can provide students with knowledge for future courses so that grades of prior courses can be used to predict grades in a future course. The MLP ignores the temporal dynamics of students' knowledge evolution. Hence, we propose RNN for students' performance prediction. To evaluate the performance of the proposed models, we performed extensive experiments on data collected from a large public university. The experimental results show that the proposed models achieve better performance than prior state-of-the-art approaches. Besides more accurate results, Bayesian deep learning models estimate uncertainty associated with the predictions. We explore how uncertainty estimation can be applied towards developing a reliable educational early warning system. In addition to uncertainty, we also develop an approach to explain the prediction results, which is useful for advisors to provide personalized feedback to students.", "authors": ["Qian Hu", "Huzefa Rangwala"], "session": "SESSION: Machine Learning I"}, {"title": "user2code2vec: Embeddings for Profiling Students Based on Distributional Representations of Source Code", "pages": "86-95", "doi": "10.1145/3303772.3303813", "abstract": "In this work, we propose a new methodology to profile individual students of computer science based on their programming design using a technique called embeddings. We investigate different approaches to analyze user source code submissions in the Python language. We compare the performances of different source code vectorization techniques to predict the correctness of a code submission. In addition, we propose a new mechanism to represent students based on their code submissions for a given set of laboratory tasks on a particular course. This way, we can make deeper recommendations for programming solutions and pathways to support student learning and progression in computer programming modules effectively at a Higher Education Institution. Recent work using Deep Learning tends to work better when more and more data is provided. However, in Learning Analytics, the number of students in a course is an unavoidable limit. Thus we cannot simply generate more data as is done in other domains such as FinTech or Social Network Analysis. Our findings indicate there is a need to learn and develop better mechanisms to extract and learn effective data features from students so as to analyze the students' progression and performance effectively.", "authors": ["David Azcona", "Piyush Arora", "I-Han Hsiao", "Alan Smeaton"], "session": "SESSION: Machine Learning I"}, {"title": "Clustering Analysis Reveals Authentic Science Inquiry Trajectories Among Undergraduates", "pages": "96-100", "doi": "10.1145/3303772.3303831", "abstract": "Science education reforms in the United States call for an emphasis on teaching of scientific practices, such as inquiry. Previous work examined expert versus novice practices in authentic science inquiry and found although experts have fairly consistent inquiry strategies, novices exist on a continuum. In this paper, we extend our previous qualitative work to quantitatively analyze differences in inquiry practices among novices. Using clustering analysis, we found that non-science majors who performed simple investigations tended to cluster together and biology majors who performed complex investigations also tended to cluster together. We observed two additional clusters that contain both non-science majors and biology majors, but who performed distinct inquiry strategies. This raises some critical questions about how to pedagogically target students within each cluster.", "authors": ["Melanie Peffer", "David Quigley", "Mehrgan Mostowfi"], "session": "SESSION: Machine Learning I"}, {"title": "Can Background Music Facilitate Learning?: Preliminary Results on Reading Comprehension", "pages": "101-105", "doi": "10.1145/3303772.3303839", "abstract": "It is a common phenomenon for students to listen to background music while studying. However, there are mixed and inconclusive Kindings in the literature, leaving it unclear whether and in which circumstances background music can facilitate or hinder learning. This paper reports a study investigating the effects of Kive different types of background audio (four types of music and one environmental sound) on reading comprehension. An experiment was conducted with 33 graduate students, where a series of cognitive, metacognitive, affective variables and physiological signals were collected and analyzed. Preliminary results show that there were differences on these variables across different music types. This study contributes to the understanding and optimizing of background music for facilitating learning.", "authors": ["Xiao Hu", "Fanjie Li", "Runzhi Kong"], "session": "SESSION: Reading Analytics"}, {"title": "Would you?: Could you? On a tablet? Analytics of Children's eBook Reading", "pages": "106-110", "doi": "10.1145/3303772.3303833", "abstract": "It is difficult to overstate the importance of literacy for adequate functioning in society, from educational attainment and employment opportunities to health outcomes. We created a reading app with the goal of helping readers improve their reading skill while reading for meaning and pleasure, and used it to collect unique data on children's extended reading. Analysis of the data reveals the importance of a behavioral factor in understanding observed reading performance.", "authors": ["Beata Beigman Klebanov", "Anastassia Loukina", "Nitin Madnani", "John Sabatini", "Jennifer Lentini"], "session": "SESSION: Reading Analytics"}, {"title": "Comprehension Factor Analysis: Modeling student's reading behaviour: Accounting for reading practice in predicting students' learning in MOOCs", "pages": "111-115", "doi": "10.1145/3303772.3303817", "abstract": "Massive Open Online Courses (MOOCs) often incorporate lecture-based learning along with lecture notes, textbooks, and videos to students. Moreover, MOOCs also incorporate practice activities and quizzes. Student learning in MOOCs can be tracked and improved using state-of-the-art student modeling. Currently, this means employing conventional student models that are constructed around Intelligent Tutoring Systems (ITS). Traditional ITS systems only utilize students performance interactions (quiz, problem-solving or practice activities). Therefore, text interactions are entirely ignored while modeling students performance in MOOCs using these cognitive models. In this work, we propose a Comprehension Factor Analysis model (CFM) for online courses, which integrates student reading interactions in student models to track and predict learning outcomes. Our model evaluation shows that CFM outperforms state-of-the-art models in predicting students' performance in a MOOC. These models can help better student-wise adaptation in the context of MOOCs.", "authors": ["Khushboo Thaker", "Paulo Carvalho", "Kenneth Koedinger"], "session": "SESSION: Reading Analytics"}, {"title": "Are You Talking to Me?: Multi-Dimensional Language Analysis of Explanations during Reading", "pages": "116-120", "doi": "10.1145/3303772.3303835", "abstract": "This study examines the extent to which instructions to self-explain vs. other-explain a text lead readers to produce different forms of explanations. Natural language processing was used to examine the content and characteristics of the explanations produced as a function of instruction condition. Undergraduate students (n = 146) typed either self-explanations or other-explanations while reading a science text. The linguistic properties of these explanations were calculated using three automated text analysis tools. Machine learning classifiers in combination with the features were used to predict instruction condition (i.e., self- or other-explanation). The best machine learning model performed at rates above chance (kappa = .247; accuracy = 63%). Follow-up analyses indicated that students in the self-explanation condition generated explanations that were more cohesive and that contained words that were more related to social order (e.g., ethics). Overall, the results suggest that natural language processing techniques can be used to detect subtle differences in students' processing of complex texts.", "authors": ["Laura K. Allen", "Caitlin Mills", "Cecile Perret", "Danielle S. McNamara"], "session": "SESSION: Reading Analytics"}, {"title": "Exploring the Subtleties of Agency and Indirect Control in Digital Learning Games", "pages": "121-129", "doi": "10.1145/3303772.3303797", "abstract": "How do the features of a learning environment's user interface impact learners' agency and, further, their learning? We explored this question in the context of Decimal Point, a digital learning game designed to support middle school students in learning decimals. Previous studies of the game showed that giving students the ability to choose the order and number of mini-games to play did not significantly impact their learning outcomes compared to a condition without choice. In this paper we explore whether some elements of the game's interface may have inadvertently exerted indirect control over students' choice, leading to the previous effects. We conducted a classroom study using a new version of the game that varied whether students saw a visual path connecting mini-games on the game map to modulate the level of indirect control students would experience with an implied ordering. Ultimately, we found that students in the no-line condition exercised significantly more agency but did not learn any less than the line condition. These results suggest that indirect control can be a subtle but powerful way to direct student attention in digital learning games.", "authors": ["Erik Harpstead", "J. Elizabeth Richey", "Huy Nguyen", "Bruce M. McLaren"], "session": "SESSION: Games and Learning"}, {"title": "Differences in Student Trajectories via Filtered Time Series Analysis in an Immersive Virtual World", "pages": "130-134", "doi": "10.1145/3303772.3303832", "abstract": "To scaffold students' investigations of an inquiry-based immersive virtual world for science education without undercutting the affordances an open-ended activity provides, this study explores ways time-stamped log files of groups' actions may enable the automatic generation of formative supports. Groups' logged actions in the virtual world are filtered via principal component analysis to provide a time series trajectory showing the rate of their investigative activities over time. This technique functions well in open-ended environments and examines the entire course of their experience in the virtual world instead of specific subsequences. Groups' trajectories are grouped via k-means clustering to identify different typical pathways taken through the immersive virtual world. These different approaches are then correlated with learning gains across several survey constructs (affective dimensions, ecosystem science content, understanding of causality, and experimental methods) to see how various trends are associated with different outcomes. Differences by teacher and school are explored to see how best to support inclusion and success of a diverse array of learners.", "authors": ["Joseph M. Reilly", "Chris Dede"], "session": "SESSION: Games and Learning"}, {"title": "Effective Feature Learning with Unsupervised Learning for Improving the Predictive Models in Massive Open Online Courses", "pages": "135-144", "doi": "10.1145/3303772.3303795", "abstract": "The effectiveness of learning in massive open online courses (MOOCs) can be significantly enhanced by introducing personalized intervention schemes which rely on building predictive models of student learning behaviors such as some engagement or performance indicators. A major challenge that has to be addressed when building such models is to design handcrafted features that are effective for the prediction task at hand. In this paper, we make the first attempt to solve the feature learning problem by taking the unsupervised learning approach to learn a compact representation of the raw features with a large degree of redundancy. Specifically, in order to capture the underlying learning patterns in the content domain and the temporal nature of the clickstream data, we train a modified auto-encoder (AE) combined with the long short-term memory (LSTM) network to obtain a fixed-length embedding for each input sequence. When compared with the original features, the new features that correspond to the embedding obtained by the modified LSTM-AE are not only more parsimonious but also more discriminative for our prediction task. Using simple supervised learning models, the learned features can improve the prediction accuracy by up to 17% compared with the supervised neural networks and reduce overfitting to the dominant low-performing group of students, specifically in the task of predicting students' performance. Our approach is generic in the sense that it is not restricted to a specific supervised learning model nor a specific prediction task for MOOC learning analytics.", "authors": ["Mucong Ding", "Kai Yang", "Dit-Yan Yeung", "Ting-Chuen Pong"], "session": "SESSION: Machine Learning II"}, {"title": "Transfer Learning using Representation Learning in Massive Open Online Courses", "pages": "145-154", "doi": "10.1145/3303772.3303794", "abstract": "In a Massive Open Online Course (MOOC), predictive models of student behavior can support multiple aspects of learning, including instructor feedback and timely intervention. Ongoing courses, when the student outcomes are yet unknown, must rely on models trained from the historical data of previously offered courses. It is possible to transfer models, but they often have poor prediction performance. One reason is features that inadequately represent predictive attributes common to both courses. We present an automated transductive transfer learning approach that addresses this issue. It relies on problem-agnostic, temporal organization of the MOOC clickstream data, where, for each student, for multiple courses, a set of specific MOOC event types is expressed for each time unit. It consists of two alternative transfer methods based on representation learning with auto-encoders: a passive approach using transductive principal component analysis and an active approach that uses a correlation alignment loss term. With these methods, we investigate the transferability of dropout prediction across similar and dissimilar MOOCs and compare with known methods. Results show improved model transferability and suggest that the methods are capable of automatically learning a feature representation that expresses common predictive characteristics of MOOCs.", "authors": ["Mucong Ding", "Yanbang Wang", "Erik Hemberg", "Una-May O'Reilly"], "session": "SESSION: Machine Learning II"}, {"title": "Exploring Programming Semantic Analytics with Deep Learning Models", "pages": "155-159", "doi": "10.1145/3303772.3303823", "abstract": "There are numerous studies have reported the effectiveness of example-based programming learning. However, less is explored recommending code examples with advanced Machine Learning-based models. In this work, we propose a new method to explore the semantic analytics between programming codes and the annotations. We hypothesize that these semantics analytics will capture mass amount of valuable information that can be used as features to build predictive models. We evaluated the proposed semantic analytics extraction method with multiple deep learning algorithms. Results showed that deep learning models outperformed other models and baseline in most cases. Further analysis indicated that in special cases, the proposed method outperformed deep learning models by restricting false-positive classifications.", "authors": ["Yihan Lu", "I-Han Hsiao"], "session": "SESSION: Machine Learning II"}, {"title": "Social Comparison in MOOCs: Perceived SES, Opinion, and Message Formality", "pages": "160-169", "doi": "10.1145/3303772.3303773", "abstract": "There has been limited research on how perceptions of socioeconomic status (SES) and opinion difference could influence peer feedback in Massive Open Online Courses (MOOCs). Using social comparison theory [12], we investigated the influence of ability and opinion-related factors on peer feedback text in a data science MOOC. Perceived SES of peers and the formality of written responses were used as the ability-related factor, while agreement between learners represented the opinion-related factor. We focused on understanding the behaviors of those learners who are most prevalent in MOOCs; those from high socioeconomic countries. Through two studies, we found a strong and repeated influence of agreement on affect and formality in feedback to peers. While a mediation effect of perceived SES was found, a significant effect of formality was not. This work contributes to an understanding of how social comparison theory can be operationalized in online peer writing environments.", "authors": ["Heeryung Choi", "Nia Dowell", "Christopher Brooks", "Stephanie Teasley"], "session": "SESSION: Dialogue & Engagement"}, {"title": "Analysing discussion forum data: a replication study avoiding data contamination", "pages": "170-179", "doi": "10.1145/3303772.3303779", "abstract": "The widespread use of online discussion forums in educational settings provides a rich source of data for researchers interested in how collaboration and interaction can foster effective learning. Such online behaviour can be understood through the Community of Inquiry framework, and the cognitive presence construct in particular can be used to characterise the depth of a student's critical engagement with course material. Automated methods have been developed to support this task, but many studies used small data sets, and there have been few replication studies. In this work, we present findings related to the robustness and generalisability of automated classification methods for detecting cognitive presence in discussion forum transcripts. We closely examined one published state-of-the-art model, comparing different approaches to managing unbalanced classes in the data. By demonstrating how commonly-used data preprocessing practices can lead to over-optimistic results, we contribute to the development of the field so that the results of automated content analysis can be used with confidence.", "authors": ["Elaine Farrow", "Johanna Moore", "Dragan Ga\u0161evi\u0107"], "session": "SESSION: Dialogue & Engagement"}, {"title": "Exploring Learner Engagement Patterns in Teach-Outs Using Topic, Sentiment and On-topicness to Reflect on Pedagogy", "pages": "180-184", "doi": "10.1145/3303772.3303836", "abstract": "MOOCs have developed into multiple learning design models with a wide range of objectives. Teach-Outs are one such example, aiming to drive meaningful discussions around topics of pressing social urgency without the use of formal assessments. Given this approach, it is crucial to evaluate learners' engagement in the discussion forum to understand their experiences. This paper presents a pilot study that applied unsupervised natural language processing techniques to understand what and how students engage in dialogue in a Teach-Out. We used topic modeling to discover the emerging topics in the discussion forums and evaluated the on-topicness of the discussions (i.e. the degree to which discussions were relevant to the Teach-Out content). We also applied content analysis to investigate the sentiments associated with the discussions. We have taken a step toward extracting structure from students' discussions to understand learning behaviors happen in the discussion forum. This is the first study to analyze discussion forums in a Teach-Out.", "authors": ["Wenfei Yan", "Nia Dowell", "Caitlin Holman", "Stephen S. Welsh", "Heeryung Choi", "Christopher Brooks"], "session": "SESSION: Dialogue & Engagement"}, {"title": "DiAd: Domain Adaptation for Learning at Scale", "pages": "185-194", "doi": "10.1145/3303772.3303810", "abstract": "Massive online courses occupy an important place in the educational landscape of today. We study an approach to scale predictive analytic models derived from online course discussion fora--specifically that of confusion detection--onto other courses. The primary challenge here is the lack of labeled examples in a new course and this calls for unsupervised domain adaptation (DA). As a first step in exploring DA in the education domain, we propose a simple algorithm, DiAd, which adapts a classifier trained on a course with labeled data by selectively choosing instances from a new course (with no labeled data) that are most dissimilar to the course with labeled data and on which the classifier is very confident of classification. Our algorithm is empirically validated on the confusion detection task across multiple online courses. We find that DiAd outperforms other methods on the target domain, while showing a comparable performance to a popular method that uses labeled data from the target domain.", "authors": ["Ziheng Zeng", "Snigdha Chaturvedi", "Suma Bhat", "Dan Roth"], "session": "SESSION: Computational Methods"}, {"title": "The Timeliness Deviation: A novel Approach to Evaluate Educational Recommender Systems for Closed-Courses", "pages": "195-204", "doi": "10.1145/3303772.3303774", "abstract": "The decision on what item to learn next in a course can be supported by a recommender system (RS), which aims at making the learning process more efficient and effective. However, learners and learning activities frequently change over time. The question is: how are timely appropriate recommendations of learning resources actually evaluated and how can they be compared? Researchers have found that, in addition to a standardized dataset definition, there is also a lack of standardized definitions of evaluation procedures for RS in the area of Technology Enhanced Learning. This paper argues that, in a closed-course setting, a time-dependent split into the training set and test set is more appropriate than the usual cross-validation to evaluate the Top-N recommended learning resources at various points in time. Moreover, a new measure is introduced to determine the timeliness deviation between the point in time of an item recommendation and the point in time of the actual access by the user. Different recommender algorithms, including two novel ones, are evaluated with the time-dependent evaluation framework and the results, as well as the appropriateness of the framework, are discussed.", "authors": ["Christopher Krauss", "Agathe Merceron", "Stefan Arbanowski"], "session": "SESSION: Computational Methods"}, {"title": "Comparison of Ranking and Rating Scales in Online Peer Assessment: Simulation Approach", "pages": "205-209", "doi": "10.1145/3303772.3303820", "abstract": "This study examines fidelity of ranking and rating scales in the context of online peer review and assessment. Using the Monte-Carlo simulation technique, we demonstrated that rating scales outperform ranking scales in revealing the relative \"true\" latent quality of the peer-assessed artifacts via the observed aggregate peer assessment scores. Our analysis focused on a simple, single-round peer assessment process and took into account peer assessment network topology, network size, the number of assessments per artifact, and the correlation statistics used. This methodology allows to separate the effects of structural components of peer assessment from cognitive effects.", "authors": ["Dmytro Babik", "Scott Stevens", "Andrew E. Waters"], "session": "SESSION: Computational Methods"}, {"title": "Contextualizable Learning Analytics Design: A Generic Model and Writing Analytics Evaluations", "pages": "210-219", "doi": "10.1145/3303772.3303785", "abstract": "A major promise of learning analytics is that through the collection of large amounts of data we can derive insights from authentic learning environments, and impact many learners at scale. However, the context in which the learning occurs is important for educational innovations to impact student learning. In particular, for student-facing learning analytics systems like feedback tools to work effectively, they have to be integrated with pedagogical approaches and the learning design. This paper proposes a conceptual model to strike a balance between the concepts of generalizable scalable support and contextualized specific support by clarifying key elements that help to contextualize student-facing learning analytics tools. We demonstrate an implementation of the model using a writing analytics example, where the features, feedback and learning activities around the automated writing feedback tool are tuned for the pedagogical context and the assessment regime in hand, by co-designing them with the subject experts. The model can be employed for learning analytics to move from generalized support to meaningful contextualized support for enhancing learning.", "authors": ["Antonette Shibani", "Simon Knight", "Simon Buckingham Shum"], "session": "SESSION: Text Analytics I"}, {"title": "Topic Development to Support Revision Feedback", "pages": "220-224", "doi": "10.1145/3303772.3303816", "abstract": "Revision is important but challenging for novice writers, particularly in post-secondary education where opportunities for personalized feedback are limited. Inexperienced writers typically overlook revision; when they do revise, they focus on surface errors rather than global revisions that enhance meaning and coherence. Writing analytics can automate personalized prompts to guide revision. We use topic modelling LDA as grounds for an analytic to scaffold holistic revision at paragraph and essay levels. The analytic visualizes topic distribution and generates three types of prompts: Introduction, Paragraph and Conclusion. Feedback encourages revisions focusing on sequencing topics, expanding underdeveloped ideas, and making holistic revisions to improve clarity and coherence of paragraphs. Model feedback was evaluated using undergraduate student essays on various topics scored by human evaluators. Model accuracy was strong for all types of feedback. This opens new branches of research to explore generating personalized feedback at paragraph and essay levels.", "authors": ["Jovita M. Vytasek", "Alexandra Patzak", "Philip H. Winne"], "session": "SESSION: Text Analytics I"}, {"title": "Evaluating the Fairness of Predictive Student Models Through Slicing Analysis", "pages": "225-234", "doi": "10.1145/3303772.3303791", "abstract": "Predictive modeling has been a core area of learning analytics research over the past decade, with such models currently deployed in a variety of educational contexts from MOOCs to K-12. However, analyses of the differential effectiveness of these models across demographic, identity, or other groups has been scarce. In this paper, we present a method for evaluating unfairness in predictive student models. We define this in terms of differential accuracy between subgroups, and measure it using a new metric we term the Absolute Between-ROC Area (ABROCA). We demonstrate the proposed method through a gender-based \"slicing analysis\" using five different models replicated from other works and a dataset of 44 unique MOOCs and over four million learners. Our results demonstrate (1) significant differences in model fairness according to (a) statistical algorithm and (b) feature set used; (2) that the gender imbalance ratio, curricular area, and specific course used for a model all display significant association with the value of the ABROCA statistic; and (3) that there is not evidence of a strict tradeoff between performance and fairness. This work provides a framework for quantifying and understanding how predictive models might inadvertently privilege, or disparately impact, different student subgroups. Furthermore, our results suggest that learning analytics researchers and practitioners can use slicing analysis to improve model fairness without necessarily sacrificing performance.1", "authors": ["Josh Gardner", "Christopher Brooks", "Ryan Baker"], "session": "SESSION: Predictive and Privacy"}, {"title": "Learning analytics at the intersections of student trust, disclosure and benefit", "pages": "235-244", "doi": "10.1145/3303772.3303796", "abstract": "Evidence suggests that individuals are often willing to exchange personal data for (real or perceived) benefits. Such an exchange may be impacted by their trust in a particular context and their (real or perceived) control over their data. Students remain concerned about the scope and detail of surveillance of their learning behavior, their privacy, their control over what data are collected, the purpose of the collection, and the implications of any analysis. Questions arise as to the extent to which students are aware of the benefits and risks inherent in the exchange of their data, and whether they are willing to exchange personal data for more effective and supported learning experiences. This study reports on the views of entry level students at the Open University (OU) in 2018. The primary aim is to explore differences between stated attitudes to privacy and their online behaviors, and whether these same attitudes extend to their university's uses of their (personal) data. The analysis indicates, inter alia, that there is no obvious relationship between how often students are online or their awareness of/concerns about privacy issues in online contexts and what they actually do to protect themselves. Significantly though, the findings indicate that students overwhelmingly have an inherent trust in their university to use their data appropriately and ethically. Based on the findings, we outline a number of issues for consideration by higher education institutions, such as the need for transparency (of purpose and scope), the provision of some element of student control, and an acknowledgment of the exchange value of information in the nexus of the privacy calculus.", "authors": ["Sharon Slade", "Paul Prinsloo", "Mohammad Khalil"], "session": "SESSION: Predictive and Privacy"}, {"title": "Predicting the Well-functioning of Learning Groups under Privacy Restrictions", "pages": "245-249", "doi": "10.1145/3303772.3303826", "abstract": "Establishing small learning groups in online courses is a possible way to foster collaborative knowledge building in an engaging and effective learning community. To enable group activities it is not enough to design collaborative tasks and to provide collaboration tools for online scenarios. Collaboration in such learning groups is prone to fail or even not to be initiated without explicit guidance. In the target situations, interventions and guiding mechanisms have to scale with a growing number of course participants. To achieve this under privacy constraints, we aim at identifying target indicators for well-functioning group work that do not rely on any kind of information about individual learners.", "authors": ["Tobias Hecking", "Dorian Doberstein", "H. Ulrich Hoppe"], "session": "SESSION: Predictive and Privacy"}, {"title": "Exploring students' sensemaking of learning analytics dashboards: Does frame of reference make a difference?", "pages": "250-259", "doi": "10.1145/3303772.3303804", "abstract": "Learning Analytics Dashboards (LAD) are becoming an increasingly popular way to provide students with personalised feedback. Despite the number of LADs being developed, significant research gaps exist around the student perspective, especially how students make sense of graphics provided in LADs, and how they intend to act on the feedback provided therein. This study employed a randomized-controlled trial to examine students' sense-making of LADs showing four different frames of reference, and to what extent the impact of LADs was mediated by baseline self-regulation. Using a mix of quantitative and qualitative data analysis, the results revealed rather distinct patterns in students' sense-making across the four LADs. These patterns involved the intersection of visual salience and planned learning actions. However, collectively, across all four LADs a consistent theme emerged around students planned learning actions. This theme was classified as time and study environment management. A key finding of the study is that the use of LADs as a primary feedback process should be personalized and include training and support to aid student sensemaking.", "authors": ["Lisa Lim", "Shane Dawson", "Srecko Joksimovic", "Dragan Ga\u0161evi\u0107"], "session": "SESSION: Dashboards I"}, {"title": "Top Concept Networks of Professional Education Reflections", "pages": "260-264", "doi": "10.1145/3303772.3303840", "abstract": "This study explores the application of computational techniques to extract information about dental students' developing conceptions of their profession from digital reflective journal entries. Top concept networks were created for two cohorts of students at the beginning and end of their four-year program. A shift from a collection of general notions about becoming a professional to a more integrated, patient-centered conceptualization was found for both cohorts. The two groups initially differed in their perception of dental school (a mechanism for being able to work as a dentist versus a place to learn the skills to serve patients well) and subsequently in the extent of attention they paid to the feelings of their patients and themselves, as well as the continual growth of skill after graduation. Several useful linguistic markers were identified for examining these same issues in other cohorts. The results suggest that top concept networks can offer a useful window into students' developing conceptions of their profession. This kind of information can support student success on a macro level by offering feedback on existing curricula / informing learning designs to cultivate desired conceptions, and on a micro level through identifying particular ways individuals align with and diverge from the common trajectories.", "authors": ["Alyssa Friend Wise", "Yi Cui"], "session": "SESSION: Dashboards I"}, {"title": "Different Types of Response-Based Feedback in Mathematics: The case of textual and symbolic messages", "pages": "265-269", "doi": "10.1145/3303772.3303815", "abstract": "The current study compares textual and symbolic elaborated, response-based feedback in mathematics. We use a randomized experiment in Khan Academy to measure feedback effect in four different topics. Overall, we point out to the superiority of symbolic feedback.", "authors": ["Tomer Gal", "Arnon Hershkovitz"], "session": "SESSION: Feedback and Measurement"}, {"title": "Validating the Use of LMS-Derived Rubric Structural Features to Facilitate Automated Measurement of Rubric Quality", "pages": "270-274", "doi": "10.1145/3303772.3303829", "abstract": "Rubrics are widely used throughout postsecondary education as means for aiding in instruction and evaluation. However, despite their broad global adoption, very little is known about the quality of rubrics in use. We develop two measures to assess the quality of rubrics: (1) a checklist identifying criteria of high-quality rubrics based on analytic rubric design best practices and (2) a set of LMS-derived features that are hypothesized to represent structural components that are, in general, necessary but not sufficient for high quality rubrics. The validity of using the feature-generated scores as proxies for identifying rubric quality is evaluated through several means. First, the feature-generated scores are calculated for a set of external exemplary rubrics of known high quality. Second, the feature-scores for a subset of internal rubrics are compared to average human rater scores of rubric quality based on the checklist. We discuss the results, practical applications, and a larger research program surrounding the feature-generated scores.", "authors": ["Philip Arcuria", "William Morgan", "Thomas G. Fikes"], "session": "SESSION: Feedback and Measurement"}, {"title": "Measuring Knowledge Gaps in Student Responses by Mining Networked Representations of Texts", "pages": "275-279", "doi": "10.1145/3303772.3303822", "abstract": "Gaps between knowledge sources are interesting to various stakeholders: they might indicate potential misconceptions awaiting correction, complex or novel knowledge that requires careful delivery or studying. Motivated by these underlying values, this study explores the knowledge gap phenomenon in the context of student textual responses. In the method proposed in this study, discourses are first mapped into structured knowledge spaces where gaps between correct/incorrect responses and assessed knowledge are measured by network-based metrics. Empirical results demonstrate the effectiveness of the proposed method in measuring gaps in student responses. The networked representation of texts proposed in this study is novel in quantitatively framing gaps of knowledge. It also offers a set of validated metrics for analyzing student responses in research and practice.", "authors": ["Chen Qiao", "Xiao Hu"], "session": "SESSION: Feedback and Measurement"}, {"title": "Motivated Information Seeking and Graph Comprehension Among College Students", "pages": "280-289", "doi": "10.1145/3303772.3303805", "abstract": "Learning Analytics Dashboards (LADs) are predicated on the notion that access to more academic information can help students regulate their academic behaviors, but what is the association between information seeking preferences and help-seeking practices among college students? If given access to more information, what might college students do with it? We investigated these questions in a series of two studies. Study 1 validates a measure of information-seeking preferences---the Motivated Information-Seeking Questionnaire (MISQ)----using a college student sample drawn from across the country (n = 551). In a second study, we used the MISQ to measure college students' (n=210) performance-avoid (i.e., avoiding seeming incompetent in relation to one's peers) and performance-approach (i.e., wishing to outperform one's peers) information seeking preferences, their help-seeking behaviors, and their ability to comprehend line graphs and bar graphs---two common graphs types for LADs. Results point to a negative relationship between graph comprehension and help-seeking strategies, such as attending office hours, emailing one's professor for help, or visiting a study center---even after controlling for academic performance and demographic characteristics. This suggests that students more capable of readings graphs might not seek help when needed. Further results suggest a positive relationship between performance-approach information-seeking preferences, and how often students compare themselves to their peers. This study contributes to our understanding of the motivational implications of academic data visualizations in academic settings, and increases our knowledge of the way students interpret visualizations. It uncovers tensions between what students want to see, versus what it might be more motivationally appropriate for them to see. Importantly, the MISQ and graph comprehension measure can be used in future studies to better understand the role of students' information seeking tendencies with regard to their interpretation of various kinds of feedback present in LADs.", "authors": ["Stephen J. Aguilar", "Clare Baek"], "session": "SESSION: Dashboards II"}, {"title": "Using Detailed Access Trajectories for Learning Behavior Analysis", "pages": "290-299", "doi": "10.1145/3303772.3303781", "abstract": "Student learning activity in MOOCs can be viewed from multiple perspectives. We present a new organization of MOOC learner activity data at a resolution that is in between the fine granularity of the clickstream and coarse organizations that count activities, aggregate students or use long duration time units. A detailed access trajectory (DAT) consists of binary values and is two dimensional with one axis that is a time series, and the other that is a chronologically ordered list of a MOOC component type's instances, videos in instructional order, for example. Most popular MOOC platforms generate data that can be organized as detailed access trajectories (DATs). We explore the value of DATs by conducting four empirical mini-studies. Our studies suggest DATs contain rich information about students' learning behaviors and facilitate MOOC learning analyses.", "authors": ["Yanbang Wang", "Nancy Law", "Erik Hemberg", "Una-May O'Reilly"], "session": "SESSION: Logging Activity"}, {"title": "The validity and utility of activity logs as a measure of student engagement", "pages": "300-309", "doi": "10.1145/3303772.3303789", "abstract": "Learning management system (LMS) web logs provide granular, near-real-time records of student behavior as learners interact with online course materials in digital learning environments. However, it remains unclear whether LMS activity indeed reflects behavioral properties of student engagement, and it also remains unclear how to deal with variability in LMS usage across a diversity of courses. In this study, we evaluate whether instructors' subjective ratings of their students' engagement are related to features of LMS activity for 9,021 students enrolled in 473 for-credit courses. We find that estimators derived from LMS web logs are closely related to instructor ratings of engagement, however, we also observe that there is not a single generic relationship between activity and engagement, and what constitutes the behavioral components of \"engagement\" will be contingent on course structure. However, for many of these courses, modeled engagement scores are comparable to instructors' ratings in their sensitivity for predicting academic performance. As long as they are tuned to the differences between courses, activity indices from LMS web logs can provide a valid and useful proxy measure of student engagement.", "authors": ["Benjamin Motz", "Joshua Quick", "Noah Schroeder", "Jordon Zook", "Matthew Gunkel"], "session": "SESSION: Logging Activity"}, {"title": "Towards Enabling Feedback on Rhetorical Structure with Neural Sequence Models", "pages": "310-319", "doi": "10.1145/3303772.3303808", "abstract": "Analysis of student writing, both for assessment and for enabling feedback have been of interest to the field of learning analytics. While much progress can be made through detection of local cues in writing, structured prediction approaches offer capabilities that are particularly well tailored to the needs of models aiming to offer substantive feedback on rhetorical structure. We thus cast the analysis of rhetorical structure in academic writing as a structured prediction task in which we employ models that leverage both local and global cues in writing. In particular, this paper presents a hierarchical neural architecture that performs this task. The evaluation demonstrates that the architecture achieves near-human performance while significantly surpassing state-of-the-art baselines. A multifaceted approach to model interpretation offers insights into the inner workings of the model.", "authors": ["James Fiacco", "Elena Cotos", "Carolyn Ros\u00e9"], "session": "SESSION: Text Analytics II"}, {"title": "Language as Thought: Using Natural Language Processing to Model Noncognitive Traits that Predict College Success", "pages": "320-329", "doi": "10.1145/3303772.3303801", "abstract": "It is widely acknowledged that the language we use reflects numerous psychological constructs, including our thoughts, feelings, and desires. Can the so called \"noncognitive\" traits with known links to success, such as growth mindset, leadership ability, and intrinsic motivation, be similarly revealed through language? We investigated this question by analyzing students' 150-word open-ended descriptions of their own extracurricular activities or work experiences included in their college applications. We used the Common Application-National Student Clearinghouse data set, a six-year longitudinal dataset that includes college application data and graduation outcomes for 278,201 U.S. high-school students. We first developed a coding scheme from a stratified sample of 4,000 essays and used it to code seven traits: growth mindset, perseverance, goal orientation, leadership, psychological connection (intrinsic motivation), self-transcendent (prosocial) purpose, and team orientation, along with earned accolades. Then, we used standard classifiers with bag-of-n-grams as features and deep learning techniques (recurrent neural networks) with word embeddings to automate the coding. The models demonstrated convergent validity with the human coding with AUCs ranging from .770 to .925 and correlations ranging from .418 to .734. There was also evidence of discriminant validity in the pattern of inter-correlations (rs between -.206 to .306) for both human- and model-coded traits. Finally, the models demonstrated incremental predictive validity in predicting six-year graduation outcomes net of sociodemographics, intelligence, academic achievement, and institutional graduation rates. We conclude that language provides a lens into noncognitive traits important for college success, which can be captured with automated methods.", "authors": ["Cathlyn Stone", "Abigail Quirk", "Margo Gardener", "Stephen Hutt", "Angela L. Duckworth", "Sidney K. D'Mello"], "session": "SESSION: Text Analytics II"}, {"title": "Square it up!: How to model step duration when predicting student performance", "pages": "330-334", "doi": "10.1145/3303772.3303827", "abstract": "In this paper, we explore how we can model students' response times to predict student performance in Intelligent Tutoring Systems. Related research suggests that response time can provide information with respect to correctness. However, time is not consistently used when modeling students' performance. Here, we build on previous work that indicated that the relationship between response time and student performance is non-linear. Based on this concept, we compare three models: a standard Additive Factors Analysis Model (AFM), an AFM model enhanced with a linear step duration parameter and an AFM model enhanced with a quadratic, step duration parameter. The results of this comparison show that the AFM model that is enhanced with the quadratic step duration parameter outperforms the other models over four different datasets and for most of the metrics we used to evaluate the models in cross validation and prediction.", "authors": ["Irene-Angelica Chounta", "Paulo F. Carvalho"], "session": "SESSION: Intelligent Tutoring Systems I"}, {"title": "Fairer but Not Fair Enough On the Equitability of Knowledge Tracing", "pages": "335-339", "doi": "10.1145/3303772.3303838", "abstract": "Adaptive educational technologies have the capacity to meet the needs of individual students in theory, but in some cases, the degree of personalization might be less than desired, which could lead to inequitable outcomes for students. In this paper, we use simulations to demonstrate that while knowledge tracing algorithms are substantially more equitable than giving all students the same amount of practice, such algorithms can still be inequitable when they rely on inaccurate models. This can arise as a result of two factors: (1) using student models that are fit to aggregate populations of students, and (2) using student models that make incorrect assumptions about student learning. In particular, we demonstrate that both the Bayesian knowledge tracing algorithm and the N-Consecutive Correct Responses heuristic are susceptible to these concerns, but that knowledge tracing with the additive factor model may be more equitable. The broader message of this paper is that when designing learning analytics algorithms, we need to explicitly consider whether the algorithms act fairly with respect to different populations of students, and if not, how we can make our algorithms more equitable.", "authors": ["Shayan Doroudi", "Emma Brunskill"], "session": "SESSION: Intelligent Tutoring Systems I"}, {"title": "Deep Knowledge Tracing and Engagement with MOOCs", "pages": "340-342", "doi": "10.1145/3303772.3303830", "abstract": "MOOCs and online courses have notoriously high attrition [1]. One challenge is that it can be difficult to tell if students fail to complete because of disinterest or because of course difficulty. Utilizing a Deep Knowledge Tracing framework, we account for student engagement by including course interaction covariates. With these, we find that we can predict a student's next item response with over 88% accuracy. Using these predictions, targeted interventions can be offered to students and targeted improvements can be made to courses. In particular, this approach would allow for gating of content until a student has reasonable likelihood of succeeding.", "authors": ["Kritphong Mongkhonvanit", "Klint Kanopka", "David Lang"], "session": "SESSION: Intelligent Tutoring Systems I"}, {"title": "Towards Value-Sensitive Learning Analytics Design", "pages": "343-352", "doi": "10.1145/3303772.3303798", "abstract": "To support ethical considerations and system integrity in learning analytics, this paper introduces two cases of applying the Value Sensitive Design methodology to learning analytics design. The first study applied two methods of Value Sensitive Design, namely stakeholder analysis and value analysis, to a conceptual investigation of an existing learning analytics tool. This investigation uncovered a number of values and value tensions, leading to design trade-offs to be considered in future tool refinements. The second study holistically applied Value Sensitive Design to the design of a recommendation system for the Wikipedia WikiProjects. To proactively consider values among stakeholders, we derived a multi-stage design process that included literature analysis, empirical investigations, prototype development, community engagement, iterative testing and refinement, and continuous evaluation. By reporting on these two cases, this paper responds to a need of practical means to support ethical considerations and human values in learning analytics systems. These two cases demonstrate that Value Sensitive Design could be a viable approach for balancing a wide range of human values, which tend to encompass and surpass ethical issues, in learning analytics design.", "authors": ["Bodong Chen", "Haiyi Zhu"], "session": "SESSION: Design"}, {"title": "Student Centred Design of a Learning Analytics System", "pages": "353-362", "doi": "10.1145/3303772.3303793", "abstract": "Current Learning Analytics (LA) systems are primarily designed with University staff members as the target audience; very few are aimed at students, with almost none being developed with direct student involvement and undertaking a comprehensive evaluation. This paper describes a HEFCE funded project that has employed a variety of methods to engage students in the design, development and evaluation of a student facing LA dashboard. LA was integrated into the delivery of 4 undergraduate modules with 169 student sign-ups. The design of the dashboard uses a novel approach of trying to understand the reasons why students want to study at university and maps their engagement and predicted outcomes to these motivations, with weekly personalised notifications and feedback. Students are also given the choice of how to visualise the data either via a chart-based view or to be represented as themselves. A mixed-methods evaluation has shown that students' feelings of dependability and trust of the underlying analytics and data is variable. However, students were mostly positive about the usability and interface design of the system and almost all students once signed-up did interact with their LA. The majority of students could see how the LA system could support their learning and said that it would influence their behaviour. In some cases, this has had a direct impact on their levels of engagement. The main contribution of this paper is the transparent documentation of a User Centred Design approach that has produced forms of LA representation, recommendation and interaction design that go beyond those used in current similar systems and have been shown to motivate students and impact their learning behaviour.", "authors": ["Ed de Quincey", "Chris Briggs", "Theocharis Kyriacou", "Richard Waller"], "session": "SESSION: Design"}, {"title": "The Impact of an Online Tutoring Program for Algebra Readiness on Mathematics Achievements; Results of a Randomized Experiment", "pages": "363-372", "doi": "10.1145/3303772.3303777", "abstract": "We study the impact of an online tutoring program, AnimalWatch, for algebra readiness on mathematics achievements of grade 6 students. We use the data from a randomized experimental design conducted on 69 teachers and 2025 students in California in the academic years 2011-2012. After a brief description of the experimental design and the system implementation, we analyze the treatment effect of employing AnimalWatch using the popular hierarchical linear models and find a small positive effect. We further use the logged system usage data such as time spent in the system, modules completed, correct/incorrect/no-answers records of students in each login to analyze how system implementation and usage helped different students. Our results provide insights into the limitations in implementing such a study in a real world setting and suggests recommendations for future research.", "authors": ["Sahba Akhavan Niaki", "Clint P. George", "George Michailidis", "Carole R. Beal"], "session": "SESSION: Sequences"}, {"title": "UPM: Discovering Course Enrollment Sequences Associated with Success", "pages": "373-382", "doi": "10.1145/3303772.3303799", "abstract": "Identifying enrollment patterns associated with course success can help educators design better degree plans, and students make informed decisions about future enrollments. While discriminating pattern mining techniques can be used to address this problem, course enrollment patterns include sequence and quantity (grades) information. None of the existing methods were designed to account for both factors. In this work we present UPM, a Universal discriminating Pattern Mining framework that simultaneously mines various types of enrollment patterns while accounting for sequence and quantity using an expansion-specific approach. Unlike the existing methods, UPM expands a given pattern with an item by finding a minimum-entropy split over the item's quantities. We then use UPM to extract discriminating enrollment patterns from the high and the low performing student groups. These patterns can be utilized by educators for degree planning. To evaluate the quality of the extracted patterns, we adopt a supervised classification approach where we apply various classification techniques to label students according tho their performance based on the extracted patterns. Our evaluation shows that the classification accuracies obtained using the UPM extracted patterns are higher than the accuracies obtained using patterns extracted by other techniques. Accuracy improves significantly for students with larger numbers of patterns. Moreover, expansion-specific quantitative mining leads to more accurate classifications than the methods that do not account for quantities (grades).", "authors": ["Asmaa Elbadrawy", "George Karypis"], "session": "SESSION: Sequences"}, {"title": "Affect Sequences and Learning in Betty's Brain", "pages": "383-390", "doi": "10.1145/3303772.3303807", "abstract": "Education research has explored the role of students' affective states in learning, but some evidence suggests that existing models may not fully capture the meaning or frequency of how students transition between different states. In this study we examine the patterns of educationally-relevant affective states within the context of Betty's Brain, an open-ended, computer-based learning system used to teach complex scientific processes. We examine three types of affective transitions based on similarity with the theorized D'Mello and Graesser model, transition between two affective states, and the sustained instances of certain states. We correlate of the frequency of these patterns with learning outcomes and our findings suggest that boredom is a powerful indicator of students' knowledge, but not necessarily indicative of learning. We discuss our findings within the context of both research and theory on affect dynamics and the implications for pedagogical and system design.", "authors": ["Juliana Ma. Alexandra L. Andres", "Jaclyn Ocumpaugh", "Ryan S. Baker", "Stefan Slater", "Luc Paquette", "Yang Jiang", "Shamya Karumbaiah", "Nigel Bosch", "Anabil Munshi", "Allison Moore", "Gautam Biswas"], "session": "SESSION: Sequences"}, {"title": "Refusing to Try: Characterizing Early Stopout on Student Assignments", "pages": "391-400", "doi": "10.1145/3303772.3303806", "abstract": "A prominent issue faced by the education research community is that of student attrition. While large research efforts have been devoted to studying course-level attrition, widely referred to as dropout, less research has been focused on finer-grained assignment-level attrition commonly observed in K-12 classrooms. This later instantiation of attrition, referred to in this paper as \"stopout,\" is characterized by students failing to complete their assigned work, but the cause of such behavior are not often known. This becomes a large problem for educators and developers of learning platforms as students who give up on assignments early are missing opportunities to learn and practice the material which may affect future performance on related topics; similarly, it is difficult for researchers to develop, and subsequently difficult for computer-based systems to deploy interventions aimed at promoting productive persistence once a student has ceased interaction with the software. This difficulty highlights the importance to understand and identify early signs of stopout behavior in order to provide aid to students preemptively to promote productive persistence in their learning. While many cases of student stopout may be attributable to gaps in student knowledge and indicative of struggle, student attributes such as grit and persistence may be further affected by other factors. This work focuses on identifying different forms of stopout behavior in the context of middle school math by observing student behaviors at the sub-problem level. We find that students exhibit disproportionate stopout on the first problem of their assignments in comparison to stopout on subsequent problems, identifying a behavior that we call \"refusal,\" and use the emerging patterns of student activity to better understand the potential causes underlying stopout behavior early in an assignment.", "authors": ["Anthony F. Botelho", "Ashvini Varatharaj", "Eric G. Van Inwegen", "Neil T. Heffernan"], "session": "SESSION: Machine Learning III"}, {"title": "An Analysis of Student Representation, Representative Features and Classification Algorithms to Predict Degree Dropout", "pages": "401-410", "doi": "10.1145/3303772.3303800", "abstract": "Identifying and monitoring students who are likely to dropout is a vital issue for universities. Early detection allows institutions to intervene, addressing problems and retaining students. Prior research into the early detection of at-risk students has opted for the use of predictive models, but a comprehensive assessment of the suitability of different algorithms and approaches is complicated by the large number of variable features that constitute a student's educational experience. Predictive models vary in terms of their amplitude, temporality and the learning algorithms employed. While amplitude refers to the ability of the model to operate on multiple degrees, temporality is often considered due to the natural temporal aspect of the data. In the absence of a comparative framework of learning algorithms, the aim of this paper has been to provide such an analysis, based on a proposed classification of strategies for predicting dropouts in Higher Education Institutions. Three different student representations are implemented (namely Global Feature-Based, Local Feature-Based, and Time Series) in conjunction with the appropriate learning algorithms for each of them. A description of each approach, as well as its implementation process, are presented in this paper as technical contributions. An experiment based on a dataset of student information from two degrees, namely Business Administration and Architecture, acquired through an automated management system from a university in Brazil is used. Our findings can be summarized as: (i) of the three proposed student representations, the Local Feature-Based was the most suitable approach for predicting dropout. In addition to providing high quality results, the Local Feature-Based representations are simple to build, and the construction of the model is less expensive when compared to more complex ones; (ii) as a conclusion of the results obtained via Local Feature-Based, dropout can be said to be accurately predicted using grades of a few core courses, so there is no need for a complex features extraction process; (iii) considering temporal aspects of the data does not seem to contribute to the prediction performance although it increases computational costs as the model complexity increases.", "authors": ["Rub\u00e9n Manrique", "Bernardo Pereira Nunes", "Olga Marino", "Marco Antonio Casanova", "Terhi Nurmikko-Fuller"], "session": "SESSION: Machine Learning III"}, {"title": "The Impact of Student Opt-Out on Educational Predictive Models", "pages": "411-420", "doi": "10.1145/3303772.3303809", "abstract": "Privacy concerns may lead people to opt-in or opt-out of having their educational data collected. These decisions may impact the performance of educational predictive models. To understand this, we conducted a survey to determine the propensity of students to withhold or grant access to their data for the purposes of training predictive models. We simulated the effects of opt-out on the accuracy of educational predictive models by dropping a random sample of data over a range of increments, and then contextualize our findings using the survey results. We find that grade predictive models are fairly robust and that kappa scores do not decrease unless there is signiicant opt-out, but when there is, the deteriorating performance disproportionately affects certain subpopulations.", "authors": ["Warren Li", "Christopher Brooks", "Florian Schaub"], "session": "SESSION: Machine Learning III"}, {"title": "Where You Are, Not What You See: The Impact of Learning Environment on Mind Wandering and Material Retention", "pages": "421-425", "doi": "10.1145/3303772.3303824", "abstract": "Online lectures are an increasingly popular tool for learning, yet research on instructor visibility during an online lecture, and students' environmental settings, has not been well-explored. The current study addresses this gap in the literature by experimentally manipulating online display format and social learning settings to understand their influence on student learning and mind-wandering experiences. Results suggest that instructor visibility within an online lecture does not impact students' MW or retention performance. However, we found some evidence that students' social setting during viewing has an impact on MW (p = .05). Specifically, students who watched the lecture in a classroom with others reported significantly more MW than students who watched the lecture alone. Finally, social setting also moderated the negative relationship between MW and material retention. Our results demonstrate that learning experiences during online lectures can vary based on where, and with whom, the lectures are watched.", "authors": ["Trish L. Varao-Sousa", "Caitlin Mills", "Alan Kingstone"], "session": "SESSION: Classroom & Collaboration"}, {"title": "DEBE feedback for large lecture classroom analytics", "pages": "426-430", "doi": "10.1145/3303772.3303821", "abstract": "Learning Analytics (LA) research has demonstrated the potential of LA in detecting and monitoring cognitive-affective parameters and improving student success. But most of it has been applied to online and computerized learning environments whereas physical classrooms have largely remained outside the scope of such research. This paper attempts to bridge that gap by proposing a student feedback model in which they report on the difficult/easy and engaging/boring aspects of their lecture. We outline the pedagogical affordances of an aggregated time-series of such data and discuss it within the context of LA research.", "authors": ["Ritayan Mitra", "Pankaj Chavan"], "session": "SESSION: Classroom & Collaboration"}, {"title": "Modeling gender dynamics in intra and interpersonal interactions during online collaborative learning", "pages": "431-435", "doi": "10.1145/3303772.3303837", "abstract": "There has been long-standing stereotypes on men and women's communication styles, such as men using more assertive or aggressive language and women showing more agreeableness and emotions in interactions. In the context of collaborative learning, male learners often believed to be more active participants while female learners are less engaged. To further explore gender differences in learners communication behavior and whether it has changed in the context of online synchronous collaboration, we examined students interactions at a sociocognitive level with a methodology called Group Communication Analysis (GCA). We found that there were no significant differences between men and women in the degree of participation. However, women exhibited significantly higher average social impact, responsivity and internal cohesion compared to men. We also compared the proportion of learners interaction profiles, and results suggest that women are more likely to be effective and cohesive communicators. We discussed implications of these findings for pedagogical practices to promote inclusivity and equity in collaborative learning online.", "authors": ["Yiwen Lin", "Nia Dowell", "Andrew Godfrey", "Heeryung Choi", "Christopher Brooks"], "session": "SESSION: Classroom & Collaboration"}, {"title": "Predicting Student Success in Communication Skills Learning Scenarios with Virtual Humans", "pages": "436-440", "doi": "10.1145/3303772.3303828", "abstract": "Virtual humans are frequently used to help medical students practice communication skills. Here, we show that communication skills features drawn from the literature on best practices for doctor-patient communication can be used to predict student interviewers' success in a given domain skill. We also demonstrate the viability of Bayesian Rule Lists, an interpretable machine learning model, for this use case. Bayesian Rule Lists' predictive performance is comparable to that of other other commonly used algorithms, including decision trees. This suggests that Bayesian Rule Lists, which produce simple, human-readable trained binary classifiers, may be suitable for providing feedback for educational purposes.", "authors": ["Stephanie Carnell", "Benjamin Lok", "Melva T. James", "Jonathan K. Su"], "session": "SESSION: Classroom & Collaboration"}, {"title": "Challenges on implementing Learning Analytics over countrywide K-12 data", "pages": "441-445", "doi": "10.1145/3303772.3303819", "abstract": "The present work describes the challenges faced during the development of a countrywide Learning Analytics tool focused on tracking the trajectories of Uruguayan students during their first three years of secondary education. Due to the large-scale of the project, which covers an entire national educational system, several challenges and constraints (both technical and legal) were faced during its conception and development. This paper presents the design decisions and solutions found to address or mitigate the problems found, with the current state of the project. Early results point out the feasibility of finding meaningful patterns in the available data (using data mining techniques) which can be embedded into a prototype for tracking the students scholar trajectory.", "authors": ["Luiz Antonio Macarini", "Cristian Cechinel", "Henrique Lemos dos Santos", "Xavier Ochoa", "Virg\u00ednia Rod\u00e9s", "Guillermo Ettlin Alonso", "Al\u00e9n P\u00e9rez Casas", "Patricia D\u00edaz"], "session": "SESSION: Implementation"}, {"title": "Increasing the Impact of Learning Analytics", "pages": "446-455", "doi": "10.1145/3303772.3303784", "abstract": "Learning Analytics (LA) studies the learning process in order to optimize learning opportunities for students. Although LA has quickly risen to prominence, there remain questions regarding the impact LA has made to date. To evaluate the extent that LA has impacted our understanding of learning and produced insights that have been translated to mainstream practice or contributed to theory, we reviewed the research published in 2011-2018 LAK conferences and Journal of Learning Analytics. The reviewed studies were coded according to five dimensions: study focus, data types, purpose, institutional setting, and scale of research and implementation. The coding and subsequent epistemic network analysis indicates that while LA research has developed in the areas of focus and sophistication of analyses, the impact on practice, theory and frameworks have been limited. We hypothesize that this finding is due to a continuing predominance of small-scale techno-centric exploratory studies that to date have not fully accounted for the multi-disciplinarity that comprises education. For the field to reach its potential in understanding and optimizing learning and learning environments, there must be a purposeful shift to move from exploratory models to more holistic and integrative systems-level research. This necessitates greater effort applied to understanding the research cycles that emerge when multiple knowledge domains coalesce into new fields of research.", "authors": ["Shane Dawson", "Srecko Joksimovic", "Oleksandra Poquet", "George Siemens"], "session": "SESSION: Implementation"}, {"title": "Utilizing Learning Analytics to Map Students' Self-Reported Study Strategies to Click Behaviors in STEM Courses", "pages": "456-460", "doi": "10.1145/3303772.3303841", "abstract": "Informed by cognitive theories of learning, this work examined how students' self-reported study patterns (spacing vs. cramming) corresponded to their engagement with the Learning Management System (LMS) across two years in a large biology course. We specifically focused on how students accessed non-mandatory resources (lecture videos, lecture slides) and considered whether this pattern differed by underrepresented minority (URM) status. Overall, students who self-reported utilizing spacing strategies throughout the course had higher grades than students who reported cramming throughout the course. When examining LMS engagement, only a small percentage of students accessed the lecture videos and lecture slides. Applying a negative binomial regression model to daily counts of click activities, we also found that students who utilized spacing strategies accessed LMS resources more often but not earlier before major deadlines. Moreover, this finding was not different for underrepresented students. Our results provide some initial evidence showing how spacing behaviors correspond to accessing learning resources. However, given the lack of general engagement with LMS resources, our results underscore the value of encouraging students to utilize these resources when studying course material.", "authors": ["Fernando Rodriguez", "Renzhe Yu", "Jihyun Park", "Mariela Janet Rivas", "Mark Warschauer", "Brian K. Sato"], "session": "SESSION: Self-Regulated Learning"}, {"title": "Analytics of Learning Strategies: Associations with Academic Performance and Feedback", "pages": "461-470", "doi": "10.1145/3303772.3303787", "abstract": "Learning analytics has the potential to detect and explain characteristics of learning strategies through analysis of trace data and communicate the findings via feedback. However, the role of learning analytics-based feedback in selection and regulation of learning strategies is still insufficiently explored and understood. This research aims to examine the sequential and temporal characteristics of learning strategies and investigate their association with feedback. Three years of trace data were collected from online pre-class activities of a flipped classroom, where different types of feedback were employed in each year. Clustering, sequence mining, and process mining were used to detect and interpret learning tactics and strategies. Inferential statistics were used to examine the association of feedback with the learning performance and the detected learning strategies. The results suggest a positive association between the personalised feedback and the effective strategies.", "authors": ["Wannisa Matcha", "Dragan Ga\u0161evi\u0107", "Nora'Ayu Ahmad Uzir", "Jelena Jovanovi\u0107", "Abelardo Pardo"], "session": "SESSION: Self-Regulated Learning"}, {"title": "Towards Hybrid Human-System Regulation: Understanding Children' SRL Support Needs in Blended Classrooms", "pages": "471-480", "doi": "10.1145/3303772.3303780", "abstract": "This paper proposes a new approach to translate learner data into self-regulated learning support. Learning phases in blended classrooms place unique requirements on students' self-regulated learning (SRL). Learning path graphs merge moment-by-moment learning curves and learning phase data to understand student' SRL support needs. Results indicate 4 groups with different SRL support needs. Students in the self-regulated learning group are capable of learning without external regulation. In the teacher regulation group students need initial teacher regulation but rely on SRL thereafter. Students in the system regulation group require teacher and system regulation to learn. Finally, the advanced system support group is in need of support beyond the current level of system regulation. Based on these insights, the application of personalized dashboards and hybrid human-system regulation is further specified.", "authors": ["Inge Molenaar", "Anne Horvers", "Ryan S. Baker"], "session": "SESSION: Self-Regulated Learning"}, {"title": "Investigating the Usage Patterns of Algebra Nation Tutoring Platform", "pages": "481-490", "doi": "10.1145/3303772.3303788", "abstract": "We study the usage of a self-guided online tutoring platform called Algebra Nation, which is widely by middle school and high school students who take the End-of-Course Algebra I exam at the end of the school year. This article aims to study how the platform contributes to increasing students' exam scores by examining users' logs over a three year period. The platform under consideration was used by more than 36,000 students in the first year, to nearly 67,000 by the third year, thus enabling us to examine how usage patterns evolved and influenced students' performance at scale. We first identify which Algebra Nation usage factors in conjunction with math overall preparation and socioeconomic factors contribute to the students' exam performance. Subsequently, we investigate the effect of increased teacher familiarity level with the Algebra Nation on students' scores across different grades through mediation analysis. The results show that the indirect effect of teacher's familiarity with the platform through increasing student's usage dosage is more significant in higher grades.", "authors": ["Sahba Akhavan Niaki", "Clint P. George", "George Michailidis", "Carole R. Beal"], "session": "SESSION: Intelligent Tutoring Systems II"}, {"title": "Knowledge Query Network for Knowledge Tracing: How Knowledge Interacts with Skills", "pages": "491-500", "doi": "10.1145/3303772.3303786", "abstract": "Knowledge Tracing (KT) is to trace the knowledge of students as they solve a sequence of problems represented by their related skills. This involves abstract concepts of students' states of knowledge and the interactions between those states and skills. Therefore, a KT model is designed to predict whether students will give correct answers and to describe such abstract concepts. However, existing methods either give relatively low prediction accuracy or fail to explain those concepts intuitively. In this paper, we propose a new model called Knowledge Query Network (KQN) to solve these problems. KQN uses neural networks to encode student learning activities into knowledge state and skill vectors, and models the interactions between the two types of vectors with the dot product. Through this, we introduce a novel concept called probabilistic skill similarity that relates the pairwise cosine and Euclidean distances between skill vectors to the odds ratios of the corresponding skills, which makes KQN interpretable and intuitive. On four public datasets, we have carried out experiments to show the following: 1. KQN outperforms all the existing KT models based on prediction accuracy. 2. The interaction between the knowledge state and skills can be visualized for interpretation. 3. Based on probabilistic skill similarity, a skill domain can be analyzed with clustering using the distances between the skill vectors of KQN. 4. For different values of the vector space dimensionality, KQN consistently exhibits high prediction accuracy and a strong positive correlation between the distance matrices of the skill vectors.", "authors": ["Jinseok Lee", "Dit-Yan Yeung"], "session": "SESSION: Intelligent Tutoring Systems II"}, {"title": "Counting Clicks is Not Enough: Validating a Theorized Model of Engagement in Learning Analytics", "pages": "501-510", "doi": "10.1145/3303772.3303775", "abstract": "Student engagement is often considered an overarching construct in educational research and practice. Though frequently employed in the learning analytics literature, engagement has been subjected to a variety of interpretations and there is little consensus regarding the very definition of the construct. This raises grave concerns with regards to construct validity: namely, do these varied metrics measure the same thing? To address such concerns, this paper proposes, quantifies, and validates a model of engagement which is both grounded in the theoretical literature and described by common metrics drawn from the field of learning analytics. To identify a latent variable structure in our data we used exploratory factor analysis and validated the derived model on a separate sub-sample of our data using confirmatory factor analysis. To analyze the associations between our latent variables and student outcomes, a structural equation model was fitted, and the validity of this model across different course settings was assessed using MIMIC modeling. Across different domains, the broad consistency of our model with the theoretical literature suggest a mechanism that may be used to inform both interventions and course design.", "authors": ["Ed Fincham", "Alexander Whitelock-Wainwright", "Vitomir Kovanovi\u0107", "Sre\u0107ko Joksimovi\u0107", "Jan-Paul van Staalduinen", "Dragan Ga\u0161evi\u0107"], "session": "SESSION: Educational Theory"}, {"title": "Introducing meaning to clicks: Towards traced-measures of self-efficacy and cognitive load", "pages": "511-520", "doi": "10.1145/3303772.3303782", "abstract": "The use of learning trace data together with various analytical methods has proven successful in detecting patterns in learning behaviour, identifying student profiles, and clustering learning resources. However, interpretation of the findings is often difficult and uncertain due to a lack of contextual data (e.g., data on student motivation, emotion or curriculum design). In this study we explored the integration of student self-reports about cognitive load and self-efficacy into the learning process and collection of relevant students' perceptions as learning traces. Our objective was to examine the association of traced measures of relevant learning constructs (cognitive load and self-efficacy) with i) indicators of the students' learning behaviour derived from trace data, and ii) the students' academic performance. The results indicated the presence of association between some indicators of students' engagement with learning activities and traced measures of cognitive load and self-efficacy. Correlational analysis demonstrated significant positive correlation between the students' course performance and traced measures of cognitive load and self-efficacy.", "authors": ["Jelena Jovanovi\u0107", "Dragan Ga\u0161evi\u0107", "Abelardo Pardo", "Shane Dawson", "Alexander Whitelock-Wainwright"], "session": "SESSION: Educational Theory"}, {"title": "Integrated Closed-loop Learning Analytics Scheme in a First Year Experience Course", "pages": "521-530", "doi": "10.1145/3303772.3303803", "abstract": "Identifying non-thriving students and intervening to boost them are two processes that recent literature suggests should be more tightly integrated. We perform this integration over six semesters in a First Year Experience (FYE) course with the aim of boosting student success, by using an integrated closed-loop learning analytics scheme that consists of multiple steps broken into three main phases, as follows: Architecting for Collection (steps: design, build, capture), Analyzing for Action (steps: identify, notify, boost), and Assessing for Improvement (steps: evaluate, report). We close the loop by allowing later steps to inform earlier ones in real-time during a semester and iteratively year to year, thereby improving the course from data-driven insights. This process depends on the purposeful design of an integrated learning environment that facilitates data collection, storage, and analysis. Methods for evaluating the effectiveness of our analytics-based student interventions show that our criterion for identifying non-thriving students was satisfactory and that non-thriving students demonstrated more substantial changes from mid-term to final course grades than already-thriving students. Lastly, we make a case for using early performance in the FYE as an indicator of overall performance and retention of first-year students.", "authors": ["Munira Syed", "Trunojoyo Anggara", "Alison Lanski", "Xiaojing Duan", "G. Alex Ambrose", "Nitesh V. Chawla"], "session": "SESSION: Campus Experience"}, {"title": "Descriptive and Predictive Modeling of Student Achievement, Satisfaction, and Mental Health for Data-Driven Smart Connected Campus Life Service", "pages": "531-538", "doi": "10.1145/3303772.3303792", "abstract": "Yonsei University in Korea launched an educational innovation project entitled \"Data-Driven Smart-Connected Campus Life Service\", for which student-related data have been accumulated at university level since spring of 2015, and descriptive, predictive and prescriptive modeling have been conducted to offer innovative education service to students. The dataset covers not only conventional student information, student questionnaire survey, and university administrative data, but also unconventional data sets such as student location data and learning management system (LMS) log data. Based on the datasets, with respect to 4,000+ freshman students at residential college, we conducted preliminary implementation of descriptive and predictive modeling for student achievement, satisfaction, and mental health. The results were overall promising. First, descriptive and predictive modeling of GPA for student achievement presented a list of significant predictive variables from student locations and LMS activities. Second, descriptive modeling of student satisfaction revealed influential variables such as \"improvement of creativity\" and \"ability of cooperation\". Third, similar descriptive modeling was applied to students' mental health changes by semesters, and the study uncovered influential factors such as \"difficulty with relationship\" and \"time spent with friends increased' as key determinants of student mental health. Although the educational innovation project is still in its early stages, we have three strategies of the future modelling efforts: They are: (1) step-by-step improvement from descriptive, predictive, to prescriptive modelling; (2) full use of recurring data acquisition; (3) different level of segmentation.", "authors": ["Joon Heo", "Hyoungjoon Lim", "Sung Bum Yun", "Sungha Ju", "Sangyoon Park", "Rebekah Lee"], "session": "SESSION: Campus Experience"}, {"title": "Beyond A/B Testing: Sequential Randomization for Developing Interventions in Scaled Digital Learning Environments", "pages": "539-548", "doi": "10.1145/3303772.3303812", "abstract": "Randomized experiments ensure robust causal inference that is critical to effective learning analytics research and practice. However, traditional randomized experiments, like A/B tests, are limiting in large scale digital learning environments. While traditional experiments can accurately compare two treatment options, they are less able to inform how to adapt interventions to continually meet learners' diverse needs. In this work, we introduce a trial design for developing adaptive interventions in scaled digital learning environments -- the sequential randomized trial (SRT). With the goal of improving learner experience and developing interventions that benefit all learners at all times, SRTs inform how to sequence, time, and personalize interventions. In this paper, we provide an overview of SRTs, and we illustrate the advantages they hold compared to traditional experiments. We describe a novel SRT run in a large scale data science MOOC. The trial results contextualize how learner engagement can be addressed through culturally-targeted reminder emails. We also provide practical advice for researchers who aim to run their own SRTs to develop adaptive interventions in scaled digital learning environments.", "authors": ["Timothy NeCamp", "Josh Gardner", "Christopher Brooks"], "session": "SESSION: Design and Development"}]