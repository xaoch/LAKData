[{"title": "Developing a MOOC experimentation platform: insights from a user study", "pages": "1-5", "doi": "10.1145/3027385.3027398", "abstract": "In 2011, the phenomenon of MOOCs had swept the world of education and put online education in the focus of the public discourse around the world. Although researchers were excited with the vast amounts of MOOC data being collected, the benefits of this data did not stand to the expectations due to several challenges. The analyses of MOOC data are very time-consuming and labor-intensive, and require and require a highly advanced set of technical skills, often not available to the education researchers. Because of this MOOC data analyses are rarely done before the courses end, limiting the potential of data to impact the student learning outcomes and experience. In this paper we introduce MOOCito (MOOC intervention tool), a user-friendly software platform for the analysis of MOOC data, that focuses on conducting data-informed instructional interventions and course experimentations. We cover important design principles behind MOOCito and provide an overview of the trends in MOOC research leading to its development. Although a work-in-progress, in this paper, we outline the prototype of MOOCito and the results of a user evaluation study that focused on system's perceived usability and ease-of-use. The results of the study are discussed, as well as their practical implications.", "authors": ["Vitomir Kovanovi\u0107", "Sre\u0107ko Joksimovi\u0107", "Philip Katerinopoulos", "Charalampos Michail", "George Siemens", "Dragan Ga\u0161evi\u0107"], "session": "SESSION: LA infrastructure"}, {"title": "Ouroboros: early identification of at-risk students without models based on legacy data", "pages": "6-15", "doi": "10.1145/3027385.3027449", "abstract": "This paper focuses on the problem of identifying students, who are at risk of failing their course. The presented method proposes a solution in the absence of data from previous courses, which are usually used for training machine learning models. This situation typically occurs in new courses. We present the concept of a \"self-learner\" that builds the machine learning models from the data generated during the current course. The approach utilises information about already submitted assessments, which introduces the problem of imbalanced data for training and testing the classification models. There are three main contributions of this paper: (1) the concept of training the models for identifying at-risk students using data from the current course, (2) specifying the problem as a classification task, and (3) tackling the challenge of imbalanced data, which appears both in training and testing data. The results show the comparison with the traditional approach of learning the models from the legacy course data, validating the proposed concept.", "authors": ["Martin Hlosta", "Zdenek Zdrahal", "Jaroslav Zendulka"], "session": "SESSION: Students at-risk - studies"}, {"title": "Impact of student choice of content adoption delay on course outcomes", "pages": "16-20", "doi": "10.1145/3027385.3027437", "abstract": "It is difficult for a student to succeed in a course without access to course materials and assignments; and yet, some students delay up to a month in obtaining access to these essential materials. Students delay buying material required for their course due to multiple reasons. Out of a concern for students with limited financial resources, some publishers offer a period of free courtesy access. But this may lead to students having access later in the course but then having a lapsed period until they pay for the materials after the courtesy access period ends. Not having key course materials early on probably hurts learning, but how much? In this paper, we investigate the question, \"Does lack of access to instructional material impact student performance in blended learning courses?\" Specifically, we analyze students who purchased and obtained access to online content at different points in the course. We determine that both types of failure to obtain access to course materials (delaying in signing up for the product, or signing up for a free trial and letting the trial period lapse without purchasing the materials) are associated with substantially worse student outcomes. Students who purchased the product within the first few days of class had the best scores (median 77). Those who waited two weeks before accessing the product did the worst (median 56, effect size Cliff's Delta=0.31 1). We conclude with a discussion of possible interventions and actions that can be taken to ameliorate the situation.", "authors": ["Lalitha Agnihotri", "Alfred Essa", "Ryan Baker"], "session": "SESSION: Students at-risk - studies"}, {"title": "Detecting changes in student behavior from clickstream data", "pages": "21-30", "doi": "10.1145/3027385.3027430", "abstract": "Student clickstream data can provide valuable insights about student activities in an online learning environment and how these activities inform their learning outcomes. However, given the noisy and complex nature of this data, an on-going challenge involves devising statistical techniques that capture clear and meaningful aspects of students' click patterns. In this paper, we utilize statistical change detection techniques to investigate students' online behaviors. Using clickstream data from two large university courses, one face-to-face and one online, we illustrate how this methodology can be used to detect when students change their previewing and reviewing behavior, and how these changes can be related to other aspects of students' activity and performance.", "authors": ["Jihyun Park", "Kameryn Denaro", "Fernando Rodriguez", "Padhraic Smyth", "Mark Warschauer"], "session": "SESSION: Modelling student behaviour"}, {"title": "Modeling exploration strategies to predict student performance within a learning environment and beyond", "pages": "31-40", "doi": "10.1145/3027385.3027422", "abstract": "Modeling and predicting student learning is an important task in computer-based education. A large body of work has focused on representing and predicting student knowledge accurately. Existing techniques are mostly based on students' performance and on timing features. However, research in education, psychology and educational data mining has demonstrated that students' choices and strategies substantially influence learning. In this paper, we investigate the impact of students' exploration strategies on learning and propose the use of a probabilistic model jointly representing student knowledge and strategies. Our analyses are based on data collected from an interactive computer-based game. Our results show that exploration strategies are a significant predictor of the learning outcome. Furthermore, the joint models of performance and knowledge significantly improve the prediction accuracy within the game as well as on external post-test data, indicating that this combined representation provides a better proxy for learning.", "authors": ["Tanja K\u00e4ser", "Nicole R. Hallinen", "Daniel L. Schwartz"], "session": "SESSION: Modelling student behaviour"}, {"title": "Opportunities for personalization in modeling students as Bayesian learners", "pages": "41-45", "doi": "10.1145/3027385.3027410", "abstract": "The following paper is a proof-of-concept demonstration of a novel Bayesian framework for making inferences about individual students and the context in which they are learning. It has implications for both efforts to automate personalized instruction and to probabilistically model educational context. By modelling students as Bayesian learners, individuals who weigh their prior belief against current circumstantial data to reach conclusions, it becomes possible to both generate estimates of performance and the impact of the educational environment in probabilistic terms. This framework is tested through a Bayesian algorithm that can be used to characterize student prior knowledge in course material and predict student performance. This is demonstrated using both simulated data. The algorithm generates estimates that behave qualitatively as expected on simulated data and predict student performance substantially better than chance. A discussion of the results and the conceptual benefits of the framework follow.", "authors": ["Charles Lang"], "session": "SESSION: Modelling student behaviour"}, {"title": "An elephant in the learning analytics room: the obligation to act", "pages": "46-55", "doi": "10.1145/3027385.3027406", "abstract": "As higher education increasingly moves to online and digital learning spaces, we have access not only to greater volumes of student data, but also to increasingly fine-grained and nuanced data. A significant body of research and existing practice are used to convince key stakeholders within higher education of the potential of the collection, analysis and use of student data to positively impact on student experiences in these environments. Much of the recent focus in learning analytics is around predictive modeling and uses of artificial intelligence to both identify learners at risk, and to personalize interventions to increase the chance of success. In this paper we explore the moral and legal basis for the obligation to act on our analyses of student data. The obligation to act entails not only the protection of student privacy and the ethical collection, analysis and use of student data, but also, the effective allocation of resources to ensure appropriate and effective interventions to increase effective teaching and learning. The obligation to act is, however tempered by a number of factors, including inter and intra-departmental operational fragmentation and the constraints imposed by changing funding regimes. Increasingly higher education institutions allocate resources in areas that promise the greatest return. Choosing (not) to respond to the needs of specific student populations then raises questions regarding the scope and nature of the moral and legal obligation to act. There is also evidence that students who are at risk of failing often do not respond to institutional interventions to assist them. In this paper we build and expand on recent research by, for example, the LACE and EP4LA workshops to conceptually map the obligation to act which flows from both higher education's mandate to ensure effective and appropriate teaching and learning and its fiduciary duty to provide an ethical and enabling environment for students to achieve success. We examine how the collection and analysis of student data links to both the availability of resources and the will to act and also to the obligation to act. Further, we examine how that obligation unfolds in two open distance education providers from the perspective of a key set of stakeholders - those in immediate contact with students and their learning journeys - the tutors or adjunct faculty.", "authors": ["Paul Prinsloo", "Sharon Slade"], "session": "SESSION: Learning analytics ethics"}, {"title": "Where is the evidence?: a call to action for learning analytics", "pages": "56-65", "doi": "10.1145/3027385.3027396", "abstract": "Where is the evidence for learning analytics? In particular, where is the evidence that it improves learning in practice? Can we rely on it? Currently, there are vigorous debates about the quality of research evidence in medicine and psychology, with particular issues around statistical good practice, the 'file drawer effect', and ways in which incentives for stakeholders in the research process reward the quantity of research produced rather than the quality. In this paper, we present the Learning Analytics Community Exchange (LACE) project's Evidence Hub, an effort to relate research evidence in learning analytics to four propositions about learning analytics: whether they support learning, support teaching, are deployed widely, and are used ethically. Surprisingly little evidence in this strong, specific sense was found, and very little was negative (7%, N=123), suggesting that learning analytics is not immune from the pressures in other areas. We explore the evidence in one particular area in detail (whether learning analytics improve teaching and learners support in the university sector), and set out some of the weaknesses of the evidence available. We conclude that there is considerable scope for improving the evidence base for learning analytics, and set out some suggestions of ways for various stakeholders to achieve this.", "authors": ["Rebecca Ferguson", "Doug Clow"], "session": "SESSION: Learning analytics ethics"}, {"title": "Student perceptions of their privacy in leaning analytics applications", "pages": "66-69", "doi": "10.1145/3027385.3027392", "abstract": "Over the past five years, ethics and privacy around student data have become major topics of conversation in the learning analytics field. However, the majority of these have been theoretical in nature. The authors of this paper posit that more direct student engagement needs to be undertaken, and initial data from institutions beginning this process is shared. We find that, while the majority of respondents are accepting of the use of their data by their institutions, approval varies depending on the proposed purpose of the analytics. There also appear to be notable variations between students enrolled at United Kingdom and American institutions.", "authors": ["Kimberly E. Arnold", "Niall Sclater"], "session": "SESSION: Learning analytics ethics"}, {"title": "Understanding student learning trajectories using multimodal learning analytics within an embodied-interaction learning environment", "pages": "70-79", "doi": "10.1145/3027385.3027429", "abstract": "The aim of this paper is to show how multimodal learning analytics (MMLA) can help understand how elementary students explore the concept of feedback loops while controlling an embodied simulation of a predator-prey ecosystem using hand movements as an interface with the computer simulation. We represent student motion patterns from fine-grained logs of hands and gaze data, and then map these observed motion patterns against levels of student performance to make inferences about how embodiment plays a role in the learning process. Results show five distinct motion sequences in students' embodied interactions, and these motion patterns are statistically associated with initial and post-tutorial levels of students' understanding of feedback loops. Analysis of student gaze also shows distinctive patterns as to how low- and high-performing students attended to information presented in the simulation. Using MMLA, we show how students' explanations of feedback loops look differently according to cluster membership, which provides evidence that embodiment interacts with conceptual understanding.", "authors": ["Alejandro Andrade"], "session": "SESSION: Understanding student behaviour - multimodal analytics"}, {"title": "Put your thinking cap on: detecting cognitive load using EEG during learning", "pages": "80-89", "doi": "10.1145/3027385.3027431", "abstract": "Current learning technologies have no direct way to assess students' mental effort: are they in deep thought, struggling to overcome an impasse, or are they zoned out? To address this challenge, we propose the use of EEG-based cognitive load detectors during learning. Despite its potential, EEG has not yet been utilized as a way to optimize instructional strategies. We take an initial step towards this goal by assessing how experimentally manipulated (easy and difficult) sections of an intelligent tutoring system (ITS) influenced EEG-based estimates of students' cognitive load. We found a main effect of task difficulty on EEG-based cognitive load estimates, which were also correlated with learning performance. Our results show that EEG can be a viable source of data to model learners' mental states across a 90-minute session.", "authors": ["Caitlin Mills", "Igor Fridman", "Walid Soussou", "Disha Waghray", "Andrew M. Olney", "Sidney K. D'Mello"], "session": "SESSION: Understanding student behaviour - multimodal analytics"}, {"title": "Analytics meet patient manikins: challenges in an authentic small-group healthcare simulation classroom", "pages": "90-94", "doi": "10.1145/3027385.3027401", "abstract": "Healthcare simulations are hands-on learning experiences aimed at allowing students to practice essential skills that they may need when working with real patients in clinical workplaces. Some clinical classrooms are equipped with patient manikins that can respond to actions or that can be programmed to deteriorate over time. Students can perform assessments and interventions, and enhance their critical thinking and communication skills. There is an opportunity to exploit the students' digital traces that these manikins can pervasively capture to make key aspects of the learning process visible. The setting can be augmented with sensors to capture traces of group interaction. These multimodal data can be used to generate visualisations or feedback for students or teachers. This paper reports on an authentic classroom study using analytics to integrate multimodal data of students' interactions with the manikins and their peers in simulation scenarios. We report on the challenges encountered in deploying such analytics 'in the wild', using an analysis framework that considers the social, epistemic and physical dimensions of collocated group activity.", "authors": ["Roberto Martinez-Maldonado", "Tamara Power", "Carolyn Hayes", "Adrian Abdiprano", "Tony Vo", "Carmen Axisa", "Simon Buckingham Shum"], "session": "SESSION: Understanding student behaviour - multimodal analytics"}, {"title": "How to assign students into sections to raise learning", "pages": "95-104", "doi": "10.1145/3027385.3027439", "abstract": "Grouping students with similar past achievement together (tracking) might affect their reading achievement. Multilevel analyses of 208,057 fourth grade students in 40 countries showed that clustering students in schools by past achievement was linked to higher reading achievement, consistent with the benefits of customized, targeted instruction. Meanwhile, students had higher reading achievement with greater differences (variances) among classmates' past achievement, reading attitudes, or family SES; these results are consistent with the view that greater student differences yield more help opportunities (higher achievers help lower achievers, so that both learn), and foster learning from their different resources, attitudes and behaviors. Also, a student had higher reading achievement when classmates had more resources (SES, home educational resources, reading attitude, past achievement), suggesting that classmates shared their resources and helped one another. Modeling of non-linear relations and achievement subsamples of students supported the above interpretations. Principals can use these results and a simpler version of this methodology to re-allocate students and resources into different course sections at little cost to improve students' reading achievement.", "authors": ["Ming Ming Chiu", "Bonnie Wing-Yin Chow", "Sung Wook Joh"], "session": "SESSION: Improving learning"}, {"title": "Improving learning through achievement priming in crowdsourced information finding microtasks", "pages": "105-114", "doi": "10.1145/3027385.3027402", "abstract": "Crowdsourcing has become an increasingly popular means to acquire human input on demand. Microtask crowdsourcing market-places facilitate the access to millions of people (called workers) who are willing to participate in tasks in return for monetary rewards or other forms of compensation. This paradigm presents a unique learning context where workers have to learn to complete tasks on-the-fly by applying their learning immediately through the course of tasks. However, most workers typically dropout early in large batches of tasks, depriving themselves of the opportunity to learn on-the-fly through the course of batch completion. By doing so workers squander a potential chance at improving their performance and completing tasks effectively. In this paper, we propose a novel method to engage and retain workers, to improve their learning in crowdsourced information finding tasks by using achievement priming. Through rigorous experimental findings, we show that it is possible to retain workers in long batches of tasks by triggering their inherent motivation to achieve and excel. As a consequence of increased worker retention, we find that workers learn to perform more effectively, depicting relatively more stable accuracy and lower task completion times in comparison to workers who drop out early.", "authors": ["Ujwal Gadiraju", "Stefan Dietze"], "session": "SESSION: Improving learning"}, {"title": "Exploring the asymmetry of metacognition", "pages": "115-119", "doi": "10.1145/3027385.3027388", "abstract": "People in general and students in particular have a tendency to misinterpret their own abilities. Some tend to underestimate their skills, while others tend to overestimate them. This paper investigates the degree to which metacognition is asymmetric in real-world learning and examines the change of a students' confidence over the course of a semester and its impact on the students' academic performance. Our findings, conducted using 129,644 students learning in eight courses within the LearnSmart platform, indicate that poor or unrealistic metacognition is asymmetric. These students are biased in one direction: they are more likely to be overconfident than underconfident. Additionally, while the examination of the temporal aspects of confidence reveals no significant change throughout the semester, changes are more apparent in the first and the last few weeks of the course. More specifically, there is a sharp increase in underconfidence and a simultaneous decrease in realistic evaluation toward the end of the semester. Finally, both overconfidence and underconfidence seem to be correlated with students' overall course performance. An increase in overconfidence is related to higher overall performance, while an increase in underconfidence is associated with lower overall performance.", "authors": ["Ani Aghababyan", "Nicholas Lewkow", "Ryan Baker"], "session": "SESSION: Improving learning"}, {"title": "Temporal analytics with discourse analysis: tracing ideas and impact on communal discourse", "pages": "120-127", "doi": "10.1145/3027385.3027386", "abstract": "This paper presents a study of temporal analytics and discourse analysis of an online discussion, through investigation of a group of 13 in-service teachers and 2 instructors. A discussion forum consisting of 281 posts on an online collaborative learning environment was investigated. A text-mining tool was used to discover keywords from the discourse, and through social network analysis based on these keywords, a significant presence of relevant and promising ideas within discourse was revealed. However, uncovering the key ideas alone is insufficient to clearly explain students' level of understanding regarding the discussed topics. A more thorough analysis was thus performed by using temporal analytics with step-wise discourse analysis to trace the ideas and determine their impact on communal discourse. The results indicated that most ideas within the discourse could be traced to the origin of a set of improvable ideas, which impacted and also increased the community's level of interest in sharing and discussing ideas through discourse.", "authors": ["Alwyn Vwen Yen Lee", "Seng Chee Tan"], "session": "SESSION: Understanding discourse I"}, {"title": "Dynamics of MOOC discussion forums", "pages": "128-137", "doi": "10.1145/3027385.3027391", "abstract": "In this integrated study of dynamics in MOOCs discussion forums, we analyze the interplay of temporal patterns, discussion content, and the social structure emerging from the communication using mixed methods. A special focus is on the yet under-explored aspect of time dynamics and influence of the course structure on forum participation. Our analyses show dependencies between the course structure (video opening time and assignment deadlines) and the over-all forum activity whereas such a clear link could only be partially observed considering the discussion content. For analyzing the social dimension we apply role modeling techniques from social network analysis. While the types of user roles based on connection patterns are relatively stable over time, the high fluctuation of active contributors lead to frequent changes from active to passive roles during the course. However, while most users do not create many social connections they can play an important role in the content dimension triggering discussions on the course subject. Finally, we show that forum activity level can be predicted one week in advance based on the course structure, forum activity history and attributes of the communication network which enables identification of periods when increased tutor supports in the forum is necessary.", "authors": ["Mina Shirvani Boroujeni", "Tobias Hecking", "H. Ulrich Hoppe", "Pierre Dillenbourg"], "session": "SESSION: Understanding discourse I"}, {"title": "Assessment of language in authentic science inquiry reveals putative differences in epistemology", "pages": "138-142", "doi": "10.1145/3027385.3027425", "abstract": "Science epistemology, or beliefs about what it means to do science and how science knowledge is generated, is an integral part of authentic science inquiry. Although the development of a sophisticated science epistemology is critical for attaining science literacy, epistemology remains an elusive construct to precisely and quantitatively evaluate. Previous work has suggested that analysis of student practices in science inquiry, such as their use of language, may be reflective of their underlying epistemologies. Here we describe the usage of a learning analytics tool, TAALES, and keyness analysis to analyze the concluding statements made by students at the end of a computer-based authentic science inquiry experience. Preliminary results indicate that linguistic analysis reveals differences in domain-general lexical sophistication and in domain-specific verb usage that are consistent with the expertise level of the participant. For example, experts tend to use more hedging language such as \"may\" and \"support\" during conclusions whereas novices use stronger language such as \"cause.\" Using these differences, a simple, rule-based prediction algorithm with LOOCV achieved prediction accuracies of greater than 80%. These data underscore the potential for the use of learning analytics in simulated authentic inquiry to provide a novel and valuable method of assessing inquiry practices and related epistemologies.", "authors": ["Melanie E. Peffer", "Kristopher Kyle"], "session": "SESSION: Understanding discourse I"}, {"title": "Predicting the decrease of engagement indicators in a MOOC", "pages": "143-147", "doi": "10.1145/3027385.3027387", "abstract": "Predicting the decrease of students' engagement in typical MOOC tasks such as watching lecture videos or submitting assignments is key to trigger timely interventions in order to try to avoid the disengagement before it takes place. This paper proposes an approach to build the necessary predictive models using students' data that becomes available during a course. The approach was employed in an experimental study to predict the decrease of three different engagement indicators in a MOOC. The results suggest its feasibility with values of area under the curve for different predictors ranging from 0.718 to 0.914.", "authors": ["Miguel L. Bote-Lorenzo", "Eduardo G\u00f3mez-S\u00e1nchez"], "session": "SESSION: Understanding student behaviour - engagement"}, {"title": "Studying engagement and performance with learning technology in an African classroom", "pages": "148-152", "doi": "10.1145/3027385.3027395", "abstract": "In this paper, we study the engagement and performance of students in a classroom using a system the Cognitive Learning Companion (CLC). CLC is designed to keep track of the relationship between the student, content interaction and learning progression. It also provides evidence-based engagement-oriented actionable insights to teachers by assessing information from a sensor-rich instrumented learning environment in order to infer a learner's cognitive and affective states. Data captured from the instrumented environment is aggregated and analyzed to create interlinked insights helping teachers identify how students engage with learning content and view their performance records on selected assignments. We conducted a 1 month pilot with 27 learners in a primary school in Nairobi, Kenya during their maths and science instructional periods. We present our primary analysis of content-level interactions and engagement at the individual student and classroom level.", "authors": ["Juliet Mutahi", "Andrew Kinai", "Nelson Bore", "Abdigani Diriye", "Komminist Weldemariam"], "session": "SESSION: Understanding student behaviour - engagement"}, {"title": "Reflective writing analytics for actionable feedback", "pages": "153-162", "doi": "10.1145/3027385.3027436", "abstract": "Reflective writing can provide a powerful way for students to integrate professional experience and academic learning. However, writing reflectively requires high quality actionable feedback, which is time-consuming to provide at scale. This paper reports progress on the design, implementation, and validation of a Reflective Writing Analytics platform to provide actionable feedback within a tertiary authentic assessment context. The contributions are: (1) a new conceptual framework for reflective writing; (2) a computational approach to modelling reflective writing, deriving analytics, and providing feedback; (3) the pedagogical and user experience rationale for platform design decisions; and (4) a pilot in a student learning context, with preliminary data on educator and student acceptance, and the extent to which we can evidence that the software provided actionable feedback for reflective writing.", "authors": ["Andrew Gibson", "Adam Aitken", "\u00c1gnes S\u00e1ndor", "Simon Buckingham Shum", "Cherie Tsingos-Lucas", "Simon Knight"], "session": "SESSION: Reflective writing"}, {"title": "Reflective writing analytics: empirically determined keywords of written reflection", "pages": "163-167", "doi": "10.1145/3027385.3027394", "abstract": "Despite their importance for educational practice, reflective writings are still manually analysed and assessed, posing a constraint on the use of this educational technique. Recently, research started to investigate automated approaches for analysing reflective writing. Foundational to many automated approaches is the knowledge of words that are important for the genre. This research presents keywords that are specific to several categories of a reflective writing model. These keywords have been derived from eight datasets, which contain several thousand instances using the log-likelihood method. Both performance measures, the accuracy and the Cohen's \u03ba, for these keywords were estimated with ten-fold cross validation. The results reached an accuracy of 0.78 on average for all eight categories and a fair to good interrater reliability for most categories even though it did not make use of any sophisticated rule-based mechanisms or machine learning approaches. This research contributes to the development of automated reflective writing analytics that are based on data-driven empirical foundations.", "authors": ["Thomas Daniel Ullmann"], "session": "SESSION: Reflective writing"}, {"title": "Unravelling the dynamics of instructional practice: a longitudinal study on learning design and VLE activities", "pages": "168-177", "doi": "10.1145/3027385.3027409", "abstract": "Substantial progress has been made in understanding how teachers design for learning. However, there remains a paucity of evidence of the actual students' response towards leaning designs. Learning analytics has the power to provide just-in-time support, especially when predictive analytics is married with the way teachers have designed their course, or so-called a learning design. This study investigates how learning designs are configured over time and their impact on student activities by analyzing longitudinal data of 38 modules with a total of 43,099 registered students over 30 weeks at the Open University UK, using social network analysis and panel data analysis. Our analysis unpacked dynamic configurations of learning designs between modules over time, which allows teachers to reflect on their practice in order to anticipate problems and make informed interventions. Furthermore, by controlling for the heterogeneity between modules, our results indicated that learning designs were able to explain up to 60% of the variability in student online activities, which reinforced the importance of pedagogical context in learning analytics.", "authors": ["Quan Nguyen", "Bart Rienties", "Lisette Toetenel"], "session": "SESSION: Learning design"}, {"title": "Sequencing content in an adaptive testing system: the role of choice", "pages": "178-182", "doi": "10.1145/3027385.3027412", "abstract": "The effect of choice on student achievement and engagement has been an extensively researched area of learning analytics. Current research findings suggest a positive relationship between choice and varied outcome measures, but little has been reported to indicate whether these findings hold in the context of Intelligent Tutoring Systems (ITS). In this paper, we report the results of a randomized controlled experiment in which we investigate the effect of student choice on assignment completion and future achievement in an ITS. The experimental design uses three conditions to observe the effect of choice. In the first condition, students are able to choose the order in which to complete assignments, while in the second condition, students are prescribed an intuitive order in which to complete assignments. Those in the third condition were prescribed a counter-intuitive order in which to complete assignments. Results indicate that allowing students to choose the order in which to work on assignments leads to higher completion rates and better achievement at posttest. A post-hoc analysis also revealed that even considering students with similar completion rates, those given choice had higher posttest scores than those observed in any other condition. These results seem to support the many theories of the positive effect of choice on student achievement.", "authors": ["Seth A. Adjei", "Anthony F. Botelho", "Neil T. Heffernan"], "session": "SESSION: Learning design"}, {"title": "ATCE: an analytics tool to trace the creation and evaluation of inclusive and accessible open educational resources", "pages": "183-187", "doi": "10.1145/3027385.3027413", "abstract": "The creation of Inclusive and Accessible Open Educational Resources (IA-OERs) is a challenge for teachers because they have to invest time and effort to create learning contents considering students' learning needs and preferences. An IA-OER is characterized by its alignment with the Universal Design Learning (UDL) principles, the quality on its contents and the web accessibility as a way to address the diversity of students. Creating an IA-OER with these characteristics is not a straightforward task, especially when teachers do not have enough information/feedback to make decisions on how to improve the learning contents. In this paper we introduce ATCE - an Analytics Tool to Trace the Creation and Evaluation of IA-OERs. This tool focuses in particular on the accessibility and quality of the IA-OERs. ATCE was developed as a module within the ATutor Learning Management System (LMS). An analytics dashboard with visualizations related to the teachers' competences in the creation and evaluation of IA-OERs was included as part of the tool. This paper also presents a use case of the visualizations obtained from the creation and evaluation of one IA-OER after using our analytics tool.", "authors": ["Cecilia Avila", "Silvia Baldiris", "Ramon Fabregat", "Sabine Graf"], "session": "SESSION: Learning design"}, {"title": "Learning pulse: a machine learning approach for predicting performance in self-regulated learning using multimodal data", "pages": "188-197", "doi": "10.1145/3027385.3027447", "abstract": "Learning Pulse explores whether using a machine learning approach on multimodal data such as heart rate, step count, weather condition and learning activity can be used to predict learning performance in self-regulated learning settings. An experiment was carried out lasting eight weeks involving PhD students as participants, each of them wearing a Fitbit HR wristband and having their application on their computer recorded during their learning and working activities throughout the day. A software infrastructure for collecting multimodal learning experiences was implemented. As part of this infrastructure a Data Processing Application was developed to pre-process, analyse and generate predictions to provide feedback to the users about their learning performance. Data from different sources were stored using the xAPI standard into a cloud-based Learning Record Store. The participants of the experiment were asked to rate their learning experience through an Activity Rating Tool indicating their perceived level of productivity, stress, challenge and abilities. These self-reported performance indicators were used as markers to train a Linear Mixed Effect Model to generate learner-specific predictions of the learning performance. We discuss the advantages and the limitations of the used approach, highlighting further development points.", "authors": ["Daniele Di Mitri", "Maren Scheffel", "Hendrik Drachsler", "Dirk B\u00f6rner", "Stefaan Ternier", "Marcus Specht"], "session": "SESSION: Self-regulated learning"}, {"title": "Transitioning self-regulated learning profiles in hypermedia-learning environments", "pages": "198-202", "doi": "10.1145/3027385.3027443", "abstract": "Self-regulated learning (SRL) is a process that highly fluctuates as students actively deploy their metacognitive and cognitive processes during learning. In this paper, we apply an extension of latent profiling, latent transition analysis (LTA), which investigates the longitudinal development of students' SRL latent class memberships over time. We will briefly review the theoretical foundations of SRL and discuss the value of using LTA to investigate this multidimensional concept. This study is based on college students (n = 75) learning about the human circulatory system while using MetaTutor, an intelligent tutoring system that adaptively supports SRL and targets specific metacognitive SRL processes including judgment of learning (JOL) and content evaluation (CE). Preliminary results identify transitional probabilities of SRL profiles from four distinct events associated with the use of SRL.", "authors": ["Clarissa Lau", "Jeanne Sinclair", "Michelle Taub", "Roger Azevedo", "Eunice Eunhee Jang"], "session": "SESSION: Self-regulated learning"}, {"title": "Expanding the scope of learning analytics data: preliminary findings on attention and self-regulation using wearable technology", "pages": "203-207", "doi": "10.1145/3027385.3027427", "abstract": "The ability to pay attention and self-regulate is a fundamental skill required of learners of all ages. Learning analytics researchers have to date relied on data generated by a computing system (such as a learning management system, click stream or log data) to examine learners' self-regulatory abilities. The development of wearable computing through fitness trackers, watches, heart rate monitors, and clinical grade devices such as Empatica's E4 wristband now provides researchers with access to biometric data as students interact with learning content or software systems. This level of data collection promises to provide valuable insight into cognitive and affective experiences of individuals, especially when combined with traditional learning analytics data sources. Our study details the use of wearable technologies to assess the relationship between heart rate variability and the self-regulatory abilities of an individual. This is relevant for the field of learning analytics as methods become more complex and the assessment of learner performance becomes more nuanced and attentive to the affective factors that contribute to learner success.", "authors": ["Catherine A. Spann", "James Schaeffer", "George Siemens"], "session": "SESSION: Self-regulated learning"}, {"title": "How effective is your facilitation?: group-level analytics of MOOC forums", "pages": "208-217", "doi": "10.1145/3027385.3027404", "abstract": "The facilitation of interpersonal relationships within a respectful learning climate is an important aspect of teaching practice. However, in large-scale online contexts, such as MOOCs, the number of learners and highly asynchronous nature militates against the development of a sense of belonging and dyadic trust. Given these challenges, instead of conventional instruments that reflect learners' affective perceptions, we suggest a set of indicators that can be used to evaluate social activity in relation to the participation structure. These group-level indicators can then help teachers to gain insights into the evolution of social activity shaped by their facilitation choices. For this study, group-level indicators were derived from measuring information exchange activity between the returning MOOC posters. By conceptualizing this group as an identity-based community, we can apply exponential random graph modelling to explain the network's structure through the configurations of direct reciprocity, triadic-level exchange, and the effect of participants demonstrating super-posting behavior. The findings provide novel insights into network amplification, and highlight the differences between the courses with different facilitation strategies. Direct reciprocation was characteristic of non-facilitated groups. Exchange at the level of triads was more prominent in highly facilitated online communities with instructor's involvement. Super-posting activity was less pronounced in networks with higher triadic exchange, and more pronounced in networks with higher direct reciprocity.", "authors": ["Oleksandra Poquet", "Shane Dawson", "Nia Dowell"], "session": "SESSION: Understanding discourse II"}, {"title": "Words matter: automatic detection of teacher questions in live classroom discourse using linguistics, acoustics, and context", "pages": "218-227", "doi": "10.1145/3027385.3027417", "abstract": "We investigate automatic detection of teacher questions from audio recordings collected in live classrooms with the goal of providing automated feedback to teachers. Using a dataset of audio recordings from 11 teachers across 37 class sessions, we automatically segment the audio into individual teacher utterances and code each as containing a question or not. We train supervised machine learning models to detect the human-coded questions using high-level linguistic features extracted from automatic speech recognition (ASR) transcripts, acoustic and prosodic features from the audio recordings, as well as context features, such as timing and turn-taking dynamics. Models are trained and validated independently of the teacher to ensure generalization to new teachers. We are able to distinguish questions and non-questions with a weighted F1 score of 0.69. A comparison of the three feature sets indicates that a model using linguistic features outperforms those using acoustic-prosodic and context features for question detection, but the combination of features yields a 5% improvement in overall accuracy compared to linguistic features alone. We discuss applications for pedagogical research, teacher formative assessment, and teacher professional development.", "authors": ["Patrick J. Donnelly", "Nathaniel Blanchard", "Andrew M. Olney", "Sean Kelly", "Martin Nystrand", "Sidney K. D'Mello"], "session": "SESSION: Understanding discourse II"}, {"title": "Towards mining sequences and dispersion of rhetorical moves in student written texts", "pages": "228-232", "doi": "10.1145/3027385.3027433", "abstract": "There is an increasing interest in the analysis of both student's writing and the temporal aspects of learning data. The analysis of higher-level learning features in writing contexts requires analyses of data that could be characterised in terms of the sequences and processes of textual features present. This paper (1) discusses the extant literature on sequential and process analyses of writing; and, based on this and our own first-hand experience on sequential analysis, (2) proposes a number of approaches to both pre-process and analyse sequences in whole-texts. We illustrate how the approaches could be applied to examples drawn from our own datasets of 'rhetorical moves' in written texts, and the potential each approach holds for providing insight into that data. Work is in progress to apply this model to provide empirical insights. Although, similar sequence or process mining techniques have not yet been applied to student writing, techniques applied to event data could readily be operationalised to undercover patterns in texts.", "authors": ["Simon Knight", "Roberto Martinez-Maldonado", "Andrew Gibson", "Simon Buckingham Shum"], "session": "SESSION: Understanding discourse II"}, {"title": "Learning analytics in higher education --- challenges and policies: a review of eight learning analytics policies", "pages": "233-242", "doi": "10.1145/3027385.3027400", "abstract": "This paper presents the results of a review of eight policies for learning analytics of relevance for higher education, and discusses how these policies have tried to address prominent challenges in the adoption of learning analytics, as identified in the literature. The results show that more considerations need to be given to establishing communication channels among stakeholders and adopting pedagogy-based approaches to learning analytics. It also reveals the shortage of guidance for developing data literacy among end-users and evaluating the progress and impact of learning analytics. Moreover, the review highlights the need to establish formalised guidelines to monitor the soundness, effectiveness, and legitimacy of learning analytics. As interest in learning analytics among higher education institutions continues to grow, this review will provide insights into policy and strategic planning for the adoption of learning analytics.", "authors": ["Yi-Shan Tsai", "Dragan Gasevic"], "session": "SESSION: Learning analytics policies"}, {"title": "The influence of data protection and privacy frameworks on the design of learning analytics systems", "pages": "243-252", "doi": "10.1145/3027385.3027414", "abstract": "Learning analytics open up a complex landscape of privacy and policy issues, which, in turn, influence how learning analytics systems and practices are designed. Research and development is governed by regulations for data storage and management, and by research ethics. Consequently, when moving solutions out the research labs implementers meet constraints defined in national laws and justified in privacy frameworks. This paper explores how the OECD, APEC and EU privacy frameworks seek to regulate data privacy, with significant implications for the discourse of learning, and ultimately, an impact on the design of tools, architectures and practices that now are on the drawing board. A detailed list of requirements for learning analytics systems is developed, based on the new legal requirements defined in the European General Data Protection Regulation, which from 2018 will be enforced as European law. The paper also gives an initial account of how the privacy discourse in Europe, Japan, South-Korea and China is developing and reflects upon the possible impact of the different privacy frameworks on the design of LA privacy solutions in these countries. This research contributes to knowledge of how concerns about privacy and data protection related to educational data can drive a discourse on new approaches to privacy engineering based on the principles of Privacy by Design. For the LAK community, this study represents the first attempt to conceptualise the issues of privacy and learning analytics in a cross-cultural context. The paper concludes with a plan to follow up this research on privacy policies and learning analytics systems development with a new international study.", "authors": ["Tore Hoel", "Dai Griffiths", "Weiqin Chen"], "session": "SESSION: Learning analytics policies"}, {"title": "An information policy perspective on learning analytics", "pages": "253-256", "doi": "10.1145/3027385.3027389", "abstract": "Policy for learning analytics joins a stream of initiatives aimed at understanding the expanding world of information collection, storage, processing and dissemination that is being driven by computing technologies. This paper offers a information policy perspective on learning analytics, joining work by others on ethics and privacy in the management of learning analytics data [8], but extending to consider how issues play out across the information lifecycle and in the formation of policy. Drawing on principles from information policy both informs learning analytics and brings learning analytics into the information policy domain. The resulting combination can help inform policy development for educational institutions as they implement and manage learning analytics policy and practices. The paper begins with a brief summary of the information policy perspective, then addresses learning analytics with attention to various categories of consideration for policy development.", "authors": ["Caroline Haythornthwaite"], "session": "SESSION: Learning analytics policies"}, {"title": "Intelligent tutors as teachers' aides: exploring teacher needs for real-time analytics in blended classrooms", "pages": "257-266", "doi": "10.1145/3027385.3027451", "abstract": "Intelligent tutoring systems (ITSs) are commonly designed to enhance student learning. However, they are not typically designed to meet the needs of teachers who use them in their classrooms. ITSs generate a wealth of analytics about student learning and behavior, opening a rich design space for real-time teacher support tools such as dashboards. Whereas real-time dashboards for teachers have become popular with many learning technologies, we are not aware of projects that have designed dashboards for ITSs based on a broad investigation of teachers' needs. We conducted design interviews with ten middle school math teachers to explore their needs for on-the-spot support during blended class sessions, as a first step in a user-centered design process of a real-time dashboard. Based on multi-methods analyses of this interview data, we identify several opportunities for ITSs to better support teachers' needs, noting that the analytics commonly generated by existing teacher support tools do not strongly align with the analytics teachers expect to be most useful. We highlight key tensions and tradeoffs in the design of such real-time supports for teachers, as revealed by \"Speed Dating\" possible futures with teachers. This paper has implications for our ongoing co-design of a real-time dashboard for ITSs, as well as broader implications for the design of ITSs that can effectively collaborate with teachers in classroom settings.", "authors": ["Kenneth Holstein", "Bruce M. McLaren", "Vincent Aleven"], "session": "SESSION: Teacher support tools I"}, {"title": "Implementing predictive learning analytics on a large scale: the teacher's perspective", "pages": "267-271", "doi": "10.1145/3027385.3027397", "abstract": "In this paper, we describe a large-scale study about the use of predictive learning analytics data with 240 teachers in 10 modules at a distance learning higher education institution. The aim of the study was to illuminate teachers' uses and practices of predictive data, in particular identify how predictive data was used to support students at risk of not completing or failing a module. Data were collected from statistical analysis of 17,033 students' performance by the end of the intervention, teacher usage statistics, and five individual semi-structured interviews with teachers. Findings revealed that teachers endorse the use of predictive data to support their practice yet in diverse ways and raised the need for devising appropriate intervention strategies to support students at risk.", "authors": ["Christothea Herodotou", "Bart Rienties", "Avinash Boroowa", "Zdenek Zdrahal", "Martin Hlosta", "Galina Naydenova"], "session": "SESSION: Teacher support tools I"}, {"title": "An instructor dashboard for real-time analytics in interactive programming assignments", "pages": "272-279", "doi": "10.1145/3027385.3027441", "abstract": "Many introductory programming environments generate a large amount of log data, but making insights from these data accessible to instructors remains a challenge. This research demonstrates that student outcomes can be accurately predicted from student program states at various time points throughout the course, and integrates the resulting predictive models into an instructor dashboard. The effectiveness of the dashboard is evaluated by measuring how well the dashboard analytics correctly suggest that the instructor help students classified as most in need. Finally, we describe a method of matching low-performing students with high-performing peer tutors, and show that the inclusion of peer tutors not only increases the amount of help given, but the consistency of help availability as well.", "authors": ["Nicholas Diana", "Michael Eagle", "John Stamper", "Shuchi Grover", "Marie Bienkowski", "Satabdi Basu"], "session": "SESSION: Teacher support tools II"}, {"title": "Real-time learning analytics for C programming language courses", "pages": "280-288", "doi": "10.1145/3027385.3027407", "abstract": "Many universities choose the C programming language (C) as the first one they teach their students, early on in their program. However, students often consider programming courses difficult, and these courses often have among the highest dropout rates of computer science courses offered. It is therefore critical to provide more effective instruction to help students understand the syntax of C and prevent them losing interest in programming. In addition, homework and paper-based exams are still the main assessment methods in the majority of classrooms. It is difficult for teachers to grasp students' learning situation due to the large amount of evaluation work. To facilitate teaching and learning of C, in this article we propose a system---LAPLE (Learning Analytics in Programming Language Education)---that provides a learning dashboard to capture the behavior of students in the classroom and identify the different difficulties faced by different students looking at different knowledge. With LAPLE, teachers may better grasp students' learning situation in real time and better improve educational materials using analysis results. For their part, novice undergraduate programmers may use LAPLE to locate syntax errors in C and get recommendations from educational materials on how to fix them.", "authors": ["Xinyu Fu", "Atsushi Shimada", "Hiroaki Ogata", "Yuta Taniguchi", "Daiki Suehiro"], "session": "SESSION: Teacher support tools II"}, {"title": "Widget, widget as you lead, I am performing well indeed!: using results from an exploratory offline study to inform an empirical online study about a learning analytics widget in a collaborative learning environment", "pages": "289-298", "doi": "10.1145/3027385.3027428", "abstract": "The collaborative learning processes of students in online learning environments can be supported by providing learning analytics-based visualisations that foster awareness and reflection about an individual's as well as the team's behaviour and their learning and collaboration processes. For this empirical study we implemented an activity widget into the online learning environment of a live five-months Master course and investigated the predictive power of the widget indicators towards the students' grades and compared the results to those from an exploratory study with data collected in previous runs of the same course where the widget had not been in use. Together with information gathered from a quantitative as well as a qualitative evaluation of the activity widget during the course, the findings of this current study show that there are indeed predictive relations between the widget indicators and the grades, especially those regarding responsiveness, and indicate that some of the observed differences in the last run could be attributed to the implemented activity widget.", "authors": ["Maren Scheffel", "Hendrik Drachsler", "Karel Kreijns", "Joop de Kraker", "Marcus Specht"], "session": "SESSION: Student support tools"}, {"title": "Building a transcript of the future", "pages": "299-308", "doi": "10.1145/3027385.3027418", "abstract": "The pathways and learning outcomes of university students are the culmination of numerous experiences inside and outside of the classroom, with faculty and with other students, in both formal and casual settings. These interactions are guided by the general education requirements of the university and by the learning goals of the student. The only official record and representation of each student's education is captured by their academic transcript: typically a list of courses described by name and number, grades recorded on an A-F scale and summarized by GPA, degrees awarded, and honors received. This limited approach reflects the technological affordances of a 20th century industrial age. In recent years, scholars have begun to imagine a transcript of the future, perhaps combining a richer record of the student experience along with a portfolio of authentic products of student work. In this paper, we concentrate on first, and develop analytic methods for improving measures of both classroom performance and intellectual breadth. In each case, this is done by placing elements of individual transcripts in context using information about their peers. We frame the study by addressing basic questions. Were the courses taken by the student difficult on average? Did the individual stand out from their peers? Were the courses representative of a broad intellectual experience, or did the student delve into detail in the chosen field of study? And with whom did they take courses?", "authors": ["Benjamin P. Koester", "James Fogel", "William Murdock, III", "Galina Grom", "Timothy A. McKay"], "session": "SESSION: Student support tools"}, {"title": "Trends and issues in student-facing learning analytics reporting systems research", "pages": "309-318", "doi": "10.1145/3027385.3027403", "abstract": "We conducted a literature review on systems that track learning analytics data (e.g., resource use, time spent, assessment data, etc.) and provide a report back to students in the form of visualizations, feedback, or recommendations. This review included a rigorous article search process; 945 articles were identified in the initial search. After filtering out articles that did not meet the inclusion criteria, 94 articles were included in the final analysis. Articles were coded on five categories chosen based on previous work done in this area: functionality, data sources, design analysis, perceived effects, and actual effects. The purpose of this review is to identify trends in the current student-facing learning analytics reporting system literature and provide recommendations for learning analytics researchers and practitioners for future work.", "authors": ["Robert Bodily", "Katrien Verbert"], "session": "SESSION: Feedback systems"}, {"title": "Uncovering reviewing and reflecting behaviors from paper-based formal assessment", "pages": "319-328", "doi": "10.1145/3027385.3027415", "abstract": "In this paper, we study students' learning effectiveness through their use of a homegrown educational technology, Web Programming Grading Assistant (WPGA), which facilitates grading and feedback delivery of paper-based assessments. We designed a classroom study and collected data from a lower-division blended-instruction computer science class. We tracked and modeled students' reviewing and reflecting behaviors from WPGA. The results show that students demonstrated an effort and desire to review assessments regardless of if they were graded for academic performance or for attendance. Hardworking students achieved higher exam scores on average and were found to review their exams and the correct questions frequently. Additionally, student cohorts exhibited similar initial reviewing patterns, but different in-depth reviewing and reflecting strategies. Ultimately, this work contributes to the aggregation of multidimensional learning analytics across the physical and cybersphere.", "authors": ["I-Han Hsiao", "Po-Kai Huang", "Hannah Murphy"], "session": "SESSION: Feedback systems"}, {"title": "Scientific modeling: using learning analytics to examine student practices and classroom variation", "pages": "329-338", "doi": "10.1145/3027385.3027420", "abstract": "Modeling has a strong focus in current science learning frameworks as a critical skill for students to learn. However, understanding students' scientific models and their modeling practices at scale is a difficult task that has not been taken up by the research literature. The complex variables involved in classroom learning, such as teacher differences, increase the difficulty of understanding this problem. This work begins with an exploration of the methods used to explore students' scientific modeling in the learning sciences space and the frameworks developed to characterize student modeling practices. Learning analytics can be used to leverage these frameworks of scientific modeling practices to explore questions around students' scientific models and their modeling practices. These analyses are focused around the use of EcoSurvey, a collaborative, digital tool used in high-school biology classrooms to model the local ecosystem. This tool was deployed in ten biology classrooms and used with varying degrees of success. There are significant teacher-level differences found in the activity sequences of students using the EcoSurvey tool. The theoretical metrics around scientific modeling practices and automatically extracted feature sequences were also used in a classification task to automatically determine a particular student's teacher. These results underline the power of learning analytics methods to give insight into how modeling practices are realized in the classroom. This work also informs changes to modeling tools, associated curricula, and supporting professional development around scientific modeling.", "authors": ["David Quigley", "Jonathan Ostwald", "Tamara Sumner"], "session": "SESSION: Skill assessment"}, {"title": "Predicting math performance using natural language processing tools", "pages": "339-347", "doi": "10.1145/3027385.3027399", "abstract": "A number of studies have demonstrated links between linguistic knowledge and performance in math. Studies examining these links in first language speakers of English have traditionally relied on correlational analyses between linguistic knowledge tests and standardized math tests. For second language (L2) speakers, the majority of studies have compared math performance between proficient and non-proficient speakers of English. In this study, we take a novel approach and examine the linguistic features of student language while they are engaged in collaborative problem solving within an on-line math tutoring system. We transcribe the students' speech and use natural language processing tools to extract linguistic information related to text cohesion, lexical sophistication, and sentiment. Our criterion variables are individuals' pretest and posttest math performance scores. In addition to examining relations between linguistic features of student language production and math scores, we also control for a number of non-linguistic factors including gender, age, grade, school, and content focus (procedural versus conceptual). Linear mixed effect modeling indicates that non-linguistic factors are not predictive of math scores. However, linguistic features related to cohesion affect and lexical proficiency explained approximately 30% of the variance (R2 = .303) in the math scores.", "authors": ["Scott Crossley", "Ran Liu", "Danielle McNamara"], "session": "SESSION: Skill assessment"}, {"title": "Learning analytics in a seamless learning environment", "pages": "348-357", "doi": "10.1145/3027385.3027408", "abstract": "This paper describes seamless learning analytics methods of VASCORLL (Visualization and Analysis System for COnnecting Relationships of Learning Logs). VASCORLL is a system for visualizing and analyzing the learning logs collected by the seamless learning system, which supports language learning in the real-world. As far, several studies have been made in the seamless learning environments in order to bridge formal learning over informal learning. However, their focus was the implementation of the seamless learning environment in education. This study focuses on visualizing and analyzing learning logs collected in the seamless learning environment. This paper describes how our analytics could contribute to bridging the gap between formal and informal learning. An experiment was conducted to evaluate 1) whether our developed VASCORLL is effective in connecting the words learned in formal learning to the ones learned in informal learning, 2) which social network algorithm is effective to enhance learning in the seamless learning environment. Twenty international students participated in the evaluation experiment, and they were able to increase their learning opportunities by using VASCORLL. In addition, it was found that the betweenness centrality is useful in finding central words bridging formal and informal learning.1", "authors": ["Kousuke Mouri", "Hiroaki Ogata", "Noriko Uosaki"], "session": "SESSION: Understanding student behaviour - general"}, {"title": "SPACLE: investigating learning across virtual and physical spaces using spatial replays", "pages": "358-367", "doi": "10.1145/3027385.3027450", "abstract": "Classroom experiments that evaluate the effectiveness of educational technologies do not typically examine the effects of classroom contextual variables (e.g., out-of-software help-giving and external distractions). Yet these variables may influence students' instructional outcomes. In this paper, we introduce the Spatial Classroom Log Explorer (SPACLE): a prototype tool that facilitates the rapid discovery of relationships between within-software and out-of-software events. Unlike previous tools for retrospective analysis, SPACLE replays moment-by-moment analytics about student and teacher behaviors in their original spatial context. We present a data analysis workflow using SPACLE and demonstrate how this workflow can support causal discovery. We share the results of our initial replay analyses using SPACLE, which highlight the importance of considering spatial factors in the classroom when analyzing ITS log data. We also present the results of an investigation into the effects of student-teacher interactions on student learning in K-12 blended classrooms, using our workflow, which combines replay analysis with SPACLE and causal modeling. Our findings suggest that students' awareness of being monitored by their teachers may promote learning, and that \"gaming the system\" behaviors may extend outside of educational software use.", "authors": ["Kenneth Holstein", "Bruce M. McLaren", "Vincent Aleven"], "session": "SESSION: Understanding student behaviour - general"}, {"title": "What do students want?: towards an instrument for students' evaluation of quality of learning analytics services", "pages": "368-372", "doi": "10.1145/3027385.3027419", "abstract": "Quality assurance in any organization is important for ensuring that service users are satisfied with the service offered. For higher education institutes, the use of service quality measures allows for ideological gaps to be both identified and resolved. The learning analytic community, however, has rarely addressed the concept of service quality. A potential outcome of this is the provision of a learning analytics service that only meets the expectations of certain stakeholders (e.g., managers), whilst overlooking those who are most important (e.g., students). In order to resolve this issue, we outline a framework and our current progress towards developing a scale to assess student expectations and perceptions of learning analytics as a service.", "authors": ["Alexander Whitelock-Wainwright", "Dragan Ga\u0161evi\u0107", "Ricardo Tejeiro"], "session": "SESSION: Learning analytics adoption - recommendations"}, {"title": "What'd you say again?: recurrence quantification analysis as a method for analyzing the dynamics of discourse in a reading strategy tutor", "pages": "373-382", "doi": "10.1145/3027385.3027445", "abstract": "In this study, we investigated the degree to which the cognitive processes in which students engage during reading comprehension could be examined through dynamical analyses of their natural language responses to texts. High school students (n = 142) generated typed self-explanations while reading a science text. They then completed a comprehension test that measured their comprehension at both surface and deep levels. The recurrent patterns of the words in students' self-explanations were first visualized in recurrence plots. These visualizations allowed us to qualitatively analyze the different self-explanation processes of skilled and less skilled readers. These recurrence plots then allowed us to calculate recurrence indices, which represented the properties of these temporal word patterns. Results of correlation and regression analyses revealed that these recurrence indices were significantly related to the students' comprehension scores at both surface- and deep levels. Additionally, when combined with summative metrics of word use, these indices were able to account for 32% of the variance in students' overall text comprehension scores. Overall, our results suggest that recurrence quantification analysis can be utilized to guide both qualitative and quantitative assessments of students' comprehension.", "authors": ["Laura K. Allen", "Cecile Perret", "Aaron Likens", "Danielle S. McNamara"], "session": "SESSION: Understanding discourse III"}, {"title": "Honing in on social learning networks in MOOC forums: examining critical network definition decisions", "pages": "383-392", "doi": "10.1145/3027385.3027446", "abstract": "This study examines the impact of content-based network partitioning and tie definition on social network structures and interpretation for MOOC discussion forums. Using dynamic interrelated post and thread categorization [5] based on a previously developed natural language model [27], 817 threads containing 3124 discussion posts from 567 learners in a MOOC on the use of statistics in medicine were characterized as either related to the learning of course content or not. Content-related, non-content, and unpartitioned interaction networks were constructed based on five different tie definitions: Direct Reply, Star, Direct Reply+Star, Limited Copresence, and Total Copresence. Results showed content-related and non-content networks to have distinct characteristics at the network, community, and individual node levels, validating the usefulness of the content/non-content distinction as an analytic tool. Network properties were less sensitive to differences in tie definition with the exception of Total Copresence, which showed distinct characteristics presenting dangers for general use, but usefulness for detecting inflated social status due to \"superthread\" initiation.", "authors": ["Alyssa Friend Wise", "Yi Cui", "Wan Qi Jin"], "session": "SESSION: Understanding discourse III"}, {"title": "Using correlational topic modeling for automated topic identification in intelligent tutoring systems", "pages": "393-397", "doi": "10.1145/3027385.3027438", "abstract": "Student knowledge modeling is an important part of modern personalized learning systems, but typically relies upon valid models of the structure of the content and skill in a domain. These models are often developed through expert tagging of skills to items. However, content creators in crowdsourced personalized learning systems often lack the time (and sometimes the domain knowledge) to tag skills themselves. Fully automated approaches that rely on the covariance of correctness on items can lead to effective skill-item mappings, but the resultant mappings are often difficult to interpret. In this paper we propose an alternate approach to automatically labeling skills in a crowdsourced personalized learning system using correlated topic modeling, a natural language processing approach, to analyze the linguistic content of mathematics problems. We find a range of potentially meaningful and useful topics within the context of the ASSISTments system for mathematics problem-solving.", "authors": ["Stefan Slater", "Ryan Baker", "Ma. Victoria Almeda", "Alex Bowers", "Neil Heffernan"], "session": "SESSION: Understanding discourse III"}, {"title": "Enhancing learning through virtual reality and neurofeedback: a first step", "pages": "398-403", "doi": "10.1145/3027385.3027390", "abstract": "Virtual reality presents exciting new prospects for the delivery of educational materials to students. By combining this technology with biological sensors, a student in a virtual educational environment can be monitored for physiological markers of engagement or more cognitive states of learning. With this information, the virtual reality environment can be adaptively altered to reflect the student's state, essentially creating a closed-loop feedback system. This paper explores these concepts, and presents preliminary data on a combined EEG-VR working memory experiment as a first step toward a broader implementation of an intelligent adaptive learning system. This first-pass neural time-series and oscillatory data suggest that while an EEG-based neurofeedback system is feasible, more work on removing artifacts and identifying relevant and important features will lead to higher prediction accuracy.", "authors": ["Ryan Hubbard", "Aldis Sipolins", "Lin Zhou"], "session": "SESSION: Adaptive learning"}, {"title": "Measures for recommendations based on past students' activity", "pages": "404-408", "doi": "10.1145/3027385.3027426", "abstract": "This paper introduces two measures for the recommendation of study materials based on students' past study activity. We use records from the Virtual Learning Environment (VLE) and analyse the activity of previous students. We assume that the activity of past students represents patterns, which can be used as a basis for recommendations to current students. The measures we define are Relevance, for description of a supposed VLE activity derived from previous students of the course, and Effort, that represents the actual effort of individual current students. Based on these measures, we propose a composite measure, which we call Importance. We use data from the previous course presentations to evaluate of the consistency of students' behaviour. We use correlation of the defined measures Relevance and Average Effort to evaluate the behaviour of two different student cohorts and the Root Mean Square Error to measure the deviation of Average Effort and individual student Effort.", "authors": ["Michal Huptych", "Michal Bohuslavek", "Martin Hlosta", "Zdenek Zdrahal"], "session": "SESSION: Adaptive learning"}, {"title": "Supporting collaborative learning with tag recommendations: a real-world study in an inquiry-based classroom project", "pages": "409-418", "doi": "10.1145/3027385.3027421", "abstract": "In online social learning environments, tagging has demonstrated its potential to facilitate search, to improve recommendations and to foster reflection and learning.Studies have shown that shared understanding needs to be established in the group as a prerequisite for learning. We hypothesise that this can be fostered through tag recommendation strategies that contribute to semantic stabilization. In this study, we investigate the application of two tag recommenders that are inspired by models of human memory: (i) the base-level learning equation BLL and (ii) Minerva. BLL models the frequency and recency of tag use while Minerva is based on frequency of tag use and semantic context. We test the impact of both tag recommenders on semantic stabilization in an online study with 56 students completing a group-based inquiry learning project in school. We find that displaying tags from other group members contributes significantly to semantic stabilization in the group, as compared to a strategy where tags from the students' individual vocabularies are used. Testing for the accuracy of the different recommenders revealed that algorithms using frequency counts such as BLL performed better when individual tags were recommended. When group tags were recommended, the Minerva algorithm performed better. We conclude that tag recommenders, exposing learners to each other's tag choices by simulating search processes on learners' semantic memory structures, show potential to support semantic stabilization and thus, inquiry-based learning in groups.", "authors": ["Simone Kopeinik", "Elisabeth Lex", "Paul Seitlinger", "Dietrich Albert", "Tobias Ley"], "session": "SESSION: Understanding student behaviour - help-seeking / search"}, {"title": "Classifying help seeking behaviour in online communities", "pages": "419-423", "doi": "10.1145/3027385.3027442", "abstract": "While help seeking has been extensively studied using self report survey data and models, there is a lack of content analysis techniques that can be directly applied to classify help seeking behaviour. In this preliminary work we propose a coding scheme which is then applied to an open dataset that we have created by carefully selecting sub groups from two popular discussion sites (Reddit and StackExchange). We then explore the possibility for automatically classifying help seeking behaviour using machine learning models. A preliminary model provides good initial results, suggesting that it may indeed be possible to construct student support systems that build off of an accurate classifier.", "authors": ["Sebastian Cross", "Zak Waters", "Kirsty Kitto", "Guido Zuccon"], "session": "SESSION: Understanding student behaviour - help-seeking / search"}, {"title": "Using learning analytics to explore help-seeking learner profiles in MOOCs", "pages": "424-428", "doi": "10.1145/3027385.3027448", "abstract": "In online learning environments, learners are often required to be more autonomous in their approach to learning. In scaled online learning environments, like Massive Open Online Courses (MOOCs), there are differences in the ability of learners to access teachers and peers to get help with their study than in more traditional educational environments. This exploratory study examines the help-seeking behaviour of learners across several MOOCs with different audiences and designs. Learning analytics techniques (e.g., dimension reduction with t-sne and clustering with affinity propagation) were applied to identify clusters and determine profiles of learners on the basis of their help-seeking behaviours. Five help-seeking learner profiles were identified which provide an insight into how learners' help-seeking behaviour relates to performance. The development of a more in-depth understanding of how learners seek help in large online learning environments is important to inform the way support for learners can be incorporated into the design and facilitation of online courses delivered at scale.", "authors": ["Linda Corrin", "Paula G. de Barba", "Aneesha Bakharia"], "session": "SESSION: Understanding student behaviour - help-seeking / search"}, {"title": "EMODA: a tutor oriented multimodal and contextual emotional dashboard", "pages": "429-438", "doi": "10.1145/3027385.3027434", "abstract": "Learners' emotional state has proven to be a key factor for successful learning. Visualizing learners' emotions during synchronous on-line learning activities can help tutors in creating and maintaining socio-affective relationships with their learners. However, few dashboards offer emotional information on the learning activity. The current study focuses on synchronous interactions via a videoconferencing tool dedicated to foreign language training. We collected data on learners' emotions in real conditions during ten sessions (five sessions for two learners). We propose to adopt and combine different models of emotions (discrete and dimensional) and to use heterogeneous APIs for measuring learners' emotions from different data sources (audio, video, self-reporting and interaction traces). Based on a thorough data analysis, we propose an approach to combine different cues to infer information on learners' emotional states. We finally present the EMODA dashboard, an affective multimodal and contextual visual analytics dashboard, which allows the tutor to monitor learners' emotions and better understand their evolution during the synchronous learning activity.", "authors": ["Mohamed Ez-zaouia", "Elise Lavou\u00e9"], "session": "SESSION: Affective learning"}, {"title": "Person-centered approach to explore learner's emotionality in learning within a 3D narrative game", "pages": "439-443", "doi": "10.1145/3027385.3027432", "abstract": "Emotions form an integral part of our cognitive function. Past research has demonstrated conclusive associations between emotions and learning achievement [7, 26, 27]. This paper used a person-centered approach to explore students' (N = 65) facial behavior, emotions, learner traits and learning. An automatic facial expression recognition system was used to detect both middle school and university students' real-time facial movements while they learned scientific tasks in a 3D narrative video game. The results indicated a strong statistical relationship between three specific facial movements (i.e., outer brow raising, lip tightening and lip pressing), student self-regulatory learning strategy and learning performance. Outer brow raising (AU2) had strong predictive power when a student is confronted with obstacles and does not know how to proceed. Both lip tightening and pressing (AU23 and AU24) were predictive when a student engaged in a task that requires a deep level of incoming information processing and short memory activation. The findings also suggested a correlational relationship between student self-regulatory learning strategy use and neutral state. It is hoped that this study will provide empirical evidence for helping us develop a deeper understanding of the relationship between facial behavior and complex learning especially in educational games.", "authors": ["Zhenhua Xu", "Earl Woodruff"], "session": "SESSION: Affective learning"}, {"title": "Using data visualizations to foster emotion regulation during self-regulated learning with advanced learning technologies: a conceptual framework", "pages": "444-448", "doi": "10.1145/3027385.3027440", "abstract": "Emotions play a critical role during learning and problem solving with advanced learning technologies (ALTs). Despite their importance, relatively few attempts have been made to understand learners' emotional monitoring and regulation by using data visualizations of their own (and others') cognitive, affective, metacognitive, and motivational (CAMM) self-regulated learning (SRL) processes to potentially foster their emotion regulation (ER). We present a theoretically based and empirically driven conceptual framework that addresses ER by proposing the use of visualizations of one's own and others' CAMM SRL multichannel data to facilitate learners' monitoring and regulation of emotions during learning with ALTs. We use an example with eye-tracking data to illustrate the mapping between theoretical assumptions, ER strategies, and the types of data visualizations that can enhance learners' ER, including key processes such as emotion flexibility, emotion adaptivity, and emotion efficacy. We conclude with future directions leading to a systematic interdisciplinary research agenda that addresses outstanding ER-related issues by integrating models, theories, methods, and analytical techniques for the cognitive, learning, and affective sciences; human- computer interaction (HCI); data visualization; big data; data mining; and SRL.", "authors": ["Roger Azevedo", "Garrett C. Millar", "Michelle Taub", "Nicholas V. Mudrick", "Amanda E. Bradbury", "Megan J. Price"], "session": "SESSION: Affective learning"}, {"title": "Strategies for data and learning analytics informed national education policies: the case of Uruguay", "pages": "449-453", "doi": "10.1145/3027385.3027444", "abstract": "This work provides an overview of an education and technology monitoring system developed at Plan Ceibal, a nationwide initiative created to enable technology enhanced learning in Uruguay. Plan Ceibal currently offers one-to-one access to technology and connectivity to every student and teacher (from primary and secondary education) as well as a comprehensive set of educational software platforms. All these resources generate massive amounts of data about the progress and style of students learning. This work introduces the conceptual framework, design and preliminary results of the Big Data Center for learning analytics currently being developed at Plan Ceibal. This initiative is focused on exploiting these datasets and conducting advanced analytics to support the educational system. To this aim, a 360 degrees profile will be built including information characterizing the user's online behavior as well as a set of technology enhanced learning factors. These profiles will be studied both at user (e.g., student or teacher) and larger scale levels (e.g., per school or school system), addressing both the need of understanding how technology is being used for learning as well as to provide accurate feedback to support evidence based educational policies.", "authors": ["Cecilia Aguerrebere", "Crist\u00f3bal Cobo", "Marcela Gomez", "Mat\u00edas Mateu"], "session": "SESSION: LA adoption - experiences"}, {"title": "Follow the successful crowd: raising MOOC completion rates through social comparison at scale", "pages": "454-463", "doi": "10.1145/3027385.3027411", "abstract": "Social comparison theory asserts that we establish our social and personal worth by comparing ourselves to others. In in-person learning environments, social comparison offers students critical feedback on how to behave and be successful. By contrast, online learning environments afford fewer social cues to facilitate social comparison. Can increased availability of such cues promote effective self-regulatory behavior and achievement in Massive Open Online Courses (MOOCs)? We developed a personalized feedback system that facilitates social comparison with previously successful learners based on an interactive visualization of multiple behavioral indicators. Across four randomized controlled trials in MOOCs (overall N = 33, 726), we find: (1) the availability of social comparison cues significantly increases completion rates, (2) this type of feedback benefits highly educated learners, and (3) learners' cultural context plays a significant role in their course engagement and achievement.", "authors": ["Dan Davis", "Ioana Jivet", "Ren\u00e9 F. Kizilcec", "Guanliang Chen", "Claudia Hauff", "Geert-Jan Houben"], "session": "SESSION: Retention"}, {"title": "Planning prompts increase and forecast course completion in massive open online courses", "pages": "464-473", "doi": "10.1145/3027385.3027416", "abstract": "Among all of the learners in Massive Open Online Courses (MOOCs) who intend to complete a course, the majority fail to do so. This intention-action gap is found in many domains of human experience, and research in similar goal pursuit domains suggests that plan-making is a cheap and effective nudge to encourage follow-through. In a natural field experiment in three HarvardX courses, some students received open-ended planning prompts at the beginning of a course. These prompts increased course completion by 29%, and payment for certificates by 40%. This effect was largest for students enrolled in traditional schools. Furthermore, the contents of students' plans could predict which students were least likely to succeed - in particular, students whose plans focused on specific times were unlikely to complete the course. Our results suggest that planning prompts can help learners adopted productive frames of mind at the outset of a learning goal that encourage and forecast student success.", "authors": ["Michael Yeomans", "Justin Reich"], "session": "SESSION: Retention"}, {"title": "From prediction to impact: evaluation of a learning analytics retention program", "pages": "474-478", "doi": "10.1145/3027385.3027405", "abstract": "Learning analytics research has often been touted as a means to address concerns regarding student retention outcomes. However, few research studies to date, have examined the impact of the implemented intervention strategies designed to address such retention challenges. Moreover, the methodological rigor of some of the existing studies has been challenged. This study evaluates the impact of a pilot retention program. The study contrasts the findings obtained by the use of different methods for analysis of the effect of the intervention. The pilot study was undertaken between 2012 and 2014 resulting in a combined enrolment of 11,160 students. A model to predict attrition was developed, drawing on data from student information system, learning management system interactions, and assessment. The predictive model identified some 1868 students as academically at-risk. Early interventions were implemented involving learning and remediation support. Common statistical methods demonstrated a positive association between the intervention and student retention. However, the effect size was low. The use of more advanced statistical methods, specifically mixed-effect methods explained higher variability in the data (over 99%), yet found the intervention had no effect on the retention outcomes. The study demonstrates that more data about individual differences is required to not only explain retention but to also develop more effective intervention approaches.", "authors": ["Shane Dawson", "Jelena Jovanovic", "Dragan Ga\u0161evi\u0107", "Abelardo Pardo"], "session": "SESSION: Retention"}, {"title": "Guidance counselor reports of the ASSISTments college prediction model (ACPM)", "pages": "479-488", "doi": "10.1145/3027385.3027435", "abstract": "Advances in the learning analytics community have created opportunities to deliver early warnings that alert teachers and instructors when a student is at risk of not meeting academic goals [6], [71]. Alert systems have also been developed for school district leaders [33] and for academic advisors in higher education [39], but other professionals in the K-12 system, namely guidance counselors, have not been widely served by these systems. In this study, we use college enrollment models created for the ASSISTments learning system [55] to develop reports that target the needs of these professionals, who often work directly with students, but usually not in classroom settings. These reports are designed to facilitate guidance counselors' efforts to help students to set long term academic and career goals. As such, they provide the calculated likelihood that a student will attend college (the ASSISTments College Prediction Model or ACPM), alongside student engagement and learning measures. Using design principles from risk communication research and student feedback theories to inform a co-design process, we developed reports that can inform guidance counselor efforts to support student achievement.", "authors": ["Jaclyn Ocumpaugh", "Ryan S. Baker", "Maria O. C. Z. San Pedro", "M. Aaron Hawn", "Cristina Heffernan", "Neil Heffernan", "Stefan A. Slater"], "session": "SESSION: Students at-risk - systems"}, {"title": "Don't call it a comeback: academic recovery and the timing of educational technology adoption", "pages": "489-493", "doi": "10.1145/3027385.3027393", "abstract": "Recent research using learning analytics data to explore student performance over the course of a term suggests that a substantial percentage of students who are classified as academically struggling manage to recover. In this study, we report the result of a hazard analysis based on students' behavioral engagement with different digital instructional technologies over the course of a semester. We observe substantially different adoption and use behavior between students who did and did not experience academic difficulty in the course. Students who experienced moderate academic difficulty benefited the most from using tools that helped them plan their study behaviors. Students who experienced more severe academic difficulty benefited from tools that helped them prepare for exams. We observed that students adopted most tools and system features before they experienced academic difficulty, and students who adopted early were more likely to recover.", "authors": ["Michael Geoffrey Brown", "R. Matthew DeMonbrun", "Stephanie D. Teasley"], "session": "SESSION: Students at-risk - systems"}, {"title": "LA policy: developing an institutional policy for learning analytics using the RAPID outcome mapping approach", "pages": "494-495", "doi": "10.1145/3027385.3029424", "abstract": "This workshop aims to promote strategic planning for learning analytics in higher education through developing institutional policies. While adoption of learning analytics is predominantly seen in small-scale and bottom-up patterns, it is believed that a systemic implementation can bring the widest impact to the education system and lasting benefits to learners. However, the success of it highly depends on the adopted strategy that meets the needs of various stakeholders and systematically pushes the institution towards achieving its targets. It is imperative to develop a learning analytics policy that ensures a practice that is valid, effective and ethical. The workshop involves two components. The first component includes a set of presentations about the state of learning analytics in higher education, drawing on results from an Australian and a European project examining institutional learning analytics policy and adoption processes. The second component is an interactive session where participants are encouraged to share their motivations for adopting learning analytics and the diversity of challenges they perceive impede analytics adoption in their institution. Using the RAPID Outcome Mapping Approach (ROMA), participants will create a draft policy that articulates how the various challenges can be addressed. This workshop aims to further develop our understanding of how learning analytics operates in an organizational system and promote a cultural change in how such analytics are adopted in higher education.", "authors": ["Yi-Shan Tsai", "Dragan Gasevic", "Pedro J. Mu\u00f1oz-Merino", "Shane Dawson"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "Writing analytics literacy: bridging from research to practice", "pages": "496-497", "doi": "10.1145/3027385.3029425", "abstract": "There is untapped potential in achieving the full impact of learning analytics through the integration of tools into practical pedagogic contexts. To meet this potential, more work must be conducted to support educators in developing learning analytics literacy. The proposed workshop addresses this need by building capacity in the learning analytics community and developing an approach to resourcing for building 'writing analytics literacy'.", "authors": ["Simon Knight", "Laura Allen", "Andrew Gibson", "Danielle McNamara", "Simon Buckingham Shum"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "Developing institutional learning analytics 'communities of transformation' to support student success", "pages": "498-499", "doi": "10.1145/3027385.3029426", "abstract": "Institutional implementation of learning analytics calls for thoughtful management of cultural change. This interactive halfday workshop responds to the LA literature describing the benefits and challenges of institutional LA implementation by offering participants an opportunity to learn about and begin planning for a program to actively engage faculty as leaders of data exploration around the theme of 'student success'. This session will share experiences from five institutions actively engaged in fostering Learning Analytics Communities (LAC) by identifying key issues, sharing lessons learned, and considering structural frameworks that are transferable to other institutional contexts. Structured discussion and activities will engage participants in developing an action plan for establishing an LAC on their own campus.", "authors": ["Leah P. Macfadyen", "Dennis Groth", "George Rehrey", "Linda Shepard", "Jim Greer", "Douglas Ward", "Caroline Bennett", "Jake Kaupp", "Marco Molinaro", "Matt Steinwachs"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "Workshop on methodology in learning analytics (MLA)", "pages": "500-501", "doi": "10.1145/3027385.3029427", "abstract": "Learning analytics is an interdisciplinary and inclusive field, a fact which makes the establishment of methodological norms both challenging and important. This community-building workshop intends to convene methodology-focused researchers to discuss new and established approaches, comment on the state of current practice, author pedagogical manuscripts, and co-develop guidelines to help move the field forward with quality and rigor.", "authors": ["Yoav Bergner", "Charles Lang", "Geraldine Gray"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "Quasi-experimental design for causal inference using Python and Apache Spark: a hands-on tutorial", "pages": "502-503", "doi": "10.1145/3027385.3029428", "abstract": "Educational practitioners and policy makers require evidence supporting claims about educational efficacy. Evidence is often found using causal relationships between education inputs and student learning outcomes. Causal inference covers a wide range of topics in education research, including efficacy studies to prove if a new policy, software, curriculum or intervention is effective in improving student learning outcomes. Randomized controlled trials (RCT) are considered a gold standard method to demonstrate causality. However, these studies are expensive, timely and costly, as well as not being ethical to conduct in many educational contexts. Causality can also be deducted purely from observational data. In this tutorial, we will review methodologies for estimating the causal effects of education inputs on student learning outcomes using observational data. This is an inherently complex task due to many hidden variables and their interrelationships in educational research. In this tutorial, we discuss causal inference in the context of educational research with big data. This is the first tutorial of its kind at Learning Analytics and Knowledge Conference (LAK) that provides a hands-on experience with Python and Apache Spark as a practical tool for educational researchers to conduct causal inference. As a prerequisite, attendees are required to have familiarity with Python.", "authors": ["Shirin Mojarad", "Nicholas Lewkow", "Alfred Essa", "Jie Zhang", "Jacqueline Feild"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "Beyond failure: the 2nd LAK Failathon", "pages": "504-505", "doi": "10.1145/3027385.3029429", "abstract": "The 2nd LAK Failathon will build on the successful event in 2016 and extend the workshop beyond discussing individual experiences of failure to exploring how the field can improve, particularly regarding the creation and use of evidence. Failure in research is an increasingly hot topic, with high-profile crises of confidence in the published research literature in medicine and psychology. Among the major factors in this research crisis are the many incentives to report and publish only positive findings. These incentives prevent the field in general from learning from negative findings, and almost entirely preclude the publication of mistakes and errors. Thus providing an alternative forum for practitioners and researchers to learn from each other's failures can be very productive. The first LAK Failathon, held in 2016, provided just such an opportunity for researchers and practitioners to share their failures and negative findings in a lower-stakes environment, to help participants learn from each other's mistakes. It was very successful, and there was strong support for running it as an annual event. This workshop will build on that success, with twin objectives to provide an environment for individuals to learn from each other's failures, and also to co-develop plans for how we as a field can better build and deploy our evidence base.", "authors": ["Doug Clow", "Rebecca Ferguson", "Kirsty Kitto", "Yong-Sang Cho", "Mike Sharkey", "Cecilia Aguerrebere"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "Workshop on integrated learning analytics of MOOC post-course development", "pages": "506-507", "doi": "10.1145/3027385.3029430", "abstract": "MOOC research is typically limited to evaluations of learner behavior in the context of the learning environment. However, some research has begun to recognize that the impact of MOOCs may extend beyond the confines of the course platform or conclusion of the course time limit. This workshop aims to encourage our community of learning analytics researchers to examine the relationship between performance and engagement within the course and learner behavior and development beyond the course. This workshop intends to build awareness in the community regarding the importance of research measuring multi-platform activity and long-term success after taking a MOOC. We hope to build the community's understanding of what it takes to operationalize MOOC learner success in a novel context by employing data traces across the social web.", "authors": ["Yuan Wang", "Dan Davis", "Guanliang Chen", "Luc Paquette"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "DesignLAK17: quality metrics and indicators for analytics of assessment design at scale", "pages": "508-509", "doi": "10.1145/3027385.3029431", "abstract": "Notions of what constitutes quality in design in traditional on-campus or online teaching and learning may not always translate into scaled digital environments. The DesignLAK17 workshop builds on the DesignLAK16 workshop to explore one aspect of this theme, namely the opportunities arising from the use of analytics in scaled assessment design. New paradigms for learning design are exploiting the distinctive characteristics and potentials of analytics, trace data and newer kinds of sensory data usable on digital platforms to transform assessment. But, characteristics of quality assessment design need to be reconsidered, and new metrics for capturing quality are required. This symposium and workshop focuses on what might be appropriate quality metrics and indicators for assessment design in scaled learning. It aims to build a community of interest round the topic, to share perspectives, and to generate design and research ideas.", "authors": ["Ulla Ringtved", "Sandra Milligan", "Linda Corrin", "Allison Littlejohn", "Nancy Law"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "2nd cross-LAK: learning analytics across physical and digital spaces", "pages": "510-511", "doi": "10.1145/3027385.3029432", "abstract": "Student's learning happens where the learner is, rather than being constrained to a single physical or digital environment. It is of high relevance for the LAK community to provide analytics support in blended learning scenarios where students can interact at diverse learning spaces and with a variety of educational tools. This workshop aims to gather the sub-community of LAK researchers, learning scientists and researchers in other areas, interested in the intersection between ubiquitous, mobile and/or classroom learning analytics. The underlying concern is how to integrate and coordinate learning analytics seeking to understand the particular pedagogical needs and context constraints to provide learning analytics support across digital and physical spaces. The goals of the workshop are to consolidate the Cross-LAK sub-community and provide a forum for idea generation that can build up further collaborations. The workshop will also serve to disseminate current work in the area by both producing proceedings of research papers and working towards a journal special issue.", "authors": ["Roberto Martinez-Maldonado", "Davinia Hernandez-Leo", "Abelardo Pardo", "Hiroaki Ogata"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "FutureLearn data: what we currently have, what we are learning and how it is demonstrating learning in MOOCs", "pages": "512-513", "doi": "10.1145/3027385.3029433", "abstract": "Compared to other platforms such as Coursera and EdX, FutureLearn is a relatively new player in the MOOC arena and received limited coverage in the Learning Analytics and Educational Data Mining research. Founded by a partnership between the Open University in the UK, the BBC, The British Library and (originally) 12 universities in the UK, FutureLearn has two distinctive features relevant to the way their data is displayed and analyzed: 1) it was designed with a specific educational philosophy in mind which focuses on the social dimension of learning and 2) every learning activity provide opportunities for formal discussion and commenting. This workshop provides an opportunity to invite contributions and connect individual and groups to share their research activities on an international stage. As the first of its kind, this workshop will bring in a number of scholars and practitioners, as well as data scientists and analyst involved in the reporting, researching and developments emerging from the data offered by the platform.", "authors": ["Lorenzo Vigentini", "Manuel Le\u00f3n Urrutia", "Ben Fields"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "LAK17 hackathon: getting the right information to the right people so they can take the right action", "pages": "514-515", "doi": "10.1145/3027385.3029435", "abstract": "The hackathon is intended to be a practical hands-on workshop involving participants from academia and commercial organizations with both technical and practitioner expertise. It will consider the outstanding challenge of visualizations which are effective for the intended audience: informing action, not likely to be misinterpreted, and embodying contextual appropriacy, etc. It will surface particular issues as workshop challenges and explore responses to these challenges as visualizations resting upon interoperability standards and API-oriented open architectures.", "authors": ["Adam Cooper", "Alan Berg", "Niall Sclater", "Tanya Dorey-Elias", "Kirsty Kitto"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "Learning analytics and policy (LAP): international aspirations, achievements and constraints", "pages": "516-517", "doi": "10.1145/3027385.3029436", "abstract": "The Learning Analytics and Policy (LAP) workshop explores and documents the ways in which policies at national and regional level are shaping the development of learning analytics. It brings together representatives from around the world who report on the circumstances in their own country. The workshop is preceded by an information gathering phase, and followed by the authoring of a report. The aspirations, achievements and constraints in the different countries are contrasted and documented, providing a valuable resource for the future development of learning analytics.", "authors": ["Megan Bowe", "Weiqin Chen", "Dai Griffiths", "Tore Hoel", "Jaeho Lee", "Hiroaki Ogata", "Griff Richards", "Li Yuan", "Jingjing Zhang"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "Current and future multimodal learning analytics data challenges", "pages": "518-519", "doi": "10.1145/3027385.3029437", "abstract": "Multimodal Learning Analytics (MMLA) captures, integrates and analyzes learning traces from different sources in order to obtain a more holistic understanding of the learning process, wherever it happens. MMLA leverages the increasingly widespread availability of diverse sensors, high-frequency data collection technologies and sophisticated machine learning and artificial intelligence techniques. The aim of this workshop is twofold: first, to expose participants to, and develop, different multimodal datasets that reflect how MMLA can bring new insights and opportunities to investigate complex learning processes and environments; second, to collaboratively identify a set of grand challenges for further MMLA research, built upon the foundations of previous workshops on the topic.", "authors": ["Daniel Spikol", "Luis P. Prieto", "M. J. Rodr\u00edguez-Triana", "Marcelo Worsley", "Xavier Ochoa", "Mutlu Cukurova", "Bahtijar Vogel", "Emanuele Ruffaldi", "Ulla Lunde Ringtved"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "Building the learning analytics curriculum: workshop", "pages": "520-521", "doi": "10.1145/3027385.3029439", "abstract": "Learning Analytics courses and degree programs both on-and offline have begun to proliferate over the last three years. As a result of this growth in interest from students, university administrators, researchers and instructors we believe it is a good time to review how these educational efforts are impacting the field, how synergy between instructors might be developed to greater serve the field and what kinds of best practices could be developed.", "authors": ["Charles Lang", "Stephanie Teasley", "John Stamper"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "Connecting data with student support actions in a course: a hands-on tutorial", "pages": "522-523", "doi": "10.1145/3027385.3029441", "abstract": "The amount of data extracted from learning experiences has grown at an astonishing pace both in depth due to the increasing variety of data sources, and in breath with courses now being offered to massive student cohorts. However, in this emerging scenario instructors are now facing the challenge of connecting the knowledge emerging from data analysis with the provision of meaningful support actions to students within the context of an instructional design. The objective of this tutorial is to give attendees a set of hypothetical scenarios in which the knowledge extracted from a learning experience needs to be used to provide frequent personalized feedback to students.", "authors": ["Abelardo Pardo", "Roberto Mart\u00ednez-Maldonado", "Simon Buckingham Shum", "Jurgen Schulte", "Simon McIntyre", "Dragan Ga\u0161evi\u0107", "Jing Gao", "George Siemens"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "Community based educational data repositories and analysis tools", "pages": "524-525", "doi": "10.1145/3027385.3029442", "abstract": "This workshop will explore community based repositories for educational data and analytic tools that are used to connect researchers and reduce the barriers to data sharing. Leading innovators in the field, as well as attendees, will identify and report on bottlenecks that remain toward our goal of a unified repository. We will discuss these as well as possible solutions. We will present LearnSphere, an NSF funded system that supports collaborating on and sharing a wide variety of educational data, learning analytics methods, and visualizations while maintaining confidentiality. We will then have hands-on sessions in which attendees have the opportunity to apply existing learning analytics workflows to their choice of educational datasets in the repository (using a simple drag-and-drop interface), add their own learning analytics workflows (requires very basic coding experience), or both. Leaders and attendees will then jointly discuss the unique benefits as well as the limitations of these solutions. Our goal is to create building blocks to allow researchers to integrate their data and analysis methods with others, in order to advance the future of learning science.", "authors": ["Ken Koedinger", "Ran Liu", "John Stamper", "Candace Thille", "Phil Pavlik"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "Student empowerment, awareness, and self-regulation through a quantified-self student tool", "pages": "526-527", "doi": "10.1145/3027385.3029434", "abstract": "The purpose of this paper is to examine the cross institutional use of a quantified-self application called Pattern, which is designed to promote self-regulation and reflective learning in learners. This paper provides a brief look into how learners report spending their time and react to in-app recommendations. Initial data is encouraging; however, there are limitations of Pattern, and additional research and development must be undertaken.", "authors": ["Kimberly E. Arnold", "Brandon Karcher", "Casey V. Wright", "James McKay"], "session": "POSTER SESSION: Posters"}, {"title": "A systematic review of studies on predicting student learning outcomes using learning analytics", "pages": "528-529", "doi": "10.1145/3027385.3029438", "abstract": "Predicting student learning outcomes is one of the prominent themes in Learning Analytics research. These studies varied to a significant extent in terms of the techniques being used, the contexts in which they were situated, and the consequent effectiveness of the prediction. This paper presented the preliminary results of a systematic review of studies in predictive learning analytics. With the goal to find out what methodologies work for what circumstances, this study will be able to facilitate future research in this area, contributing to relevant system developments that are of pedagogic values.", "authors": ["Xiao Hu", "Christy W. L. Cheong", "Wenwen Ding", "Michelle Woo"], "session": "POSTER SESSION: Posters"}, {"title": "A framework for hypothesis-driven approaches to support data-driven learning analytics in measuring computational thinking in block-based programming", "pages": "530-531", "doi": "10.1145/3027385.3029440", "abstract": "K-12 classrooms use block-based programming environments (BBPEs) for teaching computer science and computational thinking (CT). To support assessment of student learning in BBPEs, we propose a learning analytics framework that combines hypothesis- and data-driven approaches to discern students' programming strategies from BBPE log data. We use a principled approach to design assessment tasks to elicit evidence of specific CT skills. Piloting these tasks in high school classrooms enabled us to analyze student programs and video recordings of students as they built their programs. We discuss a priori patterns derived from this analysis to support data-driven analysis of log data in order to better assess understanding and use of CT in BBPEs.", "authors": ["Shuchi Grover", "Marie Bienkowski", "Satabdi Basu", "Michael Eagle", "Nicholas Diana", "John Stamper"], "session": "POSTER SESSION: Posters"}, {"title": "Dear learner: participatory visualisation of learning data for sensemaking", "pages": "532-533", "doi": "10.1145/3027385.3029443", "abstract": "We discuss the application of a hand-drawn self-visualization approach to learner-data, to draw attention to the space of representational possibilities, the power of representation interactions, and the performativity of information representation.", "authors": ["Simon Knight", "Theresa Anderson", "Kelly Tall"], "session": "POSTER SESSION: Posters"}, {"title": "Video annotation tool for learning job interview", "pages": "534-535", "doi": "10.1145/3027385.3029444", "abstract": "In this paper, video annotation tool for learning job interview is proposed. To visualize the difference of obtained descriptions, the proposed tool uses correspondence analysis. The results of correspondence analysis are used to give feedback to learners. By the results, the learner can understand the characteristics of his/her descriptions among the others.", "authors": ["Yoshitomo Yaginuma", "Masako Furukawa", "Tsuneo Yamada"], "session": "POSTER SESSION: Posters"}, {"title": "Reproducibility of findings from educational big data: a preliminary study", "pages": "536-537", "doi": "10.1145/3027385.3029445", "abstract": "In this paper, we examined whether previous findings on educational big data consisting of e-book logs from a given academic course can be reproduced with different data from other academic courses. The previous findings showed that (1) students who attained consistently good achievement more frequently browsed different e-books and their pages than low achievers and that (2) this difference was found only for logs of preparation for course sessions (preview), not for reviewing material (review). Preliminarily, we analyzed e-book logs from four courses. The results were reproduced in only one course and only partially, that is, (1) high achievers more frequently changed e-books than low achievers (2) for preview. This finding suggests that to allow effective usage of learning and teaching analyses, we need to carefully construct an educational environment to ensure reproducibility.", "authors": ["Misato Oi", "Masanori Yamada", "Fumiya Okubo", "Atsushi Shimada", "Hiroaki Ogata"], "session": "POSTER SESSION: Posters"}, {"title": "Large scale predictive process mining and analytics of university degree course data", "pages": "538-539", "doi": "10.1145/3027385.3029446", "abstract": "For students, in particular freshmen, the degree pathway from semester to semester is not that transparent, although students have a reasonable idea what courses are expected to be taken each semester. An often-pondered question by students is: \"what can I expect in the next semester?\" More precisely, given the commitment and engagement I presented in this particular course and the respective performance I achieved, can I expect a similar outcome in the next semester in the particular course I selected? Are the demands and expectations in this course much higher so that I need to adjust my commitment and engagement and overall workload if I expect a similar outcome? Is it better to drop a course to manage expectations rather than to (predictably) fail, and perhaps have to leave the degree altogether? Degree and course advisors and student support units find it challenging to provide evidence based advise to students. This paper presents research into educational process mining and student data analytics in a whole university scale approach with the aim of providing insight into the degree pathway questions raised above. The beta-version of our course level degree pathway tool has been used to shed light for university staff and students alike into our university's 1,300 degrees and associated 6 million course enrolments over the past 20 years.", "authors": ["Jurgen Schulte", "Pedro Fernandez de Mendonca", "Roberto Martinez-Maldonado", "Simon Buckingham Shum"], "session": "POSTER SESSION: Posters"}, {"title": "Beyond failure: the 2nd LAK Failathon poster", "pages": "540-541", "doi": "10.1145/3027385.3029447", "abstract": "This poster will be a chance for a wider LAK audience to engage with the 2nd LAK Failathon workshop. Both of these will build on the successful Failathon event in 2016 and extend beyond discussing individual experiences of failure to exploring how the field can improve, particularly regarding the creation and use of evidence. Failure in research is an increasingly hot topic, with high-profile crises of confidence in the published research literature in medicine and psychology. Among the major factors in this research crisis are the many incentives to report and publish only positive findings. These incentives prevent the field in general from learning from negative findings, and almost entirely preclude the publication of mistakes and errors. Thus providing an alternative forum for practitioners and researchers to learn from each other's failures can be very productive. The first LAK Failathon, held in 2016, provided just such an opportunity for researchers and practitioners to share their failures and negative findings in a lower-stakes environment, to help participants learn from each other's mistakes. It was very successful, and there was strong support for running it as an annual event. The 2nd LAK Failathon workshop will build on that success, with twin objectives to provide an environment for individuals to learn from each other's failures, and also to co-develop plans for how we as a field can better build and deploy our evidence base. This poster is an opportunity for wider feedback on the plans developed in the workshop, with interactive use of sticky notes to add new ideas and coloured dots to illustrate prioritisation. This broadens the participant base in this important work, which should improve the quality of the plans and the commitment of the community to delivering them.", "authors": ["Doug Clow", "Rebecca Ferguson", "Kirsty Kitto", "Yong-Sang Cho", "Mike Sharkey", "Cecilia Aguerrebere"], "session": "POSTER SESSION: Posters"}, {"title": "Examining motivations and self-regulated learning strategies of returning MOOCs learners", "pages": "542-543", "doi": "10.1145/3027385.3029448", "abstract": "The present study examines behavioral patterns, motivations, and self-regulated learning strategies of returning learners---a special learner subpopulation in massive open online courses (MOOCs). To this end, data were collected from a teacher professional development MOOC that has been offered for seven iterations during 2014--2016. Data analysis identified more than 15% of all registrants as returning learners. Findings from click log analysis identified possible motivations of re-enrollment including improving grades, refreshing theoretical understanding, and solving practical problems. Further analysis uncovered evidence of self-regulated learning strategies among returning learners. Taken together, this study contributes to ongoing inquiry into MOOCs learning pathways, informs future MOOC design, and sheds light on the exploration of MOOCs as a viable option for teacher professional development.", "authors": ["Bodong Chen", "Yizhou Fan", "Guogang Zhang", "Qiong Wang"], "session": "POSTER SESSION: Posters"}, {"title": "Learning from learning curves: discovering interpretable learning trajectories", "pages": "544-545", "doi": "10.1145/3027385.3029449", "abstract": "We propose a data driven method for decomposing population level learning curve models into mutually exclusive distinctive groups each consisting of similar learning trajectories. We validate this method on six knowledge components from the log data from an online tutoring system ASSIST-ment. Preliminary analysis reveals interpretable patterns of \"skill growth\" that correlate with students' performance in the subsequently administered state standardized tests.", "authors": ["Lujie Chen", "Artur Dubrawski"], "session": "POSTER SESSION: Posters"}, {"title": "Utilizing visualization and feature selection methods to identify important learning objectives in a course", "pages": "546-547", "doi": "10.1145/3027385.3029450", "abstract": "There have been numerous efforts to increase students' academic success. One data-driven approach is to highlight the important learning objectives in a course. In this paper, we used visualization and three feature selection methods to highlight the important learning objectives in a course. Identifying important learning objectives as well as the relation among the learning objectives have multiple educational advantages. First, it informs the instructors and students of the important topics in the course; without learning them properly students will not be successful. Second, it highlights any inconsistencies in defining the learning objective, how they are being assessed, and design of the course. Thus, this approach can be used as a course design diagnostic tool.", "authors": ["Farshid Marbouti", "Heidi Diefes-Dux", "Krishna Madhavan"], "session": "POSTER SESSION: Posters"}, {"title": "How can we accelerate dissemination of knowledge and learning?: developing an online knowledge management platform for networked improvement communities", "pages": "548-549", "doi": "10.1145/3027385.3029451", "abstract": "The Networked Improvement Learning and Support (NILS) platform is an online tool designed to accelerate the initiation and development of Networked Improvement Communities in a disciplined manner. Its main goal is to promote social, organizational learning through curation and synthesis and tacit to explicit knowledge conversion to facilitate knowledge construction and ownership by the communities regarding improvement practice in education. In this proposal we will discuss the NILS platform, a few use cases, and a plan of analytics development that advances knowledge dissemination and monitors the health status of networks.", "authors": ["Ouajdi Manai", "Hiroyuki Yamada"], "session": "POSTER SESSION: Posters"}, {"title": "Students' emotional self-labels for personalized models", "pages": "550-551", "doi": "10.1145/3027385.3029452", "abstract": "There are some implementations towards understanding students' emotional states through automated systems with machine learning models. However, generic AI models of emotions lack enough accuracy to autonomously and meaningfully trigger any interventions. Collecting self-labels from students as they assess their internal states can be a way to collect labeled subject specific data necessary to obtain personalized emotional engagement models. In this paper, we outline preliminary analysis on emotional self-labels collected from students while using a learning platform.", "authors": ["Sinem Aslan", "Eda Okur", "Nese Alyuz", "Sinem Emine Mete", "Ece Oktay", "Utku Genc", "Asli Arslan Esme"], "session": "POSTER SESSION: Posters"}, {"title": "Write-and-learn: promoting meaningful learning through concept map-based formative feedback on writing assignments", "pages": "552-553", "doi": "10.1145/3027385.3029453", "abstract": "A primary goal of higher education is to promote meaningful learning: the delivery of core academic content to students in innovative ways that allow them to learn and then apply what they have learned. As a pedagogical strategy, Writing-to-Learn (WTL) intends to use writing to improve students' understanding of course content and concepts. To improve students' meaningful learning of conceptual knowledge in WTL activities, the project proposes to develop the Write-and-Learn system to generate automated formative feedback by taking advantage of the concept maps constructed from instructors' lecture notes and individual students' writing assignments. The proposed research aims to provide insights into how to apply concept maps into WTL activities to generate effective formative feedback on the acquisition and development of conceptual knowledge, and explore how and to what extent concept map-based formative feedback can be utilized to scaffold and promote meaningful learning in WTL activities.", "authors": ["Ye Xiong", "Yi-Fang Brook Wu"], "session": "POSTER SESSION: Posters"}, {"title": "Data-assisted instructional video revision via course-level exploratory video retention analysis", "pages": "554-555", "doi": "10.1145/3027385.3029454", "abstract": "Since teachers are not physically present in an online class, instructional video is the major carrier of course contents in an online learning environment. This paper aims to investigate how course-level exploratory video retention analysis can be used for identifying moments with abnormal watching behaviors and revising videos for a higher video retention. We have empirically evaluated the effectiveness of video analysis and revisions, based on evaluating retentions of revised videos.", "authors": ["Chi-Un Lei", "Donn Gonda", "Xiangyu Hou", "Elizabeth Oh", "Xinyu Qi", "Tyrone T. O. Kwok", "Yip-Chun Au Yeung", "Ray Lau"], "session": "POSTER SESSION: Posters"}, {"title": "Using predictive analytics in a self-regulated learning university course to promote student success", "pages": "556-557", "doi": "10.1145/3027385.3029455", "abstract": "Prior research offers evidence that differing levels of student engagement are associated with different outcomes in terms of performance. In this study, we investigating the efficacy of a model of behavioural and agentic engagement to predict student performance (low, middle, high) at four timepoints in a semester. The model was significant at all four timepoints. Measures of behavioural and agentic engagement predicted membership across the three groups differently. With a few exceptions, these differences were consistent across timepoints. Looking at variations in student engagement across time can be used to target interventions to support student success at the undergraduate level.", "authors": ["Rebecca L. Edwards", "Sarah K. Davis", "Allyson F. Hadwin", "Todd M. Milford"], "session": "POSTER SESSION: Posters"}, {"title": "What are visitors up to?: helping museum facilitators know what visitors are doing", "pages": "558-559", "doi": "10.1145/3027385.3029456", "abstract": "In this paper, we describe a tablet application designed around an interactive game-based science museum exhibit. It is aimed to help provide museum docents useful information about the visitors' actions, in a way that is actionable, and enables docents to provide assistance and prompts to visitors that are more meaningful, compared to what they are typically able to do without this interface augmentation.", "authors": ["Vishesh Kumar", "Mike Tissenbaum", "Matthew Berland"], "session": "POSTER SESSION: Posters"}, {"title": "Predicting e-textbook adoption based on event segmentation of teachers' usage", "pages": "560-561", "doi": "10.1145/3027385.3029457", "abstract": "Customized content of e-textbook require teachers to spend greater efforts using authoring tools and planning activities before class, and teachers with various contexts have different demands on e-textbook. However, some teachers who lack ICT skills and dissatisfy with the features tend to give up using e-textbook. Thus we need to know the status of teachers' usage earlier before we decide to give them some technical supports. This paper describes an analysis method for predicting e-textbook adoption from usage records in early days, and an event segmentation method of teachers' usage is used in effort to provide features of predictive model.", "authors": ["Longwei Zheng", "Wei Gong", "Xiaoqing Gu"], "session": "POSTER SESSION: Posters"}, {"title": "Business intelligence (BI) for personalized student dashboards", "pages": "562-563", "doi": "10.1145/3027385.3029458", "abstract": "At Stenden University students from all over the world study together; all these different nationalities and cultures result in different ideas concerning academic success. The basis of this project was to develop a personalized dashboard for students via Microsoft Office 365 Power BI in which students can set their own personal KPI's. The raw data from the Student Information System (SIS) was transformed into clear visualizations that will help students gain better insight into their academic performance. This information can be used either independently or in consultation with their student advisor.", "authors": ["J. Sluijter", "M. Otten"], "session": "POSTER SESSION: Posters"}, {"title": "When learning is high stake", "pages": "564-565", "doi": "10.1145/3027385.3029461", "abstract": "Firefighter learning is high stake. They need to maintain certain competence levels related to physical, mental, and firefighting and rescue skills in order to provide the public with a high level of emergency service. Fire and Rescue Services need to maintain an overview of the current competences of their personnel and to react when there is a competence gap. This poster presents our approach to using competence modelling, learner models, learning analytics, and visualisations in order provide insight into competence status and development on the individual, team, and organisation level, and to provide early-alerts and automated messages to instructors responsible for planning training activities, as well as to team leaders responsible for making decisions about teams in high stakes situations.", "authors": ["Cecilie Johanne Slokvik Hansen", "Barbara Wasson", "Hans Skretting", "Grete Netteland", "Marina Hirnstein"], "session": "POSTER SESSION: Posters"}, {"title": "Mining knowledge components from many untagged questions", "pages": "566-567", "doi": "10.1145/3027385.3029462", "abstract": "An ongoing study is being run to ensure that the McGraw-Hill Education LearnSmart platform teaches students as efficiently as possible. The first step in doing so is to identify what Knowledge Components (KCs) exist in the content; while the content is tagged by experts, these tags need to be re-calibrated periodically. LearnSmart courses are organized into chapters corresponding to those found in a textbook; each chapter can have anywhere from about a hundred to a few thousand questions. The KC extraction algorithms proposed by Barnes [1] and Desmarais et al [3] are applied on a chapter-by-chapter basis. To assess the ability of each mined q matrix to describe the observed learning, the PFA model of Pavlik et al [4] is fitted to it and a cross-validated AUC is calculated. The models are assessed based on whether PFA's predictions of student correctness are accurate. Early results show that both algorithms do a reasonable job of describing student progress, but q matrices with very different numbers of KCs fit observed data similarly well. Consequently, further consideration is required before automated extraction is practical in this context.", "authors": ["Neil L. Zimmerman", "Ryan S. Baker"], "session": "POSTER SESSION: Posters"}, {"title": "Relevance of learning analytics to measure and support students' learning in adaptive educational technologies", "pages": "568-569", "doi": "10.1145/3027385.3029463", "abstract": "In this poster, we describe the aim and current activities of the EARLI-Centre for Innovative Research (E-CIR) \"Measuring and Supporting Student's Self-Regulated Learning in Adaptive Educational Technologies\" which is funded by the European Association for Research on Learning and Instruction (EARLI) from 2015 to 2019. The aim is to develop our understanding of multimodal data that unobtrusively capture cognitive, meta-cognitive, affective and motivational states of learners over time. This demands for a concerted interdisciplinary dialogue combining findings from psychology and educational sciences with advances in computer sciences and artificial intelligence. The participants in this E-CIR are leading international researchers who have articulated different emerging perspectives and methodologies to measure cognition, metacognition, motivation, and emotions during learning. The participants recognize the need for intensive collaboration to accelerate progress with new interdisciplinary methods including learning analytics to develop more powerful adaptive educational technologies.", "authors": ["Maria Bannert", "Inge Molenaar", "Roger Azevedo", "Sanna J\u00e4rvel\u00e4", "Dragan Ga\u0161evi\u0107"], "session": "POSTER SESSION: Posters"}, {"title": "Exploring the measurement of collaborative problem solving using a human-agent educational game", "pages": "570-571", "doi": "10.1145/3027385.3029464", "abstract": "Collaborative problem solving (CPS) is a process that relies on both cognitive and social skills contributions by those involved in the joint activity. If a student is matched with a problematic group of peers, then there will be no valid measurement of the CPS skills. In the human-agent settings, CPS skills are measured by pairing each individual student with a computer agent or agents that can be programmed to act as team members with varying characteristics relevant to different CPS skills and contexts. This paper describes current research on measuring CPS skills through human-agent interactions in a prototype of a collaborative educational game.", "authors": ["Kristin Stoeffler", "Yigal Rosen", "Alina von Davier"], "session": "POSTER SESSION: Posters"}, {"title": "Cooking with learning analytics recipes", "pages": "572-573", "doi": "10.1145/3027385.3029465", "abstract": "Learning Analytics is a melting pot for a multitude of research fields and origin of many developments about learning and its environment. There is a serious hype over the concepts of learning analytics, however, concrete solutions and applications are comparably scarce. Of course, data rich environments, such as MOOCs, come with statistical analytics dashboards, although the educational value is often limited. Practical solutions for scenarios in data-lean environments or for small-scale organizations are rarely adopted. The LA4S project is dedicated to gather practical solutions, provide a tool box for practitioners, and publish a cook book with concrete learning analytics recipes for everyone.", "authors": ["Roope Jaakonm\u00e4ki", "Hendrik Drachsler", "Michael Kickmeier-Rust", "Stefan Dietze", "Albrecht Fortenbacher", "Ivana Marenzi"], "session": "POSTER SESSION: Posters"}, {"title": "Using item response theory to generate an item pool for an e-learning-system", "pages": "574-575", "doi": "10.1145/3027385.3029466", "abstract": "This paper1 demonstrates how the application of item response theory yields useful item characteristics, which further can be the foundation of item pools and therefore adaptive educational software to come.", "authors": ["M. Schweighart"], "session": "POSTER SESSION: Posters"}, {"title": "Forecasting student outcomes at university-wide scale using machine learning", "pages": "576-577", "doi": "10.1145/3027385.3029467", "abstract": "Elements of applied statistics and computer science are quickly integrating and being applied to a diverse set of problems in academia and industry. Here I explore the potential value of this multi-disciplinary approach to applications in higher education by applying it to forecasting course level outcomes for individual students at all of Penn State's campuses. Utilizing hundreds of data sources on individual students, ranging from past performance to current course engagement, I demonstrate the potential accuracy of forecasting techniques at identifying high risk students early in the course term. Our preliminary results suggest that %50 of students that earned a D or F in 2015 could have been identified prior to the start of the course.", "authors": ["Drew Wham"], "session": "POSTER SESSION: Posters"}, {"title": "Buying time: enabling learners to become earners with a real-world paid task recommender system", "pages": "578-579", "doi": "10.1145/3027385.3029469", "abstract": "Massive Open Online Courses (MOOCs) aim to educate the world, especially learners from developing countries. While MOOCs are certainly available to the masses, they are not yet fully accessible. Although all course content is just clicks away, deeply engaging with a MOOC requires a substantial time commitment, which frequently becomes a barrier to success. To mitigate the time required to learn from a MOOC, we here introduce a design that enables learners to earn money by applying what they learn in the course to real-world marketplace tasks. We present a Paid Task Recommender System (Rec-$ys), which automatically recommends course-relevant tasks to learners as drawn from online freelance platforms. Rec-$ys has been deployed into a data analysis MOOC and is currently under evaluation.", "authors": ["Guanliang Chen", "Dan Davis", "Markus Krause", "Claudia Hauff", "Geert-Jan Houben"], "session": "POSTER SESSION: Posters"}, {"title": "Discourse analysis to improve the effective engagement of MOOC videos", "pages": "580-581", "doi": "10.1145/3027385.3029470", "abstract": "Lecture videos are amongst the most commonly used instructional methods in present Massive Open Online Courses (MOOCs). As the main form of instruction, students' engagement behaviour with MOOC videos directly impacts the students' success or failure. This research focuses on an in-depth analysis of 1.5 million video interactions (e.g. pause, seek video) of a Programming MOOC. Our video-by-video analysis explores the rationale behind the time-wise variation of video interactions. We aim to analyse discourse features (e.g. syntactic simplicity of text, and speaking rate) and their correlation with the video interaction patterns. This paper presents preliminary results and educational video design implications.", "authors": ["Thushari Atapattu", "Katrina Falkner"], "session": "POSTER SESSION: Posters"}, {"title": "Understanding the relationship between technology use and cognitive presence in MOOCs", "pages": "582-583", "doi": "10.1145/3027385.3029471", "abstract": "In this poster, we present the results of the study which examined the relationship between student differences in their use of the available technology and their perceived levels of cognitive presence within the MOOC context. The cognitive presence is a construct used to measure the level of practical inquiry in the Communities of Inquiry model. Our results revealed the existence of three clusters based on student technology use. The clusters significantly differed in terms of their levels of cognitive presence, most notably they differed on the levels of problem resolution.", "authors": ["Vitomir Kovanovi\u0107", "Sre\u0107ko Joksimovi\u0107", "Oleksandra Poquet", "Thieme Hennis", "Shane Dawson", "Dragan Ga\u0161evi\u0107", "Pieter de Vries", "Marek Hatala", "George Siemens"], "session": "POSTER SESSION: Posters"}, {"title": "Supporting learning analytics in computing education", "pages": "584-585", "doi": "10.1145/3027385.3029472", "abstract": "As is the case for many undergraduate STEM degree programs, computing degree programs are plagued by high attrition rates. This is especially true in early computing courses, in which failure and drop-out rates in the 35 to 50 percent range are common. By collecting learning process data as students engage in computer programming assignments, computing educators can place themselves in a position not only to better understand students' struggles, but also to better tailor instructional interventions to students' needs. We have developed OSBLE+, a learning management and analytics environment that interfaces with a computer programming environment to support the automatic collection of learners' programming process and social data as they work on programming assignments, while also providing an interactive environment for the analysis and visualization of those data. In ongoing work, we are using OSBLE+ to explore two possibilities: (a) leveraging learning and social data to strategically deliver automated learning interventions, and (b) presenting learners with visual representations of their learning data in order to prompt them to reflect on and discuss their learning processes.", "authors": ["Daniel M. Olivares", "Christopher D. Hundhausen"], "session": "POSTER SESSION: Posters"}, {"title": "Integrating syllabus data into student success models", "pages": "586-587", "doi": "10.1145/3027385.3029473", "abstract": "In this work, we present (1) a methodology for collecting, evaluating, and utilizing human-annotated data about course syllabi in predictive models of student success, and (2) an empirical analysis of the predictiveness of such features as they relate to others in modeling end-of-course grades in traditional higher education courses. We present a two-stage approach to (1) that addresses several challenges unique to the annotation task, and address (2) using variable importance metrics from a series of exploratory models. We demonstrate that the process of supplementing traditional course data with human-annotated data can potentially improve predictive models with information not contained in university records, and highlight specific features that demonstrate these potential information gains.", "authors": ["Josh Gardner", "Ogechi Onuoha", "Christopher Brooks"], "session": "POSTER SESSION: Posters"}, {"title": "Tracing physical movement during practice-based learning through multimodal learning analytics", "pages": "588-589", "doi": "10.1145/3027385.3029474", "abstract": "In this paper, we pose the question, can the tracking and analysis of the physical movements of students and teachers within a Practice-Based Learning (PBL) environment reveal information about the learning process that is relevant and informative to Learning Analytics (LA) implementations? Using the example of trials conducted in the design of a LA system, we aim to show how the analysis of physical movement from a macro level can help to enrich our understanding of what is happening in the classroom. The results suggest that Multimodal Learning Analytics (MMLA) could be used to generate valuable information about the human factors of the collaborative learning process and we propose how this information could assist in the provision of relevant supports for small group work. More research is needed to confirm the initial findings with larger sample sizes and refine the data capture and analysis methodology to allow automation.", "authors": ["Donal Healion", "Sam Russell", "Mutlu Cukurova", "Daniel Spikol"], "session": "POSTER SESSION: Posters"}, {"title": "Automating student survey reports in online education for faculty and instructional designers", "pages": "590-591", "doi": "10.1145/3027385.3029475", "abstract": "In this paper, we discuss Colorado State University Online's progress toward designing automated survey reports for student feedback data collected through our newly designed LTI survey tool. Using multiple R packages, including 'rmarkdown' and 'likert', the reporting tool imports student survey response data and generates reports for faculty and instructional designers. These reports focus on student perceptions of communication, course design, academic challenge, general satisfaction, and more. These reports display visual representations of the Likert-type response frequencies, basic descriptive statistics, and free-response comments. Surveys are administered just before half-way through the semester to provide formative feedback and just before the end of the semester to provide summative feedback. In this way, faculty and instructional designers can obtain a quick and easily digestible report to make changes and improvements to their classes with minimal effort in the back end production.", "authors": ["Sean Burns", "Kimberley Corwin"], "session": "POSTER SESSION: Posters"}, {"title": "[LISA] learning analytics for sensor-based adaptive learning", "pages": "592-593", "doi": "10.1145/3027385.3029476", "abstract": "This paper reports on research conducted in a project named LISA which aims at supporting learners through learner-centered learning analytics using physiological sensor data as well as environmental sensors. We present the concept and a prototypical realization of a mobile sensor device used in LISA.", "authors": ["Albrecht Fortenbacher", "Niels Pinkwart", "Haeseon Yun"], "session": "POSTER SESSION: Posters"}, {"title": "What does student writing tell us about their thinking on social justice?", "pages": "594-595", "doi": "10.1145/3027385.3029477", "abstract": "In this work we investigate the use of deep learning for text analysis to measure elements of student thinking related to issues of privilege, oppression, diversity and social justice. We leverage historical expert annotations as well as a large lexical model to create a more generalizable vocabulary for identifying these characteristics in short student writing. We demonstrate the feasibility of this approach, and identify further areas for research.", "authors": ["Heeryung Choi", "Christopher Brooks", "Kevyn Collins-Thompson"], "session": "POSTER SESSION: Posters"}, {"title": "MORPH: supporting the integration of learning analytics at institutional level", "pages": "596-597", "doi": "10.1145/3027385.3029478", "abstract": "While there is high potential in using learning analytics to provide educational institutions as well as teachers and learners with actionable information and improve learning experiences, currently only very few learning analytics tools are actually used in educational institutions. In this paper, we introduce MORPH, a platform that facilitates the integration of learning analytics modules and tools into institutional learning systems. MORPH provides a robust distributed architecture which combines batch, stream and real-time data processing using a parallel processing model to enable and support efficient processing of large amounts of data. Furthermore, it provides common management and administration features that enable the seamless integration of learning analytics research modules and tools into existing institutional learning systems.", "authors": ["Zoran Jeremic", "Vive Kumar", "Sabine Graf"], "session": "POSTER SESSION: Posters"}, {"title": "A neural network approach for students' performance prediction", "pages": "598-599", "doi": "10.1145/3027385.3029479", "abstract": "In this paper, we propose a method for predicting final grades of students by a Recurrent Neural Network (RNN) from the log data stored in the educational systems. We applied this method to the log data from 108 students and examined the accuracy of prediction. From the experimental results, comparing with multiple regression analysis, it is confirmed that an RNN is effective to early prediction of final grades.", "authors": ["F. Okubo", "T. Yamashita", "A. Shimada", "H. Ogata"], "session": "POSTER SESSION: Posters"}, {"title": "Challenges and opportunities facing educational discourse researchers", "pages": "600-601", "doi": "10.1145/3027385.3029480", "abstract": "The scholarly investigation of discourse in teaching and learning is multi-disciplinary, theoretically rich, and highly technical. Researchers with backgrounds in education, cognitive psychology, computer science, and the social sciences apply a diverse set of techniques to understand how student discussions affect learning. Aided by big data coming from learning content management and massive open online course systems, these researchers have an unparalleled opportunity for insight into the teaching and learning process. In this paper we summarize some of the challenges and opportunities arising out of three workshops on Educational Discourse. These workshops convened both expert and emerging scholars to discuss the (i) ethical, (ii) technical, and (iii) infrastructure barriers to building a research community focused on computer-mediated educational discourse. Of particular note is that while computational infrastructure exists for storing and manipulating educational discourse, there is a need for a sociotechnical infrastructure upon which community members can come together to engage in joint work.", "authors": ["Christopher Brooks", "Stephanie Teasley", "George Siemens"], "session": "POSTER SESSION: Posters"}, {"title": "Using learning analytics in iterative design of a digital modeling tool", "pages": "602-603", "doi": "10.1145/3027385.3029482", "abstract": "Iterative design is a powerful method for developing digital classroom tools and curricula. We explore how infusing learning analytics into this process has influenced our development of EcoSurvey, a digital modeling tool for mapping the organisms and interactions in the local ecosystem. We have found that analytic techniques can help us discover areas in which students struggle to engage with scientific modeling, and we can iteratively use learning analytics to demonstrate the impact of design changes.", "authors": ["David Quigley", "Conor McNamara", "Tamara Sumner"], "session": "POSTER SESSION: Posters"}, {"title": "An outcome-based dashboard for moodle and Open edX", "pages": "604-605", "doi": "10.1145/3027385.3029483", "abstract": "This poster presents a cross-platform learning analytics dashboard on Moodle and Open edX for monitoring outcome-based learning progress. The dashboard visualizes students' interactions with the platforms in near real-time, aiming to help teachers and students monitor students' learning progress. The dashboard has been used in four large-size general education courses in a comprehensive university in Hong Kong, undergoing evaluation and improvement.", "authors": ["Xiao Hu", "Xiangyu Hou", "Chi-Un Lei", "Chengrui Yang", "Jeremy Ng"], "session": "POSTER SESSION: Posters"}, {"title": "Automated analysis of aspects of written argumentation", "pages": "606-607", "doi": "10.1145/3027385.3029484", "abstract": "In this paper, we report on a model that uses a mathematically and cognitively augmented Latent Semantic Analysis method to automatically assess aspects of written argumentation, produced by students in a science communication course.", "authors": ["Noureddine Elouazizi", "G\u00fclnur Birol", "Eric Jandciu", "Gunilla \u00d6berg", "Ashley Welsh", "Andrea Han", "Alice Campbell"], "session": "POSTER SESSION: Posters"}, {"title": "An automatic approach for discovering skill relationship from learning data", "pages": "608-609", "doi": "10.1145/3027385.3029485", "abstract": "We have developed a method called skill2vec, which applies big data techniques to automatically analyze the learning data to discover skill relationship, leading to a more objective and data-informed decision making. Skill2vec is a neural network architecture which can transform a skill to a new vector space called embedding. The embedding can facilitate the comparison and visualization of different skills and their relationship. We conducted a pilot experiment using benchmark dataset to demonstrate the effectiveness of our method.", "authors": ["Tak-Lam Wong", "Haoran Xie", "Fu Lee Wang", "Chung Keung Poon", "Di Zou"], "session": "POSTER SESSION: Posters"}, {"title": "Topic models to support instructors in MOOC forums", "pages": "610-611", "doi": "10.1145/3027385.3029486", "abstract": "This paper explores the potential of using na\u00efve topic modeling to support instructors in navigating MOOC discussion forums. Categorizing discussion threads into topics can provide an overview of the discussion, improve navigation of the forum, and support replying to a representative sample of content related posts. We investigate four different approaches to using topic models to organize and present discussion posts, highlighting the strength and weaknesses of each approach to support instructors.", "authors": ["Jovita M. Vytasek", "Alyssa F. Wise", "Sonya Woloshen"], "session": "POSTER SESSION: Posters"}, {"title": "Best intentions: learner feedback on learning analytics visualization design", "pages": "612-613", "doi": "10.1145/3027385.3029487", "abstract": "A mixed methods approach was undertaken in this exploratory study to better understand how learners perceive and utilize learning analytics visualizations during online discussions activities. Internal conditions such as goal orientation and numeracy were measured alongside the external conditions created by the discussion structure and learning analytics. Our results emphasize key factors that should be considered when designing learning analytics tools.", "authors": ["Halimat Alabi", "Marek Hatala"], "session": "POSTER SESSION: Posters"}, {"title": "The effects of a learning analytics empowered technology on students' arithmetic skill development", "pages": "614-615", "doi": "10.1145/3027385.3029488", "abstract": "Learning analytics empowered educational technologies (LA-ET) in primary classrooms allow for blended learning scenarios with teacher-lead instructions, class-paced and individually-paced practice. This quasi-experimental study investigates the effects of a LA-ET on the development of students' arithmetic skills over one schoolyear. Children learning in a traditional paper & pencil condition were compared to learners using a LA-ET on tablet computers in grade 4. The educational technology combined teacher dashboards (extracted analytics) and class and individually paced assignments (embedded analytics). The results indicated that children in the LA-ET condition made significantly more progress on arithmetic skills in one schoolyear compared to children in the paper & pencil condition.", "authors": ["Inge Molenaar", "Carolien A. N. Knoop-van Campen", "Fred Hasselman"], "session": "POSTER SESSION: Posters"}, {"title": "New features in Wikiglass, a learning analytic tool for visualizing collaborative work on wikis", "pages": "616-617", "doi": "10.1145/3027385.3029489", "abstract": "Wikiglass is a learning analytic tool for visualizing collaborative work on Wikis built by groups of secondary or primary school students. This poster presents new features of Wikiglass developed recently based on requests from teachers, including flexible selection of date range, revision network, and thinking order detection. Currently the new features are used and evaluated in two secondary schools in Hong Kong.", "authors": ["Xiao Hu", "Chengrui Yang", "Chen Qiao", "Xiaoyu Lu", "Sam K. W. Chu"], "session": "POSTER SESSION: Posters"}]