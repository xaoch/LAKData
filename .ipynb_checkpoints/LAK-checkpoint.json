[{"year": 2011, "papers": [{"title": "Learnometrics: metrics for learning objects", "pages": "1-8", "doi": "10.1145/2090116.2090117", "abstract": "The field of Technology Enhanced Learning (TEL) in general, has the potential to solve one of the most important challenges of our time: enable everyone to learn anything, anytime, anywhere. However, if we look back at more than 50 years of research in TEL, it is not clear where we are in terms of reaching our goal and whether we are, indeed, moving forward. The pace at which technology and new ideas evolve have created a rapid, even exponential, rate of change. This rapid change, together with the natural difficulty to measure the impact of technology in something as complex as learning, has lead to a field with abundance of new, good ideas and scarcity of evaluation studies. This lack of evaluation has resulted into the duplication of efforts and a sense of no \"ground truth\" or \"basic theory' of TEL. This article is an attempt to stop, look back and measure, if not the impact, at least the status of a small fraction of TEL, Learning Object Technologies, in the real world. The measured apparent inexistence of the reuse paradox, the two phase linear growth of repositories or the ineffective metadata quality assessment of humans are clear reminders that even bright theoretical discussions do not compensate the lack of experimentation and measurement. Both theoretical and empirical studies should go hand in hand in order to advance the status of the field. This article is an invitation to other researchers in the field to apply Informetric techniques to measure, understand and apply in their tools the vast amount of information generated by the usage of Technology Enhanced Learning systems.", "authors": ["Xavier Ochoa"], "session": "None"}, {"title": "Attention please!: learning analytics for visualization and recommendation", "pages": "9-17", "doi": "10.1145/2090116.2090118", "abstract": "This paper will present the general goal of and inspiration for our work on learning analytics, that relies on attention metadata for visualization and recommendation. Through information visualization techniques, we can provide a dashboard for learners and teachers, so that they no longer need to \"drive blind\". Moreover, recommendation can help to deal with the \"paradox of choice\" and turn abundance from a problem into an asset for learning.", "authors": ["Erik Duval"], "session": "None"}, {"title": "Learning networks, crowds and communities", "pages": "18-22", "doi": "10.1145/2090116.2090119", "abstract": "Who we learn from, where and when is dramatically affected by the reach of the Internet. From learning for formal education to learning for pleasure, we look to the web early and often for our data and knowledge needs, but also for places and spaces where we can collaborate, contribute to, and create learning and knowledge communities. Based on the keynote presentation given at the first Learning Analytics and Knowledge Conference held in 2011 in Banff, Alberta, this paper explores a social network perspective on learning with reference to social network principles and studies by the author. The paper explores the ways a social network perspective can be used to examine learning, with attention to the structure and dynamics of online learning networks, and emerging configurations such as online crowds and communities.", "authors": ["Caroline Haythornthwaite"], "session": "None"}, {"title": "Discourse-centric learning analytics", "pages": "23-33", "doi": "10.1145/2090116.2090120", "abstract": "Drawing on sociocultural discourse analysis and argumentation theory, we motivate a focus on learners' discourse as a promising site for identifying patterns of activity which correspond to meaningful learning and knowledge construction. However, software platforms must gain access to qualitative information about the rhetorical dimensions to discourse contributions to enable such analytics. This is difficult to extract from naturally occurring text, but the emergence of more-structured annotation and deliberation platforms for learning makes such information available. Using the Cohere web application as a research vehicle, we present examples of analytics at the level of individual learners and groups, showing conceptual and social network patterns, which we propose as indicators of meaningful learning.", "authors": ["Anna De Liddo", "Simon Buckingham Shum", "Ivana Quinto", "Michelle Bachler", "Lorella Cannavacciuolo"], "session": "None"}, {"title": "iSpot analysed: participatory learning and reputation", "pages": "34-43", "doi": "10.1145/2090116.2090121", "abstract": "We present an analysis of activity on iSpot, a website supporting participatory learning about wildlife through social networking. A sophisticated and novel reputation system provides feedback on the scientific expertise of users, allowing users to track their own learning and that of others, in an informal learning context. We find steeply unequal long-tail distributions of activity, characteristic of social networks, and evidence of the reputation system functioning to amplify the contribution of accredited experts. We argue that there is considerable potential to apply such a reputation system in other participatory learning contexts.", "authors": ["Doug Clow", "Elpida Makriyannis"], "session": "None"}, {"title": "Dataset-driven research for improving recommender systems for learning", "pages": "44-53", "doi": "10.1145/2090116.2090122", "abstract": "In the world of recommender systems, it is a common practice to use public available datasets from different application environments (e.g. MovieLens, Book-Crossing, or Each-Movie) in order to evaluate recommendation algorithms. These datasets are used as benchmarks to develop new recommendation algorithms and to compare them to other algorithms in given settings. In this paper, we explore datasets that capture learner interactions with tools and resources. We use the datasets to evaluate and compare the performance of different recommendation algorithms for learning. We present an experimental comparison of the accuracy of several collaborative filtering algorithms applied to these TEL datasets and elaborate on implicit relevance data, such as downloads and tags, that can be used to improve the performance of recommendation algorithms.", "authors": ["Katrien Verbert", "Hendrik Drachsler", "Nikos Manouselis", "Martin Wolpers", "Riina Vuorikari", "Erik Duval"], "session": "None"}, {"title": "Variable construction for predictive and causal modeling of online education data", "pages": "54-63", "doi": "10.1145/2090116.2090123", "abstract": "We consider the problem of predictive and causal modeling of data collected by courseware in online education settings, focusing on graphical causal models as a formalism for such modeling. We review results from a prior study, present a new pilot study, and suggest that novel methods of constructing variables for analysis may improve our ability to infer predictors and causes of learning outcomes in online education. Finally, several general problems for causal discovery from such data are surveyed along with potential solutions.", "authors": ["Stephen E. Fancsali"], "session": "None"}, {"title": "A unified framework for multi-level analysis of distributed learning", "pages": "64-74", "doi": "10.1145/2090116.2090124", "abstract": "Learning and knowledge creation is often distributed across multiple media and sites in networked environments. Traces of such activity may be fragmented across multiple logs and may not match analytic needs. As a result, the coherence of distributed interaction and emergent phenomena are analytically cloaked. Understanding distributed learning and knowledge creation requires multi-level analysis of the situated accomplishments of individuals and small groups and of how this local activity gives rise to larger phenomena in a network. We have developed an abstract transcript representation that provides a unified analytic artifact of distributed activity, and an analytic hierarchy that supports multiple levels of analysis. Log files are abstracted to directed graphs that record observed relationships (contingencies) between events, which may be interpreted as evidence of interaction and other influences between actors. Contingency graphs are further abstracted to two-mode directed graphs that record how associations between actors are mediated by digital artifacts and summarize sequential patterns of interaction. Transitive closure of these associograms creates sociograms, to which existing network analytic techniques may be applied, yielding aggregate results that can then be interpreted by reference to the other levels of analysis. We discuss how the analytic hierarchy bridges between levels of analysis and theory.", "authors": ["Daniel Suthers", "Devan Rosen"], "session": "None"}, {"title": "Redefining dropping out in online higher education: a case study from the UOC", "pages": "75-80", "doi": "10.1145/2090116.2090125", "abstract": "In recent years, studies into the reasons for dropping out of online higher education have been undertaken with greater regularity, parallel to the rise in the relative weight of this type of education, compared with brick-and-mortar education. However, the work invested in characterising the students who drop out of education, compared with those who do not, appears not to have had the same relevance as that invested in the analysis of the causes. The definition of dropping out is very sensitive to the context. In this article, we reach a purely empirical definition of student dropping out, based on the probability of not continuing a specific academic programme following several consecutive semesters of \"theoretical break\". Dropping out should be properly defined before analysing its causes, as well as comparing the drop-out rates between the different online programmes, or between online and on-campus ones. Our results show that there are significant differences among programmes, depending on their theoretical extension, but not their domain of knowledge.", "authors": ["Josep Grau-Valldosera", "Juli\u00e0 Minguill\u00f3n"], "session": "None"}, {"title": "Usage contexts for object similarity: exploratory investigations", "pages": "81-85", "doi": "10.1145/2090116.2090127", "abstract": "We present new ways of detecting semantic relations between learning resources, e. g. for recommendations, by only taking their usage but not their content into account. We take concepts used in linguistic lexicology and transfer them from their original field of application, i. e. sequences of words, to the analysis of sequences of resources extracted from user activities. In this paper we describe three initial experiments, their evaluation and further work.", "authors": ["Katja Niemann", "Hans-Christian Schmitz", "Maren Scheffel", "Martin Wolpers"], "session": "SESSION: Vision and conceptual papers"}, {"title": "The who, what, when, and why of lecture capture", "pages": "86-92", "doi": "10.1145/2090116.2090128", "abstract": "Video lecture capture is rapidly being deploying in higher-education institutions as a means of increasing student learning, outreach, and experience. Understanding how learners use these systems and relating this use back to pedagogical and institutional goals is a hard issue that has largely been unexplored. This work describes a novel web-based lecture presentation system which contains fine-grained user tracking features. These features, along with student surveys, have been used to help analyse the behaviour of hundreds of students over an academic term, quantifying both the learning approaches of students and their perceptions on learning with lecture capture.", "authors": ["Christopher Brooks", "Carrie Demmans Epp", "Greg Logan", "Jim Greer"], "session": "SESSION: Vision and conceptual papers"}, {"title": "Towards visual analytics for teachers' dynamic diagnostic pedagogical decision-making", "pages": "93-98", "doi": "10.1145/2090116.2090129", "abstract": "The focus of this paper is to delineate and discuss design considerations for supporting teachers' dynamic diagnostic decision-making in classrooms of the 21st century. Based on the Next Generation Teaching Education and Learning for Life (NEXT-TELL) European Commission integrated project, we envision classrooms of the 21st century to (a) incorporate 1:1 computing, (b) provide computational as well as methodological support for teachers to design, deploy and assess learning activities and (c) immerse students in rich, personalized and varied learning activities in information ecologies resulting in high-performance, high-density, high-bandwidth, and data-rich classrooms. In contrast to existing research in educational data mining and learning analytics, our vision is to employ visual analytics techniques and tools to support teachers dynamic diagnostic pedagogical decision-making in real-time and in actual classrooms. The primary benefits of our vision is that learning analytics becomes an integral part of the teaching profession so that teachers can provide timely, meaningful, and actionable formative assessments to on-going learning activities in-situ. Integrating emerging developments in visual analytics and the established methodological approach of design-based research (DBR) in the learning sciences, we introduce a new method called \"Teaching Analytics\" and explore a triadic model of teaching analytics (TMTA). TMTA adapts and extends the Pair Analytics method in visual analytics which in turn was inspired by the pair programming model of the extreme programming paradigm. Our preliminary vision of TMTA consists of a collocated collaborative triad of a Teaching Expert (TE), a Visual Analytics Expert (VAE), and a Design-Based Research Expert (DBRE) analyzing, interpreting and acting upon real-time data being generated by students' learning activities by using a range of visual analytics tools. We propose an implementation of TMTA using open learner models (OLM) and conclude with an outline of future work", "authors": ["Ravi Vatrapu", "Chris Teplovs", "Nobuko Fujita", "Susan Bull"], "session": "SESSION: Vision and conceptual papers"}, {"title": "Learning analytics to identify exploratory dialogue within synchronous text chat", "pages": "99-103", "doi": "10.1145/2090116.2090130", "abstract": "While generic web analytics tend to focus on easily harvested quantitative data, Learning Analytics will often seek qualitative understanding of the context and meaning of this information. This is critical in the case of dialogue, which may be employed to share knowledge and jointly construct understandings, but which also involves many superficial exchanges. Previous studies have validated a particular pattern of 'exploratory dialogue' in learning environments to signify sharing, challenge, evaluation and careful consideration by participants. This study investigates the use of sociocultural discourse analysis to analyse synchronous text chat during an online conference. Key words and phrases indicative of exploratory dialogue were identified in these exchanges, and peaks of exploratory dialogue were associated with periods set aside for discussion and keynote speakers. Fewer individuals posted at these times, but meaningful discussion outweighed trivial exchanges. If further analysis confirms the validity of these markers as learning analytics, they could be used by recommendation engines to support learners and teachers in locating dialogue exchanges where deeper learning appears to be taking place.", "authors": ["Rebecca Ferguson", "Simon Buckingham Shum"], "session": "SESSION: Vision and conceptual papers"}, {"title": "The value of learning analytics to networked learning on a personal learning environment", "pages": "104-109", "doi": "10.1145/2090116.2090131", "abstract": "Some might argue that the analytics tools at our disposal are currently mainly used for boring purposes, such as improving processes and making money. In this paper we will try to define learning analytics and their purpose for learning and education. We will ponder on the best possible fit of particular types of research methods and their analysis. Methodological concerns related to the analysis of Big Data collected on online networks as well as ethical and privacy concerns will also be highlighted and a case study of the use of learning analytics in a Massive Open Online Course explored.", "authors": ["H\u00e9l\u00e8ne Fournier", "Rita Kop", "Hanan Sitlia"], "session": "SESSION: Vision and conceptual papers"}, {"title": "Using learning analytics to assess students' behavior in open-ended programming tasks", "pages": "110-116", "doi": "10.1145/2090116.2090132", "abstract": "There is great interest in assessing student learning in unscripted, open-ended environments, but students' work can evolve in ways that are too subtle or too complex to be detected by the human eye. In this paper, I describe an automated technique to assess, analyze and visualize students learning computer programming. I logged hundreds of snapshots of students' code during a programming assignment, and I employ different quantitative techniques to extract students' behaviors and categorize them in terms of programming experience. First I review the literature on educational data mining, learning analytics, computer vision applied to assessment, and emotion detection, discuss the relevance of the work, and describe one case study with a group undergraduate engineering students", "authors": ["Paulo Blikstein"], "session": "SESSION: Vision and conceptual papers"}, {"title": "Learning analytics as interpretive practice: applying Westerman to educational intervention", "pages": "117-121", "doi": "10.1145/2090116.2090133", "abstract": "In Westerman's [12] disruptive article, \"Quantitative research as an interpretive enterprise: The mostly unacknowledged role of interpretation in research efforts and suggestions for explicitly interpretive quantitative investigations,\" he invited qualitative researchers in psychology to adopt quantitative methods into interpretive inquiry, given that they were as capable as qualitative measures in producing meaning-laden results. The objective of this article is to identify Westerman's [12] key arguments and apply them to the practice of Learning Analytics in educational interventions. The primary implication for Learning Analytics practitioners is the need to interpret quantitative analysis procedures at every phase from philosophy to conclusions. Furthermore, Learning Analytics practitioners and consumers must critically examine any assumption that suggests quantitative methodologies in Learning Analytics are inherently objective or that Learning Analytics algorithms may replace judgment rather than aid it. Lastly we propose a method for making observational data in virtual environments concrete through nested models.", "authors": ["Michael Atkisson", "David Wiley"], "session": "SESSION: Vision and conceptual papers"}, {"title": "Academic analytics landscape at the University of Phoenix", "pages": "122-126", "doi": "10.1145/2090116.2090135", "abstract": "The University of Phoenix understands that in order to serve its large population of non-traditional students, it needs to rely on data. We have created a strong foundation with an integrated data repository that connects data from all parts of the organization. With this repository in place, we can now undertake a variety of analytics projects. One such project is an attempt to predict a student's persistence in their program using available data indicators such as schedule, grades, content usage, and demographics.", "authors": ["Mike Sharkey"], "session": "SESSION: Ideas and innovation"}, {"title": "Cultural considerations in learning analytics", "pages": "127-133", "doi": "10.1145/2090116.2090136", "abstract": "This paper discusses empirical findings demonstrating cultural influences in social behavior, communication, cognition, technology enhanced learning and draws implications for learning analytics.", "authors": ["Ravi Vatrapu"], "session": "SESSION: Ideas and innovation"}, {"title": "Social and semantic network analysis of chat logs", "pages": "134-139", "doi": "10.1145/2090116.2090137", "abstract": "Multi-user virtual environments (MUVEs) allow many users to explore the environment and interact with other users as they learn new content and share their knowledge with others. The semi-synchronous communicative interaction within these learning environments is typically text-based Internet relay chat (IRC). IRC data is stored in the form of chatlogs and can generate a large volume of data, posing a difficulty for researchers looking to evaluate learning in the interaction by analyzing and interpreting the patterns of communication structure and related content. This paper describes procedures for the measurement and visualization of chat-based communicative interaction in MUVEs. Methods are offered for structural analysis via social networks, and content analysis via semantic networks. Measuring and visualizing social and semantic networks allows for a window into the structure of learning communities, and also provides for a large cache of analytics to explore individual learning outcomes and group interaction in any virtual interaction. A case study on a learning based MUVE, SRI's Tapped-In community, is used to elaborate analytic methods.", "authors": ["Devan Rosen", "Victor Miagkikh", "Daniel Suthers"], "session": "SESSION: Ideas and innovation"}, {"title": "Applying analytics for a learning portal: the Organic.Edunet case study", "pages": "140-146", "doi": "10.1145/2090116.2090138", "abstract": "Learning portals are education-oriented Web portals, which provide access to a variety of educational material, usually coming from various sources. In order to explore how they can support their users during an educational activity (e.g. preparation of teaching a course), it would be interesting to study the behavior of their visitors, focusing on the particular context in which specific actions are taking place. For example, user activities may be analyzed during specific learning events, when activities are more focused. This paper discusses the case study of the Organic.Edunet Web portal (www.organic-edunet.eu), a learning portal for organic agriculture educators that provides access to more than 10,500 learning resources from a federation of 11 institutional repositories. The portal mostly focuses on serving school teachers and university tutors and has attracted until today almost 42.200 unique visitors from more than 160 countries, out of which about 2.600 have registered to the portal. An effort is made to study the users' behavior, focusing in tutors and educators in both schools and universities, in relation to specific training events in which we know that they have been involved. Therefore, we analyze logs of user activities that took place on specific dates and geographical locations, in order to potentially identify notable changes in their normal visiting behavior.", "authors": ["Nikos Palavitsinis", "Vassilios Protonotarios", "Nikos Manouselis"], "session": "SESSION: Ideas and innovation"}, {"title": "Generating predictive models of learner community dynamics", "pages": "147-152", "doi": "10.1145/2090116.2090139", "abstract": "In this paper we present a framework for learner modelling that combines latent semantic analysis and social network analysis of online discourse. The framework is supported by newly developed software, known as the Knowledge, Interaction, and Social Student Modelling Explorer (KISSME), that employs highly interactive visualizations of content-aware interactions among learners. Our goal is to develop, use and refine KISSME to generate and test predictive models of learner interactions to optimise learning.", "authors": ["Chris Teplovs", "Nobuko Fujita", "Ravi Vatrapu"], "session": "SESSION: Ideas and innovation"}, {"title": "Learning designs and learning analytics", "pages": "153-156", "doi": "10.1145/2090116.2090140", "abstract": "Government and institutionally-driven reforms focused on quality teaching and learning in universities emphasize the importance of developing replicable, scalable teaching approaches that can be evaluated. In this context, learning design and learning analytics are two fields of research that may help university teachers design quality learning experiences for their students, evaluate how students are learning within that intended learning context and support personalized learning experiences for students. Learning Designs are ways of describing an educational experience such that it can be applied across a range of disciplinary contexts. Learning analytics offers new approaches to investigating the data associated with a learner's experience. This paper explores the relationship between learning designs and learning analytics.", "authors": ["Lori Lockyer", "Shane Dawson"], "session": "SESSION: Ideas and innovation"}, {"title": "Revisiting formative evaluation: dynamic monitoring for the improvement of learning activity design and delivery", "pages": "157-162", "doi": "10.1145/2090116.2090141", "abstract": "Distance education courses have a tradition of a formative evaluation cycle that takes place before a course is formally delivered. This paper discusses opportunities for improving online and blended learning by collecting formative data during course presentation. With a goal of overall improvement in instructional effectiveness and identification of promising practices for inclusion in a learning activities design library, we propose the immediate and on-going monitoring of the effectiveness of learning activities, tutor facilitation and learner satisfaction during the course presentation. This has implications for constructively involving the learners and facilitators in the course improvement process. While originally conceived to reduce the time for pilot evaluation of new courses and learning activities, the proposed system could also be extended to individualized and blended learning environments, and if implemented using semantic web technologies, for research into the effectiveness of learning activity patterns.", "authors": ["Griff Richards", "Irwin DeVries"], "session": "SESSION: Ideas and innovation"}, {"title": "Stepping out of the box: towards analytics outside the learning management system", "pages": "163-167", "doi": "10.1145/2090116.2090142", "abstract": "Most of the current learning analytic techniques have as starting point the data recorded by Learning Management Systems (LMS) about the interactions of the students with the platform and among themselves. But there is a tendency on students to rely less on the functionality offered by the LMS and use more applications that are freely available on the net. This situation is magnified in studies in which students need to interact with a set of tools that are easily installed on their personal computers. This paper shows an approach using Virtual Machines by which a set of events occurring outside of the LMS are recorded and sent to a central server in a scalable and unobtrusive manner.", "authors": ["Abelardo Pardo", "Carlos Delgado Kloos"], "session": "SESSION: Ideas and innovation"}, {"title": "SNAPP: a bird's-eye view of temporal participant interaction", "pages": "168-173", "doi": "10.1145/2090116.2090144", "abstract": "The Social Networks Adapting Pedagogical Practice (SNAPP) tool was developed to provide instructors with the capacity to visualise the evolution of participant relationships within discussions forums. Providing forum facilitators with access to these forms of data visualisations and social network metrics in 'real-time', allows emergent interaction patterns to be analysed and interventions to be undertaken as required. SNAPP essentially serves as an interaction diagnostic tool that assists in bringing the affordances of 'real-time' social network analysis to fruition. This paper details the functional features included in SNAPP 2.0 and how they relate to learning activity intent and participant monitoring. SNAPP 2.0 includes the ability to view the evolution of participant interaction over time and annotate key events that occur along this timeline. This feature is useful in terms of monitoring network evolution and evaluating the impact of intervention strategies on student engagement and connectivity. SNAPP currently supports discussion forums found in popular commercial and open source Learning Management Systems (LMS) such as Blackboard, Desire2Learn and Moodle and works in both Internet Explorer and Firefox.", "authors": ["Aneesha Bakharia", "Shane Dawson"], "session": "DEMONSTRATION SESSION: Tool demonstration papers"}, {"title": "AAT: a tool for accessing and analysing students' behaviour data in learning systems", "pages": "174-179", "doi": "10.1145/2090116.2090145", "abstract": "In online learning environments, teachers and course designers often get little feedback about how students actually interact with and learn in online courses. Most of the learning systems used by educational institutions store comprehensive log data associated with students' behaviours and actions. However, these systems typically reveal or report on very general and limited information based on this data. In order to provide teachers and course designers with more detailed and meaningful information about students' behaviour and their use of learning resources within online courses, an analytics tool has been developed. The tool incorporates functionality to access and analyse data related to students' behaviours in learning systems. This tool can provide valuable information about students' learning processes allowing the identification of difficult or inappropriate learning material, and can therefore significantly contribute to the design of improved student support activities and resources.", "authors": ["Sabine Graf", "Cindy Ives", "Nazim Rahman", "Arnold Ferri"], "session": "DEMONSTRATION SESSION: Tool demonstration papers"}, {"title": "Evolving a learning analytics platform", "pages": "180-185", "doi": "10.1145/2090116.2090146", "abstract": "Web-based learning systems offer researchers the ability to collect and analyze fine-grained educational data on the performance and activity of students, as a basis for better understanding and supporting learning among those students. The availability of this data enables stakeholders to pose a variety of interesting questions, often specifically focused on some subset of students. As a system matures, the number of stakeholders, the number of interesting questions, and the number of relevant sub-populations of students also grow, adding complexity to the data analysis task. In this work, we describe an internal analytics system designed and developed to address this challenge, adding flexibility and scalability. Here we present several examples of typical examples of analysis, discuss a few uncommon but powerful use-cases, and share lessons learned from the first two years of iteratively developing the platform.", "authors": ["Ari Bader-Natal", "Thomas Lotze"], "session": "DEMONSTRATION SESSION: Tool demonstration papers"}]}, {"year": 2012, "papers": [{"title": "Networked individualism: how the personalized internet, ubiquitous connectivity, and the turn to social networks can affect learning analytics", "pages": "1-1", "doi": "10.1145/2330601.2330603", "abstract": "The Triple Revolution---the coming together of the turn to social networks, the personalized internet, and accessible mobile connectivity---has fostered networked individualism. This has implications for learning analytics, in the need to move beyond analyzing bounded groups and aggregates of individuals to taking into account complex, partial networks of social relationships.", "authors": ["Barry Wellman"], "session": "SESSION: Keynote"}, {"title": "Visual analytics in support of education", "pages": "2-3", "doi": "10.1145/2330601.2330604", "abstract": "The amount of data about us and our world is increasing rapidly, and the capability to analyze large data sets---so-called big data---becomes a key basis of competition, underpinning new waves of productivity growth and innovation. The big data phenomenon is fueled by cheap sensors and high-throughput simulation models, the increasing volume and detail of information captured by enterprises, the rise of multimedia, social media, and the Internet. It exists from social media to cell biology offering unparalleled opportunities to document the inner workings of many complex systems [1]. Research by MGI and McKinsey's Business Technology Office argues that there will be a shortage of talent necessary for organizations to take advantage of big data. \"By 2018, the United States alone could face a shortage of 140,000 to 190,000 people with deep analytical skills as well as 1.5 million managers and analysts with the know-how to use the analysis of big data to make effective decisions\" [2]. In everyday life, people deal with large amounts of data regularly: online search engines provide access to millions of web sites almost instantly; consumer sites offer literally thousands of purchase options seamlessly; and social media sites let you create and benefit from extensive social networks. In bestselling books like Freakonomics, Super Crunchers and The Numerati, authors illuminate how more and more decisions in health care, politics, education, and other sectors utilize big data and data analysis [3]. The texts highlight the growing need for specialists and every-day citizens to be able to understand and interpret data. Whether it is a table of nutritional information, a graph of stock prices, or a chart comparing health care plans, the skills of understanding and interpreting data are necessary to navigate successfully through daily life. This talk starts with a review of visual analytics projects that aim to increase our understanding of how people learn, increase the efficacy of learning environments, or support decision making in education [4]. The second part of the talk provides a theoretical framework for the design of effective data analysis workflows and insightful visualizations. It also introduces plug-and-play macroscope tools [5], see also http://cishell.org, that were designed for different research communities and are used by more than 120,000 users from 40+ countries to design and benefit from visualizations of complex data. The talk concludes with a discussion of challenges that arise when visual analytics tools are introduced to classrooms and informal science education.", "authors": ["Katy B\u00f6rner"], "session": "SESSION: Keynote"}, {"title": "Learning analytics: envisioning a research discipline and a domain of practice", "pages": "4-8", "doi": "10.1145/2330601.2330605", "abstract": "Learning analytics are rapidly being implemented in different educational settings, often without the guidance of a research base. Vendors incorporate analytics practices, models, and algorithms from datamining, business intelligence, and the emerging \"big data\" fields. Researchers, in contrast, have built up a substantial base of techniques for analyzing discourse, social networks, sentiments, predictive models, and in semantic content (i.e., \"intelligent\" curriculum). In spite of the currently limited knowledge exchange and dialogue between researchers, vendors, and practitioners, existing learning analytics implementations indicate significant potential for generating novel insight into learning and vital educational practices. This paper presents an integrated and holistic vision for advancing learning analytics as a research discipline and a domain of practices. Potential areas of collaboration and overlap are presented with the intent of increasing the impact of analytics on teaching, learning, and the education system.", "authors": ["George Siemens"], "session": "SESSION: Keynote"}, {"title": "1st International Workshop on Learning Analytics and Linked Data", "pages": "9-10", "doi": "10.1145/2330601.2330607", "abstract": "The main objective of the 1st International Workshop on Learning Analytics and Linked Data (#LALD2012) is to connect the research efforts on Linked Data and Learning Analytics in order to create visionary ideas and foster synergies between the two young research fields. Therefore, the workshop will collect, explore, and present datasets, technologies and applications for Technology Enhanced Learning (TEL) to discuss Learning Analytics approaches that make use of educational data or Linked Data sources. During the workshop, an overview of available educational datasets and related initiatives will be given. The participants will have the opportunity to present their own research with respect to educational datasets, technologies and applications and discuss major challenges to collect, reuse, and share these datasets.", "authors": ["Hendrik Drachsler", "Stefan Dietze", "Wolfgang Greller", "Mathieu D'Aquin", "Jelena Jovanovic", "Abelardo Pardo", "Wolfgang Reinhardt", "Katrien Verbert"], "session": "WORKSHOP SESSION: Workshop"}, {"title": "Connecting levels and methods of analysis in networked learning communities", "pages": "11-13", "doi": "10.1145/2330601.2330608", "abstract": "This paper describes the rationale behind a workshop on using data-intensive computational methods of analysis for empirical-analytical studies of collaborative and networked learning, with a particular focus on how learning takes place in the technically-mediated interplay between individual, small group and collective levels of agency. This workshop is primarily designed for researchers interested in empirical-analytical studies using data-intensive computational methods of analysis (including social-network analysis, log-file analysis, data mining, video analysis).", "authors": ["Daniel D. Suthers", "H. Ulrich Hoppe", "Maarten de Laat", "Simon Buckingham Shum"], "session": "WORKSHOP SESSION: Workshop"}, {"title": "Where learning analytics meets learning design", "pages": "14-15", "doi": "10.1145/2330601.2330609", "abstract": "The wealth of data available through student management systems and eLearning systems has the potential to provide faculty with important, just-in-time information that may allow them to positively intervene with struggling students and/or enhance the learning experience during the delivery of a course. This information might also facilitate post-delivery review and reflection for faculty who wish to revise course design and content. But to be effective, this data needs to be appropriate to the context or pedagogical intent of the course -- this is where learning analytics meets learning design.", "authors": ["Lori Lockyer", "Shane Dawson"], "session": "WORKSHOP SESSION: Workshop"}, {"title": "Learning analytics and higher education: ethical perspectives", "pages": "16-17", "doi": "10.1145/2330601.2330610", "abstract": "Take two students who were enrolled on the same higher education course, both of whom were identified as likely to benefit from additional support and tailoring of their learning experience. Three years later, one student has gone on to gain a good degree and is now making great progress in her career. The other student, whose background and learning needs appeared similar, scraped through the experience, has recently been eased out of her organization and is unemployed. To what extent were decisions taken by their tutors and institution about the design of their learning experiences, responsible for these two very different outcomes?", "authors": ["Sharon Slade", "Fenella Galpin"], "session": "WORKSHOP SESSION: Workshop"}, {"title": "Building organizational capacity for analytics: panel proposal", "pages": "18-19", "doi": "10.1145/2330601.2330612", "abstract": "The field of analytics is mushrooming. Analytics is perceived as the potential decoder for institutional transformation. Given the mandates for improved assessment, accountability and performance, analytical tools are in high demand. A critical goal is to optimize student success by managing the student pipeline to success, eliminating structural and programmatic impediments to retention and success and by utilizing dynamic query, reporting, intervention and embedded predictive analytics to respond to at-risk behavior. Additional optimization practices are emerging as well: Expanded data mining, early-stage learner relationship management practices, and consideration of employability success. This panel presentation will describe the tools leading-edge institutions are using and what tools vendors are offering. The gap between supply and demand will be the main focus of the session.", "authors": ["Donald M. Norris", "Linda Baer"], "session": "PANEL SESSION: Panel"}, {"title": "Educational data mining meets learning analytics", "pages": "20-20", "doi": "10.1145/2330601.2330613", "abstract": "W This panel is proposed as a means of promoting mutual learning and continued dialogue between the Educational Data Mining and Learning Analytics communities. EDM has been developing as a community for longer than the LAK conference, so what if anything makes the LAK community different, and where is the common ground?", "authors": ["Ryan S. J. d. Baker", "Erik Duval", "John Stamper", "David Wiley", "Simon Buckingham Shum"], "session": "PANEL SESSION: Panel"}, {"title": "Building a data governance model for learning analytics", "pages": "21-22", "doi": "10.1145/2330601.2330614", "abstract": "This international panel presentation aims to explore and discuss the issues that emerge when an educational institution decides to develop learning analytics initiatives. While learning analytics may provide data that lead to improvements in the quality of teaching and learning design, and therefore has the potential to enhance the overall quality of education, the successful development and implementation of tools and processes for learning analytics are complex and problematic. In this panel, data governance considerations will be discussed from organizational, ethical, learning design, and technical points of view.", "authors": ["Sabine Graf", "Cindy Ives", "Lori Lockyer", "Paul Hobson", "Doug Clow"], "session": "PANEL SESSION: Panel"}, {"title": "Social learning analytics: five approaches", "pages": "23-33", "doi": "10.1145/2330601.2330616", "abstract": "This paper proposes that Social Learning Analytics (SLA) can be usefully thought of as a subset of learning analytics approaches. SLA focuses on how learners build knowledge together in their cultural and social settings. In the context of online social learning, it takes into account both formal and informal educational environments, including networks and communities. The paper introduces the broad rationale for SLA by reviewing some of the key drivers that make social learning so important today. Five forms of SLA are identified, including those which are inherently social, and others which have social dimensions. The paper goes on to describe early work towards implementing these analytics on SocialLearn, an online learning space in use at the UK's Open University, and the challenges that this is raising. This work takes an iterative approach to analytics, encouraging learners to respond to and help to shape not only the analytics but also their associated recommendations.", "authors": ["Rebecca Ferguson", "Simon Buckingham Shum"], "session": "SESSION: Social learning analytics"}, {"title": "Modelling learning & performance: a social networks perspective", "pages": "34-42", "doi": "10.1145/2330601.2330617", "abstract": "Traditional models of learning using a sociological perspective include social learning, situated learning and models of connectivisim and self-efficacy. While these models explain how individuals learn in varying social dimensions, very few studies provide empirical validation of such models and extend them to include group learning and performance. In this exploratory study, we develop a theoretical model based on social learning and social network theories to understand how knowledge professionals engage in learning and performance, both as individuals and as groups. We investigate the association between egocentric network properties (structure, position and tie), 'content richness' in the social learning process and performance. Analysis from data collected using an online eLearning environment shows that rather than performance; social learning is influenced by properties of social network structure (density, inter-group and intra-network communication), relations (tie strength) and position (efficiency). Furthermore, individuals who communicate with others internal rather than external to the group show higher tendencies of social learning. The contribution of this study is therefore two-fold: a theoretical development of a social learning and networks based model for understanding learning and performance; and the construction of a novel metric called 'content richness' as a surrogate measure for social learning. In conclusion, a useful implication of the study is that the model fosters understanding social factors that influence learning and performance in the domain of learning analytics. It also begs the question of whether the relationship between social networks and performance is mediated or moderated by learning and whether assumptions of the model hold true in non-educational domains.", "authors": ["Walter Christian Paredes", "Kon Shing Kenneth Chung"], "session": "SESSION: Social learning analytics"}, {"title": "Multi-mediated community structure in a socio-technical network", "pages": "43-53", "doi": "10.1145/2330601.2330618", "abstract": "Digital environments for networked learning and professional networks may not comprise one \"community:\" identification of clusters of affiliated groups of participants that potentially constitute embedded communities is an empirical matter, and one of interest to managers of large learning and professional networks. Also, these socio-technical networks are typically multi-mediated, in that they offer multiple means of participation, each with their own interactional affordances. Different communities may be using the multiple media in different ways. We have developed an analytic framework for extracting events from log files and representing interaction and affiliations at different granularities as needed for analysis. In this paper we show how bimodal networks of actors and media artifacts can be constructed in which directed arcs relate actors to the artifacts they read, write or edit, and how the resulting graphs can be used to detect community structures that extend across different media. We illustrate these ideas with a study that characterizes community structure within the Tapped In network of educational professionals, and how the associations between members of this network are distributed across media (chat rooms, discussion forums and file sharing).", "authors": ["Dan Suthers", "Kar-Hai Chu"], "session": "SESSION: Social learning analytics"}, {"title": "Challenges and opportunities for learning analytics when formal teaching meets social spaces", "pages": "54-58", "doi": "10.1145/2330601.2330619", "abstract": "Social networking is revolutionizing the world in ways few imagined just a few years ago. The power of social networking technology can also be leveraged to improve education and enhance the instructor and learner experience. Unlike conventional learning management systems, social software environments such as Athabasca Landing provide a persistent space and are flexible enough to support social and learner-led methods of informal, non-formal, and formal learning. Analytics can be used to effectively track and measure personal progress and help uncover extra-curricular factor affecting learner success such as network formation and growth. The paper reports on an attempt to explore this problem through analysis of student behaviour on the Athabasca Landing site within the context of a course. Its findings, explanation, and potential implications are listed. Effects of social learning on learners, based on the learner's behaviour before, during, and after the course are described and discussed. Finally, features of an open source tool created for this analysis, LASSIE is presented.", "authors": ["Nazim Rahman", "Jon Dron"], "session": "SESSION: Social learning analytics"}, {"title": "Network awareness tool - learning analytics in the workplace: detecting and analyzing informal workplace learning", "pages": "59-64", "doi": "10.1145/2330601.2330620", "abstract": "This paper aims to contribute to the understanding of informal workplace learning in contemporary face-to-face and virtual environments. Informal learning is an important driver for professional development and workplace learning. However powerful informal learning may be, there is a problem when it comes to making it a real asset within organizations: Informal learning activities are mostly invisible to others, sometimes the learners themselves might not even be aware of the learning that occurs. As a consequence informal learning in organizations goes undetected, remains off the radar of HR departments and is therefore hard to asses, manage and value [1]. This problem poses an interesting challenge for the field of Learning Analytics, namely finding ways to capture and analyse traces of (social) informal learning in every day life and work networks. Therefore empirical research and tools are needed that can raise awareness about informal learning activities to make it surface the radar, amplify the benefits of it and strengthen the social relations through which it occurs. In this paper we introduce a tool that aims to facilitate exactly this and we hope to stimulate to widen the discussion on Learning Analytics by expanding the field from a predominantly educational focus to informal and workplace learning. In this paper we will discuss methodologies that Learning Analytics can draw upon to make informal learning more explicit and accessible to analyse and to share amongst professionals.", "authors": ["Schreurs Bieke", "De Laat Maarten"], "session": "SESSION: Social learning analytics"}, {"title": "Cyberlearners and learning resources", "pages": "65-68", "doi": "10.1145/2330601.2330621", "abstract": "The discovery of community structure in real world networks has transformed the way we explore large systems. We propose a visual method to extract communities of cyberlearners in a large interconnected network consisting of cyberlearners and learning resources. The method used is heuristic and is based on visual clustering and a modularity measure. Each cluster of users is considered as a subset of the community of learners sharing a similar domain of interest. Accordingly, a recommender system is proposed to predict and recommend learning resources to cyberlearners within the same community. Experiments on real, dynamic data reveal the structure of community in the network. Our approach used the optimal discovered structure based on the modularity value to design a recommender system.", "authors": ["Leyla Zhuhadar", "Rong Yang"], "session": "SESSION: Social learning analytics"}, {"title": "First steps towards a social learning analytics for online communities of practice for educators", "pages": "69-72", "doi": "10.1145/2330601.2330622", "abstract": "Learning analytics has the potential to provide actionable insights for managers of online communities of practice. Because the purposes of such communities and the patterns of activity that might further them are diverse, a wider range of methods may be needed than in formal educational settings. This paper describes the proposed learning analytics approach of the U. S. Department of Education's Connected Educatorsproject, and presents preliminary applications of social network analysis to the National Science Teachers Association Learning Center as an illustration.", "authors": ["Darren Cambridge", "Kathleen Perez-Lopez"], "session": "SESSION: Social learning analytics"}, {"title": "It's just about learning the multiplication table", "pages": "73-81", "doi": "10.1145/2330601.2330624", "abstract": "One of the first and basic mathematical knowledge of school children is the multiplication table. At the age of 8 to 10 each child has to learn by training step by step, or more scientifically, by using a behavioristic learning concept. Due to this fact it can be mentioned that we know very well about the pedagogical approach, but on the other side there is rather less knowledge about the increase of step-by-step knowledge of the school children. In this publication we present some data documenting the fluctuation in the process of acquiring the multiplication tables. We report the development of an algorithm which is able to adapt the given tasks out of a given pool to unknown pupils. For this purpose a web-based application for learning the multiplication table was developed and then tested by children. Afterwards so-called learning curves of each child were drawn and analyzed by the research team as well as teachers carrying out interesting outcomes. Learning itself is maybe not as predictable as we know from pedagogical experiences, it is a very individualized process of the learners themselves. It can be summarized that the algorithm itself as well as the learning curves are very useful for studying the learning success. Therefore it can be concluded that learning analytics will become an important step for teachers and learners of tomorrow.", "authors": ["Martin Sch\u00f6n", "Martin Ebner", "Georg Kothmeier"], "session": "SESSION: Adaptive-recommender systems"}, {"title": "Sherpa: increasing student success with a recommendation engine", "pages": "82-83", "doi": "10.1145/2330601.2330625", "abstract": "Students flock to online services like Amazon, Pandora and Netflix that offer personalized recommendations, in stark contrast to the \"one size fits all\" services in higher education. In this session we demonstrate Sherpa, a recommendation engine for courses, information and services that utilizes both human and machine intelligence.", "authors": ["Robert Bramucci", "Jim Gaston"], "session": "SESSION: Adaptive-recommender systems"}, {"title": "Using an instructional expert to mediate the locus of control in adaptive e-learning systems", "pages": "84-87", "doi": "10.1145/2330601.2330626", "abstract": "This paper considers the issue of the locus of control in adaptive e-learning environments from the perspective of a new stakeholder; the instructional expert. With an ever increasing ability to gain insight into learners based on their online activities, instructors and instructional designers are poised to add value to the process of adaptation, a process normally reserved for either systems designers or the end user. This work describes the design of an e-learning system which provides automated analytics information to these experts for consideration, and then leverages the insights these experts have made as the basis for content and feature adaptation.", "authors": ["Christopher A. Brooks", "Jim Greer", "Carl Gutwin"], "session": "SESSION: Adaptive-recommender systems"}, {"title": "What to do with actionable intelligence: E2Coach as an intervention engine", "pages": "88-91", "doi": "10.1145/2330601.2330627", "abstract": "In this paper, we describe a new, analytics driven approach to supporting students in large introductory physics courses. For this project, we have assembled data for more than 49,000 physics students at the University of Michigan. For each, we combine an extensive portrait of background and preparation with details of progress through the course and final outcome. This information allows us to construct models predicting student performance with a dispersion of half a letter grade. We explore residuals to this model, conducting structured interviews with students who did better (and worse) than expected, identifying strategies which lead to student success (and failure) at all levels of preparation. This work was done in preparation for the launch of E2Coach: a computer tailored educational coaching project which provides a model for an intervention engine, capable of dealing with actionable information for thousands of students.", "authors": ["Tim McKay", "Kate Miller", "Jared Tritz"], "session": "SESSION: Adaptive-recommender systems"}, {"title": "Learning dispositions and transferable competencies: pedagogy, modelling and learning analytics", "pages": "92-101", "doi": "10.1145/2330601.2330629", "abstract": "Theoretical and empirical evidence in the learning sciences substantiates the view that deep engagement in learning is a function of a complex combination of learners' identities, dispositions, values, attitudes and skills. When these are fragile, learners struggle to achieve their potential in conventional assessments, and critically, are not prepared for the novelty and complexity of the challenges they will meet in the workplace, and the many other spheres of life which require personal qualities such as resilience, critical thinking and collaboration skills. To date, the learning analytics research and development communities have not addressed how these complex concepts can be modelled and analysed, and how more traditional social science data analysis can support and be enhanced by learning analytics. We report progress in the design and implementation of learning analytics based on a research validated multidimensional construct termed \"learning power\". We describe, for the first time, a learning analytics infrastructure for gathering data at scale, managing stakeholder permissions, the range of analytics that it supports from real time summaries to exploratory research, and a particular visual analytic which has been shown to have demonstrable impact on learners. We conclude by summarising the ongoing research and development programme and identifying the challenges of integrating traditional social science research, with learning analytics and modelling.", "authors": ["Simon Buckingham Shum", "Ruth Deakin Crick"], "session": "SESSION: Analytics for reflective learning"}, {"title": "Exploring reflection in online communities", "pages": "102-110", "doi": "10.1145/2330601.2330630", "abstract": "Commons-based Peer Production is the process by which internet communities create media and software artefacts. Learning is integral to the success of these communities as it encourages contribution on an individual level, helps to build and sustain commitment on a group level and provides a means for adaption at an organisational level. While some communities have established ways to support organisational learning -- through a forum or thread reserved for community discussion -- few have investigated how more in-depth visual and analytic interfaces could help formalise this process. In this paper, we explore how social network visualisation can be used to encourage reflection and thus support organisational learning in online communities. We make the following contributions: First, we describe Commons-Based Peer Production, in terms of a socio-technical learning system that includes individual, group and organisational learning. Second, we present a novel visualisation environment that embeds social network visualisation in an asynchronous collaborative architecture. Third, we present results from an evaluation and discuss the potential for visualisation to support the process of organisational reflection in online communities.", "authors": ["John McAuley", "Alexander O'Connor", "Dave Lewis"], "session": "SESSION: Analytics for reflective learning"}, {"title": "Applying quantified self approaches to support reflective learning", "pages": "111-114", "doi": "10.1145/2330601.2330631", "abstract": "This paper presents a framework for technical support of reflective learning, derived from a unification of reflective learning theory with a conceptual framework of Quantified Self tools -- tools for collecting personally relevant information for gaining self-knowledge. Reflective learning means returning to and evaluating past experiences in order to promote continuous learning and improve future experiences. Whilst the reflective learning theories do not sufficiently consider technical support, Quantified Self (QS) approaches are rather experimental and the many emergent tools are disconnected from the goals and benefits of their use. This paper brings these two strands into one unified framework that shows how QS approaches can support reflective learning processes on the one hand and how reflective learning can inform the design of new QS tools for informal learning purposes on the other hand.", "authors": ["Ver\u00f3nica Rivera-Pelayo", "Valentin Zacharias", "Lars M\u00fcller", "Simone Braun"], "session": "SESSION: Analytics for reflective learning"}, {"title": "Learn-B: a social analytics-enabled tool for self-regulated workplace learning", "pages": "115-119", "doi": "10.1145/2330601.2330632", "abstract": "In this design briefing, we introduce the Learn-B environment, our attempt in designing and implementing a research prototype to address some of the challenges inherent in workplace learning: the informal aspect of workplace learning requires knowledge workers to be supported in their self-regulatory learning (SRL) processes, whilst its social nature draws attention to the role of collective in those processes. Moreover, learning at workplace is contextual and on-demand, thus requiring organizations to recognize and motivate the learning and knowledge building activities of their employees, where individual learning goals are harmonized with those of the organization. In particular, we focus on the analytics-based features of Learn-B, illustrate their design and current implementation, and discuss how each of them is hypothesized to target the above challenges.", "authors": ["Melody Siadaty", "Dragan Ga\u0161evi\u0107", "Jelena Jovanovi\u0107", "Nikola Miliki\u0107", "Zoran Jeremi\u0107", "Liaqat Ali", "Aleksandar Giljanovi\u0107", "Marek Hatala"], "session": "SESSION: Analytics for reflective learning"}, {"title": "The pulse of learning analytics understandings and expectations from the stakeholders", "pages": "120-129", "doi": "10.1145/2330601.2330634", "abstract": "While there is currently much buzz about the new field of learning analytics [19] and the potential it holds for benefiting teaching and learning, the impression one currently gets is that there is also much uncertainty and hesitation, even extending to scepticism. A clear common understanding and vision for the domain has not yet formed among the educator and research community. To investigate this situation, we distributed a stakeholder survey in September 2011 to an international audience from different sectors of education. The findings provide some further insights into the current level of understanding and expectations toward learning analytics among stakeholders. The survey was scaffolded by a conceptual framework on learning analytics that was developed based on a recent literature review. It divides the domain of learning analytics into six critical dimensions. The preliminary survey among 156 educational practitioners and researchers mostly from the higher education sector reveals substantial uncertainties in learning analytics. In this article, we first briefly introduce the learning analytics framework and its six domains that formed the backbone structure to our survey. Afterwards, we describe the method and key results of the learning analytics questionnaire and draw further conclusions for the field in research and practice. The article finishes with plans for future research on the questionnaire and the publication of both data and the questions for others to utilize.", "authors": ["Hendrik Drachsler", "Wolfgang Greller"], "session": "SESSION: Institutional perspectives"}, {"title": "Learning analytics: challenges, paradoxes and opportunities for mega open distance learning institutions", "pages": "130-133", "doi": "10.1145/2330601.2330635", "abstract": "Despite all the research on student retention and success since the first conceptual mappings of student success e.g. Spady [12], there have not been equal impacts on the rates of both student success and retention. To realise the potential of learning analytics to impact on student retention and success, mega open distance learning (ODL) institutions face a number of challenges, paradoxes and opportunities. For the purpose of this paper we critique a 'closed' view of learning analytics as focusing only on data produced by students' interactions with institutions of higher learning. Students are not the only actors in their learning journeys and it would seem crucial that learning analytics also includes the impacts of all stakeholders on students' learning journeys in order to increase the success of students' learning. As such the notion of 'Thirdspace' as used by cultural, postmodern and identity theorists provide a useful heuristic to map the challenges and opportunities, but also the paradoxes of learning analytics and its potential impact on student success and retention. This paper explores some of these challenges, paradoxes and opportunities with reference to two mega ODL institutions namely the Open University in the UK (OU) and the University of South Africa (Unisa). Although these two institutions share a number of characteristics, there are also some major and important differences between them. We explore some of the shared challenges, paradoxes and opportunities learning analytics offer in the context of these two institutions.", "authors": ["Paul Prinsloo", "Sharon Slade", "Fenella Galpin"], "session": "SESSION: Institutional perspectives"}, {"title": "The learning analytics cycle: closing the loop effectively", "pages": "134-138", "doi": "10.1145/2330601.2330636", "abstract": "This paper develops Campbell and Oblinger's [4] five-step model of learning analytics (Capture, Report, Predict, Act, Refine) and other theorisations of the field, and draws on broader educational theory (including Kolb and Sch\u00f6n) to articulate an incrementally more developed, explicit and theoretically-grounded Learning Analytics Cycle. This cycle conceptualises successful learning analytics work as four linked steps: learners (1) generating data (2) that is used to produce metrics, analytics or visualisations (3). The key step is 'closing the loop' by feeding back this product to learners through one or more interventions (4). This paper seeks to begin to place learning analytics practice on a base of established learning theory, and draws several implications from this theory for the improvement of learning analytics projects. These include speeding up or shortening the cycle so feedback happens more quickly, and widening the audience for feedback (in particular, considering learners and teachers as audiences for analytics) so that it can have a larger impact.", "authors": ["Doug Clow"], "session": "SESSION: Institutional perspectives"}, {"title": "Mining academic data to improve college student retention: an open source perspective", "pages": "139-142", "doi": "10.1145/2330601.2330637", "abstract": "In this paper we report ongoing research on the Open Academic Analytics Initiative (OAAI), a project aimed at increasing college student retention by performing early detection of academic risk using data mining methods. The paper describes the goals and objectives of the OAAI, and lays out a methodological framework to develop models that can be used to perform inferential queries on student performance using open source course management system data and student academic records. Preliminary results on initial model development using several data mining algorithms for classification are presented.", "authors": ["Eitel J. M. Laur\u00eda", "Joshua D. Baron", "Mallika Devireddy", "Venniraiselvi Sundararaju", "Sandeep M. Jayaprakash"], "session": "SESSION: Institutional perspectives"}, {"title": "Goal-oriented visualizations of activity tracking: a case study with engineering students", "pages": "143-152", "doi": "10.1145/2330601.2330639", "abstract": "Increasing motivation of students and helping them to reflect on their learning processes is an important driver for learning analytics research. This paper presents our research on the development of a dashboard that enables self-reflection on activities and comparison with peers. We describe evaluation results of four iterations of a design based research methodology that assess the usability, use and usefulness of different visualizations. Lessons learned from the different evaluations performed during each iteration are described. In addition, these evaluations illustrate that the dashboard is a useful tool for students. However, further research is needed to assess the impact on the learning process.", "authors": ["Jose Luis Santos", "Sten Govaerts", "Katrien Verbert", "Erik Duval"], "session": "SESSION: Visual analytics"}, {"title": "Seeing what the system thinks you know: visualizing evidence in an open learner model", "pages": "153-157", "doi": "10.1145/2330601.2330640", "abstract": "User knowledge levels in adaptive learning systems can be assessed based on user interactions that are interpreted as Knowledge Indicating Events (KIE). Such an approach makes complex inferences that may be hard to understand for users, and that are not necessarily accurate. We present MyExperiences, an open learner model designed for showing the users the inferences about them, as well as the underlying data. MyExperiences is one of the first open learner models based on tree maps. It constitutes an example of how research into open learner models and information visualization can be combined in an innovative way.", "authors": ["Barbara Kump", "Christin Seifert", "Guenter Beham", "Stefanie N. Lindstaedt", "Tobias Ley"], "session": "SESSION: Visual analytics"}, {"title": "Student success system: risk analytics and data visualization using ensembles of predictive models", "pages": "158-161", "doi": "10.1145/2330601.2330641", "abstract": "We propose a novel design of a Student Success System (S3), a holistic analytical system for identifying and treating at-risk students. S3 synthesizes several strands of risk analytics: the use of predictive models to identify academically at-risk students, the creation of data visualizations for reaching diagnostic insights, and the application of a case-based approach for managing interventions. Such a system poses numerous design, implementation, and research challenges. In this paper we discuss a core research challenge for designing early warning systems such as S3. We then propose our approach for meeting that challenge. A practical implementation of an student risk early warning system, utilizing predictive models, must meet two design criteria: a) the methodology for generating predictive models must be flexible to allow generalization from one context to another; b) the underlying mechanism of prediction should be easily interpretable by practitioners whose end goal is to design meaningful interventions on behalf of students. Our proposed solution applies an ensemble method for predictive modeling using a strategy of decomposition. Decomposition provides a flexible technique for generating and generalizing predictive models across different contexts. Decomposition into interpretable semantic units, when coupled with data visualizations and case management tools, allows practitioners, such as instructors and advisors, to build a bridge between prediction and intervention.", "authors": ["Alfred Essa", "Hanan Ayad"], "session": "SESSION: Visual analytics"}, {"title": "GLASS: a learning analytics visualization tool", "pages": "162-163", "doi": "10.1145/2330601.2330642", "abstract": "The use of technology in every day tasks enables the possibility to collect large amounts of observations of events taking place in different environments. Most tools are capable of storing a detailed account of the operations executed by users in certain files commonly known as logs. These files can be further analyzed to infer information that is not directly visible such as the most popular applications, times of the day with highest activity, calories burnt after a running session, etc. Graphic visualizations of this data can be used to support this type of analysis as shown in [1]. Visualization can also be applied in the domain of learning experiences to track and analyse the data obtained from both learners and instructors. There are several tools that have been proposed in specific environments such as, for example, in personal learning environments [5], to foster self-reflection and awareness [2], and to support instructors in web-based distance learning [3]. These visualizations need to take into account aspects such as how to access and protect personal data, filter management, multi-user support and availability. In this paper, the web-based visualization platform GLASS (Gradient's Learning Analytics System) is presented. The architecture of the tool has been conceived to support a large number of modular visualizations derived from a common dataset containing a large number of recorded events. The tool was developed following a bottom-up methodology to provide a set of basic operations required by any visualization. The design goal is to provide a highly versatile, modular platform that simplifies the implementation of new visualizations. The main functionality elements considered in GLASS are database access, module management, visualization parameters, and the web interface. The platform uses datasets stored using the CAM schema (Contextualized Attention Metadata) [6]. This schema allows to capture events occurring during the use of various computer applications which, in our case, are the tools used by students when working in a learning environment. The process to obtain events from learning environments has been described in [4]. GLASS is able to connect to more than one CAM database, thus allowing access to events obtained in different contexts. The tool is extensible through the installation of modules. A module is a structured set of scripts and resources that, given a dataset of events and a set of filters, generates at least one visualization. In order to simplify the development of new modules, the platform provides an API to manage common visualizations settings such as the date range and other typical filters. A visualization may include a simpler version suitable to be displayed in the user's Dashboard, which is the entry page of the application. Figure 1 shows an example of dashboard in GLASS. Additionally, visualizations can be exported as HTML code to be embedded in another website. The GLASS architecture consists of four layers: data layer, code base, modules and visualizations, as depicted in Figure 2. The data layer is composed of a set of CAM databases and a database to store the platform parameters. The code base is in charge of the main functionalities of GLASS regarding module and user management and interfaces. Modules must comply with the platform specifications to generate visualizations and the settings that can affect their appearance. Currently, the tool includes a default module that provides two visualizations as shown in Figure 1): a frequency time line of activity events and a bar-chart with grouped bars of events generated by different user groups (e.g. events from students individually, or groups). The default module also serves as an example of how to develop a additional modules. Currently, GLASS is able to support new visualizations and is undergoing additional testing in different learning scenarios. Preliminary results obtained from user tests indicate that visualizations need to be very intuitive for both instructors and learners. The current development effort is focused on providing visualizations that show the most-common learners events and the most active learners in a given context. To encourage its use in other institutions, the tool has been released with an open source license and can be obtained from http://glass.mozart.gast.it.uc3m.es. A video demonstrating the tool is available at http://bit.ly/glass-lak12.", "authors": ["Derick Leony", "Abelardo Pardo", "Luis de la Fuente Valent\u00edn", "David S\u00e1nchez de Castro", "Carlos Delgado Kloos"], "session": "SESSION: Visual analytics"}, {"title": "Applying artificial intelligence to the educational data: an example of syllabus quality analysis", "pages": "164-169", "doi": "10.1145/2330601.2330644", "abstract": "Developing new courses and updating existing ones are routine activities for an educator. The quality of a new or updated course depends on the course structure as well as its individual elements. The syllabus defines the structure and the details of the course, thus contributing to the overall quality of the course. This research proposes a new AI based framework to manage the quality of the syllabus. We apply AI methods to automatically evaluate a syllabus on the basis of such characteristics as validity, usability, and efficiency. We provide user trials to show the advantages of the developed approach against the traditional human-based process of syllabi verification and evaluation.", "authors": ["Denis Smolin", "Sergey Butakov"], "session": "SESSION: Educator interventions"}, {"title": "Educational monitoring tool based on faceted browsing and data portraits", "pages": "170-178", "doi": "10.1145/2330601.2330645", "abstract": "Due to the idiosyncrasy of online education, students may become disoriented, frustrated or confused if they do not receive the support, feedback or guidance needed to be successful. To avoid this, the role of teachers is essential. In this regard, instructors should be facilitators who guide students throughout the teaching-learning process and arrange meaningful learner-centered experiences. However, unlike face-to-face classes, teachers have difficulty in monitoring their learners in an online environment, since a lot of learning management systems provide faculty with student tracking data in a poor tabular format that is difficult to understand. In order to overcome this drawback, this paper presents a novel graphical educational monitoring tool based on faceted browsing that helps instructors to gain an insight into their classrooms' performance. Moreover, this tool depicts information of each individual student by using a data portrait. Thanks to this monitoring tool, teachers can, on the one hand, track their students during the teaching-learning process and, on the other, detect potential problems in time.", "authors": ["David Garc\u00eda-Sol\u00f3rzano", "Germ\u00e1n Cobo", "Eug\u00e8nia Santamar\u00eda", "Jose Antonio Mor\u00e1n", "Carlos Monzo", "Javier Melench\u00f3n"], "session": "SESSION: Educator interventions"}, {"title": "Exploring qualitative analytics for e-mentoring relationships building in an online social learning environment", "pages": "179-183", "doi": "10.1145/2330601.2330646", "abstract": "The language of mentoring has become established within the workplace and has gained ground within education. As work based education moves online so we see an increased use of what is termed e-mentoring. In this paper we explore some of the challenges of forming and supporting mentoring relationships virtually, and we explore the solutions afforded by online social learning and Web 2.0. Based on a conceptualization of learning network theory derived from the literature and the qualitative learning analytics, we propose that an e-mentoring relationships is mediated by a connection with or through a person or learning objects. We provide an example to illustrate how this might work.", "authors": ["Haiming Liu", "Ronald Macintyre", "Rebecca Ferguson"], "session": "SESSION: Educator interventions"}, {"title": "Bridging the gap from knowledge to action: putting analytics in the hands of academic advisors", "pages": "184-187", "doi": "10.1145/2330601.2330647", "abstract": "This paper presents current findings from an ongoing design-based research project aimed at developing an early warning system (EWS) for academic mentors in an undergraduate engineering mentoring program. This paper details our progress in mining Learning Management System data and translating these data into an EWS for academic mentors. We focus on the role of mentors and advisors, and elaborate on their importance in learning analytics-based interventions developed for higher education.", "authors": ["Steven Lonn", "Andrew E. Krumm", "R. Joseph Waddington", "Stephanie D. Teasley"], "session": "SESSION: Educator interventions"}, {"title": "Using computational methods to discover student science conceptions in interview data", "pages": "188-197", "doi": "10.1145/2330601.2330649", "abstract": "A large body of research in the learning sciences has focused on students' commonsense science knowledge---the everyday knowledge of the natural world that is gained outside of formal instruction. Although researchers studying commonsense science have employed a variety of methods, one-on-one clinical interviews have played a unique and central role. The data that result from these interviews take the form of video recordings, which in turn are often compiled into written transcripts, and coded by human analysts. In my team's work on learning analytics, we draw on this same type of data, but we attempt to automate its analysis. In this paper, I describe the success we have had using extremely simple methods from computational linguistics---methods that are based on rudimentary vector space models and simple clustering algorithms. These automated analyses are employed in an exploratory mode, as a way to discover student conceptions in the data. The aims of this paper are primarily methodological in nature; I will attempt to show that it is possible to use techniques from computational linguistics to analyze data from commonsense science interviews. As a test bed, I draw on transcripts of a corpus of interviews in which 54 middle school students were asked to explain the seasons.", "authors": ["Bruce Sherin"], "session": "SESSION: Textual analytics & analytics infrastructure"}, {"title": "Deriving group profiles from social media to facilitate the design of simulated environments for learning", "pages": "198-207", "doi": "10.1145/2330601.2330650", "abstract": "Simulated environments for learning are becoming increasingly popular to support experiential learning in complex domains. A key challenge when designing simulated learning environments is how to align the experience in the simulated world with real world experiences. Social media resources provide user-generated content that is rich in digital traces of real world experiences. People comments, tweets, and blog posts in social spaces can reveal interesting aspects of real world situations or can show what particular group of users is interested in or aware of. This paper examines a systematic way to analyze user-generated content in social media resources to provide useful information for learning simulator design. A hybrid framework exploiting Machine Learning and Semantics for social group profiling is presented. The framework has five stages: (1) Retrieval of user-generated content from the social resource (2) Content noise filtration, removing spam, abuse, and content irrelevant to the learning domain; (3) Deriving individual social profiles for the content authors; (4) Clustering of individuals into groups of similar authors; and (5) Deriving group profiles, where interesting concepts suitable for the use in simulated learning systems are extracted from the aggregated content authored by each group. The framework is applied to derive group profiles by mining user comments on YouTube videos. The application is evaluated in an experimental study within the context of learning interpersonal skills in job interviews. The paper discusses how the YouTube-based group profiles can be used to facilitate the design of a job interview skills learning simulator, considering: (1) identifying learning needs based on digital traces of real world experiences; and (2) augmenting learner models in simulators based on group characteristics derived from social media.", "authors": ["Ahmad Ammari", "Lydia Lau", "Vania Dimitrova"], "session": "SESSION: Textual analytics & analytics infrastructure"}, {"title": "The learning registry: building a foundation for learning resource analytics", "pages": "208-211", "doi": "10.1145/2330601.2330651", "abstract": "We describe our experimentation with the current implementation of a distribution system used to share descriptive and social metadata about learning resources. The Learning Registry, developed and released in a beta version in October 2011, is intended to store and forward learning-resource metadata among a distributed, de-centralized network of nodes. The Learning Registry also accepts social/attention metadata---data about users of and activity around the learning resource. The Learning Registry open-source community has proposed a schema for sharing social metadata, and has experimented with a number of organizations representing their social metadata using that schema. This paper describes the results and challenges, and the learning-resource analytics applications that will use Learning Registry data as their foundation.", "authors": ["Marie Bienkowski", "John Brecht", "Jim Klo"], "session": "SESSION: Textual analytics & analytics infrastructure"}, {"title": "Monitoring student progress through their written \"point of originality\"", "pages": "212-221", "doi": "10.1145/2330601.2330653", "abstract": "This paper describes a new method for the objective evaluation of student work through the identification of original content in writing assignments. Using WordNet as a lexical reference, this process allows instructors to track how key phrases are employed and evolve over the course of a student's writing, and to automatically visualize the point at which the student's language first demonstrates original thought, phrased in their own, original words. The paper presents a case study where the analysis method was evaluated by analyzing co-blogging data from a reading and writing intensive undergraduate course. The evidence shows that the tool can be predictive of students' writing in a manner that correlates with their progress in the course and engagement in the technology-mediated activity. By visualizing otherwise subjective information in a way that is objectively intelligible, the goal is to provide educators with the ability to monitor student investment in concepts from the course syllabus, and to extend or modify the boundaries of the syllabus in anticipation of pre-existing knowledge or trends in interest. A tool of this sort can be of value particularly in larger gateway courses, where the sheer size of the class makes the ongoing evaluation of student progress a daunting if not otherwise impossible task.", "authors": ["J\u00f3hann Ari L\u00e1russon", "Brandon White"], "session": "SESSION: Empirical studies"}, {"title": "Learning analytics for collaborative writing: a prototype and case study", "pages": "222-225", "doi": "10.1145/2330601.2330654", "abstract": "This paper explores the ways in which participants in writing intensive environments might use learning analytics to make productive interventions during, rather than after, the collaborative construction of written artifacts. Specifically, our work considered how university students learning in a knowledge work model---one that is collaborative, project-based, and that relies on consistent peer-to-peer interaction and feedback---might leverage learning analytics as formative assessment to foster metacognition and improve final deliverables. We describe Uatu, a system designed to visualize the real time contribution and edit history of collaboratively written documents. After briefly describing the technical details of this system, we offer initial findings from a fifteen week qualitative case study of 8 computer science students who used Uatu in conjunction with Google Docs while collaborating on a variety of writing and programming tasks. These findings indicate both the challenges and promise of delivering useful metrics for collaborative writing scenarios in academe and industry.", "authors": ["Brian J. McNely", "Paul Gestwicki", "J. Holden Hill", "Philip Parli-Horne", "Erika Johnson"], "session": "SESSION: Empirical studies"}, {"title": "The relationship between educational performance and online access routines: analysis of students' access to an online discussion forum", "pages": "226-229", "doi": "10.1145/2330601.2330655", "abstract": "A study of behaviour patterns associated with students accessing an online discussion forum is presented. Data collected on the frequency of access and the duration of sessions is analysed to establish several categories of learners, which depict the differences among the cohort in terms of participation in social learning. A British business school course for second year undergraduates was studied over two years (i.e. two cohorts) and the results were combined to derive categories of learner types. We conclude that that academic attainment does not appear to be related to student access behaviour necessarily.", "authors": ["Tariq M. Khan", "Fintan Clear", "Samira Sadat Sajadi"], "session": "SESSION: Empirical studies"}, {"title": "Investigating the core group effect in usage of resources with analytics", "pages": "230-233", "doi": "10.1145/2330601.2330656", "abstract": "In many educational institutions, face to face as well as on-line teaching is supported by the use of a Learning Management System (LMS). To be able to analyze better data stored by LMS, we have started developing a dedicated tool for this purpose. While analyzing usage data with teachers, we have noticed that the number of students attempting non self-tests decreases during the semester. Teachers were interested in investigating this pattern further to uncover the strategy adopted by students. In this paper, we explain our approach to investigate the core group effect in resources usage: given a set of resources, is a group of students emerging that continuously uses the resources or, on the contrary, are the resources used on an irregular basis by different students? We answer this question checking the confidence of what we call local rules and global rules. We show a case study conducted with our analysis tool as a first step to validate our approach.", "authors": ["Agathe Merceron"], "session": "SESSION: Empirical studies"}, {"title": "Does the length of time off-task matter?", "pages": "234-237", "doi": "10.1145/2330601.2330657", "abstract": "We investigate the relationship between a student's time off-task and the amount that he or she learns to see whether or not the relationship between time off-task and learning is a more complex model than the traditional linear model typically studied. The data collected is based off of students' interactions with Cognitive Tutor learning software. Analysis suggested that more complex functions did not fit the data significantly better than a linear function. In addition, there was not evidence that the length of a specific pause matters for predicting learning outcomes; e.g. students who make many short pauses do not appear to learn more or less than students who make a smaller number of long pauses. As such, previous theoretical accounts arguing that off-task behavior primarily reduces learning by reducing the amount of time spent learning remain congruent with the current evidence.", "authors": ["Daniel Roberge", "Anthony Rojas", "Ryan Baker"], "session": "SESSION: Empirical studies"}, {"title": "Clustering by usage: higher order co-occurrences of learning objects", "pages": "238-247", "doi": "10.1145/2330601.2330659", "abstract": "In this paper, we introduce a new way of detecting semantic similarities between learning objects by analyzing their usage in a web portal. Our approach does not rely on the content of the learning objects or on the relations between the users and the learning objects but on usage-based relations between the objects themselves. The technique we apply for calculating higher order co-occurrences to create semantically homogenous clusters of data objects is taken from corpus driven lexicology where it is used to cluster words. We expect the members of a higher order co-occurrence class to be similar according to their content and present the evaluations of that assumption using two teaching and learning systems.", "authors": ["Katja Niemann", "Hans-Christian Schmitz", "Uwe Kirschenmann", "Martin Wolpers", "Anna Schmidt", "Tim Krones"], "session": "SESSION: Educational data mining"}, {"title": "Using agglomerative hierarchical clustering to model learner participation profiles in online discussion forums", "pages": "248-251", "doi": "10.1145/2330601.2330660", "abstract": "Online discussion forums are a key element in virtual learning environments. The way learners participate in discussion boards can be a very useful source of indicators for teachers to facilitate their tasks. The use of a two-stage analysis strategy based on an agglomerative hierarchical clustering algorithm is proposed in this paper to identify different participation profiles adopted by learners in online discussion forums. Different parameters are used to characterize learners' activity (amount of posts, rhythm, depth of threads, crossed replies, etc). Participation profiles are identified and analyzed in terms of behavior and performance.", "authors": ["Germ\u00e1n Cobo", "David Garc\u00eda-Sol\u00f3rzano", "Jose Antonio Mor\u00e1n", "Eug\u00e8nia Santamar\u00eda", "Carlos Monzo", "Javier Melench\u00f3n"], "session": "SESSION: Educational data mining"}, {"title": "Learning analytics and educational data mining: towards communication and collaboration", "pages": "252-254", "doi": "10.1145/2330601.2330661", "abstract": "Growing interest in data and analytics in education, teaching, and learning raises the priority for increased, high-quality research into the models, methods, technologies, and impact of analytics. Two research communities -- Educational Data Mining (EDM) and Learning Analytics and Knowledge (LAK) have developed separately to address this need. This paper argues for increased and formal communication and collaboration between these communities in order to share research, methods, and tools for data mining and analysis in the service of developing both LAK and EDM fields.", "authors": ["George Siemens", "Ryan S. J. d. Baker"], "session": "SESSION: Educational data mining"}, {"title": "Probability estimation and a competence model for rule based e-tutoring systems", "pages": "255-258", "doi": "10.1145/2330601.2330663", "abstract": "In this paper, we present a student model for rule based e-tutoring systems. This model describes both properties of rewrite rules (difficulty and discriminativity) and of students (start competence and learning speed). The model is an extension of the two-parameter logistic ogive function of Item Response Theory. We show that the model can be applied even to relatively small datasets. We gather data from students working on problems in the logic domain, and show that the model estimates of rule difficulty correspond well to expert opinions. We also show that the estimated start competence corresponds well to our expectations based on the previous experience of the students in the logic domain. We point out that this model can be used to inform students about their competence and learning, and teachers about the students and the difficulty and discriminativity of the rules.", "authors": ["Diederik M. Roijers", "Johan Jeuring", "Ad Feelders"], "session": "SESSION: Predictive modeling"}, {"title": "Course correction: using analytics to predict course success", "pages": "259-262", "doi": "10.1145/2330601.2330664", "abstract": "Predictive analytics techniques applied to a broad swath of student data can aid in timely intervention strategies to help prevent students from failing a course. This paper discusses a predictive analytic model that was created for the University of Phoenix. The purpose of the model is to identify students who are in danger of failing the course in which they are currently enrolled. Within the model's architecture, data from the learning management system (LMS), financial aid system, and student system are combined to calculate a likelihood of any given student failing the current course. The output can be used to prioritize students for intervention and referral to additional resources. The paper includes a discussion of the predictor and statistical tests used, validation procedures, and plans for implementation.", "authors": ["Rebecca Barber", "Mike Sharkey"], "session": "SESSION: Predictive modeling"}, {"title": "Predicting failure: a case study in co-blogging", "pages": "263-266", "doi": "10.1145/2330601.2330665", "abstract": "Monitoring student progress in homework is important but difficult to do. The work in this paper presents a method for monitoring student progress based on their participation. By tracking participation we can successfully create a model that predicts, with very high accuracy, if a student is going to score a low grade on her current assignment before it is completed, thus enabling selective interventions.", "authors": ["Bjorn Levi Gunnarsson", "Richard Alterman"], "session": "SESSION: Predictive modeling"}, {"title": "Course signals at Purdue: using learning analytics to increase student success", "pages": "267-270", "doi": "10.1145/2330601.2330666", "abstract": "In this paper, an early intervention solution for collegiate faculty called Course Signals is discussed. Course Signals was developed to allow instructors the opportunity to employ the power of learner analytics to provide real-time feedback to a student. Course Signals relies not only on grades to predict students' performance, but also demographic characteristics, past academic history, and students' effort as measured by interaction with Blackboard Vista, Purdue's learning management system. The outcome is delivered to the students via a personalized email from the faculty member to each student, as well as a specific color on a stoplight -- traffic signal -- to indicate how each student is doing. The system itself is explained in detail, along with retention and performance outcomes realized since its implementation. In addition, faculty and student perceptions will be shared.", "authors": ["Kimberly E. Arnold", "Matthew D. Pistilli"], "session": "SESSION: Predictive modeling"}]}, {"year": 2013, "papers": [{"title": "Learning analytics as a \"middle space\"", "pages": "1-4", "doi": "10.1145/2460296.2460298", "abstract": "Learning Analytics, an emerging field concerned with analyzing the vast data \"given off\" by learners in technology supported settings to inform educational theory and practice, has from its inception taken a multidisciplinary approach that integrates studies of learning with technological capabilities. In this introduction to the Proceedings of the Third International Learning Analytics & Knowledge Conference, we discuss how Learning Analytics must function in the \"middle space\" where learning and analytic concerns meet. Dialogue in this middle space involves diverse stakeholders from multiple disciplines with various conceptions of the agency and nature of learning. We hold that a singularly unified field is not possible nor even desirable if we are to leverage the potential of this diversity, but progress is possible if we support \"productive multivocality\" between the diverse voices involved, facilitated by appropriate use of boundary objects. We summarize the submitted papers and contents of these Proceedings to characterize the voices and topics involved in the multivocal discourse of Learning Analytics.", "authors": ["Dan Suthers", "Katrien Verbert"], "session": "SESSION: Reflections on learning analytics"}, {"title": "Multidisciplinarity vs. Multivocality, the case of \"learning analytics\"", "pages": "5-13", "doi": "10.1145/2460296.2460299", "abstract": "In this paper, we consider an analysis of the TeLearn archive, of the Grand Challenges from the STELLAR Network of Excellence, of two Alpine Rendez-Vous 2011 workshops and research conducted in the Productive Multivocality initiative in order to discuss the notions of multidisciplinarity, multivocality and interidisciplinarity. We use this discussion as a springboard for addressing the term \"Learning Analytics\" and its relation to \"Educational Data Mining\". Our goal is to launch a debate pertaining to what extent the different disciplines involved in the TEL community can be integrated on methodological and theoretical levels.", "authors": ["Nicolas Balacheff", "Kristine Lund"], "session": "SESSION: Reflections on learning analytics"}, {"title": "Addressing learner issues with StepUp!: an evaluation", "pages": "14-22", "doi": "10.1145/2460296.2460301", "abstract": "This paper reports on our research on the use of learning analytics dashboards to support awareness, self-reflection, sensemaking and impact for learners. So far, little research has been done to evaluate such dashboards with students and to assess their impact on learning. In this paper, we present the results of an evaluation study of our dashboard, called StepUp!, and the extent to which it addresses issues and needs of our students. Through brainstorming sessions with our students, we identified and prioritized learning issues and needs. In a second step, we deployed StepUp! during one month and we evaluated to which extent our dashboard addresses the issues and needs identified earlier in different courses. The results show that our tool has potentially higher impact for students working in groups and sharing a topic than students working individually on different topics.", "authors": ["Jose Luis Santos", "Katrien Verbert", "Sten Govaerts", "Erik Duval"], "session": "SESSION: Visualization to support awareness and reflection"}, {"title": "Live interest meter: learning from quantified feedback in mass lectures", "pages": "23-27", "doi": "10.1145/2460296.2460302", "abstract": "There is currently little or no support for speakers to learn by reflection when addressing a big audience, like mass lectures, virtual courses or conferences. Reliable feedback from the audience could improve personal skills and work performance. To address this shortcoming we have developed the Live Interest Meter App (LIM App) that supports the gathering, aggregation and visualization of feedback. This application allows audience members to easily provide and quantify their feedback through a simple meter. We conducted several experimental tests to investigate the acceptance and perceived usefulness of the LIM App and a user study in an academic setting to inform its further development. The results of the study illustriate the potential of the LIM App to be used in such scenarios. Main findings show the need for motivating students to use the application, the readiness of presenters to learn retrospectively, and distraction as the main concern of end users.", "authors": ["Ver\u00f3nica Rivera-Pelayo", "Johannes Munk", "Valentin Zacharias", "Simone Braun"], "session": "SESSION: Visualization to support awareness and reflection"}, {"title": "Considering formal assessment in learning analytics within a PLE: the HOU2LEARN case", "pages": "28-32", "doi": "10.1145/2460296.2460304", "abstract": "Personal Learning Environments are used more and more by the academic community. They can coexist with formal courses as a communication and collaboration channel. In this paper, an application of learning analytics into HOU2LEARN, a Personal Learning Environment set by Hellenic Open University is discussed. The present part of research focuses on the social network analysis as a branch of learning analytics, along with formal grading system. Since it is an ongoing research, this paper presents the preliminary results of the study of the correlation between the social network metrics and the formal grades, through a test case course, the PLH42.", "authors": ["Eleni Koulocheri", "Michalis Xenos"], "session": "SESSION: Social network analysis and visualization"}, {"title": "Visualizing social learning ties by type and topic: rationale and concept demonstrator", "pages": "33-37", "doi": "10.1145/2460296.2460305", "abstract": "Social Learning Analytics (SLA) are designed to support students learning through social networks, and reflective practitioners engage in informal learning through a community of practice. This short paper reports work in progress to develop SLA motivated specifically by Networked Learning Theory, drawing on the related concepts and tools of Social Network Analytics and Social Capital Theory, which provide complementary perspectives onto the structure and content of such networks. We propose that SLA based on these perspectives needs to devise models and visualizations capable of showing not only the usual SNA metrics, but the types of social tie forged between actors, and topic-specific subnetworks. We describe a technical implementation demonstrating this approach, which extends the Network Awareness Tool by automatically populating it with data from a social learning platform SocialLearn. The result is the ability to visualize relationships between people who interact around the same topics.", "authors": ["Bieke Schreurs", "Chris Teplovs", "Rebecca Ferguson", "Maarten de Laat", "Simon Buckingham Shum"], "session": "SESSION: Social network analysis and visualization"}, {"title": "Analysis of collaborative writing processes using revision maps and probabilistic topic models", "pages": "38-47", "doi": "10.1145/2460296.2460307", "abstract": "The use of cloud computing writing tools, such as Google Docs, by students to write collaboratively provides unprecedented data about the progress of writing. This data can be exploited to gain insights on how learners' collaborative activities, ideas and concepts are developed during the process of writing. Ultimately, it can also be used to provide support to improve the quality of the written documents and the writing skills of learners involved. In this paper, we propose three visualisation approaches and their underlying techniques for analysing writing processes used in a document written by a group of authors: (1) the revision map, which summarises the text edits made at the paragraph level, over the time of writing. (2) the topic evolution chart, which uses probabilistic topic models, especially Latent Dirichlet Allocation (LDA) and its extension, DiffLDA, to extract topics and follow their evolution during the writing process. (3) the topic-based collaboration network, which allows a deeper analysis of topics in relation to author contribution and collaboration, using our novel algorithm DiffATM in conjunction with a DiffLDA-related technique. These models are evaluated to examine whether these automatically discovered topics accurately describe the evolution of writing processes. We illustrate how these visualisations are used with real documents written by groups of graduate students.", "authors": ["Vilaythong Southavilay", "Kalina Yacef", "Peter Reimann", "Rafael A. Calvo"], "session": "SESSION: Communication and collaboration"}, {"title": "Learning analytics for online discussions: a pedagogical model for intervention with embedded and extracted analytics", "pages": "48-56", "doi": "10.1145/2460296.2460308", "abstract": "This paper describes an application of learning analytics that builds on an existing research program investigating how students contribute and attend to the messages of others in online discussions. A pedagogical model that translates the concepts and findings of the research program into guidelines for practice and analytics with which students and instructors can assess their discussion participation are presented. The analytics are both embedded in the learning environment and extracted from it, allowing for integrated and reflective metacognitive activity. The pedagogical intervention is based on the principles of (1) Integration (2) Diversity (of Metrics) (3) Agency (4) Reflection (5) Parity and (6) Dialogue. Details of an initial implementation of this approach and preliminary findings are described. Initial results strongly support the value of student-teacher dialogue around the analytics. In contrast, instructor parity in analytics use did not seem as important to students as was expected. Analytics were reported as useful in validating invisible discussion activity, but at times triggered emotionally-charged responses.", "authors": ["Alyssa Friend Wise", "Yuting Zhao", "Simone Nicole Hausknecht"], "session": "SESSION: Communication and collaboration"}, {"title": "Understanding promotions in a case study of student blogging", "pages": "57-65", "doi": "10.1145/2460296.2460309", "abstract": "Promoting blog content is a social activity; it is a means of communicating one student's appreciation of another student's work. This paper explores the feasibility of using student promotions of content, in a blogosphere, to identify quality content, and implications for instructors. We show that students actively and voluntarily promote content, use promotion data to select which posts to read, and with considerable accuracy identify quality material. We explore the benefits of knowing which students are good and poor predictors of quality content, and what instructors can do with this information in terms of feedback and guidance.", "authors": ["Bjorn Levi Gunnarsson", "Richard Alterman"], "session": "SESSION: Communication and collaboration"}, {"title": "Analyzing the flow of ideas and profiles of contributors in an open learning community", "pages": "66-74", "doi": "10.1145/2460296.2460311", "abstract": "This paper provides an introduction to the scientometric method of main path analysis and its application to detecting idea flows in an online learning community using data from Wikiversity. We see this as a step forward in adapting and adopting network analysis techniques for analyzing the evolution of artifacts in knowledge building communities. The analysis steps are presented in detail including the description of a tool environment (\"workbench\") designed for flexible use by non-computer experts. Through the definition of directed acyclic graphs the meaningful interconnectedness of learning resources is made accessible to analysis in consideration of the temporal sequence of their creation during a collaborative process. The potential of the method is elaborated for analyzing the overall learning process of a community as well as the individual contributions of the participants.", "authors": ["Iassen Halatchliyski", "Tobias Hecking", "Tilman G\u00f6hnert", "H. Ulrich Hoppe"], "session": "SESSION: Discourse analytics"}, {"title": "Epistemology, pedagogy, assessment and learning analytics", "pages": "75-84", "doi": "10.1145/2460296.2460312", "abstract": "There is a well-established literature examining the relationships between epistemology (the nature of knowledge), pedagogy (the nature of learning and teaching), and assessment. Learning Analytics (LA) is a new assessment technology and should engage with this literature since it has implications for when and why different LA tools might be deployed. This paper discusses these issues, relating them to an example construct, epistemic beliefs -- beliefs about the nature of knowledge -- for which analytics grounded in pragmatic, sociocultural theory might be well placed to explore. This example is particularly interesting given the role of epistemic beliefs in the everyday knowledge judgements students make in their information processing. Traditional psychological approaches to measuring epistemic beliefs have parallels with high stakes testing regimes; this paper outlines an alternative LA for epistemic beliefs which might be readily applied to other areas of interest. Such sociocultural approaches afford opportunity for engaging LA directly in high quality pedagogy.", "authors": ["Simon Knight", "Simon Buckingham Shum", "Karen Littleton"], "session": "SESSION: Discourse analytics"}, {"title": "An evaluation of learning analytics to identify exploratory dialogue in online discussions", "pages": "85-93", "doi": "10.1145/2460296.2460313", "abstract": "Social learning analytics are concerned with the process of knowledge construction as learners build knowledge together in their social and cultural environments. One of the most important tools employed during this process is language. In this paper we take exploratory dialogue, a joint form of co-reasoning, to be an external indicator that learning is taking place. Using techniques developed within the field of computational linguistics, we build on previous work using cue phrases to identify exploratory dialogue within online discussion. Automatic detection of this type of dialogue is framed as a binary classification task that labels each contribution to an online discussion as exploratory or non-exploratory. We describe the development of a self-training framework that employs discourse features and topical features for classification by integrating both cue-phrase matching and k-nearest neighbour classification. Experiments with a corpus constructed from the archive of a two-day online conference show that our proposed framework outperforms other approaches. A classifier developed using the self-training framework is able to make useful distinctions between the learning dialogue taking place at different times within an online conference as well as between the contributions of individual participants.", "authors": ["Rebecca Ferguson", "Zhongyu Wei", "Yulan He", "Simon Buckingham Shum"], "session": "SESSION: Discourse analytics"}, {"title": "Towards the development of multimodal action based assessment", "pages": "94-101", "doi": "10.1145/2460296.2460315", "abstract": "In this paper, we describe multimodal learning analytics techniques for understanding and identifying expertise as students engage in a hands-on building activity. Our techniques leverage process-oriented data, and demonstrate how this temporal data can be used to study student learning. The proposed techniques introduce useful insights in how to segment and analyze gesture- and action-based generally, and may also be useful for other sources of process rich data. Using this approach we uncover new ideas about how experts engage in building activities. Finally, a primary objective of this work is to motivate additional research and development in the area of authentic, automated, process-oriented assessments.", "authors": ["Marcelo Worsley", "Paulo Blikstein"], "session": "SESSION: Behavior analysis"}, {"title": "Multimodal learning analytics", "pages": "102-106", "doi": "10.1145/2460296.2460316", "abstract": "New high-frequency data collection technologies and machine learning analysis techniques could offer new insights into learning, especially in tasks in which students have ample space to generate unique, personalized artifacts, such as a computer program, a robot, or a solution to an engineering challenge. To date most of the work on learning analytics and educational data mining has focused on online courses or cognitive tutors, in which the tasks are more structured and the entirety of interaction happens in front of a computer. In this paper, I argue that multimodal learning analytics could offer new insights into students' learning trajectories, and present several examples of this work and its educational application.", "authors": ["Paulo Blikstein"], "session": "SESSION: Behavior analysis"}, {"title": "Toward collaboration sensing: applying network analysis techniques to collaborative eye-tracking data", "pages": "107-111", "doi": "10.1145/2460296.2460317", "abstract": "In this paper we describe preliminary applications of network analysis techniques to eye-tracking data. In a previous study, the first author conducted a collaborative learning experiment in which subjects had access (or not) to a gaze-awareness tool: their task was to learn from neuroscience diagrams in a remote collaboration. In the treatment group, they could see the gaze of their partner displayed on the screen in real-time. In the control group, they could not. Dyads in the treatment group achieved a higher quality of collaboration and a higher learning gain. In this paper, we describe how network analysis techniques can further illuminate these results, and contribute to the development of 'collaboration sensing'. More specifically, we describe two contributions: first, one can use networks to visualize and explore eye-tracking data. Second, network metrics can be computed to interpret the properties of the graph. We conclude with comments on implementing this approach for formal learning environments.", "authors": ["Bertrand Schneider", "Sami Abu-El-Haija", "Jim Reesman", "Roy Pea"], "session": "SESSION: Behavior analysis"}, {"title": "Inferring higher level learning information from low level data for the Khan Academy platform", "pages": "112-116", "doi": "10.1145/2460296.2460318", "abstract": "To process low level educational data in the form of user events and interactions and convert them into information about the learning process that is both meaningful and interesting presents a challenge. In this paper, we propose a set of high level learning parameters relating to total use, efficient use, activity time distribution, gamification habits, or exercise-making habits, and provide the measures to calculate them as a result of processing low level data. We apply these parameters and measures in a real physics course with more than 100 students using the Khan Academy platform at Universidad Carlos III de Madrid. We show how these parameters can be meaningful and useful for the learning process based on the results from this experience.", "authors": ["Pedro J. Mu\u00f1oz-Merino", "Jos\u00e9 A. Ruip\u00e9rez Valiente", "Carlos Delgado Kloos"], "session": "SESSION: Behavior analysis"}, {"title": "Affective states and state tests: investigating how affect throughout the school year predicts end of year learning outcomes", "pages": "117-124", "doi": "10.1145/2460296.2460320", "abstract": "In this paper, we investigate the correspondence between student affect in a web-based tutoring platform throughout the school year and learning outcomes at the end of the year, on a high-stakes mathematics exam. The relationships between affect and learning outcomes have been previously studied, but not in a manner that is both longitudinal and finer-grained. Affect detectors are used to estimate student affective states based on post-hoc analysis of tutor log-data. For every student action in the tutor the detectors give us an estimated probability that the student is in a state of boredom, engaged concentration, confusion, and frustration, and estimates of the probability that they are exhibiting off-task or gaming behaviors. We ran the detectors on two years of log-data from 8th grade student use of the ASSISTments math tutoring system and collected corresponding end of year, high stakes, state math test scores for the 1,393 students in our cohort. By correlating these data sources, we find that boredom during problem solving is negatively correlated with performance, as expected; however, boredom is positively correlated with performance when exhibited during scaffolded tutoring. A similar pattern is unexpectedly seen for confusion. Engaged concentration and frustration are both associated with positive learning outcomes, surprisingly in the case of frustration.", "authors": ["Zachary A. Pardos", "Ryan S. J. D. Baker", "Maria O. C. Z. San Pedro", "Sujith M. Gowda", "Supreeth M. Gowda"], "session": "SESSION: Affect analytics"}, {"title": "An eye-tracking study of notational, informational, and emotional aspects of learning analytics representations", "pages": "125-134", "doi": "10.1145/2460296.2460321", "abstract": "This paper presents an eye-tracking study of notational, informational, and emotional aspects of nine different notational systems (Skill Meters, Smilies, Traffic Lights, Topic Boxes, Collective Histograms, Word Clouds, Textual Descriptors, Table, and Matrix) and three different information states (Weak, Average, & Strong) used to represent student's learning. Findings from the eye-tracking study show that higher emotional activation was observed for the metaphorical notations of traffic lights and smilies and collective representations. Mean view time was higher for representations of the \"average\" informational learning state. Qualitative data analysis of the think-aloud comments and post-study interview show that student participants reflected on the meaning-making opportunities and action-taking possibilities afforded by the representations. Implications for the design and evaluation of learning analytics representations and discourse environments are discussed.", "authors": ["Ravi Vatrapu", "Peter Reimann", "Susan Bull", "Matthew Johnson"], "session": "SESSION: Affect analytics"}, {"title": "What can we learn from Facebook activity?: using social learning analytics to observe new media literacy skills", "pages": "135-144", "doi": "10.1145/2460296.2460323", "abstract": "Social media platforms such as Facebook are now a ubiquitous part of everyday life for many people. New media scholars posit that the participatory culture encouraged by social media gives rise to new forms of literacy skills that are vital to learning. However, there have been few attempts to use analytics to understand the new media literacy skills that may be embedded in an individual's participation in social media. In this paper, I collect raw activity data that was shared by an exploratory sample of Facebook users. I then utilize factor analysis and regression models to show how (a) Facebook members' online activity coalesce into distinct categories of social media behavior and (b) how these participatory behaviors correlate with and predict measures of new media literacy skills. The study demonstrates the use of analytics to understand the literacies embedded in people's social media activity. The implications speak to the potential of social learning analytics to identify and predict new media literacy skills from data streams in social media platforms.", "authors": ["June Ahn"], "session": "SESSION: Predictive analytics"}, {"title": "Improving retention: predicting at-risk students by analysing clicking behaviour in a virtual learning environment", "pages": "145-149", "doi": "10.1145/2460296.2460324", "abstract": "One of the key interests for learning analytics is how it can be used to improve retention. This paper focuses on work conducted at the Open University (OU) into predicting students who are at risk of failing their module. The Open University is one of the worlds largest distance learning institutions. Since tutors do not interact face to face with students, it can be difficult for tutors to identify and respond to students who are struggling in time to try to resolve the difficulty. Predictive models have been developed and tested using historic Virtual Learning Environment (VLE) activity data combined with other data sources, for three OU modules. This has revealed that it is possible to predict student failure by looking for changes in user's activity in the VLE, when compared against their own previous behaviour, or that of students who can be categorised as having similar learning behaviour. More focused analysis of these modules applying the GUHA (General Unary Hypothesis Automaton) method of data analysis has also yielded some early promising results for creating accurate hypothesis about students who fail.", "authors": ["Annika Wolff", "Zdenek Zdrahal", "Andriy Nikolov", "Michal Pantucek"], "session": "SESSION: Predictive analytics"}, {"title": "Open academic analytics initiative: initial research findings", "pages": "150-154", "doi": "10.1145/2460296.2460325", "abstract": "This paper describes the results on research work performed by the Open Academic Analytics Initiative, an on-going research project aimed at developing an early detection system of college students at academic risk, using data mining models trained using student personal and demographic data, as well as course management data. We report initial findings on the predictive performance of those models, their portability across pilot programs in different institutions and the results of interventions applied on those pilots.", "authors": ["Eitel J. M. Laur\u00eda", "Erik W. Moody", "Sandeep M. Jayaprakash", "Nagamani Jonnalagadda", "Joshua D. Baron"], "session": "SESSION: Predictive analytics"}, {"title": "Interpreting data mining results with linked data for learning analytics: motivation, case study and directions", "pages": "155-164", "doi": "10.1145/2460296.2460327", "abstract": "Learning Analytics by nature relies on computational information processing activities intended to extract from raw data some interesting aspects that can be used to obtain insights into the behaviours of learners, the design of learning experiences, etc. There is a large variety of computational techniques that can be employed, all with interesting properties, but it is the interpretation of their results that really forms the core of the analytics process. In this paper, we look at a specific data mining method, namely sequential pattern extraction, and we demonstrate an approach that exploits available linked open data for this interpretation task. Indeed, we show through a case study relying on data about students' enrolment in course modules how linked data can be used to provide a variety of additional dimensions through which the results of the data mining method can be explored, providing, at interpretation time, new input into the analytics process.", "authors": ["Mathieu d'Aquin", "Nicolas Jay"], "session": "SESSION: Sequence analytics"}, {"title": "Nanogenetic learning analytics: illuminating student learning pathways in an online fraction game", "pages": "165-169", "doi": "10.1145/2460296.2460328", "abstract": "A working understanding of fractions is critical to student success in high school and college math. Therefore, an understanding of the learning pathways that lead students to this working understanding is important for educators to provide optimal learning environments for their students. We propose the use of microgenetic analysis techniques including data mining and visualizations to inform our understanding of the process by which students learn fractions in an online game environment. These techniques help identify important variables and classification algorithms to group students by their learning trajectories.", "authors": ["Taylor Martin", "Ani Aghababyan", "Jay Pfaffman", "Jenna Olsen", "Stephanie Baker", "Philip Janisiewicz", "Rachel Phillips", "Carmen Petrick Smith"], "session": "SESSION: Sequence analytics"}, {"title": "Deconstructing disengagement: analyzing learner subpopulations in massive open online courses", "pages": "170-179", "doi": "10.1145/2460296.2460330", "abstract": "As MOOCs grow in popularity, the relatively low completion rates of learners has been a central criticism. This focus on completion rates, however, reflects a monolithic view of disengagement that does not allow MOOC designers to target interventions or develop adaptive course features for particular subpopulations of learners. To address this, we present a simple, scalable, and informative classification method that identifies a small number of longitudinal engagement trajectories in MOOCs. Learners are classified based on their patterns of interaction with video lectures and assessments, the primary features of most MOOCs to date. In an analysis of three computer science MOOCs, the classifier consistently identifies four prototypical trajectories of engagement. The most notable of these is the learners who stay engaged through the course without taking assessments. These trajectories are also a useful framework for the comparison of learner engagement between different course structures or instructional approaches. We compare learners in each trajectory and course across demographics, forum participation, video access, and reports of overall experience. These results inform a discussion of future interventions, research, and design directions for MOOCs. Potential improvements to the classification mechanism are also discussed, including the introduction of more fine-grained analytics.", "authors": ["Ren\u00e9 F. Kizilcec", "Chris Piech", "Emily Schneider"], "session": "SESSION: MOOCs"}, {"title": "The pairing of lecture recording data with assessment scores: a method of discovering pedagogical impact", "pages": "180-184", "doi": "10.1145/2460296.2460331", "abstract": "Web technologies, such as lecture recordings, have the capacity to capture and store massive amounts of data from individuals' online behavior. Such data can provide insight into student learning processes and the relationship between online trace data and academic performance alerting educators to when intervention may be required or if their learning activities may need to be adjusted. This paper discusses how data captured from students' use of lecture recordings accessed through a Collaborative Lecture Annotation System (CLAS) when aggregated and correlated with assessment data can help educators evaluate the impact of the recordings on their students' learning. Such information can help inform and alert educators to when adjustments may be required to their pedagogical approach.", "authors": ["Negin Mirriahi", "Shane Dawson"], "session": "SESSION: MOOCs"}, {"title": "MOOCs and the funnel of participation", "pages": "185-189", "doi": "10.1145/2460296.2460332", "abstract": "Massive Online Open Courses (MOOCs) are growing substantially in numbers, and also in interest from the educational community. MOOCs offer particular challenges for what is becoming accepted as mainstream practice in learning analytics. Partly for this reason, and partly because of the relative newness of MOOCs as a widespread phenomenon, there is not yet a substantial body of literature on the learning analytics of MOOCs. However, one clear finding is that drop-out/non-completion rates are substantially higher than in more traditional education. This paper explores these issues, and introduces the metaphor of a 'funnel of participation' to reconceptualise the steep drop-off in activity, and the pattern of steeply unequal participation, which appear to be characteristic of MOOCs and similar learning environments. Empirical data to support this funnel of participation are presented from three online learning sites: iSpot (observations of nature), Cloudworks ('a place to share, find and discuss learning and teaching ideas and experiences'), and openED 2.0, a MOOC on business and management that ran between 2010--2012. Implications of the funnel for MOOCs, formal education, and learning analytics practice are discussed.", "authors": ["Doug Clow"], "session": "SESSION: MOOCs"}, {"title": "What different kinds of stratification can reveal about the generalizability of data-mined skill assessment models", "pages": "190-194", "doi": "10.1145/2460296.2460334", "abstract": "When validating assessment models built with data mining, generalization is typically tested at the student-level, where models are tested on new students. This approach, though, may fail to find cases where model performance suffers if other aspects of those cases relevant to prediction are not well represented. We explore this here by testing if scientific inquiry skill models built and validated for one science topic can predict skill demonstration for new students and a new science topic. Test cases were chosen using two methods: student-level stratification, and stratification based on the amount of trials ran during students' experimentation. We found that predictive performance of the models was different on each test set, revealing limitations that would have been missed from student-level validation alone.", "authors": ["Michael A. Sao Pedro", "Ryan S. J. D. Baker", "Janice D. Gobert"], "session": "SESSION: Assessment"}, {"title": "Assessing students' performance using the learning analytics enriched rubrics", "pages": "195-199", "doi": "10.1145/2460296.2460335", "abstract": "The assessment of students' performance in e-learning environments is a challenging and demanding task for the teachers. Focusing on this challenge, a new assessment tool, called Learning Analytics Enriched Rubric (LAe-R) is presented in this paper. LAe-R is based on the concept of assessment rubrics which is a very popular assessment technique in education. LAe-R contains \"enriched\" criteria and grading levels that are associated to data extracted from the analysis of learners' interaction and learning behavior in an e-learning environment. LAe-R has been developed as a plug-in for the Moodle learning management system. Via an example, we will show how LAe-R can be used by teachers and students.", "authors": ["Ioannis Dimopoulos", "Ourania Petropoulou", "Symeon Retalis"], "session": "SESSION: Assessment"}, {"title": "Model-driven assessment of learners in open-ended learning environments", "pages": "200-204", "doi": "10.1145/2460296.2460336", "abstract": "Open-ended learning environments (OELEs) provide students with opportunities to take part in authentic and complex problem-solving tasks. However, many students struggle to succeed in such complex learning endeavors. Without support, these students often use system tools incorrectly and adopt suboptimal learning strategies. However, providing adaptive support to students in OELEs poses significant challenges, and relatively few OELEs provide students with adaptive support. This paper presents the initial development of a systematic approach for interpreting and evaluating learner behaviors in OELEs called model-driven assessments, which uses a model of the cognitive and metacognitive processes important for completing the open-ended learning task. The model provides a means for both classifying and assessing students' learning behaviors while using the system. An evaluation of the analysis technique is presented in the context of Betty's Brain, an OELE designed to help middle school students learn about science.", "authors": ["James R. Segedy", "Kirk M. Loretz", "Gautam Biswas"], "session": "SESSION: Assessment"}, {"title": "Formative assessment and learning analytics", "pages": "205-209", "doi": "10.1145/2460296.2460337", "abstract": "Learning analytics seeks to enhance the learning process through systematic measurements of learning related data, and informing learners and teachers of the results of these measurements, so as to support the control of the learning process. Learning analytics has various sources of information, two main types being intentional and learner activity related metadata [1]. This contribution aims to provide a practical application of Shum and Crick's theoretical framework [1] of a learning analytics infrastructure that combines learning dispositions data with data extracted from computer-based, formative assessments. The latter data component is derived from one of the educational projects of ONBETWIST, part of the SURF program 'Testing and Test Driven Learning'.", "authors": ["Dirk T. Tempelaar", "Andr\u00e9 Heck", "Hans Cuypers", "Henk van der Kooij", "Evert van de Vrie"], "session": "SESSION: Assessment"}, {"title": "STEMscopes: contextualizing learning analytics in a K-12 science curriculum", "pages": "210-219", "doi": "10.1145/2460296.2460339", "abstract": "In this paper, we discuss a scalable approach for integrating learning analytics into an online K-12 science curriculum. A description of the curriculum and the underlying pedagogical framework is followed by a discussion of the challenges to be tackled as part of this integration. We also include examples of data visualization based on real student and teacher data. With more than one million students and fifty thousand teachers using the curriculum, a massive and rich dataset is continuously updated. This repository depicts teacher and students usage of an inquiry-based science program, and offers exciting opportunities to leverage research to improve both teaching and learning. The growing dataset, with more than a hundred million items of activity in six months, also poses technical challenges such as data storage, complex aggregation and analysis with broader implications for pedagogy, big data, and learning.", "authors": ["Carlos Monroy", "Virginia Snodgrass Rangel", "Reid Whitaker"], "session": "SESSION: Supporting teachers"}, {"title": "Supporting action research with learning analytics", "pages": "220-229", "doi": "10.1145/2460296.2460340", "abstract": "Learning analytics tools should be useful, i.e., they should be usable and provide the functionality for reaching the goals attributed to learning analytics. This paper seeks to unite learning analytics and action research. Based on this, we investigate how the multitude of questions that arise during technology-enhanced teaching and learning systematically can be mapped to sets of indicators. We examine, which questions are not yet supported and propose concepts of indicators that have a high potential of positively influencing teachers' didactical considerations. Our investigation shows that many questions of teachers cannot be answered with currently available research tools. Furthermore, few learning analytics studies report about measuring impact. We describe which effects learning analytics should have on teaching and discuss how this could be evaluated.", "authors": ["A. L. Dyckhoff", "V. Lukarov", "A. Muslim", "M. A. Chatti", "U. Schroeder"], "session": "SESSION: Supporting teachers"}, {"title": "A case study inside virtual worlds: use of analytics for immersive spaces", "pages": "230-234", "doi": "10.1145/2460296.2460341", "abstract": "In this paper we describe some case studies of the use of virtual worlds in corporate training as well as Higher Education. In particular for Higher Education we describe how the Virtual World constructed using the platform Avaya Live Engage, is used as an immersive environment with pre-service teachers, who are undergoing a 1-year teacher training program, and how the data analytics collected in-world is being used to monitor and direct content development. We focus our studies on the initial hypothesis that 3D immersive environments are highly engaging and offer an experience that goes beyond the 'traditional' online education. We want to combine different analysis methods to be able to get empirical evidence showing the students' engagement with the 3D space in ways that can help us in the design of the learning experience accompanying the learners in their journey. In this paper we describe the research methods we use for the study, and give an overview of the information we can collect from the in-world analytics. We also propose how these analytics can be used for a predictive model with the intention of refocusing the virtual world experience to match learner needs.", "authors": ["Vanessa Camilleri", "Sara de Freitas", "Matthew Montebello", "Paul McDonagh-Smith"], "session": "SESSION: Supporting teachers"}, {"title": "Issues, challenges, and lessons learned when scaling up a learning analytics intervention", "pages": "235-239", "doi": "10.1145/2460296.2460343", "abstract": "This paper describes an intra-institutional partnership between a research team and a technology service group that was established to facilitate the scaling up of a learning analytics intervention. Our discussion focuses on the benefits and challenges that arose from this partnership in order to provide useful information for similar partnerships developed to support scaling up learning analytics interventions.", "authors": ["Steven Lonn", "Stephen Aguilar", "Stephanie D. Teasley"], "session": "SESSION: Challenges"}, {"title": "An evaluation of policy frameworks for addressing ethical considerations in learning analytics", "pages": "240-244", "doi": "10.1145/2460296.2460344", "abstract": "Higher education institutions have collected and analysed student data for years, with their focus largely on reporting and management needs. A range of institutional policies exist which broadly set out the purposes for which data will be used and how data will be protected. The growing advent of learning analytics has seen the uses to which student data is put expanding rapidly. Generally though the policies setting out institutional use of student data have not kept pace with this change. Institutional policy frameworks should provide not only an enabling environment for the optimal and ethical harvesting and use of data, but also clarify: who benefits and under what conditions, establish conditions for consent and the de-identification of data, and address issues of vulnerability and harm. A directed content analysis of the policy frameworks of two large distance education institutions shows that current policy frameworks do not facilitate the provision of an enabling environment for learning analytics to fulfil its promise.", "authors": ["Paul Prinsloo", "Sharon Slade"], "session": "SESSION: Challenges"}, {"title": "Aggregating social and usage datasets for learning analytics: data-oriented challenges", "pages": "245-249", "doi": "10.1145/2460296.2460345", "abstract": "Recent work has studied real-life social and usage datasets from educational applications, highlighting the opportunity to combine or merge them. It is expected that being able to put together different datasets from various applications will make it possible to support learning analytics of a much larger scale and across different contexts. We examine how this can be achieved from a practical perspective by carrying out a study that focuses on three real datasets. More specifically, we combine social data that has been collected from the users of three learning portals and reflect on how they should be handled. We start by studying the data types and formats that these portals use to represent and store social and usage data. Then we develop crosswalks between the different schemas, so that merged versions of the source datasets may be created. The results of this bottom-up, hands-on investigation reveal several interesting issues that need to be overcome before aggregated sets of social and usage data can be actually used to support learning analytics research or services.", "authors": ["Katja Niemann", "Martin Wolpers", "Giannis Stoitsis", "Georgios Chinis", "Nikos Manouselis"], "session": "SESSION: Challenges"}, {"title": "From micro to macro: analyzing activity in the ROLE Sandbox", "pages": "250-254", "doi": "10.1145/2460296.2460347", "abstract": "Current learning services are increasingly based on standard Web technologies and concepts. As by-product of service operation, Web logs capture and contextualize user interactions in a generic manner, in high detail, and on a massive scale. At the same time, we face inventions of data standards for capturing and encoding learner interactions tailored to learning analytics purposes. However, such standards are often focused on institutional and management perspectives or biased by their intended use. In this paper, we argue for Web logs as valuable data sources for learning analytics on all levels of Bronfenbrenner's Ecological System Theory and introduce a simple framework for Web log data enrichment, processing and further analysis. Based on an example data set from a management service for widget-based Personal Learning Environments, we illustrate our approach and discuss the applicability of different analysis techniques along with their particular benefits for learners.", "authors": ["Dominik Renzel", "Ralf Klamma"], "session": "SESSION: Analytic architectures"}, {"title": "Analytics of collaborative planning in Metafora: architecture, data, and analytic methods", "pages": "255-259", "doi": "10.1145/2460296.2460348", "abstract": "This paper describes our approach for learning analytics in the Metafora system, a collaborative learning framework that supports self-regulated and constructionist activities in groups. Our specific interest in analysis is the nature of collaborative planning behaviour and aspects of learning to learn together (L2L2). For that end we will describe the architecture supporting diverse analytic components across all the tools used in Metafora, the data formats, storage and access methods, and the analytic principles we designed and implemented. We will also describe our first insights using these methods on real Metafora data collected during practical experimentation in schools.", "authors": ["Andreas Harrer"], "session": "SESSION: Analytic architectures"}, {"title": "GradeCraft: what can we learn from a game-inspired learning management system?", "pages": "260-264", "doi": "10.1145/2460296.2460350", "abstract": "The \"gamification\" of courses (i.e., designing courses that leverage motivational mechanisms found in videogames) is a movement that is gaining traction in educational research communities and universities. Two game-inspired courses were developed at a high-enrollment public university in an effort to increase student engagement, and to provide students with more personalized learning experiences. We designed a learning management system, GradeCraft, to foreground the affordances of these grading systems, and to enhance the \"game-like\" experience for students. Along with serving as a translation layer for the grading systems of these courses, GradeCraft is also designed with an eye towards learning analytics, and captures information that can be described as student \"process\" data. Currently this data includes what types of assignments students choose to complete; how students assign percentage weights to their chosen assignments; how often and how accurately students check or model their course grades; and how successfully assignments are completed by students individually and the class as a whole across a structured grading rubric. We hope GradeCraft will give instructors new insight into student engagement, and provide data-driven ideas about how to tailor courses to student needs.", "authors": ["Caitlin Holman", "Stephen Aguilar", "Barry Fishman"], "session": "SESSION: Design briefings"}, {"title": "System for assessing classroom attention", "pages": "265-269", "doi": "10.1145/2460296.2460351", "abstract": "In this paper we give a preview of our system for automatically evaluating attention in the classroom. We demonstrate our current behaviour metrics and preliminary observations on how they reflect the reactions of people to the given lecture. We also introduce foundations of our hypothesis on peripheral awareness of students during lectures.", "authors": ["Mirko Raca", "Pierre Dillenbourg"], "session": "SESSION: Design briefings"}, {"title": "Orchestrating of complex inquiry: three roles for learning analytics in a smart classroom infrastructure", "pages": "270-274", "doi": "10.1145/2460296.2460352", "abstract": "This paper presents our research of a pedagogical model known as Knowledge Community and Inquiry (KCI), focusing on our design of a technological infrastructure for the orchestration of the complex CSCL scripts that characterize KCI curricula. We first introduce the KCI model including some basic design principles, and describe its dependency on real time learning analytics. Next, we describe our technology, known as SAIL Smart Space (S3), which provides scaffolding and analytic support of sequenced interactions amongst people, materials, tools and environments. We outline the critical role of the teacher in our designs and describe how S3 supports their active role in orchestration. Finally we outline two implementations of KCI/S3 and the role of learning analytics, in supporting dynamic collective visualizations, real time orchestrational logic, and ambient displays.", "authors": ["James D. Slotta", "Mike Tissenbaum", "Michelle Lui"], "session": "SESSION: Design briefings"}, {"title": "Crafting transformative strategies for personalized learning/analytics", "pages": "275-277", "doi": "10.1145/2460296.2460354", "abstract": "Personalized learning environments and learning analytics hold the promise to transform learning experiences, enhance and accelerate student success, and \"open up\" student learning to resources and experiences from outside individual institutions. To achieve their potential, personalized learning projects must move beyond individual, stand-alone projects or innovations to reshaping the institutional experience. Learning science must connect with learning pedagogy and design. Learners and institutions must have access to tools and resources that assist in customizing student progress and supplemental learning needs. Teachers and faculty must be empowered to provide teaching and learning environments that allow individual students to thrive. All this will require unique partnerships and collaborations within and across institutions, incorporating the best learning science findings and bridging with public and private entities developing the learning and analytic tools to support personalized learning. Crafting a strategy to embrace and sustain the transformative power of personalized learning systems will require strong leadership and clear planning models to align with institutional planning and future investments.", "authors": ["Linda L. Baer", "Ann Hill Duin", "Donald Norris", "Robert Brodnick"], "session": "PANEL SESSION: Panels"}, {"title": "Educational data scientists: a scarce breed", "pages": "278-281", "doi": "10.1145/2460296.2460355", "abstract": "The Educational Data Scientist is currently a poorly understood, rarely sighted breed. Reports vary: some are known to be largely nocturnal, solitary creatures, while others have been reported to display highly social behaviour in broad daylight. What are their primary habits? How do they see the world? What ecological niches do they occupy now, and will predicted seismic shifts transform the landscape in their favour? What survival skills do they need when running into other breeds? Will their numbers grow, and how might they evolve? In this panel, the conference will hear and debate not only broad perspectives on the terrain, but will have been exposed to some real life specimens, and caught glimpses of the future ecosystem.", "authors": ["Simon Buckingham Shum", "Martin Hawksey", "Ryan S. J. D. Baker", "Naomi Jeffery", "John T. Behrens", "Roy Pea"], "session": "PANEL SESSION: Panels"}, {"title": "DCLA13: 1st International Workshop on Discourse-Centric Learning Analytics", "pages": "282-282", "doi": "10.1145/2460296.2460357", "abstract": "This workshop anticipates that an important class of learning analytic will emerge at the intersection of research into learning dynamics, online discussion platforms, and computational linguistics. Written discourse is arguably the primary class of data that can give us insights into deeper learning and higher order qualities such as critical thinking, argumentation, mastery of complex ideas, empathy, collaboration and interpersonal skills. Moreover, the ability to write in a scholarly manner is a core competence, often taking the form of discourse with oneself and the literature. Computational linguistics research has developed a rich array of tools for machine interpretation of human discourse, but work to develop these tools in the context of learning is at a relatively early stage. Moreover, there is a significant difference between designing tools to assist researchers in discourse analysis, and their deployment on platforms to provide meaningful analytics for the learners and educators who are conducting that discourse. This workshop aims to catalyse ideas and build community connections among those who want to shape this field.", "authors": ["Simon Buckingham Shum", "Maarten de Laat", "Anna De Liddo", "Rebecca Ferguson", "Paul Kirschner", "Andrew Ravenscroft", "\u00c1gnes S\u00e1ndor", "Denise Whitelock"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "Analytics on video-based learning", "pages": "283-284", "doi": "10.1145/2460296.2460358", "abstract": "The International Workshop on Analytics on Video-based Learning (WAVe2013) aims to connect research efforts on Video-based Learning with Learning Analytics to create visionary ideas and foster synergies between the two fields. The main objective of WAVe is to build a research community around the topical area of Analytics on video-based learning. In particular, WAVe aims to develop a critical discussion about the next generation of analytics employed on video learning tools, the form of these analytics and the way they can be analyzed in order to help us to better understand and improve the value of video-based learning. WAVe is based on the rationale that combining and analyzing learners' interactions with other available data obtained from learners, new avenues for research on video-based learning have emerged.", "authors": ["Michail N. Giannakos", "Konstantinos Chorianopoulos", "Marco Ronchetti", "Peter Szegedi", "Stephanie D. Teasley"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "Learning object analytics for collections, repositories & federations", "pages": "285-286", "doi": "10.1145/2460296.2460359", "abstract": "A large number of curated digital collections containing learning resources of a various kind has emerged in the last year. These include referatories containing descriptions for resources in the Web (as MERLOT), aggregated collections (as Organic.Edunet), concrete initiatives as Khan Academy, repositories hosting and versioning modular content (as Connexions) and meta-aggregators (as Globe and Learning Registry). Also, OpenCourseware and other OER initiatives have contributed to making this ecosystem of resources richer. Very interesting insights can be extracted when studying the usage and social data that are produced within the learning collections, repositories and federations. At the same time, concerns for the quality and sustainability of these collections have been raised, which has lead to research on quality measurement and metrics. The Workshop attempts to bring studies and demonstrations for any kind of analysis done on learning resource collections, from an interdisciplinary perspective. We consider digital collections not as merely IT deployments but as social systems with contributors, owners, evaluators and users forming patterns of interactions on top of portals or through search systems embedded in other learning technology components. This is in coherence of considering these social systems under a Web Science approach (http://webscience.org/).", "authors": ["Miguel-Angel Sicilia", "Xavier Ochoa", "Giannis Stoitsis", "Joris Klerkx"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "Second International Workshop on Teaching Analytics", "pages": "287-289", "doi": "10.1145/2460296.2460360", "abstract": "Teaching Analytics is conceived as a subfield of learning analytics that focuses on the design, development, evaluation, and education of visual analytics methods and tools for teachers in primary, secondary, and tertiary educational settings. The Second International Workshop on Teaching Analytics (IWTA) 2013 seeks to bring together researchers and practitioners in the fields of education, learning sciences, learning analytics, and visual analytics to investigate the design, development, use, evaluation, and impact of visual analytical methods and tools for teachers' dynamic diagnostic decision-making in real-world settings.", "authors": ["Ravi Vatrapu", "Peter Reimann", "Wolfgang Halb", "Susan Bull"], "session": "WORKSHOP SESSION: Workshops"}]}, {"year": 2014, "papers": [{"title": "Formative assessment method of real-world learning by integrating heterogeneous elements of behavior, knowledge, and the environment", "pages": "1-10", "doi": "10.1145/2567574.2567579", "abstract": "Real-world learning in a field is an important educational area for experience-based activities. Formative assessment by constant monitoring of the intellectual achievement of real-world learners is essential for adaptive learning support, but no assessment methodology has yet been developed. We consider a method to systematically integrate heterogeneous factors of real-world learning: learners' internal situations, their external situations, and their learning field. Then, we propose a method for formatively assessing the situation of real-world learning. The method enables us to recognize the sequence of characteristic stay behavior and the associated body posture of a learner, and to estimate the 3D location of his/her interest. The method enables the estimation of not only the learning topic that a learner is currently examining in a field but also the prospective topics that he/she should learn. Our assessment method is the basis for context-aware support to promote the emergence of new knowledge from intellectual collaboration in the world.", "authors": ["Masaya Okada", "Masahiro Tada"], "session": "SESSION: Process mining"}, {"title": "Clustering for improving educational process mining", "pages": "11-15", "doi": "10.1145/2567574.2567604", "abstract": "In this paper, we propose to use clustering to improve educational process mining. We want to improve both the performance and comprehensibility of the models obtained. We have used data from 84 undergraduate students who followed an online course using Moodle 2.0. We propose to group students firstly starting from data about Moodle's usage summary and/or the students' final marks in the course. Then, we propose to use data from Moodle's logs about each cluster/group of students separately in order to be able to obtain more specific and accurate models of students' behaviour. The results show that the fitness of the specific models is greater than the general model obtained using all the data, and the comprehensibility of the models can be also improved in some cases.", "authors": ["Alejandro Bogar\u00edn", "Crist\u00f3bal Romero", "Rebeca Cerezo", "Miguel S\u00e1nchez-Santill\u00e1n"], "session": "SESSION: Process mining"}, {"title": "Customized course advising: investigating engineering student success with incoming profiles and patterns of concurrent course enrollment", "pages": "16-25", "doi": "10.1145/2567574.2567589", "abstract": "Every college student registers for courses from a catalog of numerous offerings each term. Selecting the courses in which to enroll, and in what combinations, can dramatically impact each student's chances for academic success. Taking inspiration from the STEM Academy, we wanted to identify the characteristics of engineering students who graduate with 3.0 or above grade point average. The overall goal of the Customized Course Advising project is to determine the optimal term-by-term course selections for all engineering students based on their incoming characteristics and previous course history and performance, paying particular attention to concurrent enrollment. We found that ACT Math, SAT Math, and Advanced Placement exam can be effective measures to measure the students' academic preparation level. Also, we found that some concurrent course-enrollment patterns are highly predictive of first-term and overall academic success.", "authors": ["SungJin Nam", "Steven Lonn", "Thomas Brown", "Cinda-Sue Davis", "Darryl Koch"], "session": "SESSION: Predictive models and recommendations"}, {"title": "Explaining predictive models to learning specialists using personas", "pages": "26-30", "doi": "10.1145/2567574.2567612", "abstract": "This paper describes a method we have developed to convert statistical predictive models into visual narratives which explain student classifications. Building off of the work done within the user experience community, we apply the concept of personas to predictive models. These personas provide familiar and memorable descriptions of the learners identified by data mining activities, and bridge the gap between the data scientist and the learning specialist.", "authors": ["Christopher Brooks", "Jim Greer"], "session": "SESSION: Predictive models and recommendations"}, {"title": "Temporal learning analytics for computer based testing", "pages": "31-35", "doi": "10.1145/2567574.2567609", "abstract": "Predicting student's performance is a challenging, yet complicated task for institutions, instructors and learners. Accurate predictions of performance could lead to improved learning outcomes and increased goal achievement. In this paper we explore the predictive capabilities of student's time-spent on answering (in-)correctly each question of a multiple-choice assessment quiz, along with student's final quiz-score, in the context of computer-based testing. We also explore the correlation between the time-spent factor (as defined here) and goal-expectancy. We present a case study and investigate the value of using this parameter as a learning analytics factor for improving prediction of performance during computer-based testing. Our initial results are encouraging and indicate that the temporal dimension of learning analytics should be further explored.", "authors": ["Zacharoula K. Papamitsiou", "Vasileios Terzis", "Anastasios A. Economides"], "session": "SESSION: Predictive models and recommendations"}, {"title": "Sleepers' lag - study on motion and attention", "pages": "36-43", "doi": "10.1145/2567574.2567581", "abstract": "Human body-language is one of the richest and most obscure sources of information in inter-personal communication which we aim to re-introduce into the classroom's ecosystem. In this paper we present our observations of student-to-student influence and measurements. We show parallels with previous theories and formulate a new concept for measuring the level of attention based on synchronization of student actions. We observed that the students with lower levels of attention are slower to react then focused students, a phenomenon we named \"sleepers' lag\".", "authors": ["Mirko Raca", "Roland Tormey", "Pierre Dillenbourg"], "session": "SESSION: Alternative analytics"}, {"title": "Clustering of design decisions in classroom visual displays", "pages": "44-48", "doi": "10.1145/2567574.2567605", "abstract": "In this paper, we investigate the patterns of design choices made by classroom teachers for decorating their classroom walls, using cluster analysis to see which design decisions go together. Classroom visual design has been previously studied, but not in terms of the systematic patterns adopted by teachers in selecting what materials to place on classroom walls, or in terms of the actual semantic content of what is placed on walls. This is potentially important, as classroom walls are continuously seen by students, and form a continual off-task behavior option, available to students at all times. Using the k-means clustering algorithm, we find four types of visual classroom environments (one of them an outlier within our data set), representing teachers' strategies in classroom decoration. Our results indicate that the degree to which teachers place content-related decorations on the walls, is a feature of particular importance for distinguishing which approach teachers are using. Similarly, the type of school (e.g. whether private or charter) appeared to be another significant factor in determining teachers' design choices for classroom walls. The present findings begin the groundwork to better understand the impact of teacher decisions and choices in classroom design that lead to better outcomes in terms of engagement and learning, and finally towards developing classroom designs that are more effective and engaging for learners.", "authors": ["Ma. Victoria Almeda", "Peter Scupelli", "Ryan S. Baker", "Mimi Weber", "Anna Fisher"], "session": "SESSION: Alternative analytics"}, {"title": "Data wranglers: human interpreters to help close the feedback loop", "pages": "49-53", "doi": "10.1145/2567574.2567603", "abstract": "Closing the feedback loop to improve learning is at the heart of good learning analytics practice. However, the quantity of data, and the range of different data sources, can make it difficult to take systematic action on that data. Previous work in the literature has emphasised the need for and value of human meaning-making in the process of interpretation of data to transform it in to actionable intelligence. This paper describes a programme of human Data Wranglers deployed at the Open University, UK, charged with making sense of a range of data sources related to learning, analysing that data in the light of their understanding of practice in individual faculties/departments, and producing reports that summarise the key points and make actionable recommendations. The evaluation of and experience in this programme of work strongly supports the value of human meaning-makers in the learning analytics process, and suggests that barriers to organisational change in this area can be mitigated by embedding learning analytics work within strategic contexts, and working at an appropriate level and granularity of analysis.", "authors": ["Doug Clow"], "session": "SESSION: Alternative analytics"}, {"title": "Toward unobtrusive measurement of reading comprehension using low-cost EEG", "pages": "54-58", "doi": "10.1145/2567574.2567624", "abstract": "Assessment of reading comprehension can be costly and obtrusive. In this paper, we use inexpensive EEG to detect reading comprehension of readers in a school environment. We use EEG signals to produce above-chance predictors of student performance on end-of-sentence cloze questions. We also attempt (unsuccessfully) to distinguish among student mental states evoked by distracters that violate either syntactic, semantic, or contextual constraints. In total, this work investigates the practicality of classroom use of inexpensive EEG devices as an unobtrusive measure of reading comprehension.", "authors": ["Yueran Yuan", "Kai-min Chang", "Jessica Nelson Taylor", "Jack Mostow"], "session": "SESSION: Alternative analytics"}, {"title": "Learning analytics in CSCL with a focus on assessment: an exploratory study of activity theory-informed cluster analysis", "pages": "59-67", "doi": "10.1145/2567574.2567587", "abstract": "In this paper we propose an automated strategy to assess participation in a multi-mode math discourse environment called Virtual Math Teams with Geogrebra (VMTwG). A holistic participation clustering algorithm is applied through the lens of activity theory. Our activity theory-informed algorithm is a step toward accelerating heuristic approaches to assessing collaborative work in synchronous technology mediated environments like VMTwG. Our Exploratory findings provide an example of a novel, time-efficient, valid, and reliable participatory learning assessment tool for teachers in computer mediated learning environments. Scaling online learning with a combination of computation and theory is the overall goal of the work this paper is situated within.", "authors": ["Wanli Xing", "Bob Wadholm", "Sean Goggins"], "session": "SESSION: Learning mathematics"}, {"title": "On using markov chain to evidence the learning structures and difficulty levels of one digit multiplication", "pages": "68-72", "doi": "10.1145/2567574.2567614", "abstract": "Understanding the behavior of learners within learning applications and analyzing the factors that may influence the learning process play a key role in designing and optimizing learning applications. In this work we focus on a specific application named \"1x1 trainer\" that has been designed for primary school children to learn one digit multiplications. We investigate the database of learners' answers to the asked questions (N > 440000) by applying the Markov chains. We want to understand whether the learners' answers to the already asked questions can affect the way they will answer the subsequent asked questions and if so, to what extent. Through our analysis we first identify the most difficult and easiest multiplications for the target learners by observing the probabilities of the different answer types. Next we try to identify influential structures in the history of learners' answers considering the Markov chain of different orders. The results are used to identify pupils who have difficulties with multiplications very soon (after couple of steps) and to optimize the way questions are asked for each pupil individually.", "authors": ["Behnam Taraghi", "Martin Ebner", "Anna Saranti", "Martin Sch\u00f6n"], "session": "SESSION: Learning mathematics"}, {"title": "Context personalization, preferences, and performance in an intelligent tutoring system for middle school mathematics", "pages": "73-77", "doi": "10.1145/2567574.2567615", "abstract": "Learners often think math is unrelated to their own interests. Instructional software has the potential to provide personalized instruction that responds to individuals' interests. Carnegie Learning's MATHia\u2122 software for middle school mathematics asks learners to specify domains of their interest (e.g., sports & fitness, arts & music), as well as names of friends/classmates, and uses this information to both choose and personalize word problems for individual learners. Our analysis of MATHia's relatively coarse-grained personalization contrasts with more finegrained analysis in previous research on word problems in the Cognitive Tutor (e.g., finding effects on performance in parts of problems that depend on more difficult skills), and we explore associations of aggregate preference \"honoring\" with learner performance. To do so, we define a notion of \"strong\" learner interest area preferences and find that honoring such preferences has a small negative association with performance. However, learners that both merely express preferences (either interest area preferences or setting names of friends/classmates), and those that express strong preferences, tend to perform in ways that are associated with better learning compared to learners that do not express such preferences. We consider several explanations of these findings and suggest important topics for future research.", "authors": ["Stephen E. Fancsali", "Steven Ritter"], "session": "SESSION: Learning mathematics"}, {"title": "Interaction design for improved analytics", "pages": "78-82", "doi": "10.1145/2567574.2567628", "abstract": "In this paper, we explain a portion of the design research process that we used to develop the learning analytics for a manipulative-based fractions intervention program. In particular, we highlight a set of qualitative interviews that we conducted with individual students after a short study in which students in three classes at the same school learned to use virtual manipulatives to compare pairs of proper fractions and order groups of 3 proper fractions. These qualitative interviews provided us with considerable information that helped us improve the interactions students have with the virtual manipulatives and produce more sophisticated and informative analytics. We emphasize the importance of using mixed-methods during the iterative cycles of development that define design research.", "authors": ["Maria Mendiburo", "Brian Sulcer", "Ted Hasselbring"], "session": "SESSION: Learning mathematics"}, {"title": "Visualizing patterns of student engagement and performance in MOOCs", "pages": "83-92", "doi": "10.1145/2567574.2567586", "abstract": "In the last five years, the world has seen a remarkable level of interest in Massive Open Online Courses, or MOOCs. A consistent message from universities participating in MOOC delivery is their eagerness to understand students' online learning processes. This paper reports on an exploratory investigation of students' learning processes in two MOOCs which have different curriculum and assessment designs. When viewed through the lens of common MOOC learning analytics, the high level of initial student interest and, ultimately, the high level of attrition, makes these two courses appear very similar to each other, and to MOOCs in general. With the goal of developing a greater understanding of students' patterns of learning behavior in these courses, we investigated alternative learning analytic approaches and visual representations of the output of these analyses. Using these approaches we were able to meaningfully classify student types and visualize patterns of student engagement which were previously unclear. The findings from this research contribute to the educational community's understanding of students' engagement and performance in MOOCs, and also provide the broader learning analytics community with suggestions of new ways to approach learning analytic data analysis and visualization.", "authors": ["Carleton Coffrin", "Linda Corrin", "Paula de Barba", "Gregor Kennedy"], "session": "SESSION: MOOCs"}, {"title": "Small to big before massive: scaling up participatory learning analytics", "pages": "93-97", "doi": "10.1145/2567574.2567626", "abstract": "This case study describes how course features and individual & social learning analytics were scaled up to support \"participatory\" learning. An existing online course was turned into a \"big open online course\" (BOOC) offered to hundreds. Compared to typical open courses, relatively high levels of persistence, individual & social engagement, and achievement were obtained. These results suggest that innovative learning analytics might best be scaled (a) incrementally, (b) using design-based research methods, (c) focusing on engagement in consequential & contextual knowledge, (d) using emerging situative assessment theories.", "authors": ["Daniel T. Hickey", "Tara Alana Kelley", "Xinyi Shen"], "session": "SESSION: MOOCs"}, {"title": "Success, activity and drop-outs in MOOCs an exploratory study on the UNED COMA courses", "pages": "98-102", "doi": "10.1145/2567574.2567627", "abstract": "This paper presents an exploratory study about two language learning MOOCs deployed in the UNED COMA platform. The study identifies three research questions: a) How does activity evolve in these MOOCs? b) Are all learning activities relevant?, and c) Does the use of the target language influence?. We conclude that the MOOC activity drops not only due to the drop-outs. When students skips around 10% of the proposed activities, the percentage of passing the course decrease in a 25%. Forum activity is a useful indicator for success, however the participation in active threads is not. Finally, the use of the target language course is not an indicator to predict success.", "authors": ["Jose Luis Santos", "Joris Klerkx", "Erik Duval", "David Gago", "Luis Rodr\u00edguez"], "session": "SESSION: MOOCs"}, {"title": "Engagement vs performance: using electronic portfolios to predict first semester engineering student retention", "pages": "103-112", "doi": "10.1145/2567574.2567583", "abstract": "As providers of higher education begin to harness the power of big data analytics, one very fitting application for these new techniques is that of predicting student attrition. The ability to pinpoint students who might soon decide to drop out of a given academic program allows those in charge to not only understand the causes for this undesired outcome, but it also provides room for the development of early intervention systems. While making such inferences based on academic performance data alone is certainly possible, we claim that in many cases there is no substantial correlation between how well a student performs and his or her decision to withdraw. This is specially true when the overall set of students has a relatively similar academic performance. To address this issue, we derive measurements of engagement from students' electronic portfolios and show how these features can be effectively used to augment the quality of predictions.", "authors": ["Everaldo Aguiar", "Nitesh V. Chawla", "Jay Brockman", "G. Alex Ambrose", "Victoria Goodrich"], "session": "SESSION: Learning analytics for \"at risk\" students"}, {"title": "Perceptions and use of an early warning system during a higher education transition program", "pages": "113-117", "doi": "10.1145/2567574.2567625", "abstract": "This paper reports findings from the implementation of a learning analytics-powered Early Warning System (EWS) by academic advisors who were novice users of data-driven learning analytics tools. The information collected from these users sheds new light on how student analytic data might be incorporated into the work practices of advisors working with university students. Our results indicate that advisors predominantly used the EWS during their meetings with students---despite it being designed as a tool to provide information to prepare for meetings and identify students who are struggling academically. This introduction of an unintended audience brings significant design implications to bear that are relevant for learning analytics innovations.", "authors": ["Stephen Aguilar", "Steven Lonn", "Stephanie D. Teasley"], "session": "SESSION: Learning analytics for \"at risk\" students"}, {"title": "Modest analytics: using the index method to identify students at risk of failure", "pages": "118-122", "doi": "10.1145/2567574.2567629", "abstract": "Regression is the tool of choice for developing predictive models of student risk of failure. However, the forecasting literature has demonstrated the predictive equivalence of much simpler methods. We directly compare one simple tabulation technique, the index method, to a linear multiple regression approach for identifying students at risk. The broader purpose is to explore the plausibility of a flexible method that is conducive to adoption and diffusion. In this respect this paper fits within the ambit of the modest computing agenda, and suggests the possibility of a modest analytics. We built both regression and index method models on 2011 student data and applied these to 2012 student data. The index method was comparable in terms of predictive accuracy of student risk. We suggest that the context specificity of learning environments makes the index method a promising tool for educators who want a situated risk algorithm that is flexible and adaptable.", "authors": ["Tim Rogers", "Cassandra Colvin", "Belinda Chiera"], "session": "SESSION: Learning analytics for \"at risk\" students"}, {"title": "Analytics of the effects of video use and instruction to support reflective learning", "pages": "123-132", "doi": "10.1145/2567574.2567590", "abstract": "Although video annotation software is no longer considered as a new innovation, its application in promoting student self-regulated learning and reflection skills has only begun to emerge in the research literature. Advances in text and video analytics provide the capability of investigating students' use of the tool and the psychometrics and linguistic processes evident in their written annotations. This paper reports on a study exploring students' use of a video annotation tool when two different instructional approaches were deployed -- graded and non-graded self-reflection annotations within two courses in the performing arts. In addition to counts and temporal locations of self-reflections, the Linguistic Inquiry and Word Counts (LIWC) framework was used for the extraction of variables indicative of the linguistic and psychological processes associated with self-reflection annotations of videos. The results indicate that students in the course with graded self-reflections adopted more linguistic and psychological related processes in comparison to the course with non-graded self-reflections. In general, the effect size of the graded reflections was lower for students who took both courses in parallel. Consistent with prior research, the study identified that students tend to make the majority of their self-reflection annotations early in the video time line. The paper also provides several suggestions for future research to better understand the application of video annotations in facilitating student learning.", "authors": ["Dragan Ga\u0161evi\u0107", "Negin Mirriahi", "Shane Dawson"], "session": "SESSION: Text analytics and collaborative environments"}, {"title": "Peer assessment based on ratings in a social media course", "pages": "133-137", "doi": "10.1145/2567574.2567608", "abstract": "Peer assessment is seen as a powerful supporting tool to achieve scalability in the evaluation of complex assignments in large courses, possibly virtual ones, as in the context of massive open online courses (MOOCs). However, the adoption of peer assessment is slow due in part to the lack of ready-to-use systems. Furthermore, the validity of peer assessment is still under discussion. In this paper, in order to tackle some of these issues, we present as a proof-of-concept of a novel extension of Graasp, a social media platform, to setup a peer assessment activity. We then report a case study of peer assessment using Graasp in a Social Media course with 60 master's level university students and analyze the level of agreement between students and instructors in the evaluation of short individual reports. Finally, to see if both instructor and student evaluations were based on appearance of project reports rather than on content, we conducted a study with 40 kids who rated reports solely on their look. Our results convey the fact that unlike the kid evaluation, which shows a low level of agreement with instructors, student assessment is reliable since the level of agreement between instructors and students was high.", "authors": ["Andrii Vozniuk", "Adrian Holzer", "Denis Gillet"], "session": "SESSION: Text analytics and collaborative environments"}, {"title": "Collaborative spatial classification", "pages": "138-142", "doi": "10.1145/2567574.2567611", "abstract": "Interactive technologies have become an important part of teaching and learning. However, the data that these systems generate is increasingly unstructured, complex, and therefore difficult of which to make sense of. Current computationally driven methods (e.g., latent semantic analysis or learning based image classifiers) for classifying student contributions don't include the ability to function on multimodal artifacts (e.g., sketches, videos, or annotated images) that new technologies enable. We have developed and implemented a classifcation algorithm based on learners' interactions with the artifacts they create. This new form of semi-automated concept classification, coined Collaborative Spatial Classification, leverages the spatial arrangement of artifacts to provide a visualization that generates summary level data about about idea distribution. This approach has two benefits. First, students learn to identify and articulate patterns and connections among classmates ideas. Second, the teacher receives a high-level view of the distribution of ideas, enabling them to decide how to shift their instructional practices in real-time.", "authors": ["Eric Coopey", "R. Benjamin Shapiro", "Ethan Danahy"], "session": "SESSION: Text analytics and collaborative environments"}, {"title": "Assessing elementary students' science competency with text analytics", "pages": "143-147", "doi": "10.1145/2567574.2567620", "abstract": "Real-time formative assessment of student learning has become the subject of increasing attention. Students' textual responses to short answer questions offer a rich source of data for formative assessment. However, automatically analyzing textual constructed responses poses significant computational challenges, and the difficulty of generating accurate assessments is exacerbated by the disfluencies that occur prominently in elementary students' writing. With robust text analytics, there is the potential to accurately analyze students' text responses and predict students' future success. In this paper, we present WriteEval, a hybrid text analytics method for analyzing student-composed text written in response to constructed response questions. Based on a model integrating a text similarity technique with a semantic analysis technique, WriteEval performs well on responses written by fourth graders in response to short-text science questions. Further, it was found that WriteEval's assessments correlate with summative analyses of student performance.", "authors": ["Samuel P. Leeman-Munk", "Eric N. Wiebe", "James C. Lester"], "session": "SESSION: Text analytics and collaborative environments"}, {"title": "Techniques for data-driven curriculum analysis", "pages": "148-157", "doi": "10.1145/2567574.2567591", "abstract": "One of the key promises of Learning Analytics research is to create tools that could help educational institutions to gain a better insight of the inner workings of their programs, in order to tune or correct them. This work presents a set of simple techniques that applied to readily available historical academic data could provide such insights. The techniques described are real course difficulty estimation, dependance estimation, curriculum coherence, dropout paths and load/performance graph. The description of these techniques is accompanied by its application to real academic data from a Computer Science program. The results of the analysis are used to obtain recommendations for curriculum re-design.", "authors": ["Gonzalo M\u00e9ndez", "Xavier Ochoa", "Katherine Chiluiza"], "session": "SESSION: Institutional perspectives"}, {"title": "The impact of learning analytics on the dutch education system", "pages": "158-162", "doi": "10.1145/2567574.2567617", "abstract": "The article reports the findings of a Group Concept Mapping study that was conducted within the framework of the Learning Analytics Summer Institute (LASI) in the Netherlands. Learning Analytics are expected to be beneficial for students and teacher empowerment, personalization, research on learning design, and feedback for performance. The study depicted some management and economics issues and identified some possible treats. No differences were found between novices and experts on how important and feasible are changes in education triggered by Learning Analytics.", "authors": ["Hendrik Drachsler", "Slavi Stoyanov", "Marcus Specht"], "session": "SESSION: Institutional perspectives"}, {"title": "An exercise in institutional reflection: the learning analytics readiness instrument (LARI)", "pages": "163-167", "doi": "10.1145/2567574.2567621", "abstract": "While the landscape of learning analytics is relatively well defined, the extent to which institutions are ready to embark on an analytics implementation is less known. Further, while work has been done on measuring the maturity of an institution's implementation, this work fails to investigate how an institution that has not implemented analytics to date might become mature over time. To that end, the authors developed and piloted a survey, the Learning Analytics Readiness Instrument (LARI), in an attempt to help institutions successfully prepare themselves for a successfully analytics implementation. The LARI is comprised of 90 items encompassing five factors related to a learning analytics implementation: (1) Ability, (2) Data, (3) Culture and Process, (4) Governance and Infrastructure, and, (5) Overall Readiness Perception. Each of the five factors has a high internal consistency, as does the overall tool. This paper discusses the need for a survey such as the LARI, the tool's psychometric properties, the authors' broad interpretations of the findings, and next steps for the LARI and the research in this field.", "authors": ["Kimberly E. Arnold", "Steven Lonn", "Matthew D. Pistilli"], "session": "SESSION: Institutional perspectives"}, {"title": "Competency map: visualizing student learning to promote student success", "pages": "168-172", "doi": "10.1145/2567574.2567622", "abstract": "Adult students often struggle to appreciate the relevance of their higher educational experiences to their careers. Capella University's competency map is a dashboard that visually indicates each student's status relative to specific assessed competencies. MBA students who utilize their competency map demonstrate competencies at slightly higher levels and persist in their program at greater rates, even after statistically controlling for powerful covariates, such as course engagement.", "authors": ["Jeff Grann", "Deborah Bushway"], "session": "SESSION: Institutional perspectives"}, {"title": "Analysis of dynamic resource access patterns in a blended learning course", "pages": "173-182", "doi": "10.1145/2567574.2567584", "abstract": "This paper presents an analysis of resource access patterns in a recently conducted master level university course. The specialty of the course was that it followed a new teaching approach by providing additional learning resources such as wikis, self-tests and videos. To gain deeper insights into the usage of the provided learning material we have built dynamic bipartite student -- resource networks based on event logs of resource access. These networks are analysed using methods adapted from social network analysis. In particular we uncover bipartite clusters of students and resources in those networks and propose a method to identify patterns and traces of their evolution over time.", "authors": ["Tobias Hecking", "Sabrina Ziebarth", "H. Ulrich Hoppe"], "session": "SESSION: Analysis of resource use in LMS"}, {"title": "Analyzing the log patterns of adult learners in LMS using learning analytics", "pages": "183-187", "doi": "10.1145/2567574.2567616", "abstract": "In this paper, we describe a process of constructing proxy variables that represent adult learners' time management strategies in an online course. Based upon previous research, three values were selected from a data set. According to the result of empirical validation, an (ir)regularity of the learning interval was proven to be correlative with and predict learning performance. As indicated in previous research, regularity of learning is a strong indicator to explain learners' consistent endeavors. This study demonstrates the possibility of using learning analytics to address a learner's specific competence on the basis of a theoretical background. Implications for the learning analytics field seeking a pedagogical theory-driven approach are discussed.", "authors": ["Il-Hyun Jo", "Dongho Kim", "Meehyun Yoon"], "session": "SESSION: Analysis of resource use in LMS"}, {"title": "Practice exams make perfect: incorporating course resource use into an early warning system", "pages": "188-192", "doi": "10.1145/2567574.2567623", "abstract": "Early Warning Systems (EWSs) are being developed and used more frequently to aggregate multiple sources of data and provide timely information to stakeholders about students in need of academic support. As these systems grow more complex, there is an increasing need to incorporate relevant and real-time course-related information that could be predictors of a student's success or failure. This paper presents an investigation of how to incorporate students' use of course resources from a Learning Management System (LMS) into an existing EWS. Specifically, we focus our efforts on understanding the relationship between course resource use and a student's final course grade. Using ten semesters of LMS data from a requisite Chemistry course, we categorized course resources into four categories. We used a multinomial logistic regression model with semester fixed-effects to estimate the relationship between course resource use and the likelihood that a student receives an \"A\" or \"B\" in the course versus a \"C.\" Results suggest that students who use Exam Preparation or Lecture resources to a greater degree than their peers are more likely to receive an \"A\" or \"B\" as a final grade. We discuss the implications of our results for the further development of this EWS and EWSs in general.", "authors": ["Richard Joseph Waddington", "SungJin Nam"], "session": "SESSION: Analysis of resource use in LMS"}, {"title": "Educational data sciences: framing emergent practices for analytics of learning, organizations, and systems", "pages": "193-202", "doi": "10.1145/2567574.2567582", "abstract": "In this paper, we develop a conceptual framework for organizing emerging analytic activities involving educational data that can fall under broad and often loosely defined categories, including Academic/Institutional Analytics, Learning Analytics/Educational Data Mining, Learner Analytics/Personalization, and Systemic Instructional Improvement. While our approach is substantially informed by both higher education and K-12 settings, this framework is developed to apply across all educational contexts where digital data are used to inform learners and the management of learning. Although we can identify movements that are relatively independent of each other today, we believe they will in all cases expand from their current margins to encompass larger domains and increasingly overlap. The growth in these analytic activities leads to the need to find ways to synthesize understandings, find common language, and develop frames of reference to help these movements develop into a field.", "authors": ["Philip J. Piety", "Daniel T. Hickey", "M. J. Bishop"], "session": "SESSION: Learning analytics and learning design"}, {"title": "Designing pedagogical interventions to support student use of learning analytics", "pages": "203-211", "doi": "10.1145/2567574.2567588", "abstract": "This article addresses a relatively unexplored area in the emerging field of learning analytics, the design of learning analytics interventions. A learning analytics intervention is defined as the surrounding frame of activity through which analytic tools, data, and reports are taken up and used. It is a soft technology that involves the orchestration of the human process of engaging with the analytics as part of the larger teaching and learning activity. This paper first makes the case for the overall importance of intervention design, situating it within the larger landscape of the learning analytics field, and then considers the specific issues of intervention design for student use of learning analytics. Four principles of pedagogical learning analytics intervention design that can be used by teachers and course developers to support the productive use of learning analytics by students are introduced: Integration, Agency, Reference Frame and Dialogue. In addition three core processes in which to engage students are described: Grounding, Goal-Setting and Reflection. These principles and processes are united in a preliminary model of pedagogical learning analytics intervention design for students, presented as a starting point for further inquiry.", "authors": ["Alyssa Friend Wise"], "session": "SESSION: Learning analytics and learning design"}, {"title": "A cognitive processing framework for learning analytics", "pages": "212-216", "doi": "10.1145/2567574.2567610", "abstract": "Incorporating a learner's level of cognitive processing into Learning Analytics presents opportunities for obtaining rich data on the learning process. We propose a framework called COPA that provides a basis for mapping levels of cognitive operation into a learning analytics system. We utilise Bloom's taxonomy, a theoretically respected conceptualisation of cognitive processing, and apply it in a flexible structure that can be implemented incrementally and with varying degree of complexity within an educational organisation. We outline how the framework is applied, and its key benefits and limitations. Finally, we apply COPA to a University undergraduate unit, and demonstrate its utility in identifying key missing elements in the structure of the course.", "authors": ["Andrew Gibson", "Kirsty Kitto", "Jill Willis"], "session": "SESSION: Learning analytics and learning design"}, {"title": "Statistical discourse analysis of online discussions: informal cognition, social metacognition and knowledge creation", "pages": "217-225", "doi": "10.1145/2567574.2567580", "abstract": "To statistically model large data sets of knowledge processes during asynchronous, online forums, we must address analytic difficulties involving the whole data set (missing data, nested data and the tree structure of online messages), dependent variables (multiple, infrequent, discrete outcomes and similar adjacent messages), and explanatory variables (sequences, indirect effects, false positives, and robustness). Statistical discourse analysis (SDA) addresses all of these issues, as shown in an analysis of 1,330 asynchronous messages written and self-coded by 17 students during a 13-week online educational technology course. The results showed how attributes at multiple levels (individual and message) affected knowledge creation processes. Men were more likely than women to theorize. Asynchronous messages created a micro-sequence context; opinions and asking about purpose preceded new information; anecdotes, opinions, different opinions, elaborating ideas, and asking about purpose or information preceded theorizing. These results show how informal thinking precedes formal thinking and how social metacognition affects knowledge creation.", "authors": ["Ming Ming Chiu", "Nobuko Fujita"], "session": "SESSION: Discourse and argumentation"}, {"title": "Uncovering what matters: analyzing transitional relations among contribution types in knowledge-building discourse", "pages": "226-230", "doi": "10.1145/2567574.2567606", "abstract": "Temporality matters for analysis of collaborative learning. The present study attempts to uncover temporal patterns that distinguish \"productive\" threads of knowledge building inquiry. Using a rich knowledge building discourse dataset, in which notes' contribution types and threads' productivity have been coded, a secondary temporal analysis was conducted. In particular, Lag-sequential Analysis was conducted to identify transitional patterns among different contribution types that distinguish productive threads from \"improvable\" ones. Results indicated that productive inquiry threads involved significantly more transitions among questioning, theorizing, obtaining information, and working with information; in contrast, responding to questions and theories by merely giving opinions was not sufficient to achieve knowledge progress. This study highlights the importance of investigating temporality in collaborative learning and calls for attention to developing and testing temporal analysis methods in learning analytics research.", "authors": ["Bodong Chen", "Monica Resendes"], "session": "SESSION: Discourse and argumentation"}, {"title": "Current state and future trends: a citation network analysis of the learning analytics field", "pages": "231-240", "doi": "10.1145/2567574.2567585", "abstract": "This paper provides an evaluation of the current state of the field of learning analytics through analysis of articles and citations occurring in the LAK conferences and identified special issue journals. The emerging field of learning analytics is at the intersection of numerous academic disciplines, and therefore draws on a diversity of methodologies, theories and underpinning scientific assumptions. Through citation analysis and structured mapping we aimed to identify the emergence of trends and disciplinary hierarchies that are influencing the development of the field to date. The results suggest that there is some fragmentation in the major disciplines (computer science and education) regarding conference and journal representation. The analyses also indicate that the commonly cited papers are of a more conceptual nature than empirical research reflecting the need for authors to define the learning analytics space. An evaluation of the current state of learning analytics provides numerous benefits for the development of the field, such as a guide for under-represented areas of research and to identify the disciplines that may require more strategic and targeted support and funding opportunities.", "authors": ["Shane Dawson", "Dragan Ga\u0161evi\u0107", "George Siemens", "Srecko Joksimovic"], "session": "SESSION: Who we are and who we want to be"}, {"title": "Teaching the unteachable: on the compatibility of learning analytics and humane education", "pages": "241-245", "doi": "10.1145/2567574.2567607", "abstract": "This paper is an exploratory effort to find a place for learning analytics in humane education. After distinguishing humane education from training on the basis of the Aristotelian model of intellectual capabilities, and arguing that humane education is distinct by virtue of its interest in cultivating prudence, which is unteachable, an account of three key characteristics of humane education is provided. Appealing to thinkers of the Italian Renaissance, it is argued that ingenium, eloquence, and self-knowledge constitute the what, how, and why of humane education. Lastly, looking to several examples from recent learning analytics literature, it is demonstrated that learning analytics is not only helpful as set of aids for ensuring success in scientific and technical disciplines, but in the humanities as well. In order to function effectively as an aid to humane education, however, learning analytics must be embedded within a context that encourages continuous reflection, responsiveness, and personal responsibility for learning.", "authors": ["Timothy D. Harfield"], "session": "SESSION: Who we are and who we want to be"}, {"title": "Establishing an ethical literacy for learning analytics", "pages": "246-250", "doi": "10.1145/2567574.2567613", "abstract": "This paper borrows multiple frameworks from the field of technical communication in order to review theory, research, practice, and ethics of the Learning Analytics and Knowledge (LAK) discipline. These frameworks also guide discussion on the ethics of learning analytics \"artifacts\" (data visualizations, dashboards, and methodology), and the ethical consequences of using learning analytics (classification, social power moves, and absence of voice). Finally, the author suggests a literacy for learning analytics that includes an ethical viewpoint.", "authors": ["Jenni Swenson"], "session": "SESSION: Who we are and who we want to be"}, {"title": "Setting learning analytics in context: overcoming the barriers to large-scale adoption", "pages": "251-253", "doi": "10.1145/2567574.2567592", "abstract": "Once learning analytics have been successfully developed and tested, the next step is to implement them at a larger scale -- across a faculty, an institution or an educational system. This introduces a new set of challenges, because education is a stable system, resistant to change. Implementing learning analytics at scale involves working with the entire technological complex that exists around technology-enhanced learning (TEL). This includes the different groups of people involved -- learners, educators, administrators and support staff -- the practices of those groups, their understandings of how teaching and learning take place, the technologies they use and the specific environments within which they operate. Each element of the TEL Complex requires explicit and careful consideration during the process of implementation, in order to avoid failure and maximise the chances of success. In order for learning analytics to be implemented successfully at scale, it is crucial to provide not only the analytics and their associated tools but also appropriate forms of support, training and community building.", "authors": ["Rebecca Ferguson", "Doug Clow", "Leah Macfadyen", "Alfred Essa", "Shane Dawson", "Shirley Alexander"], "session": "PANEL SESSION: Panels"}, {"title": "Learning analytics for the social media age", "pages": "254-256", "doi": "10.1145/2567574.2576773", "abstract": "In just a short period of time, social media have altered many aspects of our daily lives, from how we form and maintain social relationships to how we discover, access and share information online. Now social media are also beginning to affect how we teach and learn in this increasingly interconnected and information-rich world. The panelists will discuss their ongoing work that seeks to understand the affordances and potential roles of social media in learning, as well as to determine and provide methods that can help researchers and educators evaluate the use of social media for teaching and learning based on automated analyses of social media texts and networks. The panel will focus on the first phase of this five-year research initiative \"Learning Analytics for the Social Media Age\" funded by the Social Science and Humanites Research Council of Canada (2013--2018).", "authors": ["Anatoliy Gruzd", "Caroline Haythornthwaite", "Drew Paulin", "Rafa Absar", "Michael Huggett"], "session": "PANEL SESSION: Panels"}, {"title": "Building institutional capacities and competencies for systemic learning analytics initiatives", "pages": "257-260", "doi": "10.1145/2567574.2567593", "abstract": "The last five years have brought an explosion of research in the learning analytics field. However, much of what has emerged has been small scale or tool-centric. While these efforts are vitally important to the development of the field, in order to truly transform education, learning analytics must scale and become institutionalized at multiple levels throughout an educational system. Many institutions are currently undertaking this grand challenge and this panel will highlight cases from: the University of Wisconsin System, the Society for Learning Analytics Research, the University of New England, and Rio Salado College.", "authors": ["Kimberly E. Arnold", "Grace Lynch", "Daniel Huston", "Lorna Wong", "Linda Jorn", "Christopher W. Olsen"], "session": "PANEL SESSION: Panels"}, {"title": "Hanzi handwriting acquisition with automatic feedback", "pages": "261-262", "doi": "10.1145/2567574.2567575", "abstract": "One of the most crucial distinctions between Chinese and Western languages is that the former is based on ideograms, whereas the latter is based on phonograms. Due to this distinction, Western learners of Chinese often experience more difficulties in grasping correct character stroke sequence and/or stroke direction relative to native Chinese speakers. In this paper, we designed a HanZi writing environment with automatic feedback to address the above issue. Before the collection of HanZi characters on a massive scale, we conducted a pilot study to collect handwritten Chinese samples from 160 college students in the U.S. The findings from this study enabled us to further refine the learning environment and design optimal learning and teaching strategies for learners and teachers.", "authors": ["Chin-Hwa Kuo", "Jian-Wen Peng", "Wen-Chen Chang"], "session": "POSTER SESSION: Posters"}, {"title": "Analyzing student notes and questions to create personalized study guides", "pages": "263-264", "doi": "10.1145/2567574.2567576", "abstract": "In the foreseeable future it will be technically possible for instructors, advisors and other delegated representatives of a college or university to access student participation and performance data in near-real time. One potential benefit of this increased data flow could include an improved ability to identify students at risk of academic failure or withdrawal. The availability of these data could also lead to creation of new adaptive learning measures that can automatically provide students personalized guidance. This demonstration will describe how the student notes and questions are being mined to provide student study guides that automatically link to outside resources. The demonstration will also report on how these new study guides have been received by the students and how they are at least partially responsible for a significant increase in student outcomes.", "authors": ["Perry J. Samson"], "session": "POSTER SESSION: Posters"}, {"title": "Visual analytics of academic writing", "pages": "265-266", "doi": "10.1145/2567574.2567577", "abstract": "This paper describes a novel analytics dashboard which visualises the key features of scholarly documents. The Dashboard aggregates the salient sentences of scholarly papers, their rhetorical types and the key concepts mentioned within these sentences. These features are extracted from papers through a Natural Language Processing (NLP) technology, called Xerox Incremental Parser (XIP). The XIP Dashboard is a set of visual analytics modules based on the XIP output. In this paper, we briefly introduce the XIP technology and demonstrate an example visualisation of the XIP Dashboard.", "authors": ["Duygu Simsek", "Simon Buckingham Shum", "Anna De Liddo", "Rebecca Ferguson", "\u00c1gnes S\u00e1ndor"], "session": "POSTER SESSION: Posters"}, {"title": "Open academic early alert system: technical demonstration", "pages": "267-268", "doi": "10.1145/2567574.2567578", "abstract": "This paper synthesizes some of the technical decisions, design strategies & concepts developed during the execution of Open Academic Analytics Initiative (OAAI), a research program aimed at improving student retention rates in colleges, by deploying an open-source academic early alert system to identify the students at academic risk. The paper explains the prototype demonstration of the system, detailing several dimensions of data mining & analysis such as: data integration, predictive modelling and scoring with reporting. The paper should be relevant to practitioners and academicians who want to better understand the implementation of an OAAI academic early-alert system.", "authors": ["Sandeep M. Jayaprakash", "Eitel J. M. Laur\u00eda"], "session": "POSTER SESSION: Posters"}, {"title": "Educational technology approach toward learning analytics: relationship between student online behavior and learning performance in higher education", "pages": "269-270", "doi": "10.1145/2567574.2567594", "abstract": "The aim of this study is to suggest more meaningful components for learning analytics in order to help learners improving their learning achievement continuously through an educational technology approach. Multiple linear regression analysis is conducted to determine which factors influence student's academic achievement. 84 undergraduate students in a women's university in South Korea participated in this study. The six-predictor model was able to account for 33.5% of the variance in final grade, F(6, 77) = 6.457, p < .001, R2 = .335. Total studying time in LMS, interaction with peers, regularity of learning interval in LMS, and number of downloads were determined to be significant factors for students' academic achievement in online learning environment. These four controllable variables not only predict learning outcomes significantly but also can be changed if learners put more effort to improve their academic performance. The results provide a rationale for the treatment for student time management effort.", "authors": ["Taeho Yu", "Il-Hyun Jo"], "session": "POSTER SESSION: Posters"}, {"title": "Visualizing semantic space of online discourse: the knowledge forum case", "pages": "271-272", "doi": "10.1145/2567574.2567595", "abstract": "This poster presents an early experimentation of applying topic modeling and visualization techniques to analyze online discourse. In particular, Latent Dirichlet Allocation was used to convert discourse into a high-dimensional semantic space. To explore meaningful visualizations of the space, Locally Linear Embedding was performed reducing it to two-dimensional. Further, Time Series Analysis was applied to track evolution of topics in the space. This work will lead to new analytic tools for collaborative learning.", "authors": ["Bodong Chen"], "session": "POSTER SESSION: Posters"}, {"title": "eGraph tool: graphing the learning process in LMSs", "pages": "273-274", "doi": "10.1145/2567574.2567596", "abstract": "eGraph is a virtual tool developed with the aim of make easier to track the students' learning process in Learning Management Systems like Moodle. It is based in the log files that the learning platform records when the students are interacting with and allows teachers, students, and researchers to track the learning route that learners have followed during a particular time span.", "authors": ["Rebeca Cerezo", "Natalia Suarez", "J. Carlos N\u00fa\u00f1ez", "Miguel S\u00e1nchez-Santill\u00e1n"], "session": "POSTER SESSION: Posters"}, {"title": "Effects of image-based and text-based activities on student learning outcomes", "pages": "275-276", "doi": "10.1145/2567574.2567597", "abstract": "Research on benefits of visual learning has relied primarily on lecture-based pedagogy, not accounting for the processing time students need to make sense of both visual and verbal material[8]. In this study, we investigate the potential differential effects of text-based and image-based student learning activities on student learning outcomes in a functional anatomy course. When controlling for demographics and prior GPA, participation in in-class image-based activities is significantly correlated with performance on associated exam questions, while text-based engagement is not. Additionally, students rated activities as helpful for seeing images of key ideas and as being significantly less mentally taxing than text-based activities.", "authors": ["Anne K. Greenberg", "Melissa Gross", "Mary C. Wright"], "session": "POSTER SESSION: Posters"}, {"title": "Peer evaluation of student generated content", "pages": "277-278", "doi": "10.1145/2567574.2567598", "abstract": "We will present three similar studies that examine online peer evaluation of student-generated explanations for missed exam problems in introductory physics. In the first study, students created video solutions using YouTube and in the second two studies, they created written solutions using Google documents. All peer evaluations were performed using a tournament module as part of the interactive online coaching system called E2Coach[4] at the University of Michigan. With the theme of LAK 2014 being \"intersection of learning analytics research, theory and practice\", we think this poster will provide an accessible example that combines a classroom experiment with rigorous analysis to understand outcomes.", "authors": ["Jared Tritz", "Nicole Michelotti", "Ginger Shultz", "Tim McKay", "Barsaa Mohapatra"], "session": "POSTER SESSION: Posters"}, {"title": "Patterns of persistence: what engages students in a remedial english writing MOOC?", "pages": "279-280", "doi": "10.1145/2567574.2567601", "abstract": "MOOCs have the potential to help institutions and students needing remedial English language instruction in two ways. First, with their capacity to use a wide range of instructional approaches and to emphasize contextualized and visual learning, MOOCS can offer potentially more effective pedagogical approaches for remedial students. Second, if students increase success meeting college-level English competencies, MOOCS can help institutions and students conserve their limited resources. Similarly, MOOCs offer domestically and international employers opportunities to provide professional development to workers both in ways that are flexible, affordable and interactive.", "authors": ["John Whitmer", "Eva Schiorring", "Pat James"], "session": "POSTER SESSION: Posters"}, {"title": "National differences in an international classroom", "pages": "281-282", "doi": "10.1145/2567574.2567602", "abstract": "The virtual classrooms of open online courses include students from a vast array of individual, social, economic, and educational contexts. Detailed data were collected for the first course MIT ran on the edX platform, including student behavior, performance, and background information. In this paper, we estimate the systematic differences in average performance, distribution of performance, and performance conditional on behaviors for countries with different characteristics (e.g., language, income).", "authors": ["Jennifer DeBoer", "Glenda S. Stump"], "session": "POSTER SESSION: Posters"}, {"title": "DCLA14: second international workshop on discourse-centric learning analytics", "pages": "283-284", "doi": "10.1145/2567574.2567631", "abstract": "The first international workshop on discourse-centric learning analytics (DCLA) took place at LAK13 in Leuven, Belgium. That workshop succeeded in its aim of catalysing ideas and building community connections between those working in this field of social learning analytics. It also proposed a mission statement for DCLA: to devise and validate analytics that look beyond surface measures in order to quantify linguistic proxies for deeper learning. This year, the focus of the second international DCLA workshop, like that of LAK14, is on the intersection of learning analytics research, theory and practice. Once researchers have developed and validated discourse-centric analytics, how can these be successfully deployed at scale to support learning?", "authors": ["Rebecca Ferguson", "Anna De Liddo", "Denise Whitelock", "Maarten de Laat", "Simon Buckingham Shum"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "Computational approaches to connecting levels of analysis in networked learning communities", "pages": "285-286", "doi": "10.1145/2567574.2567632", "abstract": "The focus of this workshop is on the potential benefits and challenges of using specific computational methods to analyze interactions in networked learning environments, particularly with respect to integrating multiple analytic approaches towards understanding learning at multiple levels of agency, from individual to collective. The workshop is designed for researchers interested in analytical studies of collaborative and networked learning in socio-technical networks, using data-intensive computational methods of analysis (including social-network analysis, log-file analysis, information extraction and data mining). The workshop may also be of interest to pedagogical professionals and educational decision makers who want to evaluate the potential of learning analytics techniques to better inform their decisions regarding learning in technology-rich environments.", "authors": ["H. Ulrich Hoppe", "Daniel D. Suthers"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "Learning analytics and machine learning", "pages": "287-288", "doi": "10.1145/2567574.2567633", "abstract": "Learning analytics (LA) as a field remains in its infancy. Many of the techniques now prominent from practitioners have been drawn from various fields, including HCI, statistics, computer science, and learning sciences. In order for LA to grow and advance as a discipline, two significant challenges must be met: 1) development of analytics methods and techniques that are native to the LA discipline, and 2) practitioners in LA to develop algorithms and models that reflect the social and computational dimensions of analytics. This workshop introduces researchers in learning analytics to machine learning (ML) and the opportunities that ML can provide in building next generation analysis models.", "authors": ["Dragan Gasevic", "Carolyn Rose", "George Siemens", "Annika Wolff", "Zdenek Zdrahal"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "The learning analytics & knowledge (LAK) data challenge 2014", "pages": "289-290", "doi": "10.1145/2567574.2567630", "abstract": "The LAK Data Challenge 2014 continues the research efforts of the second edition by stimulating research on the evolving fields Learning Analytics (LA) and Educational Data Mining (EDM). Building on a series of activities of the LinkedUp project, the challenge aims to generate new insights and analysis on the LA & EDM disciplines and is supported through the LAK Dataset - a unique corpus of LA & EDM literature, exposed in structured and machine-readable formats.", "authors": ["Hendrik Drachsler", "Stefan Dietze", "Eelco Herder", "Mathieu d'Aquin", "Davide Taibi"], "session": "WORKSHOP SESSION: Workshops"}]}, {"year": 2015, "papers": [{"title": "The LATUX workflow: designing and deploying awareness tools in technology-enabled learning settings", "pages": "1-10", "doi": "10.1145/2723576.2723583", "abstract": "Designing, deploying and validating learning analytics tools for instructors or students is a challenge requiring techniques and methods from different disciplines, such as software engineering, human-computer interaction, educational design and psychology. Whilst each of these disciplines has consolidated design methodologies, there is a need for more specific methodological frameworks within the cross-disciplinary space defined by learning analytics. In particular there is no systematic workflow for producing learning analytics tools that are both technologically feasible and truly underpin the learning experience. In this paper, we present the LATUX workflow, a five-stage workflow to design, deploy and validate awareness tools in technology-enabled learning environments. LATUX is grounded on a well-established design process for creating, testing and re-designing user interfaces. We extend this process by integrating the pedagogical requirements to generate visual analytics to inform instructors' pedagogical decisions or intervention strategies. The workflow is illustrated with a case study in which collaborative activities were deployed in a real classroom.", "authors": ["Roberto Martinez-Maldonado", "Abelardo Pardo", "Negin Mirriahi", "Kalina Yacef", "Judy Kay", "Andrew Clayphan"], "session": "SESSION: Indicators and tools for awareness"}, {"title": "Learning analytics beyond the LMS: the connected learning analytics toolkit", "pages": "11-15", "doi": "10.1145/2723576.2723627", "abstract": "We present a Connected Learning Analytics (CLA) toolkit, which enables data to be extracted from social media and imported into a Learning Record Store (LRS), as defined by the new xAPI standard. A number of implementation issues are discussed, and a mapping that will enable the consistent storage and then analysis of xAPI verb/object/activity statements across different social media and online environments is introduced. A set of example learning activities are proposed, each facilitated by the Learning Analytics beyond the LMS that the toolkit enables.", "authors": ["Kirsty Kitto", "Sebastian Cross", "Zak Waters", "Mandy Lupton"], "session": "SESSION: Indicators and tools for awareness"}, {"title": "Developing an evaluation framework of quality indicators for learning analytics", "pages": "16-20", "doi": "10.1145/2723576.2723629", "abstract": "This paper presents results from the continuous process of developing an evaluation framework of quality indicators for learning analytics (LA). Building on a previous study, a group concept mapping approach that uses multidimensional scaling and hierarchical clustering, the study presented here applies the framework to a collection of LA tools in order to evaluate the framework. Using the quantitative and qualitative results of this study, the first version of the framework was revisited so as to allow work towards an improved version of the evaluation framework of quality indicators for LA.", "authors": ["Maren Scheffel", "Hendrik Drachsler", "Marcus Specht"], "session": "SESSION: Indicators and tools for awareness"}, {"title": "Exploring networks of problem-solving interactions", "pages": "21-30", "doi": "10.1145/2723576.2723630", "abstract": "Intelligent tutoring systems and other computer-aided learning environments produce large amounts of transactional data on student problem-solving behavior, in previous work we modeled the student-tutor interaction data as a complex network, and successfully generated automated next-step hints as well as visualizations for educators. In this work we discuss the types of tutoring environments that are best modeled by interaction networks, and how the empirical observations of problem-solving result in common network features. We find that interaction networks exhibit the properties of scale-free networks such as vertex degree distributions that follow power law. We compare data from two versions of a propositional logic tutor, as well as two different representations of data from an educational game on programming. We find that statistics such as degree assortativity and the scale-free metric allow comparison of the network structures across domains, and provide insight into student problem solving behavior.", "authors": ["Michael Eagle", "Drew Hicks", "Barry Peddycord, III", "Tiffany Barnes"], "session": "SESSION: Student engagement and behaviour"}, {"title": "Towards better affect detectors: effect of missing skills, class features and common wrong answers", "pages": "31-35", "doi": "10.1145/2723576.2723618", "abstract": "The well-studied Baker et al., affect detectors on boredom, frustration, confusion and engagement concentration with ASSISTments dataset were used to predict state tests scores, college enrollment, and even whether a student majored in a STEM field. In this paper, we present three attempts to improve upon current affect detectors. The first attempt analyzed the effect of missing skill tags in the dataset to the accuracy of the affect detectors. The results show a small improvement after correctly tagging the missing skill values. The second attempt added four features related to student classes for feature selection. The third attempt added two features that described information about student common wrong answers for feature selection. Result showed that two out of the four detectors were improved by adding the new features.", "authors": ["Yutao Wang", "Neil T. Heffernan", "Cristina Heffernan"], "session": "SESSION: Student engagement and behaviour"}, {"title": "Exploring college major choice and middle school student behavior, affect and learning: what happens to students who game the system?", "pages": "36-40", "doi": "10.1145/2723576.2723610", "abstract": "Choosing a college major is a major life decision. Interests stemming from students' ability and self-efficacy contribute to eventual college major choice. In this paper, we consider the role played by student learning, affect and engagement during middle school, using data from an educational software system used as part of regular schooling. We use predictive analytics to leverage automated assessments of student learning and engagement, investigating which of these factors are related to a chosen college major. For example, we already know that students who game the system in middle school mathematics are less likely to major in science or technology, but what majors are they more likely to select? Using data from 356 college students who used the ASSISTments system during their middle school years, we find significant differences in student knowledge, performance, and off-task and gaming behaviors between students who eventually choose different college majors.", "authors": ["Maria O. Z. San Pedro", "Ryan S. Baker", "Neil T. Heffernan", "Jaclyn L. Ocumpaugh"], "session": "SESSION: Student engagement and behaviour"}, {"title": "On the validity of peer grading and a cloud teaching assistant system", "pages": "41-50", "doi": "10.1145/2723576.2723633", "abstract": "We introduce a new grading system, the Cloud Teaching Assistant System (CTAS), as an additional element to instructor grading, peer grading and automated validation in massive open online courses (MOOCs). The grading distributions of the different approaches are compared in an experiment consisting of 476 exam participants. 25 submissions were graded by all four methods. 451 submissions were graded only by peer grading and automated validation. The results of the experiment suggest that both CTAS and peer grading do not simulate instructor grading (Pearson's correlations: 0.36, 0.39). If the CTAS and not the instructor is assumed to deliver accurate grading, peer grading is concluded to be a valid grading method (Pearson's correlation: 0.76).", "authors": ["Tim Vogelsang", "Lara Ruppertz"], "session": "SESSION: MOOCs -- assessments, connections and demographics"}, {"title": "Examining engagement: analysing learner subpopulations in massive open online courses (MOOCs)", "pages": "51-58", "doi": "10.1145/2723576.2723606", "abstract": "Massive open online courses (MOOCs) are now being used across the world to provide millions of learners with access to education. Many learners complete these courses successfully, or to their own satisfaction, but the high numbers who do not finish remain a subject of concern for platform providers and educators. In 2013, a team from Stanford University analysed engagement patterns on three MOOCs run on the Coursera platform. They found four distinct patterns of engagement that emerged from MOOCs based on videos and assessments. However, not all platforms take this approach to learning design. Courses on the FutureLearn platform are underpinned by a social-constructivist pedagogy, which includes discussion as an important element. In this paper, we analyse engagement patterns on four FutureLearn MOOCs and find that only two clusters identified previously apply in this case. Instead, we see seven distinct patterns of engagement: Samplers, Strong Starters, Returners, Mid-way Dropouts, Nearly There, Late Completers and Keen Completers. This suggests that patterns of engagement in these massive learning environments are influenced by decisions about pedagogy. We also make some observations about approaches to clustering in this context.", "authors": ["Rebecca Ferguson", "Doug Clow"], "session": "SESSION: MOOCs -- assessments, connections and demographics"}, {"title": "Socioeconomic status and MOOC enrollment: enriching demographic information with external datasets", "pages": "59-63", "doi": "10.1145/2723576.2723615", "abstract": "To minimize barriers to entry, massive open online course (MOOC) providers collect minimal demographic information about users. In isolation, these data are insufficient to address important questions about socioeconomic status (SES) and MOOC enrollment and performance. We demonstrate the use of third-party datasets to enrich demographic portraits of MOOC students and answer fundamental questions about SES and MOOC enrollment. We derive demographic information from registrants' geographic location by matching self-reported mailing addresses with data available from Esri at the census block group level and the American Community Survey at the zip code level. We then use these data to compare neighborhood income and parental education for US registrants in HarvardX courses to the US population as a whole. Overall, HarvardX registrants tend to reside in more affluent neighborhoods. Registrants on average live in neighborhoods with median incomes approximately. 45 standard deviations higher than the US population. Higher levels of parental education are also associated with a higher likelihood of registration.", "authors": ["John D. Hansen", "Justin Reich"], "session": "SESSION: MOOCs -- assessments, connections and demographics"}, {"title": "How do you connect?: analysis of social capital accumulation in connectivist MOOCs", "pages": "64-68", "doi": "10.1145/2723576.2723604", "abstract": "Connections established between learners via interactions are seen as fundamental for connectivist pedagogy. Connections can also be viewed as learning outcomes, i.e. learners' social capital accumulated through distributed learning environments. We applied linear mixed effects modeling to investigate whether the social capital accumulation interpreted through learners' centrality to course interaction networks, is influenced by the language learners use to express and communicate in two connectivist MOOCs. Interactions were distributed across the three social media, namely Twitter, blog and Facebook. Results showed that learners in a cMOOC connect easier with the individuals who use a more informal, narrative style, but still maintain a deeper cohesive structure to their communication.", "authors": ["Sre\u0107ko Joksimovi\u0107", "Nia Dowell", "Oleksandra Skrypnyk", "Vitomir Kovanovi\u0107", "Dragan Ga\u0161evi\u0107", "Shane Dawson", "Arthur C. Graesser"], "session": "SESSION: MOOCs -- assessments, connections and demographics"}, {"title": "Learning analytics: European perspectives", "pages": "69-72", "doi": "10.1145/2723576.2723637", "abstract": "Since the emergence of learning analytics in North America, researchers and practitioners have worked to develop an international community. The organization of events such as SoLAR Flares and LASI Locals, as well as the move of LAK in 2013 from North America to Europe, has supported this aim. There are now thriving learning analytics groups in North American, Europe and Australia, with smaller pockets of activity emerging on other continents. Nevertheless, much of the work carried out outside these forums, or published in languages other than English, is still inaccessible to most people in the community. This panel, organized by Europe's Learning Analytics Community Exchange (LACE) project, brings together researchers from five European countries to examine the field from European perspectives. In doing so, it will identify the benefits and challenges associated with sharing and developing practice across national boundaries.", "authors": ["Rebecca Ferguson", "Adam Cooper", "Hendrik Drachsler", "G\u00e1bor Kismih\u00f3k", "Anne Boyer", "Kairit Tammets", "Alejandra Mart\u00ednez Mon\u00e9s"], "session": "SESSION: Practice across boundaries"}, {"title": "OpenCourseWare observatory: does the quality of OpenCourseWare live up to its promise?", "pages": "73-82", "doi": "10.1145/2723576.2723605", "abstract": "A vast amount of OpenCourseWare (OCW) is meanwhile being published online to make educational content accessible to larger audiences. The awareness of such courses among users and the popularity of systems providing such courses are increasing. However, from a subjective experience, OCW is frequently cursory, outdated or non-reusable. In order to obtain a better understanding of the quality of OCW, we assess the quality in terms of fitness for use. Based on three OCW use case scenarios, we define a range of dimensions according to which the quality of courses can be measured. From the definition of each dimension a comprehensive list of quality metrics is derived. In order to obtain a representative overview of the quality of OCW, we performed a quality assessment on a set of 100 randomly selected courses obtained from 20 different OCW repositories. Based on this assessment we identify crucial areas in which OCW needs to improve in order to deliver up to its promises.", "authors": ["Sahar Vahdati", "Christoph Lange", "S\u00f6ren Auer"], "session": "SESSION: Practice across boundaries"}, {"title": "Student privacy self-management: implications for learning analytics", "pages": "83-92", "doi": "10.1145/2723576.2723585", "abstract": "Optimizing the harvesting and analysis of student data promises to clear the fog surrounding the key drivers of student success and retention, and provide potential for improved student success. At the same time, concerns are increasingly voiced around the extent to which individuals are routinely and progressively tracked as they engage online. The Internet, the very thing that promised to open up possibilities and to break down communication barriers, now threatens to narrow it again through the panopticon of mass surveillance. Within higher education, our assumptions and understanding of issues surrounding student attitudes to privacy are influenced both by the apparent ease with which the public appear to share the detail of their lives and our paternalistic institutional cultures. As such, it can be easy to allow our enthusiasm for the possibilities offered by learning analytics to outweigh consideration of issues of privacy. This paper explores issues around consent and the seemingly simple choice to allow students to opt-in or opt-out of having their data tracked. We consider how 3 providers of massive open online courses (MOOCs) inform users of how their data is used, and discuss how higher education institutions can work toward an approach which engages and more fully informs students of the implications of learning analytics on their personal data.", "authors": ["Paul Prinsloo", "Sharon Slade"], "session": "SESSION: Institutional perspectives"}, {"title": "Who, when, and why: a machine learning approach to prioritizing students at risk of not graduating high school on time", "pages": "93-102", "doi": "10.1145/2723576.2723619", "abstract": "Several hundred thousand students drop out of high school every year in the United States. Interventions can help those who are falling behind in their educational goals, but given limited resources, such programs must focus on the right students, at the right time, and with the right message. In this paper, we describe an incremental approach that can be used to select and prioritize students who may be at risk of not graduating high school on time, and to suggest what may be the predictors of particular students going off-track. These predictions can then be used to inform targeted interventions for these students, hopefully leading to better outcomes.", "authors": ["Everaldo Aguiar", "Himabindu Lakkaraju", "Nasir Bhanpuri", "David Miller", "Ben Yuhas", "Kecia L. Addison"], "session": "SESSION: Students at risk"}, {"title": "Collaborative multi-regression models for predicting students' performance in course activities", "pages": "103-107", "doi": "10.1145/2723576.2723590", "abstract": "Methods that accurately predict the grade of a student at a given activity or course can identify students that are at risk in failing a course and allow their educational institution to take corrective actions. Though a number of prediction models have been developed, they either estimate a single model for all students based on their past course performance and interactions with learning management systems (LMS), or estimate student-specific models that do not take into account LMS interactions; thus, failing to exploit fine-grain information related to a student's engagement. In this work we present a class of collaborative multi-regression models that are personalized to each student and also take into account features related to student's past performance, engagement and course characteristics. These models use all historical information to estimate a small number of regression models shared by all students along with student-specific combination weights. This allows for information sharing and also generating personalized predictions. Our experimental evaluation on a large set of students, courses, and activities shows that these models are capable of improving the performance prediction accuracy by over 20%. In addition, we show that by analyzing the estimated models and the student-specific combination functions we can gain insights on the effectiveness of the educational material that is made available at the courses of different departments.", "authors": ["Asmaa Elbadrawy", "R. Scott Studham", "George Karypis"], "session": "SESSION: Student performance"}, {"title": "Investigating performance of students: a longitudinal study", "pages": "108-112", "doi": "10.1145/2723576.2723579", "abstract": "This paper, investigates how academic performance of students evolves over the years in their studies during a study programme. To determine typical progression patterns over the years, students are described by a 4 tuple (e.g. x1, x2, x3, x4), these being the clusters' mean to which a student belongs to in each year of the degree. For this purpose, two consecutive cohorts have been analyzed using X-means clustering. Interestingly the patterns found in both cohorts show that a substantial number of students stay in the same kind of groups during their studies.", "authors": ["Raheela Asif", "Agathe Merceron", "Mahmood Khan Pathan"], "session": "SESSION: Student performance"}, {"title": "Using transaction-level data to diagnose knowledge gaps and misconceptions", "pages": "113-117", "doi": "10.1145/2723576.2723620", "abstract": "The role of assessment in learning is to evaluate student comprehension and ability. Assessment instruments often function at the task level. What is rarely considered is the process students go through to reach the final solution. This often allows knowledge component gaps and misconceptions to go undetected. This research identified higher levels of knowledge component gaps and misunderstandings when assessing transaction-level knowledge component data than task-level final solution data. Final solution data showed little evidence that students had any misunderstanding or knowledge gaps about the use of absolute references. However, when analyzing these data at the transaction level we found evidence that far more students struggled than the analysis of the final solutions suggested.", "authors": ["Randall Davies", "Rob Nyland", "John Chapman", "Gove Allen"], "session": "SESSION: Student performance"}, {"title": "Estimation of ability from homework items when there are missing and/or multiple attempts", "pages": "118-125", "doi": "10.1145/2723576.2723582", "abstract": "Scoring of student item response data from online courses and especially massively open online courses (MOOCs) is complicated by two challenges, potentially large amounts of missing data and allowances for multiple attempts to answer. Approaches to ability estimation with respect to both of these issues are considered using data from a large-enrollment electrical engineering MOOC. The allowance of unlimited multiple attempts sets up a range of observed score and latent-variable approaches to scoring the constructed response homework. With respect to missing data, two classical approaches are discussed, treating omitted items as incorrect or missing at random (MAR). These treatments turn out to have slightly different interpretations depending on the scoring model. In all, twelve different homework scores are proposed based on combinations of scoring model and missing data handling. The scores are computed and correlations between each score and the final exam score are compared, with attention to different populations of course participants.", "authors": ["Yoav Bergner", "Kimberly Colvin", "David E. Pritchard"], "session": "SESSION: Predicting achievement"}, {"title": "A time series interaction analysis method for building predictive models of learners using log data", "pages": "126-135", "doi": "10.1145/2723576.2723581", "abstract": "As courses become bigger, move online, and are deployed to the general public at low cost (e.g. through Massive Open Online Courses, MOOCs), new methods of predicting student achievement are needed to support the learning process. This paper presents a novel method for converting educational log data into features suitable for building predictive models of student success. Unlike cognitive modelling or content analysis approaches, these models are built from interactions between learners and resources, an approach that requires no input from instructional or domain experts and can be applied across courses or learning environments.", "authors": ["Christopher Brooks", "Craig Thompson", "Stephanie Teasley"], "session": "SESSION: Predicting achievement"}, {"title": "Predicting success: how learners' prior knowledge, skills and activities predict MOOC performance", "pages": "136-140", "doi": "10.1145/2723576.2723593", "abstract": "While MOOCs have taken the world by storm, questions remain about their pedagogical value and high rates of attrition. In this paper we argue that MOOCs which have open entry and open curriculum structures, place pressure on learners to not only have the requisite knowledge and skills to complete the course, but also the skills to traverse the course in adaptive ways that lead to success. The empirical study presented in the paper investigated the degree to which students' prior knowledge and skills, and their engagement with the MOOC as measured through learning analytics, predict end-of-MOOC performance. The findings indicate that prior knowledge is the most significant predictor of MOOC success followed by students' ability to revise and revisit their previous work.", "authors": ["Gregor Kennedy", "Carleton Coffrin", "Paula de Barba", "Linda Corrin"], "session": "SESSION: Predicting achievement"}, {"title": "Likelihood analysis of student enrollment outcomes using learning environment variables: a case study approach", "pages": "141-145", "doi": "10.1145/2723576.2723621", "abstract": "Tertiary institutions are increasing the emphasis on generating, collecting and analyzing student data as a means of targeting student support services. This study utilizes a data set from a regional Australian university to conduct logistic regression analyzing the student enrollment outcomes. The results indicate that demographic factors have a minor effect while institutional and learning environment variables play a more significant role in determining student enrollment outcomes. Using grade distribution compared to grade point average provides better estimates as to the effect particular grades have on enrollment outcomes. Moreover, the effect of an early alert system on enrollment outcomes shows that early identification has a significant relationship to a student's choice to stay enrolled versus discontinuing, lapsing or being inactive in their enrollment. These results are vital in the targeting of student support services at the case study institution. The significant results indicate the importance of learning environment variables in understanding student enrollment outcomes at tertiary institutions. This analysis forms part of a much larger research project analyzing student retention at the institution.", "authors": ["Scott Harrison", "Renato Villano", "Grace Lynch", "George Chen"], "session": "SESSION: Predicting achievement"}, {"title": "Unsupervised modeling for understanding MOOC discussion forums: a learning analytics approach", "pages": "146-150", "doi": "10.1145/2723576.2723589", "abstract": "Massively Open Online Courses (MOOCs) have gained attention recently because of their great potential to reach learners. Substantial empirical study has focused on student persistence and their interactions with the course materials. However, most MOOCs include a rich textual dialogue forum, and these textual interactions are largely unexplored. Automatically understanding the nature of discussion forum posts holds great promise for providing adaptive support to individual students and to collaborative groups. This paper presents a study that applies unsupervised student understanding models originally developed for synchronous tutorial dialogue to MOOC forums. We use a clustering approach to group similar posts, compare the clusters with manual annotations by MOOC researchers, and further investigate clusters qualitatively. This paper constitutes a step toward applying unsupervised models to asynchronous communication, which can enable massive-scale automated discourse analysis and mining to better support students' learning.", "authors": ["Aysu Ezen-Can", "Kristy Elizabeth Boyer", "Shaun Kellogg", "Sherry Booth"], "session": "SESSION: MOOCs -- discussion forums"}, {"title": "Crowd-sourced learning in MOOCs: learning analytics meets measurement theory", "pages": "151-155", "doi": "10.1145/2723576.2723596", "abstract": "This paper illustrated the promise of the combination of measurement theory and learning analytics for understanding effective MOOC learning. It reports findings from a study of whether and how MOOC log file data can assist in understanding how MOOC participants use (often) messy, chaotic forums to support complex, unpredictable, contingent learning processes. It is argued that descriptions of posting, voting and viewing behaviours do not in and of themselves provide insights about how learning is generated in MOOC forums. Rather, it is hypothesised that there is a skill involved in using forums to learn; that theory-informed descriptions of this skill illustrate how MOOC participants use forums differently as they progress from novice to expert; that the skill progression can be validated through the use of forum log file data; and that log file data can also be used to assess an individual MOOC participant's position in relation to this progression -- that is, to measure an individual's skill in learning through forums and similar educational settings. These hypotheses were examined using data drawn from forums in a large MOOC run at the University of Melbourne in 2013.", "authors": ["Sandra Milligan"], "session": "SESSION: MOOCs -- discussion forums"}, {"title": "What do cMOOC participants talk about in social media?: a topic analysis of discourse in a cMOOC", "pages": "156-165", "doi": "10.1145/2723576.2723609", "abstract": "Creating meaning from a wide variety of available information and being able to choose what to learn are highly relevant skills for learning in a connectivist setting. In this work, various approaches have been utilized to gain insights into learning processes occurring within a network of learners and understand the factors that shape learners' interests and the topics to which learners devote a significant attention. This study combines different methods to develop a scalable analytic approach for a comprehensive analysis of learners' discourse in a connectivist massive open online course (cMOOC). By linking techniques for semantic annotation and graph analysis with a qualitative analysis of learner-generated discourse, we examined how social media platforms (blogs, Twitter, and Facebook) and course recommendations influence content creation and topics discussed within a cMOOC. Our findings indicate that learners tend to focus on several prominent topics that emerge very quickly in the course. They maintain that focus, with some exceptions, throughout the course, regardless of readings suggested by the instructor. Moreover, the topics discussed across different social media differ, which can likely be attributed to the affordances of different media. Finally, our results indicate a relatively low level of cohesion in the topics discussed which might be an indicator of a diversity of the conceptual coverage discussed by the course participants.", "authors": ["Sre\u0107ko Joksimovi\u0107", "Vitomir Kovanovi\u0107", "Jelena Jovanovi\u0107", "Amal Zouaq", "Dragan Ga\u0161evi\u0107", "Marek Hatala"], "session": "SESSION: MOOCs -- discussion forums"}, {"title": "Tracking student progress in a game-like learning environment with a Monte Carlo Bayesian knowledge tracing model", "pages": "166-170", "doi": "10.1145/2723576.2723608", "abstract": "The Bayesian Knowledge Tracing (BKT) model is a popular model used for tracking student progress in learning systems such as an intelligent tutoring system. However, the model is not free of problems. Well-recognized problems include the identifiability problem and the empirical degeneracy problem. Unfortunately, these problems are still poorly understood and how they should be dealt with in practice is unclear. Here, we analyze the mathematical structure of the BKT model, identify a source of the difficulty, and construct a simple Monte Carlo BKT model to analyze the problem in real data. Using the student activity data obtained from the ramp task module at the Concord Consortium, we find that the Monte Carlo BKT analysis is capable of detecting the identifiability problem and the empirical degeneracy problem, and, more generally, gives an excellent summary of the student learning data. In particular, the student activity monitoring parameter M emerges as the central parameter.", "authors": ["G.-H. Gweon", "Hee-Sun Lee", "Chad Dorsey", "Robert Tinker", "William Finzer", "Daniel Damelin"], "session": "SESSION: Off-task behaviour / Bayesian knowledge tracing"}, {"title": "How does Bayesian knowledge tracing model emergence of knowledge about a mechanical system?", "pages": "171-175", "doi": "10.1145/2723576.2723587", "abstract": "An interactive learning task was designed in a game format to help high school students acquire knowledge about a simple mechanical system involving a car moving on a ramp. This ramp game consisted of five challenges that addressed individual knowledge components with increasing difficulty. In order to investigate patterns of knowledge emergence during the ramp game, we applied the Monte Carlo Bayesian Knowledge Tracing (BKT) algorithm to 447 game segments produced by 64 student groups in two physics teachers' classrooms. Results indicate that, in the ramp game context, (1) the initial knowledge and guessing parameters were significantly highly correlated, (2) the slip parameter was interpretable monotonically, (3) low guessing parameter values were associated with knowledge emergence while high guessing parameter values were associated with knowledge maintenance, and (4) the transition parameter showed the speed of knowledge emergence. By applying the k-means clustering to ramp game segments represented in the three dimensional space defined by guessing, slip, and transition parameters, we identified seven clusters of knowledge emergence. We characterize these clusters and discuss implications for future research as well as for instructional game design.", "authors": ["Hee-Sun Lee", "Gey-Hong Gweon", "Chad Dorsey", "Robert Tinker", "William Finzer", "Daniel Damelin", "Nathan Kimball", "Amy Pallant", "Trudi Lord"], "session": "SESSION: Off-task behaviour / Bayesian knowledge tracing"}, {"title": "Learning analytics in outer space: a Hidden Na\u00efve Bayes model for automatic student off-task behavior detection", "pages": "176-183", "doi": "10.1145/2723576.2723602", "abstract": "Learning analytics (LA) has invested much effort in the investigation of students' behavior and performance within learning systems. This paper expands the influence of LA to students' behavior outside of learning systems and describes a novel machine learning model which automatically detects students' off-task behavior as students interact with a learning system, ASSISTments, based solely on log file data. We first operationalize social cognitive theory to introduce two new variables, affect states and problem set, both of which can be automatically derived from the logs, and can be considered to have a major influence on students' behavior. These two variables further work as the feature vector data for a K-means clustering algorithm in order to quantify students' different behavioral characteristics. This quantified variable representing student behavior type expands the feature space and contributes to the improvement of the various model performance compared with only time- and performance-related features. In addition, an advanced Hidden Na\u00efve Bayes (HNB) algorithm is coded for off-task behavior detection and to show the best performance compared with traditional modeling techniques. Implications of the study are then discussed.", "authors": ["Wanli Xing", "Sean Goggins"], "session": "SESSION: Off-task behaviour / Bayesian knowledge tracing"}, {"title": "Penetrating the black box of time-on-task estimation", "pages": "184-193", "doi": "10.1145/2723576.2723623", "abstract": "All forms of learning take time. There is a large body of research suggesting that the amount of time spent on learning can improve the quality of learning, as represented by academic performance. The wide-spread adoption of learning technologies such as learning management systems (LMSs), has resulted in large amounts of data about student learning being readily accessible to educational researchers. One common use of this data is to measure time that students have spent on different learning tasks (i.e., time-on-task). Given that LMS systems typically only capture times when students executed various actions, time-on-task measures are estimated based on the recorded trace data. LMS trace data has been extensively used in many studies in the field of learning analytics, yet the problem of time-on-task estimation is rarely described in detail and the consequences that it entails are not fully examined. This paper presents the results of a study that examined the effects of different time-on-task estimation methods on the results of commonly adopted analytical models. The primary goal of this paper is to raise awareness of the issue of accuracy and appropriateness surrounding time-estimation within the broader learning analytics community, and to initiate a debate about the challenges of this process. Furthermore, the paper provides an overview of time-on-task estimation methods in educational and related research fields.", "authors": ["Vitomir Kovanovi\u0107", "Dragan Ga\u0161evi\u0107", "Shane Dawson", "Sre\u0107ko Joksimovi\u0107", "Ryan S. Baker", "Marek Hatala"], "session": "SESSION: Off-task behaviour / Bayesian knowledge tracing"}, {"title": "You've got style: detecting writing flexibility across time", "pages": "194-202", "doi": "10.1145/2723576.2723592", "abstract": "Writing researchers have suggested that students who are perceived as strong writers (i.e., those who generate texts that are rated as high quality) demonstrate flexibility in their writing style. While anecdotally this has been a commonly held belief among researchers, scientists, and educators, there is little empirical research to support this claim. This study investigates this hypothesis by examining how students vary in their use of linguistic features across 16 prompt-based essays. Forty-five high school students wrote 16 essays across 8 sessions within an Automated Writing Evaluation (AWE) system. Natural language processing (NLP) techniques and Entropy analyses were used to calculate how rigid or flexible students were in their use of narrative linguistic features over time and how this trait related to individual differences in literacy ability and essay quality. Additional analyses indicated that NLP and Entropy reliably detected narrative flexibility (or rigidity) after session 2 and was related to students' prior literacy skills. These exploratory methodologies are important for researchers and educators, as they indicate that writing flexibility is indeed a trait of strong writers and can be detected rather quickly using the combination of textual features and dynamic analyses.", "authors": ["Erica L. Snow", "Laura K. Allen", "Matthew E. Jacovina", "Cecile A. Perret", "Danielle S. McNamara"], "session": "SESSION: Writing and discourse analysis"}, {"title": "Pssst... textual features... there is more to automatic essay scoring than just you!", "pages": "203-207", "doi": "10.1145/2723576.2723595", "abstract": "This study investigates a new approach to automatically assessing essay quality that combines traditional approaches based on assessing textual features with new approaches that measure student attributes such as demographic information, standardized test scores, and survey results. The results demonstrate that combining both text features and student attributes leads to essay scoring models that are on par with state-of-the-art scoring models. Such findings expand our knowledge of textual and non-textual features that are predictive of writing success.", "authors": ["Scott Crossley", "Laura K. Allen", "Erica L. Snow", "Danielle S. McNamara"], "session": "SESSION: Writing and discourse analysis"}, {"title": "OpenEssayist: a supply and demand learning analytics tool for drafting academic essays", "pages": "208-212", "doi": "10.1145/2723576.2723599", "abstract": "This paper focuses on the use of a natural language analytics engine to provide feedback to students when preparing an essay for summative assessment. OpenEssayist is a real-time learning analytics tool, which operates through the combination of a linguistic analysis engine that processes the text in the essay, and a web application that uses the output of the linguistic analysis engine to generate the feedback. We outline the system itself and present analysis of observed patterns of activity as a cohort of students engaged with the system for their module assignments. We report a significant positive correlation between the number of drafts submitted to the system and the grades awarded for the first assignment. We can also report that this cohort of students gained significantly higher overall grades than the students in the previous cohort, who had no access to OpenEssayist. As a system that is content free, OpenEssayist can be used to support students working in any domain that requires the writing of essays.", "authors": ["Denise Whitelock", "Alison Twiner", "John T. E. Richardson", "Debora Field", "Stephen Pulman"], "session": "SESSION: Writing and discourse analysis"}, {"title": "DOP8: merging both data and analysis operators life cycles for technology enhanced learning", "pages": "213-217", "doi": "10.1145/2723576.2723580", "abstract": "This paper presents DOP8: a Data Mining Iterative Cycle that improves the classical data life cycle. While the latter only combines the data production and data analysis phases, DOP8 also integrates the analysis operators life cycle. In this cycle, data life cycle and operators life cycle processing meet in the data analysis step. This paper also presents a reification of DOP8 in a new computing platform: UnderTracks. The latter provides a flexibility on storing and sharing data, operators and analysis processes. Undertracks is compared with three types of platform 'Storage platform', 'Analysis platform' and 'Storage and Analysis platform'. Several real TEL analysis scenarios are present into the platform, (1) to test Undertracks flexibility on storing data and operators and (2) to test Undertracks flexibility on designing analysis processes.", "authors": ["Nadine Mandran", "Michael Ortega", "Vanda Luengo", "Denis Bouhineau"], "session": "SESSION: Learning analytics tools and frameworks"}, {"title": "A handwriting recognition system for the classroom", "pages": "218-222", "doi": "10.1145/2723576.2723601", "abstract": "The Xerox Ignite\u2122 Educator Support System (henceforth referred to simply as Ignite\u2122) is a data collection, analysis, and visualization workflow and software solution to assist K-12 educators. To illustrate, suppose a third-grade teacher wants to know how well her class has grasped a lesson on fractions. She would first scan her students' homework and/or exams into the Ignite system via a range of multifunctional input devices. Xerox Ignite\u2122 reads, interprets, and analyzes the students' work in minutes. Then the teacher can select how to view the data by choosing from numerous reports. Examples are; an \"at a glance\" class summary that shows who needs extra help in what areas and who is ready to move on; a \"context\" report showing how each skill for each student is progressing over time; a grade-level performance report that helps third-grade teachers share best practices and cluster students into learning groups; and a student feedback report that tells each student what he/she needs to improve upon. Ignite\u2122 intent is also to make it easier for districts to administer, score and evaluate content based on academic goals set for schools and students. The scanning and 'mark lifting' technology embedded into Ignite\u2122 reduces the time needed to correct papers and frees time for the teacher to apply detailed insights to their day-to-day instruction tasks. Critical to this function is the automated reading of student marks, including handwriting, to enable the digitization of student performance at a detailed level. In this paper we present a system level description of the Ignite\u2122 handwriting recognition module and describe the challenges and opportunities presented in an educational environment.", "authors": ["Eric Gross", "Safwan Wshah", "Isaiah Simmons", "Gary Skinner"], "session": "SESSION: Learning analytics tools and frameworks"}, {"title": "Critical realism and learning analytics research: epistemological implications of an ontological foundation", "pages": "223-230", "doi": "10.1145/2723576.2723631", "abstract": "Learning analytics is a broad church that incorporates a range of topics and methodologies. As the field has developed some tension has emerged regarding a perceived contradiction between the implied constructivist ethos of the field and prevalent empirical practices that have been characterised as 'behaviourist' and 'positivist'. This paper argues that this tension is a sign of deeper metatheoretical faultlines that have plagued the social sciences more broadly. Critical realism is advanced as a philosophy of science that can help reconcile the apparent contradictions between the constructivist aims and the empirical practices of learning analytics and simultaneously can justify learning analytics' current methodological tolerance. The paper concludes that learning analytics, arrayed in realist terms, is essentially longitudinal and multimethodological, concerned with the socio-technical systems of learning and the problems of implementation, and has the potential to be emancipatory. Some methodological implications for learning analytics practice are discussed.", "authors": ["Tim Rogers"], "session": "SESSION: Theoretical foundations for learning analytics"}, {"title": "Topic facet modeling: semantic visual analytics for online discussion forums", "pages": "231-235", "doi": "10.1145/2723576.2723613", "abstract": "In this paper, we propose a novel Topic Facet Model (TFM), a probabilistic topic model that assumes all words in single sentence are generated from one topic facet. The model is applied to automatically extract forum posts semantics for uncovering the content latent structures. We further prototype a visual analytics interface to present online discussion forum semantics. We hypothesize that the semantic modeling through analytics on open online discussion forums can help users examine the post content by viewing the summarized topic facets. Our preliminary results demonstrated that TFM can be a promising method to extract topic specificity from conversational and relatively short texts in online programming discussion forums.", "authors": ["I-Han Hsiao", "Piyush Awasthi"], "session": "SESSION: Text and discourse analysis"}, {"title": "Effects of sequences of socially regulated learning on group performance", "pages": "236-240", "doi": "10.1145/2723576.2723586", "abstract": "Past research shows that regulative activities (metacognitive or relational) can aid learning and that sequences of cognitive, metacognitive and relational activities affect subsequent cognition. Extending this research, this study examines whether sequences of socially regulated learning differ across low, medium or high performing groups. Scaffolded by a computer avatar, 54 primary school students (working in 18 groups of 3) discussed writing a report about a foreign country for 51,338 turns. Statistical discourse analysis (SDA) of these sequences of talk showed that in high performing groups, high cognition was preceded more often by high cognition and less often by denials or low cognition. In medium performing groups, high cognition was preceded more often by high cognition or planning. As these results indicate that different sequences among students' cognitive, metacognitive and relational activities are linked to levels of performance, they can inform a micro-temporal theory of socially shared regulation.", "authors": ["Inge Molenaar", "Ming Ming Chiu"], "session": "SESSION: Text and discourse analysis"}, {"title": "Developing a multiple-document-processing performance assessment for epistemic literacy", "pages": "241-245", "doi": "10.1145/2723576.2723577", "abstract": "The LAK15 theme \"shifts the focus from data to impact\", noting the potential for Learning Analytics based on existing technologies to have scalable impact on learning for people of all ages. For such demand and potential in scalability to be met the challenges of addressing higher-order thinking skills should be addressed. This paper discuses one such approach--the creation of an analytic and task model to probe epistemic cognition in complex literacy tasks. The research uses existing technologies in novel ways to build a conceptually grounded model of trace-indicators for epistemic-commitments in information seeking behaviors. We argue that such an evidence centered approach is fundamental to realizing the potential of analytics, which should maintain a strong association with learning theory.", "authors": ["Simon Knight", "Karen Littleton"], "session": "SESSION: Text and discourse analysis"}, {"title": "Are you reading my mind?: modeling students' reading comprehension skills with natural language processing techniques", "pages": "246-254", "doi": "10.1145/2723576.2723617", "abstract": "This study builds upon previous work aimed at developing a student model of reading comprehension ability within the intelligent tutoring system, iSTART. Currently, the system evaluates students' self-explanation performance using a local, sentence-level algorithm and does not adapt content based on reading ability. The current study leverages natural language processing tools to build models of students' comprehension ability from the linguistic properties of their self-explanations. Students (n = 126) interacted with iSTART across eight training sessions where they self-explained target sentences from complex science texts. Coh-Metrix was then used to calculate the linguistic properties of their aggregated self-explanations. The results of this study indicated that the linguistic indices were predictive of students' reading comprehension ability, over and above the current system algorithms. These results suggest that natural language processing techniques can inform stealth assessments and ultimately improve student models within intelligent tutoring systems.", "authors": ["Laura K. Allen", "Erica L. Snow", "Danielle S. McNamara"], "session": "SESSION: Text and discourse analysis"}, {"title": "Identifying learning strategies associated with active use of video annotation software", "pages": "255-259", "doi": "10.1145/2723576.2723611", "abstract": "The higher education sector has seen a shift in teaching approaches over the past decade with an increase in the use of video for delivering lecture content as part of a flipped classroom or blended learning model. Advances in video technologies have provided opportunities for students to now annotate videos as a strategy to support their achievement of the intended learning outcomes. However, there are few studies exploring the relationship between video annotations, student approaches to learning, and academic performance. This study seeks to narrow this gap by investigating the impact of students' use of video annotation software coupled with their approaches to learning and academic performance in the context of a flipped learning environment. Preliminary findings reveal a significant positive relationship between annotating videos and exam results. However, negative effects of surface approaches to learning, cognitive strategy use and test anxiety on midterm grades were also noted. This indicates a need to better promote and scaffold higher order cognitive strategies and deeper learning with the use of video annotation software.", "authors": ["Abelardo Pardo", "Negin Mirriahi", "Shane Dawson", "Yu Zhao", "An Zhao", "Dragan Ga\u0161evi\u0107"], "session": "SESSION: Learning strategies and tools"}, {"title": "Planning for success: how students use a grade prediction tool to win their classes", "pages": "260-264", "doi": "10.1145/2723576.2723632", "abstract": "Gameful course designs require a significant shift in approach for both students and instructors. Transforming a standard course into a good game involves fundamentally altering how the course functions, most notably by giving students greater control over their work. We have developed an application, GradeCraft, to support this shift in pedagogy. A key feature of the application is the Grade Predictor, where students can explore coursework options and plan pathways to success. We observed students in two gameful courses with differing designs using the Grade Predictor in similar ways: they spent similar amounts of time per session, increased usage when assignments were due and before making significant course decisions, predicted different types of assignments at different rates, and made more predictions in preparation for the end of semester. This study describes how students plan their coursework using the GradeCraft Grade Predictor tool.", "authors": ["Caitlin Holman", "Stephen J. Aguilar", "Adam Levick", "Jeff Stern", "Benjamin Plummer", "Barry Fishman"], "session": "SESSION: Learning strategies and tools"}, {"title": "A process mining approach to linking the study of aptitude and event facets of self-regulated learning", "pages": "265-269", "doi": "10.1145/2723576.2723628", "abstract": "Research on self-regulated learning has taken main two paths: self-regulated learning as aptitudes and more recently, self-regulated learning as events. This paper proposes the use of the Fuzzy miner process mining technique to examine the relationship between students' self-reported aptitudes (i.e., achievement goal orientation and approaches to learning) and strategies followed in self-regulated learning. A pilot study is conducted to probe the method and the preliminary results are reported.", "authors": ["Sanam Shirazi Beheshitha", "Dragan Ga\u0161evi\u0107", "Marek Hatala"], "session": "SESSION: Learning strategies and tools"}, {"title": "Towards data-driven mastery learning", "pages": "270-274", "doi": "10.1145/2723576.2723622", "abstract": "We have developed a novel data-driven mastery learning system to improve learning in complex procedural problem solving domains. This new system was integrated into an existing logic proof tool, and assigned as homework in a deductive logic course. Student performance and dropout were compared across three systems: The Deep Thought logic tutor, Deep Thought with integrated hints, and Deep Thought with our data-driven mastery learning system. Results show that the data-driven mastery learning system increases mastery of target tutor-actions, improves tutor scores, and lowers the rate of tutor dropout over Deep Thought, with or without provided hints.", "authors": ["Behrooz Mostafavi", "Michael Eagle", "Tiffany Barnes"], "session": "SESSION: Alternative methods of improving learning"}, {"title": "Analysing reflective text for learning analytics: an approach using anomaly recontextualisation", "pages": "275-279", "doi": "10.1145/2723576.2723635", "abstract": "Reflective writing is an important learning task to help foster reflective practice, but even when assessed it is rarely analysed or critically reviewed due to its subjective and affective nature. We propose a process for capturing subjective and affective analytics based on the identification and recontextualisation of anomalous features within reflective text. We evaluate 2 human supervised trials of the process, and so demonstrate the potential for an automated Anomaly Recontextualisation process for Learning Analytics.", "authors": ["Andrew Gibson", "Kirsty Kitto"], "session": "SESSION: Alternative methods of improving learning"}, {"title": "Classifying student dialogue acts with multimodal learning analytics", "pages": "280-289", "doi": "10.1145/2723576.2723588", "abstract": "Supporting learning with rich natural language dialogue has been the focus of increasing attention in recent years. Many adaptive learning environments model students' natural language input, and there is growing recognition that these systems can be improved by leveraging multimodal cues to understand learners better. This paper investigates multimodal features related to posture and gesture for the task of classifying students' dialogue acts within tutorial dialogue. In order to accelerate the modeling process by eliminating the manual annotation bottleneck, a fully unsupervised machine learning approach is utilized for this task. The results indicate that these unsupervised models are significantly improved with the addition of automatically extracted posture and gesture information. Further, even in the absence of any linguistic features, a model that utilizes posture and gesture features alone performed significantly better than a majority class baseline. This work represents a step toward achieving better understanding of student utterances by incorporating multimodal features within adaptive learning environments. Additionally, the technique presented here is scalable to very large student datasets.", "authors": ["Aysu Ezen-Can", "Joseph F. Grafsgaard", "James C. Lester", "Kristy Elizabeth Boyer"], "session": "SESSION: Alternative methods of improving learning"}, {"title": "Automated detection of proactive remediation by teachers in reasoning mind classrooms", "pages": "290-294", "doi": "10.1145/2723576.2723607", "abstract": "Among the most important tasks of the teacher in a classroom using the Reasoning Mind blended learning system is proactive remediation: dynamically planned interventions conducted by the teacher with one or more students. While there are several examples of detectors of student behavior within an online learning environment, most have focused on behaviors occurring fully within the context of the system, and on student behaviors. In contrast, proactive remediation is a teacher-driven activity that occurs outside of the system, and its occurrence is not necessarily related to the student's current task within the Reasoning Mind system. We present a sensor-free detector of proactive remediation, which is able to distinguish these activities from other behaviors involving idle time, such as on-task conversation related to immediate learning activities and off-task behavior.", "authors": ["William L. Miller", "Ryan S. Baker", "Matthew J. Labrum", "Karen Petsche", "Yu-Han Liu", "Angela Z. Wagner"], "session": "SESSION: Interventions and remediations"}, {"title": "Reducing selection bias in quasi-experimental educational studies", "pages": "295-299", "doi": "10.1145/2723576.2723614", "abstract": "In this paper we examine the issue of selection bias in quasi-experimental (non-randomly controlled) educational studies. We provide background about common sources of selection bias and the issues involved in evaluating the outcomes of quasi-experimental studies. We describe two methods, matched sampling and propensity score matching, that can be used to overcome this bias. Using these methods, we describe their application through one case study that leverages large educational datasets drawn from higher education institutional data warehouses. The contribution of this work is the recommendation of a methodology and case study that educational researchers can use to understand, measure, and reduce selection bias in real-world educational interventions.", "authors": ["Christopher Brooks", "Omar Chavez", "Jared Tritz", "Stephanie Teasley"], "session": "SESSION: Interventions and remediations"}, {"title": "Discovering clues to avoid middle school failure at early stages", "pages": "300-304", "doi": "10.1145/2723576.2723597", "abstract": "The use of data mining techniques in educational domains helps to find new knowledge about how students learn and how to improve the resources management. Using these techniques for predicting school failure is very useful in order to carry out actions to avoid drop out. With this purpose, we try to determine the earliest stage when the quality of the results allows for clarifying the possibility of school failure. We process real information from a Spanish high school by structuring the whole data in incremental datasets, which represent how students' academic records grow. Our study reveals an early and robust detection of the risky cases of school failure at the end of the first out of four courses.", "authors": ["Manuel \u00c1ngel Jim\u00e9nez-G\u00f3mez", "Jos\u00e9 Mar\u00eda Luna", "Crist\u00f3bal Romero", "Sebasti\u00e1n Ventura"], "session": "SESSION: Interventions and remediations"}, {"title": "Combining observational and experiential data to inform the redesign of learning activities", "pages": "305-309", "doi": "10.1145/2723576.2723625", "abstract": "A main goal for learning analytics is to inform the design of a learning experience to improve its quality. The increasing presence of solutions based on big data has even questioned the validity of current scientific methods. Is this going to happen in the area of learning analytics? In this paper we postulate that if changes are driven solely by a digital footprint, there is a risk of focusing only on factors that are directly connected to numeric methods. However, if the changes are complemented with an understanding about how students approach their learning, the quality of the evidence used in the redesign is significantly increased. This reasoning is illustrated with a case study in which an initial set of activities for a first year engineering course were shaped based only on the student's digital footprint. These activities were significantly modified after collecting qualitative data about the students approach to learning. We conclude the paper arguing that the interpretation of the meaning of learning analytics is improved when combined with qualitative data which reveals how and why students engaged with the learning tasks in qualitatively different ways, which together provide a more informed basis for designing learning activities.", "authors": ["Abelardo Pardo", "Robert A. Ellis", "Rafael A. Calvo"], "session": "SESSION: Analyses with LMS data"}, {"title": "Formative and summative analyses of disciplinary engagement and learning in a big open online course", "pages": "310-314", "doi": "10.1145/2723576.2723634", "abstract": "Situative theories of knowing and participatory approaches to learning and assessment were used to offer a big open online course on Educational Assessment using Google CourseBuilder in 2013. The course was started by 160 students and completed by 60, with relatively extensive instructor interaction with individual learners. This yielded much higher levels of engagement and learning than are typical of open or conventional online courses. The course was further refined and offered a second time in 2014, where it was started by 76 students and completed by 22, with a much lower level of support. Comparable levels of engagement and learning were obtained, suggesting that this participatory approach to learning and assessment can indeed be managed with more typical instructor support. Nonetheless, additional automation and streamlining is called for if the model is to eventually be used in massive online courses with thousands of students or as an autonomous self-paced open course.", "authors": ["Daniel T. Hickey", "Joshua D. Quick", "Xinyi Shen"], "session": "SESSION: Analyses with LMS data"}, {"title": "\"Scaling up\" learning design: impact of learning design activities on LMS behavior and performance", "pages": "315-319", "doi": "10.1145/2723576.2723600", "abstract": "While substantial progress has been made in terms of predictive modeling in the Learning Analytics Knowledge (LAK) community, one element that is often ignored is the role of learning design. Learning design establishes the objectives and pedagogical plans which can be evaluated against the outcomes captured through learning analytics. However, no empirical study is available linking learning designs of a substantial number of courses with usage of Learning Management Systems (LMS) and learning performance. Using cluster- and correlation analyses, in this study we compared how 87 modules were designed, and how this impacted (static and dynamic) LMS behavior and learning performance. Our findings indicate that academics seem to design modules with an \"invisible\" blueprint in their mind. Our cluster analyses yielded four distinctive learning design patterns: constructivist, assessment-driven, balanced-variety and social constructivist modules. More importantly, learning design activities strongly influenced how students were engaging online. Finally, learning design activities seem to have an impact on learning performance, in particular when modules rely on assimilative activities. Our findings indicate that learning analytics researchers need to be aware of the impact of learning design on LMS data over time, and subsequent academic performance.", "authors": ["Bart Rienties", "Lisette Toetenel", "Annie Bryan"], "session": "SESSION: Analyses with LMS data"}, {"title": "An analysis of the impact of action order on future performance: the fine-grain action model", "pages": "320-324", "doi": "10.1145/2723576.2723616", "abstract": "To better model students' learning, user modelling should be able to use the detailed sequence of student actions to model student knowledge, not just their right/wrong scores. Our goal is to analyze the question: \"Does it matter when a hint is used?\". We look at students who use identical attempt counts to get the right answer and look for the impact of help use and action order on future performance. We conclude that students who use hints too early do worse than students who use hints later. However, students who use hints, at times, may perform as well as students who do not use hints. This paper makes a novel contribution showing for the first time that paying attention to the precise sequence of hints and attempts allows better prediction of students' performance, as well as to definitively show that, when we control for the number of attempts and hints, students that attempt problems before asking for hints show higher performance on the next question. This analysis shows that the pattern of hints and attempts, not just their numbers, is important.", "authors": ["Eric Van Inwegen", "Seth Adjei", "Yan Wang", "Neil Heffernan"], "session": "SESSION: Tutoring systems"}, {"title": "Improving students' long-term retention performance: a study on personalized retention schedules", "pages": "325-329", "doi": "10.1145/2723576.2723636", "abstract": "Traditional practices of spacing and expanding retrieval practices have typically fixed their spacing intervals to one or few predefined schedules [5, 7]. Few have explored the advantages of using personalized expanding intervals and scheduling systems to adapt to the knowledge levels and learning patterns of individual students. In this work, we are concerned with estimating the effects of personalized expanding intervals on improving students' long-term mastery level of skills. We developed a Personalized Adaptive Scheduling System (PASS) in ASSISTments' retention and relearning workflow. After implementing the PASS, we conducted a study to investigate the impact of personalized scheduling on long-term retention by comparing results from 97 classes in the summer of 2013 and 2014. We observed that students in PASS outperformed students in traditional scheduling systems on long-term retention performance (p = 0.0002), and that in particular, students with medium level of knowledge demonstrated reliable improvement (p = 0.0209) with an effect size of 0.27. In addition, the data we gathered from this study also helped to expose a few issues we have with the new system. These results suggest personalized knowledge retrieval schedules are more effective than fixed schedules and we should continue our future work on examining approaches to optimize PASS.", "authors": ["Xiaolu Xiong", "Yan Wang", "Joseph Barbosa Beck"], "session": "SESSION: Tutoring systems"}, {"title": "Curriculum analysis of CS departments based on CS2013 by simplified, supervised LDA", "pages": "330-339", "doi": "10.1145/2723576.2723594", "abstract": "The curricula higher educational institutions offer is a key asset in enabling them to systematically educate their students. We have been developing a curriculum analysis method that can help to find out differences among curricula. On the basis of \"Computing Science Curricula CS2013\", a report released by the ACM and IEEE Computer Society, we applied our method to analyzing 10 computer science (CS) related curricula offered by CS departments of universities in the United States. Using the method enables us to compare courses across universities. Through an analysis of course syllabi distribution, we found that CS2013 uniformly covered a wide area of computer science. Some universities emphasized human factors, while others attached greater importance to theoretical ones. We also found that some CS departments offered not only a CS curriculum but also an electrical engineering one, and those departments showed a tendency to have more \"Architecture and Organization (AR)\" related curricula. Furthermore, we found that even though \"Information Assurance and Security (IAS)\" has not yet become a very popular field, some universities are already offering IAS related courses.", "authors": ["Takayuki Sekiya", "Yoshitatsu Matsuda", "Kazunori Yamaguchi"], "session": "SESSION: Curricula, network and discourse analysis"}, {"title": "\"Twitter Archeology\" of learning analytics and knowledge conferences", "pages": "340-349", "doi": "10.1145/2723576.2723584", "abstract": "The goal of the present study was to uncover new insights about the learning analytics community by analyzing Twitter archives from the past four Learning Analytics and Knowledge (LAK) conferences. Through descriptive analysis, interaction network analysis, hashtag analysis, and topic modeling, we found: extended coverage of the community over the years; increasing interactions among its members regardless of peripheral and in-persistent participation; increasingly dense, connected and balanced social networks; and more and more diverse research topics. Detailed inspection of semantic topics uncovered insights complementary to the analysis of LAK publications in previous research.", "authors": ["Bodong Chen", "Xin Chen", "Wanli Xing"], "session": "SESSION: Curricula, network and discourse analysis"}, {"title": "Discourse cohesion: a signature of collaboration", "pages": "350-354", "doi": "10.1145/2723576.2723578", "abstract": "As Computer Supported Collaborative Learning (CSCL) becomes increasingly adopted as an alternative to classic educational scenarios, we face an increasing need for automatic tools designed to support tutors in the time consuming process of analyzing conversations and interactions among students. Therefore, building upon a cohesion-based model of the discourse, we have validated ReaderBench, a system capable of evaluating collaboration based on a social knowledge-building perspective. Through the inter-twining of different participants' points of view, collaboration emerges and this process is reflected in the identified cohesive links between different speakers. Overall, the current experiments indicate that textual cohesion successfully detects collaboration between participants as ideas are shared and exchanged within an ongoing conversation.", "authors": ["Mihai Dascalu", "Stefan Trausan-Matu", "Philippe Dessus", "Danielle S. McNamara"], "session": "SESSION: Curricula, network and discourse analysis"}, {"title": "Correlations between automated rhetorical analysis and tutors' grades on student essays", "pages": "355-359", "doi": "10.1145/2723576.2723603", "abstract": "When assessing student essays, educators look for the students' ability to present and pursue well-reasoned and strong arguments. Such scholarly argumentation is often articulated by rhetorical metadiscourse. Educators will be necessarily examining metadiscourse in students' writing as signals of the intellectual moves that make their reasoning visible. Therefore students and educators could benefit from available powerful automated textual analysis that is able to detect rhetorical metadiscourse. However, there is a need to validate such technologies in higher education contexts, since they were originally developed in non-educational applications. This paper describes an evaluation study of a particular language analysis tool, the Xerox Incremental Parser (XIP), on undergraduate social science student essays, using the mark awarded as a measure of the quality of the writing. As part of this exploration, the study presented in this paper seeks to assess the quality of the XIP through correlational studies and multiple regression analysis.", "authors": ["Duygu Simsek", "\u00c1gnes S\u00e1ndor", "Simon Buckingham Shum", "Rebecca Ferguson", "Anna De Liddo", "Denise Whitelock"], "session": "SESSION: Curricula, network and discourse analysis"}, {"title": "Leveraging multimodal learning analytics to differentiate student learning strategies", "pages": "360-367", "doi": "10.1145/2723576.2723624", "abstract": "Multimodal analysis has had demonstrated effectiveness in studying and modeling several human-human and human-computer interactions. In this paper, we explore the role of multimodal analysis in the service of studying complex learning environments. We compare uni-modal and multimodal; manual and semi-automated methods for examining how students learn in a hands-on, engineering design context. Specifically, we compare human annotations, speech, gesture and electro-dermal activation data from a study (N=20) where student participating in two different experimental conditions. The experimental conditions have already been shown to be associated with differences in learning gains and design quality. Hence, one objective of this paper is to identify the behavioral practices that differed between the two experimental conditions, as this may help us better understand how the learning interventions work. An additional objective is to provide examples of how to conduct learning analytics research in complex environments and compare how the same algorithm, when used with different forms of data can provide complementary results.", "authors": ["Marcelo Worsley", "Paulo Blikstein"], "session": "SESSION: Multilevel, multimodal and network analysis"}, {"title": "From contingencies to network-level phenomena: multilevel analysis of activity and actors in heterogeneous networked learning environments", "pages": "368-377", "doi": "10.1145/2723576.2723626", "abstract": "Learning in social settings is a complex phenomenon that involves multiple processes at individual and collective levels of agency. Thus, a richer understanding of learning in socio-technical networks will be furthered by analytic methods that can move between and coordinate analyses of individual, small group and network level phenomena. This paper outlines Traces, an analytic framework designed to address these and other needs, and gives examples of the framework's practical utility using data from the Tapped In educator professional network. The Traces framework identifies observable contingencies between events and uses these to build more abstract models of interaction and ties represented as graphs. Applications are illustrated to identification of sessions and key participants in the sessions, relations between sessions as mediated by participants, and longer-term participant roles.", "authors": ["Dan Suthers"], "session": "SESSION: Multilevel, multimodal and network analysis"}, {"title": "Ubiquitous learning analytics in the context of real-world language learning", "pages": "378-382", "doi": "10.1145/2723576.2723598", "abstract": "This paper describes a method of the visualization and analysis for mining useful learning logs from numerous learning experiences that learners have accumulated in the real world as the ubiquitous learning logs. Ubiquitous Learning Log (ULL) is defined as a digital record of what learners have learned in the daily life using ubiquitous technologies. It allows learners to log their learning experiences with photos, audios, videos, location, RFID tag and sensor data, and to share and reuse ULL with others. By constructing real-world corpora which comprise of accumulated ULLs with information such as what, when, where, and how learners have learned in the real world and by analyzing them, we can support learners to learn more effectively. The proposed system will predict their future learning opportunities including their learning patterns and trends by analyzing their past ULLs. The prediction is made possible both by network analysis based on ULL information such as learners, knowledge, place and time and by learners' self-analysis using time-map. By predicting what they tend to learn next in their learning paths, it provides them with more learning opportunities. Accumulated data are so big and the relationships among the data are so complicated that it is difficult to grasp how closely the ULLs are related each other. Therefore, this paper proposes a system to help learners to grasp relationships among learners, knowledge, place and time, using network graphs and network analysis.", "authors": ["Kousuke Mouri", "Hiroaki Ogata", "Noriko Uosaki"], "session": "SESSION: Multilevel, multimodal and network analysis"}, {"title": "An exploratory study using social network analysis to model eye movements in mathematics problem solving", "pages": "383-387", "doi": "10.1145/2723576.2723591", "abstract": "Eye tracking is a useful tool to understand students' cognitive process during problem solving. This paper offers a unique perspective by applying techniques from social network analysis to eye movement patterns in mathematics problem solving. We construct and visualize transition networks using eye-tracking data collected from 37 8th grade students while solving linear function problems. By applying network analysis on the constructed transition networks, we find general transition patterns between areas of interest (AOIs) for all students, and we also compare patterns for high- and low-performing students. Our results show that even though students share general transition patterns during problem solving, high-performing students made more strategic transitions among AOI triples than low-performing students.", "authors": ["Mengxiao Zhu", "Gary Feng"], "session": "SESSION: Multilevel, multimodal and network analysis"}, {"title": "It's about time: 4th international workshop on temporal analyses of learning data", "pages": "388-389", "doi": "10.1145/2723576.2723638", "abstract": "Interest in analyses that probe the temporal aspects of learning continues to grow. The study of common and consequential sequences of events (such as learners accessing resources, interacting with other learners and engaging in self-regulatory activities) and how these are associated with learning outcomes, as well as the ways in which knowledge and skills grow or evolve over time are both core areas of interest. Learning analytics datasets are replete with fine-grained temporal data: click streams; chat logs; document edit histories (e.g. wikis, etherpads); motion tracking (e.g. eye-tracking, Microsoft Kinect), and so on. However, the emerging area of temporal analysis presents both technical and theoretical challenges in appropriating suitable techniques and interpreting results in the context of learning. The learning analytics community offers a productive focal ground for exploring and furthering efforts to address these challenges. This workshop, the fourth in a series on temporal analysis of learning, provides a focal point for analytics researchers to consider issues around and approaches to temporality in learning analytics.", "authors": ["Simon Knight", "Alyssa F. Wise", "Bodong Chen", "Britte Haugan Cheng"], "session": "WORKSHOP SESSION: Workshop"}, {"title": "Ethical and privacy issues in the application of learning analytics", "pages": "390-391", "doi": "10.1145/2723576.2723642", "abstract": "The large-scale production, collection, aggregation, and processing of information from various learning platforms and online environments have led to ethical and privacy concerns regarding potential harm to individuals and society. In the past, these types of concern have impacted on areas as diverse as computer science, legal studies and surveillance studies. Within a European consortium that brings together the EU project LACE, the SURF SIG Learning Analytics, the Apereo Foundation and the EATEL SIG dataTEL, we aim to understand the issues with greater clarity, and to find ways of overcoming the issues and research challenges related to ethical and privacy aspects of learning analytics practice. This interactive workshop aims to raise awareness of major ethics and privacy issues. It will also be used to develop practical solutions to advance the application of learning analytics technologies.", "authors": ["Hendrik Drachsler", "Tore Hoel", "Maren Scheffel", "G\u00e1bor Kismih\u00f3k", "Alan Berg", "Rebecca Ferguson", "Weiqin Chen", "Adam Cooper", "Jocelyn Manderveld"], "session": "WORKSHOP SESSION: Workshop"}, {"title": "2nd int'l workshop on open badges in education (OBIE 2015): from learning evidence to learning analytics", "pages": "392-393", "doi": "10.1145/2723576.2723639", "abstract": "Open digital badges are Web-enabled tokens of learning and accomplishment. Unlike traditional grades, certificates, and transcripts, badges include specific claims about learning accomplishments and detailed evidence in support of those claims. Considering the richness of data associated with Open Badges, it is reasonable to expect a very powerful predictive element at the intersection of Open Badges and Learning Analytics. This could have substantial implications for recommending and exposing students to a variety of curricular and co-curricular pathways utilizing data sources far more nuanced than grades and achievement tests. Therefore, this workshop was aimed at: i) examining the potentials of Open Badges (including the associated data and resources) to provide new and potentially unprecedented data for analysis; ii) examining the kinds of Learning Analytics methods and techniques that could be suitable for gaining valuable insights from and/or making predictions based on the evidence (data and resources) associated with badges, and iii) connecting Open Badges communities, aiming to allow for the exchange of experiences and learning from different cultures and communities.", "authors": ["Daniel Hickey", "Jelena Jovanovic", "Steve Lonn", "James E. Willis"], "session": "WORKSHOP SESSION: Workshop"}, {"title": "VISLA: visual aspects of learning analytics", "pages": "394-395", "doi": "10.1145/2723576.2723643", "abstract": "In this paper, we briefly describe the goal and activities of the LAK15 workshop on Visual Aspects of Learning analytics.", "authors": ["Erik Duval", "Katrien Verbert", "Joris Klerkx", "Martin Wolpers", "Abelardo Pardo", "Sten Govaerts", "Denis Gillet", "Xavier Ochoa", "Denis Parra"], "session": "WORKSHOP SESSION: Workshop"}, {"title": "The 3rd LAK data competition", "pages": "396-397", "doi": "10.1145/2723576.2723641", "abstract": "The LAK Data Challenge 2015 continues the research efforts of the previous data competitions in 2013 and 2014 by stimulating research on the evolving fields Learning Analytics (LA) and Educational Data Mining (EDM). Building on a series of activities of the LinkedUp project, the challenge aims to generate new insights and analysis on the LA & EDM disciplines and is supported through the LAK Dataset - a unique corpus of LA & EDM literature, exposed in structured and machine-readable formats.", "authors": ["Hendrik Drachsler", "Stefan Dietze", "Eelco Herder", "Mathieu d'Aquin", "Davide Taibi", "Maren Scheffel"], "session": "WORKSHOP SESSION: Workshop"}, {"title": "A learning analytics approach to characterize and analyze inquiry-based pedagogical processes", "pages": "398-399", "doi": "10.1145/2723576.2723658", "abstract": "Here we describe the use of learning analytics (LA) for investigating inquiry-based science instruction. We define several variables that quantify curriculum usage and leverage tools from process mining to examine inquiry-based pedagogical processes. These are initial steps toward measuring and modeling fidelity of implementation of a science curriculum. We use data from one school district's use of an online science curriculum (N=1,021 teachers and nearly 330,000 page views).", "authors": ["Carlos Monroy", "Virginia Snodgrass Rangel", "Elizabeth R. Bell", "Reid Whitaker"], "session": "POSTER SESSION: Posters"}, {"title": "Predicting post-training readiness to work with computers: the predominance of log-based variables", "pages": "400-401", "doi": "10.1145/2723576.2723656", "abstract": "In today's job market, computer skills are part of the prerequisites for many jobs. In this paper, we report on a study of readiness to work with computers (the dependent variable) among unemployed women (N=54) after participating in a unique training focused on computer skills and empowerment. Associations were explored between this variable and 17 variables from four categories: log-based, computer literacy and experience, job-seeking motivation and practice, and training satisfaction. Only two variables were associated with the dependent variable: Knowledge post-test duration and satisfaction with content. Building a prediction model of the dependent variable, another feature was highlighted: Total number of actions in the course website along the course. Our analyses highlight the predominance of the log-based variables over the variables from the other categories, and we thoroughly discuss this finding.", "authors": ["Dalit Mor", "Hagar Laks", "Arnon Hershkovitz"], "session": "POSTER SESSION: Posters"}, {"title": "Investigating the impact of a notification system on student behaviors in a discourse-intensive hybrid course: a case study", "pages": "402-403", "doi": "10.1145/2723576.2723663", "abstract": "This study investigated the effects of students' opting to use notification tools in a collaborative discourse-intensive online graduate course. Social constructivism and self-expectancy theory were applied to frame our understanding of the interactive relationship between the use of the notification tools, student's online contribution behavior and student's self-expectancy. Log-data from a 12-week hybrid (online and face-to-face) graduate course at a Canadian faculty of education was analyzed. Findings from the correlation, mediation and ANOVA analyses suggested that activation of the notification tool system positively affected students' contribution behavior and that the influence of the use of notification tools on student contribution behavior was partially mediated by student's self-expectancy.", "authors": ["Zhenhua Xu", "Alexandra Makos"], "session": "POSTER SESSION: Posters"}, {"title": "Minimum information entropy based q-matrix learning in DINA model", "pages": "404-405", "doi": "10.1145/2723576.2723653", "abstract": "Cognitive diagnosis models (CDMs) are of growing interest in test development and measurement of learners' performance. The DINA (deterministic input, noisy, and gate) model is one of the most widely used models in CDM. In this paper, we propose a new method and present an alternating recursive algorithm to learn Q-matrix and uncertainty variables, slip and guessing parameters, based on Boolean Matrix Factorization (BMF) and Minimized Information Entropy (MIE) respectively for the DINA model. Simulation results show that our algorithm for Q-matrix learning has fast convergence to the local optimal solutions for Q-matrix and students' knowledge states A matrix. This is especially important and applicable when the method is extended to big data.", "authors": ["Shiwei Ye", "Yuan Sun", "Haobo Wang", "Yi Sun"], "session": "POSTER SESSION: Posters"}, {"title": "Integrated representations and small data: towards contextualized and embedded analytics tools for learners", "pages": "406-407", "doi": "10.1145/2723576.2723665", "abstract": "We present an approach to support learners by means of visualization and contextualization of learning analytics interventions in the learning process. We follow up on conceptual work of colleagues and derive further design principles oriented towards learners as recipients of LA results. These are shown with implementations in two distinct projects to fulfill learners information in collaborative learning processes.", "authors": ["Andreas Harrer", "Tilman G\u00f6hnert"], "session": "POSTER SESSION: Posters"}, {"title": "Frequent sequential interactions as opportunities to engage in temporal reasoning with an online GIS", "pages": "408-409", "doi": "10.1145/2723576.2723644", "abstract": "Temporal reasoning (i.e., reasoning about relationships across time) is complex and difficult, particularly when engaged through complex media such as online Geographic Information System (GIS) applications. Partnering with Social Explorer (SE), a Web-based GIS application that allows users to create interactive visualizations of large sociological datasets, we engaged in frequent sequential pattern mining of a database of users' interactions with SE. The resulting frequent sequences provide initial descriptions of how SE affords opportunities to engage in temporal reasoning.", "authors": ["Raymond Kang", "Josh Radinsky", "Leilah Lyons"], "session": "POSTER SESSION: Posters"}, {"title": "The bridge report: bringing learning analytics to low-income, urban schools", "pages": "410-411", "doi": "10.1145/2723576.2723652", "abstract": "Widespread adoption of learning analytics for risk prediction faces different challenges at low-income secondary schools than at post-secondary institutions, where such methods have been more widely adopted. To leverage the benefits of learning analytics for under-resourced communities, educators must overcome the barriers to adoption faced by local schools: internet access, data integration, data interpretation, and local alignment. We present the case study of an enhanced reporting tool for parents and teachers, the Bridge Report, locally designed to meet the needs of a low-income secondary school in New York City. Parent and Teacher focus groups suggest that addressing local obstacles to learning analytics can create conditions for enthusiastic adoption by parents and teachers.", "authors": ["Aaron Hawn"], "session": "POSTER SESSION: Posters"}, {"title": "Improving undergraduate student achievement in large blended courses through data-driven interventions", "pages": "412-413", "doi": "10.1145/2723576.2723657", "abstract": "This pilot study applied Learning Analytics methods to identify students at-risk of not succeeding in two high enrollment courses with historically low pass rates at San Diego State University: PSY 101 and STAT 119. With input from instructors, targeted interventions were developed and sent to participating students (n=882) suggesting ways to improve their performance. An experimental design was used with half of the students randomly assigned to receive these interventions via email and the other half being analyzed for at-risk triggers but receiving no intervention. Pre-course surveys on student motivation [4] and prior subject matter knowledge were conducted, and students were asked to maintain weekly logs of their activity online and offline connected to the courses. Regression analyses, incorporating feature selection methods to account for student demographic data, were used to compare the impact of the interventions between the control and experimental groups. Results showed that the interventions were associated with a higher final grade in one course, but only for a particular demographic group.", "authors": ["Bernie Dodge", "John Whitmer", "James P. Frazee"], "session": "POSTER SESSION: Posters"}, {"title": "Increasing the accessibility of learning objects by automatic tagging", "pages": "414-415", "doi": "10.1145/2723576.2723660", "abstract": "Data sets coming from the educational domain often suffer from sparsity. Hence, they might comprise potentially useful learning objects that are not findable by the users. In order to address this problem, we present a new way to automatically assign tags and classifications to learning objects offered by educational web portals that is solely based on the objects' usage.", "authors": ["Katja Niemann"], "session": "POSTER SESSION: Posters"}, {"title": "Measuring student success using predictive engine", "pages": "416-417", "doi": "10.1145/2723576.2723661", "abstract": "A basic challenge in delivering global education is improving student success. Institutions of education are increasingly focused on improving graduation and retention rates of their students. In this poster, we describe Student Success System (S3) that can measure student performance starting from the first weeks of the semester and the adoption process for S3 by University of Wisconsin System (UWS).", "authors": ["Shady Shehata", "Kimberly E. Arnold"], "session": "POSTER SESSION: Posters"}, {"title": "A learning system utilizing learners' active tracing behaviors", "pages": "418-419", "doi": "10.1145/2723576.2723655", "abstract": "A monitoring system that does not disturb learners' motivation and attention is important, especially in online learning with massive numbers of participants. We propose a learning system, called the finger trail learning system (FTLS), that can monitor participants' learning attitude by means of their finger movements. On the display of the FTLS, letters are presented with low contrast in the initial state, and the contrast of the letters changes to high when they are traced by learners. We implemented the FTLS as an iOS application and confirmed that the software can be utilized to monitor learners' attitudes. In addition, we compared trails of finger movements between participants with high and low performance. The results show that the trail of finger movements recorded by the FTLS can be an index of learners' attitudes.", "authors": ["Kazushi Maruya", "Junji Watanabe", "Hiroyuki Takahashi", "Shoji Hashiba"], "session": "POSTER SESSION: Posters"}, {"title": "A case study to track teacher gestures and performance in a virtual learning environment", "pages": "420-421", "doi": "10.1145/2723576.2723650", "abstract": "As part of normal interpersonal communication, people send and receive messages with their body, especially with their hands. Gestures play an important role in teacher-student classroom interactions. In the domain of education, many research projects have focused on the study of such gestures either in real classrooms or in tutorial settings with experienced teachers. Novice teachers especially need to understand the messages they are sending through nonverbal communication as this can have a major effect on their ability to manage behaviors and deliver content. Such learning should optimally occur before experiencing the real classroom. To assist in this process, we have developed a virtual classroom environment- TeachLivE- and used it for teacher practice, reflection and assessment. This paper investigates the way teachers use gestures in the virtual classroom settings of TeachLivE. Biology and algebra teachers were evaluated in our study. Analysis of video recordings from real and virtual environment seems to indicate that algebra teachers gesture significantly more often than biology teachers. These results have implications for providing useful feedback to participant teachers.", "authors": ["Roghayeh Barmaki", "Charles E. Hughes"], "session": "POSTER SESSION: Posters"}, {"title": "Qualitatively exploring electronic portfolios: a text mining approach to measuring student emotion as an early warning indicator", "pages": "422-423", "doi": "10.1145/2723576.2723651", "abstract": "The collection and analysis of student-level data is quickly becoming the norm across school campuses. More and more institutions are starting to use this resource as a window into better understanding the needs of their student population. In previous work, we described the use of electronic portfolio data as a proxy to measuring student engagement, and showed how it can be predictive of student retention. This paper highlights our ongoing efforts to explore and measure the valence of positive and negative emotions in student reflections and how they can serve as an early warning indicator of student disengagement.", "authors": ["Frederick Nwanganga", "Everaldo Aguiar", "G. Alex Ambrose", "Victoria Goodrich", "Nitesh V. Chawla"], "session": "POSTER SESSION: Posters"}, {"title": "Media multiplexity in connectivist MOOCs", "pages": "424-425", "doi": "10.1145/2723576.2723654", "abstract": "In this poster, we present work on exploring use of multiple social media platforms for learning in two connectivist MOOCs (or cMOOCs) to develop and evaluate methods for learning analytics to detect and study collaborative learning processes.", "authors": ["Rafa Absar", "Anatoliy Gruzd", "Caroline Haythornthwaite", "Drew Paulin"], "session": "POSTER SESSION: Posters"}, {"title": "Using learning analytics to study cognitive disequilibrium in a complex learning environment", "pages": "426-427", "doi": "10.1145/2723576.2723659", "abstract": "Cognitive disequilibrium has received significant attention for its role in fostering student learning in intelligent tutoring systems and in complex learning environments. In this paper, we both add to and extend this discussion by analyzing the emergence of four affective states associated with disequilibrium: joy, surprise, neutrality and confusion; in a collaborative hands-on, engineering design task. Specifically, we conduct a comparison between two learning strategies to make salient how the strategies are associated with different affective states. This comparison is grounded in the construction of a probabilistic model of student affective state as defined by the frequency of each state, and the rate of transition between affective states. Through this comparison we confirm prior research that highlights the importance of confusion as a marker of knowledge construction, but put to question the notion that surprise is a significant mediator of cognitive disequilibrium. Overall, we show how modeling learner affect is useful for understanding and improving learning in complex, hands-on learning environments.", "authors": ["Marcelo Worsley", "Paulo Blikstein"], "session": "POSTER SESSION: Posters"}, {"title": "Analysis of learners' study logs: mouse trajectories to identify the occurrence of hesitation in solving word-reordering problems", "pages": "428-429", "doi": "10.1145/2723576.2723645", "abstract": "In this paper, we describe a Web application we have been developing in order to help both teachers and learners notice the crucial aspects of solving word-reordering problems (WRPs). Also, we discuss ways to analyze the recorded mouse trajectories, response time, and drag and drop (D&D) logs, because these records are potential indicators of the degree of learners' understanding.", "authors": ["Mitsumasa Zushi", "Yoshinori Miyazaki", "Ken Norizuki"], "session": "POSTER SESSION: Posters"}, {"title": "How do students interpret feedback delivered via dashboards?", "pages": "430-431", "doi": "10.1145/2723576.2723662", "abstract": "Providing feedback directly to students on their engagement and performance in educational activities is important to supporting students' learning. However, questions have been raised whether such data representations are adequate to inform reflection, planning and monitoring of students' learning strategies. In this poster we present an investigation of how students interpret feedback delivered via learning analytics dashboards. The findings indicated that most students were able to articulate an interpretation of the feedback presented through the dashboard to identify gaps between their expected and actual performance to inform changes to their study strategies. However, there was also evidence of uncertain interpretation both in terms of the format of the visualization of the feedback and their inability to understand the connection between the feedback and their current strategies. The findings have been used to inform recommendations for ways to enhance the effectiveness of the delivery of feedback through dashboards to provide value to students in developing effective learning strategies to meet their educational goals.", "authors": ["Linda Corrin", "Paula de Barba"], "session": "POSTER SESSION: Posters"}, {"title": "Learning analytics in Oz: what's happening now, what's planned, and where could it (and should it) go?", "pages": "432-433", "doi": "10.1145/2723576.2723649", "abstract": "This poster outlines the process and purpose of two related Australian Office for Learning and Teaching (OLT) commissioned grants to investigate the current usage and future potential of learning analytics in Australian Higher Education, with a view to developing resources to guide Australian universities in their adoption of learning analytics. The commissioned grants run from February 2014 to June 2015. Preliminary results will be available for LAK 15.", "authors": ["Tim Rogers", "Cassandra Colvin", "Deborah West", "Shane Dawson"], "session": "POSTER SESSION: Posters"}, {"title": "Text mining approach to automate teamwork assessment in group chats", "pages": "434-435", "doi": "10.1145/2723576.2723648", "abstract": "The increasing use of chat tools for learning and collaboration emphasizes the need for automating assessment. We propose a text mining approach to automate teamwork assessment in chat data. This supervised training approach can be extended to other domains for efficient assessment.", "authors": ["Antonette Shibani", "Elizabeth Koh", "Helen Hong"], "session": "POSTER SESSION: Posters"}, {"title": "ReaderBench: An Integrated Tool Supporting both Individual and Collaborative Learning", "pages": "436-437", "doi": "10.1145/2723576.2723647", "abstract": "The core of our ReaderBench software framework exposes a unified vision for predicting and assessing comprehension in both individual and collaborative learning scenarios. ReaderBench aims to improve both the quality and the classification of the analyzed documents by using an expanded range of criteria such as: morphology, semantics, discourse analysis with emphasis on polyphony and dialogism, thus providing reliable support for both tutors and students across a range of educational settings. ReaderBench uses a unitary cohesion-based representation of discourse applied into three major directions, all tightly connected by the underlying model and the Natural Language Processing (NLP) computations: reading strategies, textual complexity, and collaboration evaluation in Computer Supported Collaborative Learning (CSCL) conversations.", "authors": ["Mihai Dascalu", "Larise L. Stavarache", "Stefan Trausan-Matu", "Philippe Dessus", "Maryse Bianco", "Danielle S. McNamara"], "session": "POSTER SESSION: Posters"}]}, {"year": 2016, "papers": [{"title": "Topic modeling for evaluating students' reflective writing: a case study of pre-service teachers' journals", "pages": "1-5", "doi": "10.1145/2883851.2883951", "abstract": "Journal writing is an important and common reflective practice in education. Students' reflection journals also offer a rich source of data for formative assessment. However, the analysis of the textual reflections in class of large size presents challenges. Automatic analysis of students' reflective writing holds great promise for providing adaptive real time support for students. This paper proposes a method based on topic modeling techniques for the task of themes exploration and reflection grade prediction. We evaluated this method on a sample of journal writings from pre-service teachers. The topic modeling method was able to discover the important themes and patterns emerged in students' reflection journals. Weekly topic relevance and word count were identified as important indicators of their journal grades. Based on the patterns discovered by topic modeling, prediction models were developed to automate the assessing and grading of reflection journals. The findings indicate the potential of topic modeling in serving as an analytic tool for teachers to explore and assess students' reflective thoughts in written journals.", "authors": ["Ye Chen", "Bei Yu", "Xuewei Zhang", "Yihan Yu"], "session": "SESSION: Discourse analytics"}, {"title": "Combining click-stream data with NLP tools to better understand MOOC completion", "pages": "6-14", "doi": "10.1145/2883851.2883931", "abstract": "Completion rates for massive open online classes (MOOCs) are notoriously low. Identifying student patterns related to course completion may help to develop interventions that can improve retention and learning outcomes in MOOCs. Previous research predicting MOOC completion has focused on click-stream data, student demographics, and natural language processing (NLP) analyses. However, most of these analyses have not taken full advantage of the multiple types of data available. This study combines click-stream data and NLP approaches to examine if students' on-line activity and the language they produce in the online discussion forum is predictive of successful class completion. We study this analysis in the context of a subsample of 320 students who completed at least one graded assignment and produced at least 50 words in discussion forums, in a MOOC on educational data mining. The findings indicate that a mix of click-stream data and NLP indices can predict with substantial accuracy (78%) whether students complete the MOOC. This predictive power suggests that student interaction data and language data within a MOOC can help us both to understand student retention in MOOCs and to develop automated signals of student success.", "authors": ["Scott Crossley", "Luc Paquette", "Mihai Dascalu", "Danielle S. McNamara", "Ryan S. Baker"], "session": "SESSION: Discourse analytics"}, {"title": "Towards automated content analysis of discussion transcripts: a cognitive presence case", "pages": "15-24", "doi": "10.1145/2883851.2883950", "abstract": "In this paper, we present the results of an exploratory study that examined the problem of automating content analysis of student online discussion transcripts. We looked at the problem of coding discussion transcripts for the levels of cognitive presence, one of the three main constructs in the Community of Inquiry (CoI) model of distance education. Using Coh-Metrix and LIWC features, together with a set of custom features developed to capture discussion context, we developed a random forest classification system that achieved 70.3% classification accuracy and 0.63 Cohen's kappa, which is significantly higher than values reported in the previous studies. Besides improvement in classification accuracy, the developed system is also less sensitive to overfitting as it uses only 205 classification features, which is around 100 times less features than in similar systems based on bag-of-words features. We also provide an overview of the classification features most indicative of the different phases of cognitive presence that gives an additional insights into the nature of cognitive presence learning cycle. Overall, our results show great potential of the proposed approach, with an added benefit of providing further characterization of the cognitive presence coding scheme.", "authors": ["Vitomir Kovanovi\u0107", "Sre\u0107ko Joksimovi\u0107", "Zak Waters", "Dragan Ga\u0161evi\u0107", "Kirsty Kitto", "Marek Hatala", "George Siemens"], "session": "SESSION: Discourse analytics"}, {"title": "Towards personalizing an e-quiz bank for primary school students: an exploration with association rule mining and clustering", "pages": "25-29", "doi": "10.1145/2883851.2883959", "abstract": "Given the importance of reading proficiency and habits for young students, an online e-quiz bank, Reading Battle, was launched in 2014 to facilitate reading improvement for primary-school students. With more than ten thousand questions in both English and Chinese, the system has attracted nearly five thousand learners who have made about half a million question answering records. In an effort towards delivering personalized learning experience to the learners, this study aims to discover potentially useful knowledge from learners' reading and question answering records in the Reading Battle system, by applying association rule mining and clustering analysis. The results show that learners could be grouped into three clusters based on their self-reported reading habits. The rules mined from different learner clusters can be used to develop personalized recommendations to the learners. Implications of the results on evaluating and further improving the Reading Battle system are also discussed.", "authors": ["Xiao Hu", "Yinfei Zhang", "Samuel K. W. Chu", "Xiaobo Ke"], "session": "SESSION: Learner models"}, {"title": "Introduction of learning visualisations and metacognitive support in a persuadable open learner model", "pages": "30-39", "doi": "10.1145/2883851.2883853", "abstract": "This paper describes open learner models as visualisations of learning for learners, with a particular focus on how information about their learning can be used to help them reflect on their skills, identify gaps in their skills, and plan their future learning. We offer an approach that, in addition to providing visualisations of their learning, allows learners to propose changes to their learner model. This aims to help improve the accuracy of the learner model by taking into account student viewpoints on their learning, while also promoting learner reflection on their learning as part of a discussion of the content of their learner model. This aligns well with recent calls for learning analytics for learners. Building on previous research showing that learners will use open learner models, we here investigate their initial reactions to open learner model features to identify the likelihood of uptake in contexts where an open learner model is offered on an optional basis. We focus on university students' perceptions of a range of visualisations and their stated preferences for a facility to view evidence for the learner model data and to propose changes to the values.", "authors": ["Susan Bull", "Blandine Ginon", "Clelia Boscolo", "Matthew Johnson"], "session": "SESSION: Learner models"}, {"title": "Impact of data collection on interpretation and evaluation of student models", "pages": "40-47", "doi": "10.1145/2883851.2883868", "abstract": "Student modeling techniques are evaluated mostly using historical data. Researchers typically do not pay attention to details of the origin of the used data sets. However, the way data are collected can have important impact on evaluation and interpretation of student models. We discuss in detail two ways how data collection in educational systems can influence results: mastery attrition bias and adaptive choice of items. We systematically discuss previous work related to these biases and illustrate the main points using both simulated and real data. We summarize specific consequences for practice -- not just for doing evaluation of student models, but also for data collection and publication of data sets.", "authors": ["Radek Pel\u00e1nek", "Jir\u00ed Rih\u00e1k", "Jan Papou\u0161ek"], "session": "SESSION: Learner models"}, {"title": "Semantic visual analytics for today's programming courses", "pages": "48-53", "doi": "10.1145/2883851.2883915", "abstract": "We designed and studied an innovative semantic visual learning analytics for orchestrating today's programming classes. The visual analytics integrates sources of learning activities by their content semantics. It automatically processs paper-based exams by associating sets of concepts to the exam questions. Results indicated the automatic concept extraction from exams were promising and could be a potential technological solution to address a real world issue. We also discovered that indexing effectiveness was especially prevalent for complex content by covering more comprehensive semantics. Subjective evaluation revealed that the dynamic concept indexing provided teachers with immediate feedback on producing more balanced exams.", "authors": ["I-Han Hsiao", "Sesha Kumar Pandhalkudi Govindarajan", "Yi-Ling Lin"], "session": "SESSION: Analytic visualizations and dashboards"}, {"title": "The role of achievement goal orientations when studying effect of learning analytics visualizations", "pages": "54-63", "doi": "10.1145/2883851.2883904", "abstract": "When designing learning analytics tools for use by learners we have an opportunity to provide tools that consider a particular learner's situation and the learner herself. To afford actual impact on learning, such tools have to be informed by theories of education. Particularly, educational research shows that individual differences play a significant role in explaining students' learning process. However, limited empirical research in learning analytics has investigated the role of theoretical constructs, such as motivational factors, that are underlying the observed differences between individuals. In this work, we conducted a field experiment to examine the effect of three designed learning analytics visualizations on students' participation in online discussions in authentic course settings. Using hierarchical linear mixed models, our results revealed that effects of visualizations on the quantity and quality of messages posted by students with differences in achievement goal orientations could either be positive or negative. Our findings highlight the methodological importance of considering individual differences and pose important implications for future design and research of learning analytics visualizations.", "authors": ["Sanam Shirazi Beheshitha", "Marek Hatala", "Dragan Ga\u0161evi\u0107", "Sre\u0107ko Joksimovi\u0107"], "session": "SESSION: Analytic visualizations and dashboards"}, {"title": "Investigating collaborative learning success with physiological coupling indices based on electrodermal activity", "pages": "64-73", "doi": "10.1145/2883851.2883897", "abstract": "Collaborative learning is considered a critical 21st century skill. Much is known about its contribution to learning, but still investigating a process of collaboration remains a challenge. This paper approaches the investigation on collaborative learning from a psychophysiological perspective. An experiment was set up to explore whether biosensors can play a role in analysing collaborative learning. On the one hand, we identified five physiological coupling indices (PCIs) found in the literature: 1) Signal Matching (SM), 2) Instantaneous Derivative Matching (IDM), 3) Directional Agreement (DA), 4) Pearson's correlation coefficient (PCC) and the 5) Fisher's z-transform (FZT) of the PCC. On the other hand, three collaborative learning measurements were used: 1) collaborative will (CW), 2) collaborative learning product (CLP) and 3) dual learning gain (DLG). Regression analyses showed that out of the five PCIs, IDM related the most to CW and was the best predictor of the CLP. Meanwhile, DA predicted DLG the best. These results play a role in determining informative collaboration measures for designing a learning analytics, biofeedback dashboard.", "authors": ["H\u00e9ctor J. Pijeira-D\u00edaz", "Hendrik Drachsler", "Sanna J\u00e4rvel\u00e4", "Paul A. Kirschner"], "session": "SESSION: Collaborative learning"}, {"title": "A pedagogical framework for learning analytics in collaborative inquiry tasks: an example from a teamwork competency awareness program", "pages": "74-83", "doi": "10.1145/2883851.2883914", "abstract": "Many pedagogical models in the field of learning analytics are implicit and do not overtly direct learner behavior. While this allows flexibility of use, this could also result in misaligned practice, and there are calls for more explicit pedagogical models in learning analytics. This paper presents an explicit pedagogical model, the Team and Self Diagnostic Learning (TSDL) framework, in the context of collaborative inquiry tasks. Key informing theories include experiential learning, collaborative learning, and the learning analytics process model. The framework was trialed through a teamwork competency awareness program for 14 year old students. A total of 272 students participated in the program. This paper foregrounds students' and teachers' evaluative accounts of the program. Findings reveal positive perceptions of the stages of the TSDL framework, despite identified challenges, which points to its potential usefulness for teaching and learning. The TSDL framework aims to provide theoretical clarity of the learning process, and foster alignment between learning analytics and the learning design. The current work provides trial outcomes of a teamwork competency awareness program that used dispositional analytics, and further efforts are underway to develop the discourse layer of the analytic engine. Future work will also be dedicated to application and refinement of the framework for other contexts and participants, both learners and teachers alike.", "authors": ["Elizabeth Koh", "Antonette Shibani", "Jennifer Pei-Ling Tan", "Helen Hong"], "session": "SESSION: Collaborative learning"}, {"title": "An analysis framework for collaborative problem solving in practice-based learning activities: a mixed-method approach", "pages": "84-88", "doi": "10.1145/2883851.2883900", "abstract": "Systematic investigation of the collaborative problem solving process in open-ended, hands-on, physical computing design tasks requires a framework that highlights the main process features, stages and actions that then can be used to provide 'meaningful' learning analytics data. This paper presents an analysis framework that can be used to identify crucial aspects of the collaborative problem solving process in practice-based learning activities. We deployed a mixed-methods approach that allowed us to generate an analysis framework that is theoretically robust, and generalizable. Additionally, the framework is grounded in data and hence applicable to real-life learning contexts. This paper presents how our framework was developed and how it can be used to analyse data. We argue for the value of effective analysis frameworks in the generation and presentation of learning analytics for practice-based learning activities.", "authors": ["Mutlu Cukurova", "Katerina Avramides", "Daniel Spikol", "Rose Luckin", "Manolis Mavrikis"], "session": "SESSION: Collaborative learning"}, {"title": "Privacy and analytics: it's a DELICATE issue a checklist for trusted learning analytics", "pages": "89-98", "doi": "10.1145/2883851.2883893", "abstract": "The widespread adoption of Learning Analytics (LA) and Educational Data Mining (EDM) has somewhat stagnated recently, and in some prominent cases even been reversed following concerns by governments, stakeholders and civil rights groups about privacy and ethics applied to the handling of personal data. In this ongoing discussion, fears and realities are often indistinguishably mixed up, leading to an atmosphere of uncertainty among potential beneficiaries of Learning Analytics, as well as hesitations among institutional managers who aim to innovate their institution's learning support by implementing data and analytics with a view on improving student success. In this paper, we try to get to the heart of the matter, by analysing the most common views and the propositions made by the LA community to solve them. We conclude the paper with an eight-point checklist named DELICATE that can be applied by researchers, policy makers and institutional managers to facilitate a trusted implementation of Learning Analytics.", "authors": ["Hendrik Drachsler", "Wolfgang Greller"], "session": "SESSION: LA challenges, accessibility and ethics"}, {"title": "What can analytics contribute to accessibility in e-learning systems and to disabled students' learning?", "pages": "99-103", "doi": "10.1145/2883851.2883946", "abstract": "This paper explores the potential of analytics for improving accessibility of e-learning and supporting disabled learners in their studies. A comparative analysis of completion rates of disabled and non-disabled students in a large five-year dataset is presented and a wide variation in comparative retention rates is characterized. Learning analytics enable us to identify and understand such discrepancies and, in future, could be used to focus interventions to improve retention of disabled students. An agenda for onward research, focused on Critical Learning Paths, is outlined. This paper is intended to stimulate a wider interest in the potential benefits of learning analytics for institutions as they try to assure the accessibility of their e-learning and provision of support for disabled students.", "authors": ["Martyn Cooper", "Rebecca Ferguson", "Annika Wolff"], "session": "SESSION: LA challenges, accessibility and ethics"}, {"title": "Affecting off-task behaviour: how affect-aware feedback can improve student learning", "pages": "104-113", "doi": "10.1145/2883851.2883936", "abstract": "This paper describes the development and evaluation of an affect-aware intelligent support component that is part of a learning environment known as iTalk2Learn. The intelligent support component is able to tailor feedback according to a student's affective state, which is deduced both from speech and interaction. The affect prediction is used to determine which type of feedback is provided and how that feedback is presented (interruptive or non-interruptive). The system includes two Bayesian networks that were trained with data gathered in a series of ecologically-valid Wizard-of-Oz studies, where the effect of the type of feedback and the presentation of feedback on students' affective states was investigated. This paper reports results from an experiment that compared a version that provided affect-aware feedback (affect condition) with one that provided feedback based on performance only (non-affect condition). Results show that students who were in the affect condition were less bored and less off-task, with the latter being statically significant. Importantly, students in both conditions made learning gains that were statistically significant, while students in the affect condition had higher learning gains than those in the non-affect condition, although this result was not statistically significant in this study's sample. Taken all together, the results point to the potential and positive impact of affect-aware intelligent support.", "authors": ["Beate Grawemeyer", "Manolis Mavrikis", "Wayne Holmes", "Sergio Gutierrez-Santos", "Michael Wiedmann", "Nikol Rummel"], "session": "SESSION: Determination of off-task/on-task behaviours"}, {"title": "Investigating boredom and engagement during writing using multiple sources of information: the essay, the writer, and keystrokes", "pages": "114-123", "doi": "10.1145/2883851.2883939", "abstract": "Writing training systems have been developed to provide students with instruction and deliberate practice on their writing. Although generally successful in providing accurate scores, a common criticism of these systems is their lack of personalization and adaptive instruction. In particular, these systems tend to place the strongest emphasis on delivering accurate scores, and therefore, tend to overlook additional indices that may contribute to students' success, such as their affective states during writing practice. This study takes an initial step toward addressing this gap by building a predictive model of students' affect using information that can potentially be collected by computer systems. We used individual difference measures, text indices, and keystroke analyses to predict engagement and boredom in 132 writing sessions. The results suggest that these three categories of indices were successful in modeling students' affective states during writing. Taken together, indices related to students' academic abilities, text properties, and keystroke logs were able classify high and low engagement and boredom in writing sessions with accuracies between 76.5% and 77.3%. These results suggest that information readily available in writing training systems can inform affect detectors and ultimately improve student models within intelligent tutoring systems.", "authors": ["Laura K. Allen", "Caitlin Mills", "Matthew E. Jacovina", "Scott Crossley", "Sidney D'Mello", "Danielle S. McNamara"], "session": "SESSION: Determination of off-task/on-task behaviours"}, {"title": "Interactive surfaces and learning analytics: data, orchestration aspects, pedagogical uses and challenges", "pages": "124-133", "doi": "10.1145/2883851.2883873", "abstract": "The proliferation of varied types of multi-user interactive surfaces (such as digital whiteboards, tabletops and tangible interfaces) is opening a new range of applications in face-to-face (f2f) contexts. They offer unique opportunities for Learning Analytics (LA) by facilitating multi-user sensemaking of automatically captured digital footprints of students' f2f interactions. This paper presents an analysis of current research exploring learning analytics associated with the use of surface devices. We use a framework to analyse our first-hand experiences, and the small number of related deployments according to four dimensions: the orchestration aspects involved; the phases of the pedagogical practice that are supported; the target actors; and the levels of iteration of the LA process. The contribution of the paper is twofold: 1) a synthesis of conclusions that identify the degree of maturity, challenges and pedagogical opportunities of the existing applications of learning analytics and interactive surfaces; and 2) an analysis framework that can be used to characterise the design space of similar areas and LA applications.", "authors": ["Roberto Martinez-Maldonado", "Bertrand Schneider", "Sven Charleer", "Simon Buckingham Shum", "Joris Klerkx", "Erik Duval"], "session": "SESSION: Learning tools and interventions"}, {"title": "Evaluation of an adaptive practice system for learning geography facts", "pages": "134-142", "doi": "10.1145/2883851.2883884", "abstract": "Computerized educational systems are increasingly provided as open online services which provide adaptive personalized learning experience. To fully exploit potential of such systems, it is necessary to thoroughly evaluate different design choices. However, both openness and adaptivity make proper evaluation difficult. We provide a detailed report on evaluation of an online system for adaptive practice of geography, and use this case study to highlight methodological issues with evaluation of open online learning systems, particularly attrition bias. To facilitate evaluation of learning, we propose to use randomized reference questions. We illustrate application of survival analysis and learning curves for declarative knowledge. The result provide an interesting insight into the impact of adaptivity on learner behaviour and learning.", "authors": ["Jan Papou\u0161ek", "V\u00edt Stanislav", "Radek Pel\u00e1nek"], "session": "SESSION: Learning tools and interventions"}, {"title": "Towards analytics for educational interactive e-books: the case of the reflective designer analytics platform (RDAP)", "pages": "143-147", "doi": "10.1145/2883851.2883943", "abstract": "This paper presents an analytics dashboard that has been developed for designers of interactive e-books. This is part of the EU-funded MC Squared project that is developing a platform for authoring interactive educational e-books. The primary objective is to develop technologies and resources that enhance creative thinking for both designers (authors) and learners. The learning material is expected to offer learners opportunities to engage creatively with mathematical problems and develop creative mathematical thinking. The analytics dashboard is designed to increase authors' awareness so that they can make informed decisions on how to redesign and improve the e-books. This paper presents architectural and design decisions on key features of the dashboard and discusses future steps with respect to the potential for exploratory data analysis.", "authors": ["Sokratis Karkalas", "Manolis Mavrikis", "Oliver Labs"], "session": "SESSION: Learning tools and interventions"}, {"title": "Teaching analytics: towards automatic extraction of orchestration graphs using wearable sensors", "pages": "148-157", "doi": "10.1145/2883851.2883927", "abstract": "'Teaching analytics' is the application of learning analytics techniques to understand teaching and learning processes, and eventually enable supportive interventions. However, in the case of (often, half-improvised) teaching in face-to-face classrooms, such interventions would require first an understanding of what the teacher actually did, as the starting point for teacher reflection and inquiry. Currently, such teacher enactment characterization requires costly manual coding by researchers. This paper presents a case study exploring the potential of machine learning techniques to automatically extract teaching actions during classroom enactment, from five data sources collected using wearable sensors (eye-tracking, EEG, accelerometer, audio and video). Our results highlight the feasibility of this approach, with high levels of accuracy in determining the social plane of interaction (90%, \u03ba=0.8). The reliable detection of concrete teaching activity (e.g., explanation vs. questioning) accurately still remains challenging (67%, \u03ba=0.56), a fact that will prompt further research on multimodal features and models for teaching activity extraction, as well as the collection of a larger multimodal dataset to improve the accuracy and generalizability of these methods.", "authors": ["Luis P. Prieto", "Kshitij Sharma", "Pierre Dillenbourg", "Mar\u00eda Jes\u00fas"], "session": "SESSION: Teaching and teacher analytics"}, {"title": "Student perspectives on data provision and use: starting to unpack disciplinary differences", "pages": "158-167", "doi": "10.1145/2883851.2883945", "abstract": "How can we best align learning analytics practices with disciplinary knowledge practices in order to support student learning? Although learning analytics itself is an interdisciplinary field, it tends to take a 'one-size-fits-all' approach to the collection, measurement, and reporting of data, overlooking disciplinary knowledge practices. In line with a recent trend in higher education research, this paper considers the contribution of a realist sociology of education to the field of learning analytics, drawing on findings from recent student focus groups at an Australian university. It examines what learners say about their data needs with reference to organizing principles underlying knowledge practices within their disciplines. The key contribution of this paper is a framework that could be used as the basis for aligning the provision and/or use of data in relation to curriculum, pedagogy, and assessment with disciplinary knowledge practices. The framework extends recent research in Legitimation Code Theory, which understands disciplinary differences in terms of the principles that underpin knowledge-building. The preliminary analysis presented here both provides a tool for ensuring a fit between learning analytics practices and disciplinary practices and standards for achievement, and signals disciplinarity as an important consideration in learning analytics practices.", "authors": ["Jen McPherson", "Huong Ly Tong", "Scott J. Fatt", "Danny Y. T. Liu"], "session": "SESSION: Teaching and teacher analytics"}, {"title": "Design and evaluation of teacher assistance tools for exploratory learning environments", "pages": "168-172", "doi": "10.1145/2883851.2883909", "abstract": "We present our approach to designing and evaluating tools that can assist teachers in classroom settings where students are using Exploratory Learning Environments (ELEs), using as our case study the MiGen system, which targets 1114 year old students' learning of algebra. We discuss the challenging role of teachers in exploratory learning settings and motivate the need for visualisation and notification tools that can assist teachers in focusing their attention across the whole class and inform their interventions. We present the design and evaluation approach followed during the development of MiGen's Teacher Assistance tools, drawing parallels with the recently proposed LATUX workflow but also discussing how we go beyond this to include a large number of teacher participants in our evaluation activities, so as to gain the benefit of different view points. We discuss the results of the evaluations, which show that participants appreciated the capabilities of the tools and were mostly able to use them quickly and accurately.", "authors": ["Manolis Mavrikis", "Sergio Gutierrez-Santos", "Alex Poulovassilis"], "session": "SESSION: Teaching and teacher analytics"}, {"title": "The learning analytics readiness instrument", "pages": "173-182", "doi": "10.1145/2883851.2883925", "abstract": "Little is known about the processes institutions use when discerning their readiness to implement learning analytics. This study aims to address this gap in the literature by using survey data from the beta version of the Learning Analytics Readiness Instrument (LARI) [1]. Twenty-four institutions were surveyed and 560 respondents participated. Five distinct factors were identified from a factor analysis of the results: Culture; Data Management Expertise; Data Analysis Expertise; Communication and Policy Application; and, Training. Data were analyzed using both the role of those completing the survey and the Carnegie classification of the institutions as lenses. Generally, information technology professionals and institutions classified as Research Universities--Very High research activity had significantly different scores on the identified factors. Working within a framework of organizational learning, this paper details the concept of readiness as a reflective process, as well as how the implementation and application of analytics should be done so with ethical considerations in mind. Limitations of the study, as well as next steps for research in this area, are also discussed.", "authors": ["Meghan Oster", "Steven Lonn", "Matthew D. Pistilli", "Michael G. Brown"], "session": "SESSION: Institutional perspectives and challenges"}, {"title": "Real-time indicators and targeted supports: using online platform data to accelerate student learning", "pages": "183-187", "doi": "10.1145/2883851.2883942", "abstract": "Statway\u00ae is one of the Community College Pathways initiatives designed to promote students' success in their developmental math sequence and reduce the time required to earn college credit. A recent causal analysis confirmed that Statway dramatically increased students' success rates in half the time across two different cohorts. These impressive results were also obtained across gender and race/ethnicity groups. However, there is still room for improvement. Students who did not succeed in Statway often did not complete the first of the two-course sequence. Therefore, the objective of this study is to formulate a series of indicators from self-report and online learning system data, alerting instructors to students' progress during the first weeks of the first course in the Statway sequence.", "authors": ["Ouajdi Manai", "Hiroyuki Yamada", "Christopher Thorn"], "session": "SESSION: Institutional perspectives and challenges"}, {"title": "Bringing order to chaos in MOOC discussion forums with content-related thread identification", "pages": "188-197", "doi": "10.1145/2883851.2883916", "abstract": "This study addresses the issues of overload and chaos in MOOC discussion forums by developing a model to categorize and identify threads based on whether or not they are substantially related to the course content. Content-related posts were defined as those that give/seek help for the learning of course material and share/comment on relevant resources. A linguistic model was built based on manually-coded starting posts in threads from a statistics MOOC (n=837) and tested on thread starting posts from the second offering of the same course (n=304) and a different statistics course (n=298). The number of views and votes threads received were tested to see if they helped classification. Results showed that content-related posts in the statistics MOOC had distinct linguistic features which appeared to be unrelated to the subject-matter domain; the linguistic model demonstrated good cross-course reliability (all recall and precision > .77) and was useful across all time segments of the courses; number of views and votes were not helpful for classification.", "authors": ["Alyssa Friend Wise", "Yi Cui", "Jovita Vytasek"], "session": "SESSION: MOOC discussion analysis"}, {"title": "Investigating social and semantic user roles in MOOC discussion forums", "pages": "198-207", "doi": "10.1145/2883851.2883924", "abstract": "This paper describes the analysis of the social and semantic structure of discussion forums in massive open online courses (MOOCs) in terms of information exchange and user roles. To that end, we analyse a network of forum users based on information-giving relations extracted from the forum data. Connection patterns that appear in the information exchange network of forum users are used to define specific user roles in a social context. Semantic roles are derived by identifying thematic areas in which an actor seeks for information (problem areas) and the areas of interest in which an actor provides information to others (expertise). The interplay of social and semantic roles is analysed using a socio-semantic blockmodelling approach. The results show that social and semantic roles are not strongly interdependent. This indicates that communication patterns and interests of users develop simultaneously only to a moderate extent. In addition to the case study, the methodological contribution is in combining traditional blockmodelling with semantic information to characterise participant roles.", "authors": ["Tobias Hecking", "Irene-Angelica Chounta", "H. Ulrich Hoppe"], "session": "SESSION: MOOC discussion analysis"}, {"title": "Untangling MOOC learner networks", "pages": "208-212", "doi": "10.1145/2883851.2883919", "abstract": "Research in formal education has repeatedly offered evidence of the importance of social interactions for student learning. However, it remains unclear whether the development of such interpersonal relationships has the same influence on learning in the context of large-scale open online learning. For instance, in MOOCs group members frequently change and the volume of interactions can quickly amass to chaos, therefore impeding an individual's propensity to foster meaningful relationships. This paper examined a MOOC for its potential to develop social processes. As it is exceedingly difficult to establish a relationship with somebody who seldom accesses a MOOC discussion, we singled out a cohort defined by its participants' regularity of forum presence. The study, analysed this 'cohort' and its development, in comparison to the entire MOOC learner network. Mixed methods of social network analysis (SNA), content analysis and statistical network modelling, revealed the potential for unfolding social processes among a more persistent group of learners in the MOOC setting.", "authors": ["Poquet Oleksandra", "Dawson Shane"], "session": "SESSION: MOOC discussion analysis"}, {"title": "Reflecting on reflective writing analytics: assessment challenges and iterative evaluation of a prototype tool", "pages": "213-222", "doi": "10.1145/2883851.2883955", "abstract": "When used effectively, reflective writing tasks can deepen learners' understanding of key concepts, help them critically appraise their developing professional identity, and build qualities for lifelong learning. As such, reflecting writing is attracting substantial interest from universities concerned with experiential learning, reflective practice, and developing a holistic conception of the learner. However, reflective writing is for many students a novel genre to compose in, and tutors may be inexperienced in its assessment. While these conditions set a challenging context for automated solutions, natural language processing may also help address the challenge of providing real time, formative feedback on draft writing. This paper reports progress in designing a writing analytics application, detailing the methodology by which informally expressed rubrics are modelled as formal rhetorical patterns, a capability delivered by a novel web application. This has been through iterative evaluation on an independently human-annotated corpus, showing improvements from the first to second version. We conclude by discussing the reasons why classifying reflective writing has proven complex, and reflect on the design processes enabling work across disciplinary boundaries to develop the prototype to its current state.", "authors": ["Simon Buckingham Shum", "\u00c1gnes S\u00e1ndor", "Rosalie Goldsmith", "Xiaolong Wang", "Randall Bass", "Mindy McWilliams"], "session": "SESSION: Language, writing, and interaction"}, {"title": "Longitudinal engagement, performance, and social connectivity: a MOOC case study using exponential random graph models", "pages": "223-230", "doi": "10.1145/2883851.2883934", "abstract": "This paper explores a longitudinal approach to combining engagement, performance and social connectivity data from a MOOC using the framework of exponential random graph models (ERGMs). The idea is to model the social network in the discussion forum in a given week not only using performance (assignment scores) and overall engagement (lecture and discussion views) covariates within that week, but also on the same person-level covariates from adjacent previous and subsequent weeks. We find that over all eight weekly sessions, the social networks constructed from the forum interactions are relatively sparse and lack the tendency for preferential attachment. By analyzing data from the second week, we also find that individuals with higher performance scores from current, previous, and future weeks tend to be more connected in the social network. Engagement with lectures had significant but sometimes puzzling effects on social connectivity. However, the relationships between social connectivity, performance, and engagement weakened over time, and results were not stable across weeks.", "authors": ["Mengxiao Zhu", "Yoav Bergner", "Yan Zhang", "Ryan Baker", "Yuan Wang", "Luc Paquette"], "session": "SESSION: Language, writing, and interaction"}, {"title": "English language learner experiences of formal and informal learning environments", "pages": "231-235", "doi": "10.1145/2883851.2883896", "abstract": "Many people who do not know English have moved to English-speaking countries to learn English. Once there, they learn English through formal and informal methods. While considerable work has studied the experiences of English language learners in different learning environments, we have yet to see analytics that detail the experiences of this population within formal and informal learning environments. This study used the experience sampling methodology to capture the information that is needed to detail the communication and affective experiences of advanced English language learners. The collected data reveals differences in how English language learners perceived their communication success based on their learning context, with higher levels of communicative success experienced in formal learning settings. No such differences were found for learners', highly negative, affect. The data suggest a need for additional emotional support within formal and informal learning environments as well as a need for oral communication support within informal contexts.", "authors": ["Carrie Demmans Epp"], "session": "SESSION: Language, writing, and interaction"}, {"title": "Analysing engagement in an online management programme and implications for course design", "pages": "236-240", "doi": "10.1145/2883851.2883894", "abstract": "We analyse engagement and performance data arising from participants' interactions with an in-house LMS at Imperial College London while a cohort of students follow two courses on a new online postgraduate degree in Management. We identify and investigate two main questions relating to the relationships between engagement and performance, drawing recommendations for improved guidelines to inform the design of such courses.", "authors": ["Marc Wells", "Alex Wollenschlaeger", "David Lefevre", "George D. Magoulas", "Alexandra Poulovassilis"], "session": "SESSION: Institutional perspectives"}, {"title": "Measuring financial implications of an early alert system", "pages": "241-248", "doi": "10.1145/2883851.2883923", "abstract": "The prevalence of early alert systems (EAS) at tertiary institutions is increasing. These systems are designed to assist with targeted student support in order to improve student retention. They also require considerable human and capital resources to implement, with significant costs involved. It is therefore an imperative that the systems can demonstrate quantifiable financial benefits to the institution. The purpose of this paper is to report on the financial implications of implementing an EAS at an Australian university as a case study. The case study institution implemented an EAS in 2011 using data generated from a data warehouse. The data set is comprised of 16,124 students enrolled between 2011 and 2013. Using a treatment effects approach, the study found that the cost of a student discontinuing was on average $4,687. Students identified by the EAS remained enrolled for longer, with the institution benefiting with approximately an additional $4,004 in revenue per student over the length of enrolment. All schools had a significant positive effect associated with the EAS and the EAS showed significant value to the institution regardless of the timing when the student was identified. The results indicate that EAS had significant financial benefits to this institution and that the benefits extended to the entire institution beyond the first year of enrolment.", "authors": ["Scott Harrison", "Renato Villano", "Grace Lynch", "George Chen"], "session": "SESSION: Institutional perspectives"}, {"title": "Data2U: scalable real time student feedback in active learning environments", "pages": "249-253", "doi": "10.1145/2883851.2883911", "abstract": "The majority of applications and products that use learning analytics to understand and improve learning experiences assume the creation of actionable items that will affect students through an intermediary. Much less focus is devoted to exploring how to provide insight directly to students. Furthermore, student engagement has always been a relevant aspect to increase the quality of a learning experience. Learning analytics techniques can be used to provide real-time insight tightly integrated with the learning outcomes directly to the students. This paper describes a case study deployed in a first year engineering course using a flipped learning strategy to explore the behavior of students interacting with a dashboard updated in real time providing indicators of their engagement with the course activities. The results show different patterns of use and their evolution throughout the experience and shed some light on how students perceived this resource.", "authors": ["Imran Khan", "Abelardo Pardo"], "session": "SESSION: Personalization"}, {"title": "Supporting learning by considering emotions: tracking and visualization a case study", "pages": "254-263", "doi": "10.1145/2883851.2883888", "abstract": "The adequate emotional state of students has proved to be essential for favoring learning. This paper explores the possibility of obtaining students' feedback about the emotions they feel in class in order to discover potential emotion patterns that might indicate learning fails. This paper presents a visual dashboard that allows students to track their emotions and follow up on their evolution during the course. We have compiled the principal classroom related emotions and developed a two-phase inquiry process to: verify the possibility to measure students' emotions in classroom; discover how emotions can be displayed to promote self-reflection; and confirm the impact of emotions on learning performance. Our results suggest that students' emotions in class are related to evaluation marks. This shows that early information about students' emotions can be useful for teachers and students to improve classroom results and learning outcomes.", "authors": ["Samara Ruiz", "Sven Charleer", "Maite Urretavizcaya", "Joris Klerkx", "Isabel Fern\u00e1ndez-Castro", "Erik Duval"], "session": "SESSION: Personalization"}, {"title": "A rule-based indicator definition tool for personalized learning analytics", "pages": "264-273", "doi": "10.1145/2883851.2883921", "abstract": "In the last few years, there has been a growing interest in learning analytics (LA) in technology-enhanced learning (TEL). Generally, LA deals with the development of methods that harness educational data sets to support the learning process. Recently, the concept of open learning analytics (OLA) has received a great deal of attention from LA community, due to the growing demand for self-organized, networked, and lifelong learning opportunities. A key challenge in OLA is to follow a personalized and goal-oriented LA model that tailors the LA task to the needs and goals of multiple stakeholders. Current implementations of LA rely on a predefined set of questions and indicators. There is, however, a need to adopt a personalized LA approach that engages end users in the indicator definition process by supporting them in setting goals, posing questions, and self-defining the indicators that help them achieve their goals. In this paper, we address the challenge of personalized LA and present the conceptual, design, and implementation details of a rule-based indicator definition tool to support flexible definition and dynamic generation of indicators to meet the needs of different stakeholders with diverse goals and questions in the LA exercise.", "authors": ["Arham Muslim", "Mohamed Amine Chatti", "Tanmaya Mahapatra", "Ulrik Schroeder"], "session": "SESSION: Personalization"}, {"title": "Designing MOOCs for success: a student motivation-oriented framework", "pages": "274-278", "doi": "10.1145/2883851.2883941", "abstract": "Considerable literature exists regarding MOOCs. Evaluations of MOOCs range from ringing endorsements to its vilification as a delivery model. Much evaluation focuses on completion rates and/or participant satisfaction. Overall, MOOCs are ill-defined and researchers struggle with appropriate evaluation criteria beyond attrition rates. In this paper, we provide a brief history of MOOCs, a summary of some evaluation research, and we propose a new model for evaluation with an example from a previously-delivered MOOC. Measurement of the MOOC success framework through four student satisfaction types is proposed in this paper with a model for informal learning satisfaction, one of the proposed types, theorized and tested. Results indicated theoretical underpinnings, while intended to improve instruction, might not have influenced the same satisfaction construct. Therefore, future research into alternative satisfaction factor models is needed.", "authors": ["Jonathan M. Kevan", "Michael P. Menchaca", "Ellen S. Hoffman"], "session": "SESSION: Theoretical and conceptual models"}, {"title": "The assessment of learning infrastructure (ALI): the theory, practice, and scalability of automated assessment", "pages": "279-288", "doi": "10.1145/2883851.2883872", "abstract": "Researchers invested in K-12 education struggle not just to enhance pedagogy, curriculum, and student engagement, but also to harness the power of technology in ways that will optimize learning. Online learning platforms offer a powerful environment for educational research at scale. The present work details the creation of an automated system designed to provide researchers with insights regarding data logged from randomized controlled experiments conducted within the ASSISTments TestBed. The Assessment of Learning Infrastructure (ALI) builds upon existing technologies to foster a symbiotic relationship beneficial to students, researchers, the platform and its content, and the learning analytics community. ALI is a sophisticated automated reporting system that provides an overview of sample distributions and basic analyses for researchers to consider when assessing their data. ALI's benefits can also be felt at scale through analyses that crosscut multiple studies to drive iterative platform improvements while promoting personalized learning.", "authors": ["Korinn S. Ostrow", "Doug Selent", "Yan Wang", "Eric G. Van Inwegen", "Neil T. Heffernan", "Joseph Jay Williams"], "session": "SESSION: Theoretical and conceptual models"}, {"title": "When to stop?: towards universal instructional policies", "pages": "289-298", "doi": "10.1145/2883851.2883961", "abstract": "The adaptivity of intelligent tutoring systems relies on the accuracy of the student model and the design of the instructional policy. Recently an instructional policy has been presented that is compatible with all common student models. In this work we present the next step towards a universal instructional policy. We introduce a new policy that is applicable to an even wider range of student models including DBNs modeling skill topologies and forgetting. We theoretically and empirically compare our policy to previous policies. Using synthetic and real world data sets we show that our policy can effectively handle wheel-spinning students as well as forgetting across a wide range of student models.", "authors": ["Tanja K\u00e4ser", "Severin Klingler", "Markus Gross"], "session": "SESSION: Theoretical and conceptual models"}, {"title": "Applying classification techniques on temporal trace data for shaping student behavior models", "pages": "299-303", "doi": "10.1145/2883851.2883926", "abstract": "Differences in learners' behavior have a deep impact on their educational performance. Consequently, there is a need to detect and identify these differences and build suitable learner models accordingly. In this paper, we report on the results from an alternative approach for dynamic student behavioral modeling based on the analysis of time-based student-generated trace data. The goal was to unobtrusively classify students according to their time-spent behavior. We applied 5 different supervised learning classification algorithms on these data, using as target values (class labels) the students' performance score classes during a Computer-Based Assessment (CBA) process, and compared the obtained results. The proposed approach has been explored in a study with 259 undergraduate university participant students. The analysis of the findings revealed that a) the low misclassification rates are indicative of the accuracy of the applied method and b) the ensemble learning (treeBagger) method provides better classification results compared to the others. These preliminary results are encouraging, indicating that a time-spent driven description of the students' behavior could have an added value towards dynamically reshaping the respective models.", "authors": ["Zacharoula Papamitsiou", "Eirini Karapistoli", "Anastasios A. Economides"], "session": "SESSION: Methodological reflections"}, {"title": "Using A/B testing in MOOC environments", "pages": "304-313", "doi": "10.1145/2883851.2883876", "abstract": "In recent years, Massive Open Online Courses (MOOCs) have become a phenomenon offering the possibility to teach thousands of participants simultaneously. In the same time the platforms used to deliver these courses are still in their fledgling stages. While course content and didactics of those massive courses are the primary key factors for the success of courses, still a smart platform may increase or decrease the learners experience and his learning outcome. The paper at hand proposes the usage of an A/B testing framework that is able to be used within an micro-service architecture to validate hypotheses about how learners use the platform and to enable data-driven decisions about new features and settings. To evaluate this framework three new features (Onboarding Tour, Reminder Mails and a Pinboard Digest) have been identified based on a user survey. They have been implemented and introduced on two large MOOC platforms and their influence on the learners behavior have been measured. Finally this paper proposes a data driven decision workflow for the introduction of new features and settings on e-learning platforms.", "authors": ["Jan Renz", "Daniel Hoffmann", "Thomas Staubitz", "Christoph Meinel"], "session": "SESSION: Methodological reflections"}, {"title": "Translating network position into performance: importance of centrality in different network configurations", "pages": "314-323", "doi": "10.1145/2883851.2883928", "abstract": "As the field of learning analytics continues to mature, there is a corresponding evolution and sophistication of the associated analytical methods and techniques. In this regard social network analysis (SNA) has emerged as one of the cornerstones of learning analytics methodologies. However, despite the noted importance of social networks for facilitating the learning process, it remains unclear how and to what extent such network measures are associated with specific learning outcomes. Motivated by Simmel's theory of social interactions and building on the argument that social centrality does not always imply benefits, this study aimed to further contribute to the understanding of the association between students' social centrality and their academic performance. The study reveals that learning analytics research drawing on SNA should incorporate both - descriptive and statistical methods to provide a more comprehensive and holistic understanding of a students' network position. In so doing researchers can undertake more nuanced and contextually salient inferences about learning in network settings. Specifically, we show how differences in the factors framing students' interactions within two instances of a MOOC affect the association between the three social network centrality measures (i.e., degree, closeness, and betweenness) and the final course outcome.", "authors": ["Sre\u0107ko Joksimovi\u0107", "Areti Manataki", "Dragan Ga\u0161evi\u0107", "Shane Dawson", "Vitomir Kovanovi\u0107", "In\u00e9s Friss de Kereki"], "session": "SESSION: Proficiency and positioning"}, {"title": "Data-driven proficiency profiling: proof of concept", "pages": "324-328", "doi": "10.1145/2883851.2883935", "abstract": "Data-driven methods have previously been used in intelligent tutoring systems to improve student learning outcomes and predict student learning methods. We have been incorporating data-driven methods for feedback and problem selection into Deep Thought, a logic tutor where students practice constructing deductive logic proofs. In this latest study we have implemented our data-driven proficiency profiler (DDPP) into Deep Thought as a proof of concept. The DDPP determines student proficiency without expert involvement by comparing relevant student rule scores to previous students who behaved similarly in the tutor and successfully completed it. The results show that the DDPP did improve in performance with additional data and proved to be an effective proof of concept.", "authors": ["Behrooz Mostafavi", "Tiffany Barnes"], "session": "SESSION: Proficiency and positioning"}, {"title": "A conceptual framework linking learning design with learning analytics", "pages": "329-338", "doi": "10.1145/2883851.2883944", "abstract": "In this paper we present a learning analytics conceptual framework that supports enquiry-based evaluation of learning designs. The dimensions of the proposed framework emerged from a review of existing analytics tools, the analysis of interviews with teachers, and user scenarios to understand what types of analytics would be useful in evaluating a learning activity in relation to pedagogical intent. The proposed framework incorporates various types of analytics, with the teacher playing a key role in bringing context to the analysis and making decisions on the feedback provided to students as well as the scaffolding and adaptation of the learning design. The framework consists of five dimensions: temporal analytics, tool-specific analytics, cohort dynamics, comparative analytics and contingency. Specific metrics and visualisations are defined for each dimension of the conceptual framework. Finally the development of a tool that partially implements the conceptual framework is discussed.", "authors": ["Aneesha Bakharia", "Linda Corrin", "Paula de Barba", "Gregor Kennedy", "Dragan Ga\u0161evi\u0107", "Raoul Mulder", "David Williams", "Shane Dawson", "Lori Lockyer"], "session": "SESSION: Learning design and analytics"}, {"title": "The impact of 151 learning designs on student satisfaction and performance: social learning (analytics) matters", "pages": "339-343", "doi": "10.1145/2883851.2883875", "abstract": "An increasing number of researchers are taking learning design into consideration when predicting learning behavior and outcomes across different modules. This study builds on preliminary learning design work that was presented at LAK2015 by the Open University UK. In this study we linked 151 modules and 111.256 students with students' satisfaction and performance using multiple regression models. Our findings strongly indicate the importance of learning design in predicting and understanding performance of students in blended and online environments. In line with proponents of social learning analytics, our primary predictor for academic retention was the amount of communication activities, controlling for various institutional and disciplinary factors. Where possible, appropriate communication tasks that align with the learning objectives of the course may be a way forward to enhance academic retention.", "authors": ["Bart Rienties", "Lisette Toetenel"], "session": "SESSION: Learning design and analytics"}, {"title": "Student differences in regulation strategies and their use of learning resources: implications for educational design", "pages": "344-353", "doi": "10.1145/2883851.2883890", "abstract": "The majority of the learning analytics research focuses on the prediction of course performance and modeling student behaviors with a focus on identifying students who are at risk of failing the course. Learning analytics should have a stronger focus on improving the quality of learning for all students, not only identifying at risk students. In order to do so, we need to understand what successful patterns look like when reflected in data and subsequently adjust the course design to avoid unsuccessful patterns and facilitate successful patterns. However, when establishing these successful patterns, it is important to account for individual differences among students since previous research has shown that not all students engage with learning resources to the same extent. Regulation strategies seem to play an important role in explaining the different usage patterns students' display when using digital learning recourses. When learning analytics research incorporates contextualized data about student regulation strategies we are able to differentiate between students at a more granular level. The current study examined if regulation strategies could account for differences in the use of various learning resources. It examines how students regulated their learning process and subsequently used the different learning resources throughout the course and established how this use contributes to course performance. The results show that students with different regulation strategies use the learning resources to the same extent. However, the use of learning resources influences course performance differently for different groups of students. This paper recognizes the importance of contextualization of learning data resources with a broader set of indicators to understand the learning process. With our focus on differences between students, we strive for a shift within learning analytics from identifying at risk students towards a contribution of learning analytics in the educational design process and enhance the quality of learning; for all students.", "authors": ["Nynke Bos", "Saskia Brand-Gruwel"], "session": "SESSION: Learning design and analytics"}, {"title": "Sequencing educational content in classrooms using Bayesian knowledge tracing", "pages": "354-363", "doi": "10.1145/2883851.2883885", "abstract": "Despite the prevalence of e-learning systems in schools, most of today's systems do not personalize educational data to the individual needs of each student. This paper proposes a new algorithm for sequencing questions to students that is empirically shown to lead to better performance and engagement in real schools when compared to a baseline approach. It is based on using knowledge tracing to model students' skill acquisition over time, and to select questions that advance the student's learning within the range of the student's capabilities, as determined by the model. The algorithm is based on a Bayesian Knowledge Tracing (BKT) model that incorporates partial credit scores, reasoning about multiple attempts to solve problems, and integrating item difficulty. This model is shown to outperform other BKT models that do not reason about (or reason about some but not all) of these features. The model was incorporated into a sequencing algorithm and deployed in two classes in different schools where it was compared to a baseline sequencing algorithm that was designed by pedagogical experts. In both classes, students using the BKT sequencing approach solved more difficult questions and attributed higher performance than did students who used the expert-based approach. Students were also more engaged using the BKT approach, as determined by their interaction time and number of log-ins to the system, as well as their reported opinion. We expect our approach to inform the design of better methods for sequencing and personalizing educational content to students that will meet their individual learning needs.", "authors": ["Yossi Ben David", "Avi Segal", "Ya'akov (Kobi) Gal"], "session": "SESSION: Bayesian modeling"}, {"title": "Studying the relationship between BKT fitting error and the skill difficulty index", "pages": "364-368", "doi": "10.1145/2883851.2883901", "abstract": "Bayesian Knowledge Tracing (BKT) is one of the most popular knowledge inference models due to its interpretability and ability to infer student knowledge. A proper student modeling can help guide the behavior of a cognitive tutor system and provide insight to researchers on understanding how students learn. Using four different datasets we study the relationship between the error coming from fitting the parameters and the difficulty index of the skills and the effect of the size of the dataset in this relationship. The relationship between the fitting error and the difficulty index can be very easy modeled and might be indicating some problems with BKTs performance. However, large datasets are required to clearly see this connection as there is an important sample size effect.", "authors": ["Francesc Martori", "Jordi Cuadros", "Lucinio Gonz\u00e1lez-Sabat\u00e9"], "session": "SESSION: Bayesian modeling"}, {"title": "Modeling common misconceptions in learning process data", "pages": "369-377", "doi": "10.1145/2883851.2883967", "abstract": "Student mistakes are often not random but, rather, reflect thoughtful yet incorrect strategies. In order for educational technologies to make full use of students' performance data to estimate the knowledge of a student, it is important to model not only the conceptions but also the misconceptions that a student's particular pattern of successes and errors may indicate. The student models that drive the \"outer loop\" of Intelligent Tutoring Systems typically do not represent or track misconceptions. Here, we present a method of representing misconceptions in the Knowledge Component models, or Q-Matrices, that are used by student models to estimate latent knowledge. We show, in a case study on a fraction arithmetic dataset, that incorporating a misconception into the Knowledge Component model dramatically improves the overall model's fit to data. We also derive qualitative insights from comparing predicted learning curves across models that incorporate varying misconception-related parameters. Finally, we show that the inclusion of a misconception in the Knowledge Component model can yield individual student estimates of misconception strength that are significantly correlated with out-of-tutor measures of student errors.", "authors": ["Ran Liu", "Rony Patel", "Kenneth R. Koedinger"], "session": "SESSION: Bayesian modeling"}, {"title": "Recipe for success: lessons learnt from using xAPI within the connected learning analytics toolkit", "pages": "378-382", "doi": "10.1145/2883851.2883882", "abstract": "An ongoing challenge for Learning Analytics research has been the scalable derivation of user interaction data from multiple technologies. The complexities associated with this challenge are increasing as educators embrace an ever growing number of social and content-related technologies. The Experience API (xAPI) alongside the development of user specific record stores has been touted as a means to address this challenge, but a number of subtle considerations must be made when using xAPI in Learning Analytics. This paper provides a general overview to the complexities and challenges of using xAPI in a general systemic analytics solution - called the Connected Learning Analytics (CLA) toolkit. The importance of design is emphasised, as is the notion of common vocabularies and xAPI Recipes. Early decisions about vocabularies and structural relationships between statements can serve to either facilitate or handicap later analytics solutions. The CLA toolkit case study provides us with a way of examining both the strengths and the weaknesses of the current xAPI specification, and we conclude with a proposal for how xAPI might be improved by using JSON-LD to formalise Recipes in a machine readable form.", "authors": ["Aneesha Bakharia", "Kirsty Kitto", "Abelardo Pardo", "Dragan Ga\u0161evi\u0107", "Shane Dawson"], "session": "SESSION: xAPI"}, {"title": "Forecasting student achievement in MOOCs with natural language processing", "pages": "383-387", "doi": "10.1145/2883851.2883932", "abstract": "Student intention and motivation are among the strongest predictors of persistence and completion in Massive Open Online Courses (MOOCs), but these factors are typically measured through fixed-response items that constrain student expression. We use natural language processing techniques to evaluate whether text analysis of open responses questions about motivation and utility value can offer additional capacity to predict persistence and completion over and above information obtained from fixed-response items. Compared to simple benchmarks based on demographics, we find that a machine learning prediction model can learn from unstructured text to predict which students will complete an online course. We show that the model performs well out-of-sample, compared to a standard array of demographics. These results demonstrate the potential for natural language processing to contribute to predicting student success in MOOCs and other forms of open online learning.", "authors": ["Carly Robinson", "Michael Yeomans", "Justin Reich", "Chris Hulleman", "Hunter Gehlbach"], "session": "SESSION: Supporting learning and achievement"}, {"title": "Is the doer effect a causal relationship?: how can we tell and why it's important", "pages": "388-397", "doi": "10.1145/2883851.2883957", "abstract": "The \"doer effect\" is an association between the number of online interactive practice activities students' do and their learning outcomes that is not only statistically reliable but has much higher positive effects than other learning resources, such as watching videos or reading text. Such an association suggests a causal interpretation--more doing yields better learning--which requires randomized experimentation to most rigorously confirm. But such experiments are expensive, and any single experiment in a particular course context does not provide rigorous evidence that the causal link will generalize to other course content. We suggest that analytics of increasingly available online learning data sets can complement experimental efforts by facilitating more widespread evaluation of the generalizability of claims about what learning methods produce better student learning outcomes. We illustrate with analytics that narrow in on a causal interpretation of the doer effect by showing that doing within a course unit predicts learning of that unit content more than doing in units before or after. We also provide generalizability evidence across four different courses involving over 12,500 students that the learning effect of doing is about six times greater than that of reading.", "authors": ["Kenneth R. Koedinger", "Elizabeth A. McLaughlin", "Julianna Zhuxin Jia", "Norman L. Bier"], "session": "SESSION: Supporting learning and achievement"}, {"title": "Towards triggering higher-order thinking behaviors in MOOCs", "pages": "398-407", "doi": "10.1145/2883851.2883964", "abstract": "With the aim of better scaffolding discussion to improve learning in a MOOC context, this work investigates what kinds of discussion behaviors contribute to learning. We explored whether engaging in higher-order thinking behaviors results in more learning than paying general or focused attention to course materials. In order to evaluate whether to attribute the effect to engagement in the associated behaviors versus persistent characteristics of the students, we adopted two approaches. First, we used propensity score matching to pair students who exhibit a similar level of involvement in other course activities. Second, we explored individual variation in engagement in higher-order thinking behaviors across weeks. The results of both analyses support the attribution of the effect to the behavioral interpretation. A further analysis using LDA applied to course materials suggests that more social oriented topics triggered richer discussion than more biopsychology oriented topics.", "authors": ["Xu Wang", "Miaomiao Wen", "Carolyn P. Ros\u00e9"], "session": "SESSION: Supporting learning and achievement"}, {"title": "A study on eye fixation patterns of students in higher education using an online learning system", "pages": "408-416", "doi": "10.1145/2883851.2883871", "abstract": "We study how the use of online learning systems stimulate cognitive activities, by conducting an experiment with the use of eye tracking technology to monitor eye fixations of 60 final year students engaging in online interactive tutorials at the start of their Final Year Project module. Our findings show that the students' visual scanning behaviours fall into three different types of eye fixation patterns, and the data corresponding to the different types relates to the performance of the students in other related academic modules. We conclude that this method of studying eye fixation patterns can identify different types of learners with respect to cognitive activities and academic potentials, allowing educators to understand how their instructional design using online learning environments can stimulate higher-order cognitive activities.", "authors": ["Benedict The", "Manolis Mavrikis"], "session": "SESSION: Real time data"}, {"title": "A gaze-based learning analytics model: in-video visual feedback to improve learner's attention in MOOCs", "pages": "417-421", "doi": "10.1145/2883851.2883902", "abstract": "In the context of MOOCs, \"With-me-ness\" refers to the extent to which the learner succeeds in following the teacher, specifically in terms of looking at the area in the video that the teacher is explaining. In our previous works, we employed eye-tracking methods to quantify learners' With-me-ness and showed that it is positively correlated with their learning gains. In this contribution, we describe a tool that is designed to improve With-me-ness by providing a visual-aid superimposed on the video. The position of the visual-aid is suggested by the teachers' dialogue and deixis, and it is displayed when the learner's With-me-ness is under the average value, which is computed from the other students' gaze behavior. We report on a user-study that examines the effectiveness of the proposed tool. The results show that it significantly improves the learning gain and it significantly increases the extent to which the students follow the teacher. Finally, we demonstrate how With-me-ness can create a complete theoretical framework for conducting gaze-based learning analytics in the context of MOOCs.", "authors": ["Kshitij Sharma", "Hamed S. Alavi", "Patrick Jermann", "Pierre Dillenbourg"], "session": "SESSION: Real time data"}, {"title": "Exploring the relation between self-regulation, online activities, and academic performance: a case study", "pages": "422-429", "doi": "10.1145/2883851.2883883", "abstract": "The areas of educational data mining and learning analytics focus on the extraction of knowledge and actionable items from data sets containing detailed information about students. However, the potential impact from these techniques is increased when properly contextualized within a learning environment. More studies are needed to explore the connection between student interactions, approaches to learning, and academic performance. Self-regulated learning (SRL) is defined as the extent to which a student is able to motivationally, metacognitively, and cognitively engage in a learning experience. SRL has been the focus of research in traditional classroom learning and is also argued to play a vital role in the online or blended learning contexts. In this paper, we study how SRL affects students' online interactions with various learning activities and its influence in academic performance. The results derived from a naturalistic experiment among a cohort of first year engineering students showed that positive self-regulated strategies (PSRS) and negative self-regulated strategies (NSRS) affected both the interaction with online activities and academic performance. NSRS directly predicted academic outcomes, whereas PSRS only contributed indirectly to academic performance via the interactions with online activities. These results point to concrete avenues to promote self-regulation among students in this type of learning contexts.", "authors": ["Abelardo Pardo", "Feifei Han", "Robert A. Ellis"], "session": "SESSION: Supporting SRL and 21st century skills"}, {"title": "Fostering 21st century literacies through a collaborative critical reading and learning analytics environment: user-perceived benefits and problematics", "pages": "430-434", "doi": "10.1145/2883851.2883965", "abstract": "The affordances of learning analytics (LA) are being increasingly harnessed to enhance 21st century (21C) pedagogy and learning. Relatively rare, however, are use cases and empirically based understandings of students' actual experiences with LA tools and environments at fostering 21C literacies, especially in secondary schooling and Asian education contexts. This paper addresses this knowledge gap by 1) presenting a first iteration design of a computer-supported collaborative critical reading and LA environment and its 16-week implementation in a Singapore high school; and 2) foregrounding students' quantitative and qualitative accounts of the benefits and problematics associated with this learning innovation. We focus the analytic lens on the LA dashboard components that provided visualizations of students' reading achievement, 21C learning dispositions, critical literacy competencies and social learning network positioning within the class. The paper aims to provide insights into the potentialities, paradoxes and pathways forward for designing LA that take into consideration the voices of learners as critical stakeholders.", "authors": ["Jennifer Pei-Ling Tan", "Simon Yang", "Elizabeth Koh", "Christin Jonathan"], "session": "SESSION: Supporting SRL and 21st century skills"}, {"title": "Improving efficacy attribution in a self-directed learning environment using prior knowledge individualization", "pages": "435-439", "doi": "10.1145/2883851.2883949", "abstract": "Models of learning in EDM and LAK are pushing the boundaries of what can be measured from large quantities of historical data. When controlled randomization is present in the learning platform, such as randomized ordering of problems within a problem set, natural quasi-randomized controlled studies can be conducted, post-hoc. Difficulty and learning gain attribution are among factors of interest that can be studied with secondary analyses under these conditions. However, much of the content that we might like to evaluate for learning value is not administered as a random stimulus to students but instead is being self-selected, such as a student choosing to seek help in the discussion forums, wiki pages, or other pedagogically relevant material in online courseware. Help seekers, by virtue of their motivation to seek help, tend to be the ones who have the least knowledge. When presented with a cohort of students with a bi-modal or uniform knowledge distribution, this can present problems with model interpretability when a single point estimation is used to represent cohort prior knowledge. Since resource access is indicative of a low knowledge student, a model can tend towards attributing the resources with low or negative learning gain in order to better explain performance given the higher average prior point estimate. In this paper we present several individualized prior strategies and demonstrate how learning efficacy attribution validity and prediction accuracy improve as a result. Level of education attained, relative past assessment performance, and the prior per student cold start heuristic were employed and compared as prior knowledge individualization strategies.", "authors": ["Zachary A. Pardos", "Yanbo Xu"], "session": "SESSION: Supporting SRL and 21st century skills"}, {"title": "Using game analytics to evaluate puzzle design and level progression in a serious game", "pages": "440-448", "doi": "10.1145/2883851.2883953", "abstract": "Our previous work has demonstrated that players who perceive a game as more challenging are likely to perceive greater learning from that game [8]. However, this may not be the case for all sources of challenge. In this study of a Science learning game called Quantum Spectre, we found that students' progress through the first zone of the game seemed to encounter a \"roadblock\" during gameplay, dropping out when they cannot (or do not want to) progress further. Previously we had identified two primary types of errors in the learning game, Quantum Spectre: Science Errors related to the game's core educational content; and Puzzle Errors related to rules of the game but not to science knowledge. Using this prior analysis, alongside Survival Analysis techniques for analyzing time-series data and drop-out rates, we explored players' gameplay patterns to help us understand player dropout in Quantum Spectre. These results demonstrate that modeling player behavior can be useful for both assessing learning and for designing complex problem solving content for learning environments.", "authors": ["Drew Hicks", "Michael Eagle", "Elizabeth Rowe", "Jodi Asbell-Clarke", "Teon Edwards", "Tiffany Barnes"], "session": "SESSION: Overcoming obstacles"}, {"title": "Bayesian modelling of student misconceptions in the one-digit multiplication with probabilistic programming", "pages": "449-453", "doi": "10.1145/2883851.2883895", "abstract": "One-digit multiplication errors are one of the most extensively analysed mathematical problems. Research work primarily emphasises the use of statistics whereas learning analytics can go one step further and use machine learning techniques to model simple learning misconceptions. Probabilistic programming techniques ease the development of probabilistic graphical models (bayesian networks) and their use for prediction of student behaviour that can ultimately influence learning decision processes.", "authors": ["Behnam Taraghi", "Anna Saranti", "Robert Legenstein", "Martin Ebner"], "session": "SESSION: Overcoming obstacles"}, {"title": "Enhancing the efficiency and reliability of group differentiation through partial credit", "pages": "454-458", "doi": "10.1145/2883851.2883910", "abstract": "The focus of the learning analytics community bridges the gap between controlled educational research and data mining. Online learning platforms can be used to conduct randomized controlled trials to assist in the development of interventions that increase learning gains; datasets from such research can act as a treasure trove for inquisitive data miners. The present work employs a data mining approach on randomized controlled trial data from ASSISTments, a popular online learning platform, to assess the benefits of incorporating additional student performance data when attempting to differentiate between two user groups. Through a resampling technique, we show that partial credit, defined as an algorithmic combination of binary correctness, hint usage, and attempt count, can benefit assessment and group differentiation. Partial credit reduces sample sizes required to reliably differentiate between groups that are known to differ by 58%, and reduces sample sizes required to reliably differentiate between less distinct groups by 9%.", "authors": ["Yan Wang", "Korinn Ostrow", "Joseph Beck", "Neil Heffernan"], "session": "SESSION: Overcoming obstacles"}, {"title": "What and when: the role of course type and timing in students' academic performance", "pages": "459-468", "doi": "10.1145/2883851.2883907", "abstract": "In this paper we discuss the results of a study of students' academic performance in first year general education courses. Using data from 566 students who received intensive academic advising as part of their enrollment in the institution's pre-major/general education program, we investigate individual student, organizational, and disciplinary factors that might predict a students' potential classification in an Early Warning System as well as factors that predict improvement and decline in their academic performance. Disciplinary course type (based on Biglan's [7] typology) was significantly related to a student's likelihood to enter below average performance classifications. Students were the most likely to enter a classification in fields like the natural science, mathematics, and engineering in comparison to humanities courses. We attribute these disparities in academic performance to disciplinary norms around teaching and assessment. In particular, the timing of assessments played a major role in students' ability to exit a classification. Implications for the design of Early Warning analytics systems as well as academic course planning in higher education are offered.", "authors": ["Michael Geoffrey Brown", "R. Matthew DeMonbrun", "Steven Lonn", "Stephen J. Aguilar", "Stephanie D. Teasley"], "session": "SESSION: Predictive modelling"}, {"title": "Predicting student performance on post-requisite skills using prerequisite skill data: an alternative method for refining prerequisite skill structures", "pages": "469-473", "doi": "10.1145/2883851.2883867", "abstract": "Prerequisite skill structures have been closely studied in past years leading to many data-intensive methods aimed at refining such structures. While many of these proposed methods have yielded success, defining and refining hierarchies of skill relationships are often difficult tasks. The relationship between skills in a graph could either be causal, therefore, a prerequisite relationship (skill A must be learned before skill B). The relationship may be non-causal, in which case the ordering of skills does not matter and may indicate that both skills are prerequisites of another skill. In this study, we propose a simple, effective method of determining the strength of pre-to-post-requisite skill relationships. We then compare our results with a teacher-level survey about the strength of the relationships of the observed skills and find that the survey results largely confirm our findings in the data-driven approach.", "authors": ["Seth A. Adjei", "Anthony F. Botelho", "Neil T. Heffernan"], "session": "SESSION: Predictive modelling"}, {"title": "Generating actionable predictive models of academic performance", "pages": "474-478", "doi": "10.1145/2883851.2883870", "abstract": "The pervasive collection of data has opened the possibility for educational institutions to use analytics methods to improve the quality of the student experience. However, the adoption of these methods faces multiple challenges particularly at the course level where instructors and students would derive the most benefit from the use of analytics and predictive models. The challenge lies in the knowledge gap between how the data is captured, processed and used to derive models of student behavior, and the subsequent interpretation and the decision to deploy pedagogical actions and interventions by instructors. Simply put, the provision of learning analytics alone has not necessarily led to changing teaching practices. In order to support pedagogical change and aid interpretation, this paper proposes a model that can enable instructors to readily identify subpopulations of students to provide specific support actions. The approach was applied to a first year course with a large number of students. The resulting model classifies students according to their predicted exam scores, based on indicators directly derived from the learning design.", "authors": ["Abelardo Pardo", "Negin Mirriahi", "Roberto Martinez-Maldonado", "Jelena Jovanovic", "Shane Dawson", "Dragan Ga\u0161evi\u0107"], "session": "SESSION: Predictive modelling"}, {"title": "Learning design and feedback processes at scale: stocktaking emergent theory and practice", "pages": "479-480", "doi": "10.1145/2883851.2883856", "abstract": "Design for learning in scaled courses is shifting away from replication of traditional on-campus or online teaching towards exploiting the distinctive characteristic and potentials of scale to transform both teaching and learning. Scaled learning environments such as MOOCs may represent a new paradigm for teaching. This workshop involves consideration of the how learning occurs in scaled environments, and how learning designers and analysts can assist. It will explore questions at the heart of effective learning design, using expert panelists and collaborative knowledge-building techniques to arrive at a stocktake of thinking.", "authors": ["Ulla Ringtved", "Sandra Milligan", "Linda Corrin"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "Critical perspectives on writing analytics", "pages": "481-483", "doi": "10.1145/2883851.2883854", "abstract": "Writing Analytics focuses on the measurement and analysis of written texts for the purpose of understanding writing processes and products, in their educational contexts, and improving the teaching and learning of writing. This workshop adopts a critical, holistic perspective in which the definition of \"the system\" and \"success\" is not restricted to IR metrics such as precision and recall, but recognizes the many wider issues that aid or obstruct analytics adoption in educational settings, such as theoretical and pedagogical grounding, usability, user experience, stakeholder design engagement, practitioner development, organizational infrastructure, policy and ethics.", "authors": ["Simon Buckingham Shum", "Simon Knight", "Danielle McNamara", "Laura Allen", "Duygu Bektik", "Scott Crossley"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "Learning analytics for workplace and professional learning", "pages": "484-485", "doi": "10.1145/2883851.2883860", "abstract": "Recognizing the need for addressing the rather fragmented character of research in this field, we have held a workshop on learning analytics for workplace and professional learning at the Learning Analytics and Knowledge (LAK) Conference. The workshop has taken a broad perspective, encompassing approaches from a number of previous traditions, such as adaptive learning, professional online communities, workplace learning and performance analytics. Being co-located with the LAK conference has provided an ideal venue for addressing common challenges and for benefiting from the strong research on learning analytics in other sectors that LAK has established. Learning Analytics for Workplace and Professional Learning is now on the research agenda of several ongoing EU projects, and therefore a number of follow-up activities are planned for strengthening integration in this emerging field.", "authors": ["Tobias Ley", "Ralf Klamma", "Stefanie Lindstaedt", "Fridolin Wild"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "Cross-LAK: learning analytics across physical and digital spaces", "pages": "486-487", "doi": "10.1145/2883851.2883855", "abstract": "It is of high relevance to the LAK community to explore blended learning scenarios where students can interact at diverse digital and physical learning spaces. This workshop aims to gather the sub-community of LAK researchers, learning scientists and researchers from other communities, interested in ubiquitous, mobile and/or face-to-face learning analytics. An overarching concern is how to integrate and coordinate learning analytics to provide continued support to learning across digital and physical spaces. The goals of the workshop are to share approaches and identify a set of guidelines to design and connect Learning Analytics solutions according to the pedagogical needs and contextual constraints to provide support across digital and physical learning spaces.", "authors": ["Roberto Martinez-Maldonado", "Davinia Hernandez-Leo", "Abelardo Pardo", "Dan Suthers", "Kirsty Kitto", "Sven Charleer", "Naif Radi Aljohani", "Hiroaki Ogata"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "Putting temporal analytics into practice: the 5th international workshop on temporality in learning data", "pages": "488-489", "doi": "10.1145/2883851.2883865", "abstract": "Interest in temporal analytics---analytics that probe temporal aspects of learning so as to gain insights into the processes through which learning occurs---continues to grow. The relationships of temporal patterns to learning outcomes is a central area of interest. However, while the literature on temporal analyses is developing, there has been less consideration of the methods by which temporal analyses might be translated to actionable insights and thus, put into use in educational practice. Emerging temporal analysis techniques present both theoretical and practical challenges for producing and interpreting results. Synergetic actions are needed in order to support practitioners.", "authors": ["Bodong Chen", "Alyssa F. Wise", "Simon Knight", "Britte Haugan Cheng"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "LAK16 workshop: extending IMS caliper analytics\u2122 with learning activity profiles", "pages": "490-491", "doi": "10.1145/2883851.2883858", "abstract": "Educational institutions are evolving away from the one-application-fits-all learning management system to a loosely connected digital learning ecosystem comprising diverse services that increasingly leverage data analytics to drive pedagogical innovation. Yet an ecosystem rich in services but lacking a common approach to measuring learning activity will find data collection, aggregation and analysis time-consuming and costly. The IMS Caliper Analytics\u2122 specification addresses the need for data and semantic interoperability by providing an extensible information model, controlled vocabularies and an API for instrumenting learning applications and systems that log learning events. However, many learning activities have yet to be modeled by the Caliper working group. Engaging the SoLAR community directly in this effort will help ensure that the needs of researchers and other consumers of learning analytics data will inform future versions of the specification. The LAK16 Caliper workshop is being offered with this goal in mind. The half-day session, facilitated by members of Team Caliper, will provide LAK16 participants with an opportunity to extend the Caliper specification by modeling new learning activity profiles. New profiles, new connections and new friendships are expected outcomes.", "authors": ["Anthony Whyte", "Prashant Nayak", "John Johnston"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "Ethical and privacy issues in the design of learning analytics applications", "pages": "492-493", "doi": "10.1145/2883851.2883933", "abstract": "Issues related to Ethics and Privacy have become a major stumbling block in application of Learning Analytics technologies on a large scale. Recently, the learning analytics community at large has more actively addressed the EP4LA issues, and we are now starting to see learning analytics solutions that are designed not only as an afterthought, but also with these issues in mind. The 2nd EP4LA@LAK16 workshop will bring the discussion on ethics and privacy for learning analytics to a the next level, helping to build an agenda for organizational and technical design of LA solutions, addressing the different processes of a learning analytics workflow.", "authors": ["Hendrik Drachsler", "Tore Hoel", "Adam Cooper", "G\u00e1bor Kismih\u00f3k", "Alan Berg", "Maren Scheffel", "Weiqin Chen", "Rebecca Ferguson"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "Learning analytics for curriculum and program quality improvement (PCLA 2016)", "pages": "494-495", "doi": "10.1145/2883851.2883899", "abstract": "This workshop on Learning Analytics for Curriculum and Program Quality Improvement investigates how LAK can drive improvements in teaching practices, instructional and curricular design, and academic program delivery. This workshop brings forward research and examples of how LAK can help build the case for instructional, curricular, or programmatic change and further how LAK can be used to foster acceptance of change processes by teachers, administrators, and other stakeholders in the educational enterprise.", "authors": ["Jim Greer", "Marco Molinaro", "Xavier Ochoa", "Timothy McKay"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "LAL workshop: learning analytics for learners", "pages": "496-497", "doi": "10.1145/2883851.2883852", "abstract": "With the arrival of 'big data; in education, the potential was recognised for learning analytics to track students' learning, to reveal patterns in their learning, or to identify at-risk students, in addition to guiding reform and supporting educators in improving teaching and learning processes [1]. Learning Analytics dashboards have been used at all levels, including institutional, regional and national level [2]. In classroom use, while learning visualisations are often based on counts of activity data or interaction patterns, there is increasing recognition that learning analytics relate to learning, and should therefore provide pedagogically useful information [3]. While increasing numbers of technology-enhanced learning applications are embracing the potential of learning analytics at the classroom level, often these are aimed at teachers. However, learners can also benefit from learning analytics data (e.g. [4][5]).", "authors": ["S. Bull", "B. Ginon", "J. Kay", "M. Kickmeier-Rust", "M. D. Johnson"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "Multimodal learning analytics data challenges", "pages": "498-499", "doi": "10.1145/2883851.2883913", "abstract": "This is a proposal for organizing a Multimodal Learning Analytics (MLA) data challenge as part of the workshop offering of the Learning Analytics and Knowledge (LAK) conference. It explains the motivation of the event, its objectives, target groups, expected format, organization, dissemination strategy and schedule.", "authors": ["Xavier Ochoa", "Marcelo Worsley", "Nadir Weibel", "Sharon Oviatt"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "Data literacy for learning analytics", "pages": "500-501", "doi": "10.1145/2883851.2883864", "abstract": "This workshop explores how data literacy impacts on learning analytics both for practitioners and for end users. The term data literacy is used to broadly describe the set of abilities around the use of data as part of everyday thinking and reasoning for solving real-world problems. It is a skill required both by learning analytics practitioners to derive actionable insights from data and by the intended end users, such that it affects their ability to accurately interpret and critique presented analysis of data. The latter is particularly important, since learning analytics outcomes can be targeted at a wide range of end users, some of whom will be young students and many of whom are not data specialists. Whilst data literacy is rarely an end goal of learning analytics projects, this workshop aims to find where issues related to data literacy have impacted on project outcomes and where important insights have been gained. This workshop will further encourage the sharing of knowledge and experience through practical activities with datasets and visualisations. This workshop aims to highlight the need for a greater understanding of data literacy as a field of study, especially with regard to communicating around large, complex, data sets.", "authors": ["Annika Wolff", "John Moore", "Zdenek Zdrahal", "Martin Hlosta", "Jakub Kuzilek"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "Smart environments and analytics on video-based learning", "pages": "502-504", "doi": "10.1145/2883851.2883898", "abstract": "The International Workshop of Smart Environments and Analytics on Video-Based Learning (SE@VBL) aims to connect research efforts on Video-Based Learning with Smart Environments and Analytics to create synergies between these fields. The main objective is to build a research community around the intersection of these topical areas. In particular, SE@VBL aims to develop a critical discussion about the next generation of video-based learning environments and their analytics, the form of these analytics and the way they can be analyzed in order to help us to better understand and improve the value of educational videos to support teaching and learning. SE@VBL is based on the rationale that combining and analyzing learners' interactions with other available data obtained from learners, new avenues for research on video-based learning have emerged. This can have a significant impact in current educational trends such as Massive Open Online Courses (MOOCs) and Flipped Classroom.", "authors": ["Michail N. Giannakos", "Demetrios G. Sampson", "\u0141ukasz Kidzi\u0144ski", "Abelardo Pardo"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "Introduction to data mining for educational researchers", "pages": "505-506", "doi": "10.1145/2883851.2883879", "abstract": "The goal of this tutorial is to share data mining tools and techniques used by computer scientists with educational social scientists. We broadly define educational social scientists as being made up of people with backgrounds in the learning sciences, cognitive psychology, and educational research. The learning analytics community is heavily populated with researchers of these backgrounds, and we believe those that find themselves at the intersection of research, theory, and practice have a particular interest in expanding their knowledge of datadriven tools and techniques.", "authors": ["Christopher A. Brooks", "Craig Thompson", "Vitomir Kovanovi\u0107"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "Educational data mining with Python and Apache spark: a hands-on tutorial", "pages": "507-508", "doi": "10.1145/2883851.2883857", "abstract": "Enormous amount of educational data has been accumulated through Massive Open Online Courses (MOOCs), as well as commercial and non-commercial learning platforms. This is in addition to the educational data released by US government since 2012 to facilitate disruption in education by making data freely available. The high volume, variety and velocity of collected data necessitate use of big data tools and storage systems such as distributed databases for storage and Apache Spark for analysis. This tutorial will introduce researchers and faculty to real-world applications involving data mining and predictive analytics in learning sciences. In addition, the tutorial will introduce statistics required to validate and accurately report results. Topics will cover how big data is being used to transform education. Specifically, we will demonstrate how exploratory data analysis, data mining, predictive analytics, machine learning, and visualization techniques are being applied to educational big data to improve learning and scale insights driven from millions of student's records. The tutorial will be held over a half day and will be hands on with pre-posted material. Due to the interdisciplinary nature of work, the tutorial appeals to researchers from a wide range of backgrounds including big data, predictive analytics, learning sciences, educational data mining, and in general, those interested in how big data analytics can transform learning. As a prerequisite, attendees are required to have familiarity with at least one programming language.", "authors": ["Lalitha Agnihotri", "Shirin Mojarad", "Nicholas Lewkow", "Alfred Essa"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "LAK failathon", "pages": "509-511", "doi": "10.1145/2883851.2883918", "abstract": "As in many fields, most papers in the learning analytics literature report success or, at least, read as if they are reporting success. This is almost certainly not because learning analytics research and activity are always successful. Generally, we report our successes widely, but keep our failures to ourselves. As Bismarck is alleged to have said: it is wise to learn from the mistakes of others. This workshop offers an opportunity for researchers and practitioners to share their failures in a lower-stakes environment, to help them learn from each other's mistakes.", "authors": ["Doug Clow", "Rebecca Ferguson", "Leah Macfadyen", "Paul Prinsloo", "Sharon Slade"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "Learning through goal setting", "pages": "512-513", "doi": "10.1145/2883851.2883859", "abstract": "Despite the mounting evidence supporting the role that goal setting has on the learning process, there seems to be only a handful of studies that directly investigate goal setting in the context of Learning Analytics (LA). Although investigations have incorporated elements of goal setting, the attention afforded to theory and operationalization have been modest. In this workshop we plan to position goal setting at the forefront of LA research. The workshop will serve as a venue to bring together researchers interested in advancing Goal Setting (GS) research in the LA field. Topics include: (1) GS theory and measurement; (2) analysis and visualization of GS data; (3) strategies for integrating GS in the learning experience; and (4) implementation of GS technologies. Participants who need tools to execute their GS ideas and those who already have tools and are exploring better ways to integrate a goal setting feature can gain a lot from this workshop. Moreover, participants will have the opportunity to contribute to the conceptualization and staging of GS ideas in LA research.", "authors": ["Stefan Mol", "Vladimer Kobayashi", "G\u00e1bor Kismih\u00f3k", "Catherine Zhao"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "Learning analytics in a flipped university course", "pages": "514-515", "doi": "10.1145/2883851.2883874", "abstract": "In this poster, we describe the design of a university course with a blended learning character. Learning analytics were used both within the course to facilitate effective teacher-student interaction, as well as after the course to examine patterns between students' activities during the course and their performance on the test and the group assignment at the end of the course.", "authors": ["Anouschka van Leeuwen"], "session": "POSTER SESSION: Posters"}, {"title": "Multimodal analytics to study collaborative problem solving in pair programming", "pages": "516-517", "doi": "10.1145/2883851.2883877", "abstract": "Collaborative problem solving (CPS) is seen as a key skill in K-12 education---in computer science as well as other subjects. Efforts to introduce children to computing rely on pair programming as a way of having young learners engage in CPS. Characteristics of quality collaboration are joint exploring or understanding, joint representation, and joint execution. We present a data driven approach to assessing and elucidating collaboration through modeling of multimodal student behavior and performance data.", "authors": ["Shuchi Grover", "Marie Bienkowski", "Amir Tamrakar", "Behjat Siddiquie", "David Salter", "Ajay Divakaran"], "session": "POSTER SESSION: Posters"}, {"title": "Automating assessment of collaborative writing quality in multiple stages: the case of wiki", "pages": "518-519", "doi": "10.1145/2883851.2883963", "abstract": "This study attempts to investigate to what extent indicators of academic writing and cognitive thinking can help measure the writing quality of group collaborative writings on Wikis. Particularly, comparisons were made on Wiki content in different stages of the projects. Preliminary results from a multiple linear regression analysis reveal that linguistic indicators such as engagement markers and self-mention were significant predictors in earlier stages to the projects, whereas verbs indicating cognitive thinking in the evaluation level were significant in later project stages.", "authors": ["Xiao Hu", "Tzi-Dong Jeremy Ng", "Lu Tian", "Chi-Un Lei"], "session": "POSTER SESSION: Posters"}, {"title": "Learning analytics community exchange: evidence hub", "pages": "520-521", "doi": "10.1145/2883851.2883878", "abstract": "This poster sets out the background and development of the LACE Evidence Hub, a site that gathers evidence about learning analytics in an accessible form. The poster also describes the functionality of the site, summarises its quantitative and thematic content to date, and assesses the state of evidence. In addition, it encourages people to add to and make use of the Hub.", "authors": ["Rebecca Ferguson", "Doug Clow"], "session": "POSTER SESSION: Posters"}, {"title": "Exploring the interplay between human and machine annotated multimodal learning analytics in hands-on STEM activities", "pages": "522-523", "doi": "10.1145/2883851.2883920", "abstract": "This poster explores how to develop a working framework for STEM education that uses both human annotated and machine data across a purpose-built learning environment. Our dual approach is to develop a robust framework for analysis and investigate how to design a learning analytics system to support hands-on engineering design tasks. Data from the first user tests are presented along with the framework for discussion.", "authors": ["Daniel Spikol", "Katerina Avramides", "Mutlu Cukurova", "Bahtijar Vogel", "Rose Luckin", "Emanuele Ruffaldi", "Manolis Mavrikis"], "session": "POSTER SESSION: Posters"}, {"title": "Using machine analysis to make elementary students' mathematical thinking visible", "pages": "524-525", "doi": "10.1145/2883851.2883922", "abstract": "The INK-12: Teaching and Learning Using Interactive Ink Inscriptions in K-12 project has been developing and investigating the use of pen-based technology in elementary math classes. This paper reports on progress made on machine analysis of students' visual representations created using digital tools developed to support learning multiplication and division. The goal of the analysis is to make student thinking visible in order to (a) better understand how students learn multiplication and division, and (b) provide feedback to teachers, e.g., about strategies students use to solve problems. Student work from a five-week trial in a third grade class provides a corpus for development and evaluation of the machine analysis routines. Preliminary findings indicate that the routines can reproduce human analyses.", "authors": ["Kimberle Koile", "Andee Rubin", "Steve Chapman", "Marlene Kliman", "Lily Ko"], "session": "POSTER SESSION: Posters"}, {"title": "Benchmarking student performance and engagement in an early alert predictive system using interactive radar charts", "pages": "526-527", "doi": "10.1145/2883851.2883940", "abstract": "This poster synthesizes the design features of a visualization layer applied on the Open Academic Analytics Initiative (OAAI), an open source academic early alert system based on predictive analytics. The poster explores ways to convey the predictive model outputs and benchmark student performances using visually intuitive radar plots.", "authors": ["Sandeep M. Jayaprakash", "Eitel J. M. Laur\u00eda", "Pritesh Gandhi", "Dinesh Mendhe"], "session": "POSTER SESSION: Posters"}, {"title": "Student affect during learning with a MOOC", "pages": "528-529", "doi": "10.1145/2883851.2883960", "abstract": "This paper presents affect data collected from periodic emotion detection surveys throughout an introductory Statistics MOOC called \"I Heart Stats.\" This is the first MOOC, to our knowledge, to capture valuable student affect data through self-reported surveys. To collect student affect, we used two self-reporting methods: (1) The Self-Assessment Manikin and (2) A discrete emotion list. We found that the most common reported MOOC emotion was Hope followed by Enjoyment and Contentment. There were substantial shifts in affective states over the course, notably with Anxiety and Pride. The most valuable result of our study is a preliminary description of the methods for collecting self-reported student affect at scale in a MOOC setting.", "authors": ["John Dillon", "G. Alex Ambrose", "Nirandika Wanigasekara", "Malolan Chetlur", "Prasenjit Dey", "Bikram Sengupta", "Sidney K. D'Mello"], "session": "POSTER SESSION: Posters"}, {"title": "Integrating physical activity data in videogames with user-centered dashboards", "pages": "530-531", "doi": "10.1145/2883851.2883958", "abstract": "To promote healthy awareness and activity learning, we gave 12-to 14-year-old youth activity monitors (Fitbits) to track their physical activity, which was then integrated into a videogame we created. The players' real-world steps transform into in-game resources needed for gameplay. In addition to requiring real-world steps for various in-game activities, a dashboard in this game presents visual representations of activity patterns, ostensibly informing students about patterns of their own activity. In this paper and poster, we discuss challenges in initial designs of our dashboard. We present findings and challenges in the process of creating a user-centered dashboard and conclude with our future design goals.", "authors": ["Danielle Hagood", "Cynthia Carter Ching", "Sara Schaefer"], "session": "POSTER SESSION: Posters"}, {"title": "Understanding learning at a glance: an overview of learning dashboard studies", "pages": "532-533", "doi": "10.1145/2883851.2883930", "abstract": "Research on learning dashboards aims to identify what data is meaningful to different stakeholders in education, and how data can be presented to support sense-making processes. This paper summarizes the main outcomes of a systematic literature review on learning dashboards, in the fields of Learning Analytics and Educational Data Mining. The query was run in five main academic databases and enriched with papers coming from GScholar, resulting in 346 papers out of which 55 were included in the final analysis. Our review distinguishes different kinds of research studies as well as different aspects of learning dashboards and their maturity in terms of evaluation. As the research field is still relatively young, many of the studies are exploratory and proof-of-concept. Among the main open issues and future lines of work in the area of learning dashboards, we identify the need for longitudinal research in authentic settings, as well as studies that systematically compare different dashboard design options.", "authors": ["Beat A. Schwendimann", "Mar\u00eda Jes\u00fas Rodr\u00edguez-Triana", "Andrii Vozniuk", "Luis P. Prieto", "Mina Shirvani Boroujeni", "Adrian Holzer", "Denis Gillet", "Pierre Dillenbourg"], "session": "POSTER SESSION: Posters"}, {"title": "Reviewing three case-studies of learning analytics interventions at the open university UK", "pages": "534-535", "doi": "10.1145/2883851.2883886", "abstract": "This study provides a conceptual framework how organizations may adopt evidence-based interventions at scale, and how institutions may evaluate the costs and benefits of such interventions. Building on a new conceptual model developed by the Open University UK (OU), we will analyse three case-studies of evidence-based interventions. By working with 90+ large-scale modules for a period of two years across the five faculties and disciplines within the OU, Analytics4Action provides a bottom-up-approach for working together with key stakeholders within their respective contexts. Using principles of embedded case-study approaches by Yin [1], by comparing the learning behavior, satisfaction and performance of 11079 learners the findings indicated that each of the three learning designs led to satisfied students and average to good student retention. In the second part we highlighted that the three module teams made in-presentation interventions based upon real-time analytics, whereby initial user data indicated VLE behaviour in line with expectations. In 2-5 years, we hope that a rich, robust evidence-base will be presented to show how learning analytics can help teachers to make informed, timely and successful interventions that will help learners to achieve their learning outcomes.", "authors": ["Bart Rienties", "Avinash Boroowa", "Simon Cross", "Lee Farrington-Flint", "Christothea Herodotou", "Lynda Prescott", "Kevin Mayles", "Tom Olney", "Lisette Toetenel", "John Woodthorpe"], "session": "POSTER SESSION: Posters"}, {"title": "Analyzing students' intentionality towards badges within a case study using Khan academy", "pages": "536-537", "doi": "10.1145/2883851.2883947", "abstract": "One of the most common gamification techniques in education is the use of badges as a reward for making specific student actions. We propose two indicators to gain insight about students' intentionality towards earning badges and use them with data from 291 students interacting with Khan Academy courses. The intentionality to earn badges was greater for repetitive badges, and this can be related to the fact that these are easier to achieve. We provide the general distribution of students depending on these badge indicators, obtaining different profiles of students which can be used for adaptation purposes.", "authors": ["Jos\u00e9 A. Ruip\u00e9rez-Valiente", "Pedro J. Mu\u00f1oz-Merino", "Carlos Delgado Kloos"], "session": "POSTER SESSION: Posters"}, {"title": "Learning analytics in practice: the effects of adaptive educational technology Snappet on students' arithmetic skills", "pages": "538-539", "doi": "10.1145/2883851.2883892", "abstract": "Even though the recent influx of tablets in primary education goes together with the vision that educational technology empowered with learning analytics will revolutionize education, empirical results supporting this claim are scares. Adaptive educational technology Snappet combines extracted and embedded learning analytics daily in classrooms. While students make exercises on the tablet this technology displays real-time data of learner performance in a teacher dashboard (extracted analytics). At the same time, learner performance is used to adaptively adjust exercises to students' progress (embedded analytics). This quasiexperimental study compares the development of students' arithmetic skills over one schoolyear (grade 2 and 4) in a traditional paper based setting to learning with the adaptive educational technology Snappet. The results indicate that students in the Snappet condition make significantly more progress on arithmetic skills in grade 4. Moreover, in this grade students with a high ability level, benefit the most from working with this adaptive educational technology. Overall the development pattern of students with different abilities was more divergent in the AET condition compared to the control condition. These results indicate that adaptive educational technologies combining extracted and embedded learning analytics are indeed creating new education scenarios that contribute to personalized learning in primary education.", "authors": ["Inge Molenaar", "Carolien Knoop van Campen"], "session": "POSTER SESSION: Posters"}, {"title": "Elaborating data intensive research methods through researcher-practitioner partnerships", "pages": "540-541", "doi": "10.1145/2883851.2883908", "abstract": "Technologies used by teachers and students generate vast amounts of data that can be analyzed to provide insights into improving teaching and learning. However, practitioners are left out of the process. We describe the development of an approach by which researchers and practitioners can work together to use data intensive research methods to launch improvement efforts within schools. This paper describes elements of the first year of a researcher-practitioner partnership, highlighting initial findings, challenges, and strategies for overcoming these challenges.", "authors": ["Mingyu Feng", "Andrew E. Krumm", "Alex J. Bowers", "Timothy Podkul"], "session": "POSTER SESSION: Posters"}, {"title": "Pipeline for expediting learning analytics and student support from data in social learning", "pages": "542-543", "doi": "10.1145/2883851.2883912", "abstract": "An important research problem in learning analytics is to expedite the cycle of data leading to the analysis of student progress and the improvement of student support. For this goal in the context of social learning, we propose a pipeline that includes data infrastructure, learning analytics, and intervention, along with computational models for individual components. Next, we describe an example of applying this pipeline to real data in a case study, whose goal is to investigate the positive effects that goal-setting students have on their peers, which suggests ways in which we might foster these social benefits through intervention.", "authors": ["Yohan Jo", "Gaurav Tomar", "Oliver Ferschke", "Carolyn Penstein Ros\u00e9", "Dragan Ga\u0161evi\u0107"], "session": "POSTER SESSION: Posters"}, {"title": "The dutch xAPI experience", "pages": "544-545", "doi": "10.1145/2883851.2883968", "abstract": "We present the collected experiences since 2012 of the Dutch Special Interest Group (SIG) for Learning Analytics in the application of the xAPI standard. We have been experimenting and exchanging best practices around the application of xAPI in various contexts. The practices include different design patterns centered around Learning Record Stores. We present three projects that apply xAPI in very different ways and publish a consistent set of xAPI recipes.", "authors": ["Alan Berg", "Maren Scheffel", "Hendrik Drachsler", "Stefaan Ternier", "Marcus Specht"], "session": "POSTER SESSION: Posters"}, {"title": "Validity: a framework for cross-disciplinary collaboration in mining indicators of learning from MOOC forums", "pages": "546-547", "doi": "10.1145/2883851.2883956", "abstract": "Two research teams from the University of Melbourne's Learning Analytics Research Group used validation as applied in educational measurement to provide a framework for collaboration. One team was focussed on defining and building measures of learning capability of MOOCs participants, and the other on using topic modelling to discover topics in MOOC forums. The collaboration explored the suitability of items discovered from MOOC forums using topic modelling as measures of learning capability of participants in MOOCs.", "authors": ["Sandra Milligan", "Jiazhen He", "James Bailey", "Rui Zhang", "Benjamin I. P Rubinstein"], "session": "POSTER SESSION: Posters"}, {"title": "The connected learning analytics toolkit", "pages": "548-549", "doi": "10.1145/2883851.2883881", "abstract": "This demonstration introduces the Connected Learning Analytics (CLA) Toolkit. The CLA toolkit harvests data about student participation in specified learning activities across standard social media environments, and presents information about the nature and quality of the learning interactions.", "authors": ["Kirsty Kitto", "Aneesha Bakharia", "Mandy Lupton", "Dann Mallet", "John Banks", "Peter Bruza", "Abelardo Pardo", "Simon Buckingham Shum", "Shane Dawson", "Dragan Ga\u0161evi\u0107", "George Siemens", "Grace Lynch"], "session": "DEMONSTRATION SESSION: Demos"}, {"title": "Wikiglass: a learning analytic tool for visualizing collaborative wikis of secondary school students", "pages": "550-551", "doi": "10.1145/2883851.2883966", "abstract": "This demo presents Wikiglass, a learning analytic tool for visualizing the statistics and timelines of collaborative Wikis built by secondary school students during their group project in inquiry-based learning. The tool adopts a modular structure for the flexibility of reuse with different data sources. The client side is built with the Model-View-Controller framework and the AngularJS library whereas the server side manages the database and data sources. The tool is currently used by secondary teachers in Hong Kong and is undergoing evaluation and improvement.", "authors": ["Xiao Hu", "Jason Ip", "Koossulraj Sadaful", "George Lui", "Sam Chu"], "session": "DEMONSTRATION SESSION: Demos"}, {"title": "Demonstration of the Unizin sentiment visualizer", "pages": "552-553", "doi": "10.1145/2883851.2883903", "abstract": "While much promise has been demonstrated in the learning analytics field with sentiment analysis, the analyses are typically post hoc. The Unizin Sentiment Visualizer demonstrates that the application of sentiment analysis in real-time provides a powerful new tool to support students in complex learning environments.", "authors": ["J. D. Freeman"], "session": "DEMONSTRATION SESSION: Demos"}]}, {"year": 2017, "papers": [{"title": "Developing a MOOC experimentation platform: insights from a user study", "pages": "1-5", "doi": "10.1145/3027385.3027398", "abstract": "In 2011, the phenomenon of MOOCs had swept the world of education and put online education in the focus of the public discourse around the world. Although researchers were excited with the vast amounts of MOOC data being collected, the benefits of this data did not stand to the expectations due to several challenges. The analyses of MOOC data are very time-consuming and labor-intensive, and require and require a highly advanced set of technical skills, often not available to the education researchers. Because of this MOOC data analyses are rarely done before the courses end, limiting the potential of data to impact the student learning outcomes and experience. In this paper we introduce MOOCito (MOOC intervention tool), a user-friendly software platform for the analysis of MOOC data, that focuses on conducting data-informed instructional interventions and course experimentations. We cover important design principles behind MOOCito and provide an overview of the trends in MOOC research leading to its development. Although a work-in-progress, in this paper, we outline the prototype of MOOCito and the results of a user evaluation study that focused on system's perceived usability and ease-of-use. The results of the study are discussed, as well as their practical implications.", "authors": ["Vitomir Kovanovi\u0107", "Sre\u0107ko Joksimovi\u0107", "Philip Katerinopoulos", "Charalampos Michail", "George Siemens", "Dragan Ga\u0161evi\u0107"], "session": "SESSION: LA infrastructure"}, {"title": "Ouroboros: early identification of at-risk students without models based on legacy data", "pages": "6-15", "doi": "10.1145/3027385.3027449", "abstract": "This paper focuses on the problem of identifying students, who are at risk of failing their course. The presented method proposes a solution in the absence of data from previous courses, which are usually used for training machine learning models. This situation typically occurs in new courses. We present the concept of a \"self-learner\" that builds the machine learning models from the data generated during the current course. The approach utilises information about already submitted assessments, which introduces the problem of imbalanced data for training and testing the classification models. There are three main contributions of this paper: (1) the concept of training the models for identifying at-risk students using data from the current course, (2) specifying the problem as a classification task, and (3) tackling the challenge of imbalanced data, which appears both in training and testing data. The results show the comparison with the traditional approach of learning the models from the legacy course data, validating the proposed concept.", "authors": ["Martin Hlosta", "Zdenek Zdrahal", "Jaroslav Zendulka"], "session": "SESSION: Students at-risk - studies"}, {"title": "Impact of student choice of content adoption delay on course outcomes", "pages": "16-20", "doi": "10.1145/3027385.3027437", "abstract": "It is difficult for a student to succeed in a course without access to course materials and assignments; and yet, some students delay up to a month in obtaining access to these essential materials. Students delay buying material required for their course due to multiple reasons. Out of a concern for students with limited financial resources, some publishers offer a period of free courtesy access. But this may lead to students having access later in the course but then having a lapsed period until they pay for the materials after the courtesy access period ends. Not having key course materials early on probably hurts learning, but how much? In this paper, we investigate the question, \"Does lack of access to instructional material impact student performance in blended learning courses?\" Specifically, we analyze students who purchased and obtained access to online content at different points in the course. We determine that both types of failure to obtain access to course materials (delaying in signing up for the product, or signing up for a free trial and letting the trial period lapse without purchasing the materials) are associated with substantially worse student outcomes. Students who purchased the product within the first few days of class had the best scores (median 77). Those who waited two weeks before accessing the product did the worst (median 56, effect size Cliff's Delta=0.31 1). We conclude with a discussion of possible interventions and actions that can be taken to ameliorate the situation.", "authors": ["Lalitha Agnihotri", "Alfred Essa", "Ryan Baker"], "session": "SESSION: Students at-risk - studies"}, {"title": "Detecting changes in student behavior from clickstream data", "pages": "21-30", "doi": "10.1145/3027385.3027430", "abstract": "Student clickstream data can provide valuable insights about student activities in an online learning environment and how these activities inform their learning outcomes. However, given the noisy and complex nature of this data, an on-going challenge involves devising statistical techniques that capture clear and meaningful aspects of students' click patterns. In this paper, we utilize statistical change detection techniques to investigate students' online behaviors. Using clickstream data from two large university courses, one face-to-face and one online, we illustrate how this methodology can be used to detect when students change their previewing and reviewing behavior, and how these changes can be related to other aspects of students' activity and performance.", "authors": ["Jihyun Park", "Kameryn Denaro", "Fernando Rodriguez", "Padhraic Smyth", "Mark Warschauer"], "session": "SESSION: Modelling student behaviour"}, {"title": "Modeling exploration strategies to predict student performance within a learning environment and beyond", "pages": "31-40", "doi": "10.1145/3027385.3027422", "abstract": "Modeling and predicting student learning is an important task in computer-based education. A large body of work has focused on representing and predicting student knowledge accurately. Existing techniques are mostly based on students' performance and on timing features. However, research in education, psychology and educational data mining has demonstrated that students' choices and strategies substantially influence learning. In this paper, we investigate the impact of students' exploration strategies on learning and propose the use of a probabilistic model jointly representing student knowledge and strategies. Our analyses are based on data collected from an interactive computer-based game. Our results show that exploration strategies are a significant predictor of the learning outcome. Furthermore, the joint models of performance and knowledge significantly improve the prediction accuracy within the game as well as on external post-test data, indicating that this combined representation provides a better proxy for learning.", "authors": ["Tanja K\u00e4ser", "Nicole R. Hallinen", "Daniel L. Schwartz"], "session": "SESSION: Modelling student behaviour"}, {"title": "Opportunities for personalization in modeling students as Bayesian learners", "pages": "41-45", "doi": "10.1145/3027385.3027410", "abstract": "The following paper is a proof-of-concept demonstration of a novel Bayesian framework for making inferences about individual students and the context in which they are learning. It has implications for both efforts to automate personalized instruction and to probabilistically model educational context. By modelling students as Bayesian learners, individuals who weigh their prior belief against current circumstantial data to reach conclusions, it becomes possible to both generate estimates of performance and the impact of the educational environment in probabilistic terms. This framework is tested through a Bayesian algorithm that can be used to characterize student prior knowledge in course material and predict student performance. This is demonstrated using both simulated data. The algorithm generates estimates that behave qualitatively as expected on simulated data and predict student performance substantially better than chance. A discussion of the results and the conceptual benefits of the framework follow.", "authors": ["Charles Lang"], "session": "SESSION: Modelling student behaviour"}, {"title": "An elephant in the learning analytics room: the obligation to act", "pages": "46-55", "doi": "10.1145/3027385.3027406", "abstract": "As higher education increasingly moves to online and digital learning spaces, we have access not only to greater volumes of student data, but also to increasingly fine-grained and nuanced data. A significant body of research and existing practice are used to convince key stakeholders within higher education of the potential of the collection, analysis and use of student data to positively impact on student experiences in these environments. Much of the recent focus in learning analytics is around predictive modeling and uses of artificial intelligence to both identify learners at risk, and to personalize interventions to increase the chance of success. In this paper we explore the moral and legal basis for the obligation to act on our analyses of student data. The obligation to act entails not only the protection of student privacy and the ethical collection, analysis and use of student data, but also, the effective allocation of resources to ensure appropriate and effective interventions to increase effective teaching and learning. The obligation to act is, however tempered by a number of factors, including inter and intra-departmental operational fragmentation and the constraints imposed by changing funding regimes. Increasingly higher education institutions allocate resources in areas that promise the greatest return. Choosing (not) to respond to the needs of specific student populations then raises questions regarding the scope and nature of the moral and legal obligation to act. There is also evidence that students who are at risk of failing often do not respond to institutional interventions to assist them. In this paper we build and expand on recent research by, for example, the LACE and EP4LA workshops to conceptually map the obligation to act which flows from both higher education's mandate to ensure effective and appropriate teaching and learning and its fiduciary duty to provide an ethical and enabling environment for students to achieve success. We examine how the collection and analysis of student data links to both the availability of resources and the will to act and also to the obligation to act. Further, we examine how that obligation unfolds in two open distance education providers from the perspective of a key set of stakeholders - those in immediate contact with students and their learning journeys - the tutors or adjunct faculty.", "authors": ["Paul Prinsloo", "Sharon Slade"], "session": "SESSION: Learning analytics ethics"}, {"title": "Where is the evidence?: a call to action for learning analytics", "pages": "56-65", "doi": "10.1145/3027385.3027396", "abstract": "Where is the evidence for learning analytics? In particular, where is the evidence that it improves learning in practice? Can we rely on it? Currently, there are vigorous debates about the quality of research evidence in medicine and psychology, with particular issues around statistical good practice, the 'file drawer effect', and ways in which incentives for stakeholders in the research process reward the quantity of research produced rather than the quality. In this paper, we present the Learning Analytics Community Exchange (LACE) project's Evidence Hub, an effort to relate research evidence in learning analytics to four propositions about learning analytics: whether they support learning, support teaching, are deployed widely, and are used ethically. Surprisingly little evidence in this strong, specific sense was found, and very little was negative (7%, N=123), suggesting that learning analytics is not immune from the pressures in other areas. We explore the evidence in one particular area in detail (whether learning analytics improve teaching and learners support in the university sector), and set out some of the weaknesses of the evidence available. We conclude that there is considerable scope for improving the evidence base for learning analytics, and set out some suggestions of ways for various stakeholders to achieve this.", "authors": ["Rebecca Ferguson", "Doug Clow"], "session": "SESSION: Learning analytics ethics"}, {"title": "Student perceptions of their privacy in leaning analytics applications", "pages": "66-69", "doi": "10.1145/3027385.3027392", "abstract": "Over the past five years, ethics and privacy around student data have become major topics of conversation in the learning analytics field. However, the majority of these have been theoretical in nature. The authors of this paper posit that more direct student engagement needs to be undertaken, and initial data from institutions beginning this process is shared. We find that, while the majority of respondents are accepting of the use of their data by their institutions, approval varies depending on the proposed purpose of the analytics. There also appear to be notable variations between students enrolled at United Kingdom and American institutions.", "authors": ["Kimberly E. Arnold", "Niall Sclater"], "session": "SESSION: Learning analytics ethics"}, {"title": "Understanding student learning trajectories using multimodal learning analytics within an embodied-interaction learning environment", "pages": "70-79", "doi": "10.1145/3027385.3027429", "abstract": "The aim of this paper is to show how multimodal learning analytics (MMLA) can help understand how elementary students explore the concept of feedback loops while controlling an embodied simulation of a predator-prey ecosystem using hand movements as an interface with the computer simulation. We represent student motion patterns from fine-grained logs of hands and gaze data, and then map these observed motion patterns against levels of student performance to make inferences about how embodiment plays a role in the learning process. Results show five distinct motion sequences in students' embodied interactions, and these motion patterns are statistically associated with initial and post-tutorial levels of students' understanding of feedback loops. Analysis of student gaze also shows distinctive patterns as to how low- and high-performing students attended to information presented in the simulation. Using MMLA, we show how students' explanations of feedback loops look differently according to cluster membership, which provides evidence that embodiment interacts with conceptual understanding.", "authors": ["Alejandro Andrade"], "session": "SESSION: Understanding student behaviour - multimodal analytics"}, {"title": "Put your thinking cap on: detecting cognitive load using EEG during learning", "pages": "80-89", "doi": "10.1145/3027385.3027431", "abstract": "Current learning technologies have no direct way to assess students' mental effort: are they in deep thought, struggling to overcome an impasse, or are they zoned out? To address this challenge, we propose the use of EEG-based cognitive load detectors during learning. Despite its potential, EEG has not yet been utilized as a way to optimize instructional strategies. We take an initial step towards this goal by assessing how experimentally manipulated (easy and difficult) sections of an intelligent tutoring system (ITS) influenced EEG-based estimates of students' cognitive load. We found a main effect of task difficulty on EEG-based cognitive load estimates, which were also correlated with learning performance. Our results show that EEG can be a viable source of data to model learners' mental states across a 90-minute session.", "authors": ["Caitlin Mills", "Igor Fridman", "Walid Soussou", "Disha Waghray", "Andrew M. Olney", "Sidney K. D'Mello"], "session": "SESSION: Understanding student behaviour - multimodal analytics"}, {"title": "Analytics meet patient manikins: challenges in an authentic small-group healthcare simulation classroom", "pages": "90-94", "doi": "10.1145/3027385.3027401", "abstract": "Healthcare simulations are hands-on learning experiences aimed at allowing students to practice essential skills that they may need when working with real patients in clinical workplaces. Some clinical classrooms are equipped with patient manikins that can respond to actions or that can be programmed to deteriorate over time. Students can perform assessments and interventions, and enhance their critical thinking and communication skills. There is an opportunity to exploit the students' digital traces that these manikins can pervasively capture to make key aspects of the learning process visible. The setting can be augmented with sensors to capture traces of group interaction. These multimodal data can be used to generate visualisations or feedback for students or teachers. This paper reports on an authentic classroom study using analytics to integrate multimodal data of students' interactions with the manikins and their peers in simulation scenarios. We report on the challenges encountered in deploying such analytics 'in the wild', using an analysis framework that considers the social, epistemic and physical dimensions of collocated group activity.", "authors": ["Roberto Martinez-Maldonado", "Tamara Power", "Carolyn Hayes", "Adrian Abdiprano", "Tony Vo", "Carmen Axisa", "Simon Buckingham Shum"], "session": "SESSION: Understanding student behaviour - multimodal analytics"}, {"title": "How to assign students into sections to raise learning", "pages": "95-104", "doi": "10.1145/3027385.3027439", "abstract": "Grouping students with similar past achievement together (tracking) might affect their reading achievement. Multilevel analyses of 208,057 fourth grade students in 40 countries showed that clustering students in schools by past achievement was linked to higher reading achievement, consistent with the benefits of customized, targeted instruction. Meanwhile, students had higher reading achievement with greater differences (variances) among classmates' past achievement, reading attitudes, or family SES; these results are consistent with the view that greater student differences yield more help opportunities (higher achievers help lower achievers, so that both learn), and foster learning from their different resources, attitudes and behaviors. Also, a student had higher reading achievement when classmates had more resources (SES, home educational resources, reading attitude, past achievement), suggesting that classmates shared their resources and helped one another. Modeling of non-linear relations and achievement subsamples of students supported the above interpretations. Principals can use these results and a simpler version of this methodology to re-allocate students and resources into different course sections at little cost to improve students' reading achievement.", "authors": ["Ming Ming Chiu", "Bonnie Wing-Yin Chow", "Sung Wook Joh"], "session": "SESSION: Improving learning"}, {"title": "Improving learning through achievement priming in crowdsourced information finding microtasks", "pages": "105-114", "doi": "10.1145/3027385.3027402", "abstract": "Crowdsourcing has become an increasingly popular means to acquire human input on demand. Microtask crowdsourcing market-places facilitate the access to millions of people (called workers) who are willing to participate in tasks in return for monetary rewards or other forms of compensation. This paradigm presents a unique learning context where workers have to learn to complete tasks on-the-fly by applying their learning immediately through the course of tasks. However, most workers typically dropout early in large batches of tasks, depriving themselves of the opportunity to learn on-the-fly through the course of batch completion. By doing so workers squander a potential chance at improving their performance and completing tasks effectively. In this paper, we propose a novel method to engage and retain workers, to improve their learning in crowdsourced information finding tasks by using achievement priming. Through rigorous experimental findings, we show that it is possible to retain workers in long batches of tasks by triggering their inherent motivation to achieve and excel. As a consequence of increased worker retention, we find that workers learn to perform more effectively, depicting relatively more stable accuracy and lower task completion times in comparison to workers who drop out early.", "authors": ["Ujwal Gadiraju", "Stefan Dietze"], "session": "SESSION: Improving learning"}, {"title": "Exploring the asymmetry of metacognition", "pages": "115-119", "doi": "10.1145/3027385.3027388", "abstract": "People in general and students in particular have a tendency to misinterpret their own abilities. Some tend to underestimate their skills, while others tend to overestimate them. This paper investigates the degree to which metacognition is asymmetric in real-world learning and examines the change of a students' confidence over the course of a semester and its impact on the students' academic performance. Our findings, conducted using 129,644 students learning in eight courses within the LearnSmart platform, indicate that poor or unrealistic metacognition is asymmetric. These students are biased in one direction: they are more likely to be overconfident than underconfident. Additionally, while the examination of the temporal aspects of confidence reveals no significant change throughout the semester, changes are more apparent in the first and the last few weeks of the course. More specifically, there is a sharp increase in underconfidence and a simultaneous decrease in realistic evaluation toward the end of the semester. Finally, both overconfidence and underconfidence seem to be correlated with students' overall course performance. An increase in overconfidence is related to higher overall performance, while an increase in underconfidence is associated with lower overall performance.", "authors": ["Ani Aghababyan", "Nicholas Lewkow", "Ryan Baker"], "session": "SESSION: Improving learning"}, {"title": "Temporal analytics with discourse analysis: tracing ideas and impact on communal discourse", "pages": "120-127", "doi": "10.1145/3027385.3027386", "abstract": "This paper presents a study of temporal analytics and discourse analysis of an online discussion, through investigation of a group of 13 in-service teachers and 2 instructors. A discussion forum consisting of 281 posts on an online collaborative learning environment was investigated. A text-mining tool was used to discover keywords from the discourse, and through social network analysis based on these keywords, a significant presence of relevant and promising ideas within discourse was revealed. However, uncovering the key ideas alone is insufficient to clearly explain students' level of understanding regarding the discussed topics. A more thorough analysis was thus performed by using temporal analytics with step-wise discourse analysis to trace the ideas and determine their impact on communal discourse. The results indicated that most ideas within the discourse could be traced to the origin of a set of improvable ideas, which impacted and also increased the community's level of interest in sharing and discussing ideas through discourse.", "authors": ["Alwyn Vwen Yen Lee", "Seng Chee Tan"], "session": "SESSION: Understanding discourse I"}, {"title": "Dynamics of MOOC discussion forums", "pages": "128-137", "doi": "10.1145/3027385.3027391", "abstract": "In this integrated study of dynamics in MOOCs discussion forums, we analyze the interplay of temporal patterns, discussion content, and the social structure emerging from the communication using mixed methods. A special focus is on the yet under-explored aspect of time dynamics and influence of the course structure on forum participation. Our analyses show dependencies between the course structure (video opening time and assignment deadlines) and the over-all forum activity whereas such a clear link could only be partially observed considering the discussion content. For analyzing the social dimension we apply role modeling techniques from social network analysis. While the types of user roles based on connection patterns are relatively stable over time, the high fluctuation of active contributors lead to frequent changes from active to passive roles during the course. However, while most users do not create many social connections they can play an important role in the content dimension triggering discussions on the course subject. Finally, we show that forum activity level can be predicted one week in advance based on the course structure, forum activity history and attributes of the communication network which enables identification of periods when increased tutor supports in the forum is necessary.", "authors": ["Mina Shirvani Boroujeni", "Tobias Hecking", "H. Ulrich Hoppe", "Pierre Dillenbourg"], "session": "SESSION: Understanding discourse I"}, {"title": "Assessment of language in authentic science inquiry reveals putative differences in epistemology", "pages": "138-142", "doi": "10.1145/3027385.3027425", "abstract": "Science epistemology, or beliefs about what it means to do science and how science knowledge is generated, is an integral part of authentic science inquiry. Although the development of a sophisticated science epistemology is critical for attaining science literacy, epistemology remains an elusive construct to precisely and quantitatively evaluate. Previous work has suggested that analysis of student practices in science inquiry, such as their use of language, may be reflective of their underlying epistemologies. Here we describe the usage of a learning analytics tool, TAALES, and keyness analysis to analyze the concluding statements made by students at the end of a computer-based authentic science inquiry experience. Preliminary results indicate that linguistic analysis reveals differences in domain-general lexical sophistication and in domain-specific verb usage that are consistent with the expertise level of the participant. For example, experts tend to use more hedging language such as \"may\" and \"support\" during conclusions whereas novices use stronger language such as \"cause.\" Using these differences, a simple, rule-based prediction algorithm with LOOCV achieved prediction accuracies of greater than 80%. These data underscore the potential for the use of learning analytics in simulated authentic inquiry to provide a novel and valuable method of assessing inquiry practices and related epistemologies.", "authors": ["Melanie E. Peffer", "Kristopher Kyle"], "session": "SESSION: Understanding discourse I"}, {"title": "Predicting the decrease of engagement indicators in a MOOC", "pages": "143-147", "doi": "10.1145/3027385.3027387", "abstract": "Predicting the decrease of students' engagement in typical MOOC tasks such as watching lecture videos or submitting assignments is key to trigger timely interventions in order to try to avoid the disengagement before it takes place. This paper proposes an approach to build the necessary predictive models using students' data that becomes available during a course. The approach was employed in an experimental study to predict the decrease of three different engagement indicators in a MOOC. The results suggest its feasibility with values of area under the curve for different predictors ranging from 0.718 to 0.914.", "authors": ["Miguel L. Bote-Lorenzo", "Eduardo G\u00f3mez-S\u00e1nchez"], "session": "SESSION: Understanding student behaviour - engagement"}, {"title": "Studying engagement and performance with learning technology in an African classroom", "pages": "148-152", "doi": "10.1145/3027385.3027395", "abstract": "In this paper, we study the engagement and performance of students in a classroom using a system the Cognitive Learning Companion (CLC). CLC is designed to keep track of the relationship between the student, content interaction and learning progression. It also provides evidence-based engagement-oriented actionable insights to teachers by assessing information from a sensor-rich instrumented learning environment in order to infer a learner's cognitive and affective states. Data captured from the instrumented environment is aggregated and analyzed to create interlinked insights helping teachers identify how students engage with learning content and view their performance records on selected assignments. We conducted a 1 month pilot with 27 learners in a primary school in Nairobi, Kenya during their maths and science instructional periods. We present our primary analysis of content-level interactions and engagement at the individual student and classroom level.", "authors": ["Juliet Mutahi", "Andrew Kinai", "Nelson Bore", "Abdigani Diriye", "Komminist Weldemariam"], "session": "SESSION: Understanding student behaviour - engagement"}, {"title": "Reflective writing analytics for actionable feedback", "pages": "153-162", "doi": "10.1145/3027385.3027436", "abstract": "Reflective writing can provide a powerful way for students to integrate professional experience and academic learning. However, writing reflectively requires high quality actionable feedback, which is time-consuming to provide at scale. This paper reports progress on the design, implementation, and validation of a Reflective Writing Analytics platform to provide actionable feedback within a tertiary authentic assessment context. The contributions are: (1) a new conceptual framework for reflective writing; (2) a computational approach to modelling reflective writing, deriving analytics, and providing feedback; (3) the pedagogical and user experience rationale for platform design decisions; and (4) a pilot in a student learning context, with preliminary data on educator and student acceptance, and the extent to which we can evidence that the software provided actionable feedback for reflective writing.", "authors": ["Andrew Gibson", "Adam Aitken", "\u00c1gnes S\u00e1ndor", "Simon Buckingham Shum", "Cherie Tsingos-Lucas", "Simon Knight"], "session": "SESSION: Reflective writing"}, {"title": "Reflective writing analytics: empirically determined keywords of written reflection", "pages": "163-167", "doi": "10.1145/3027385.3027394", "abstract": "Despite their importance for educational practice, reflective writings are still manually analysed and assessed, posing a constraint on the use of this educational technique. Recently, research started to investigate automated approaches for analysing reflective writing. Foundational to many automated approaches is the knowledge of words that are important for the genre. This research presents keywords that are specific to several categories of a reflective writing model. These keywords have been derived from eight datasets, which contain several thousand instances using the log-likelihood method. Both performance measures, the accuracy and the Cohen's \u03ba, for these keywords were estimated with ten-fold cross validation. The results reached an accuracy of 0.78 on average for all eight categories and a fair to good interrater reliability for most categories even though it did not make use of any sophisticated rule-based mechanisms or machine learning approaches. This research contributes to the development of automated reflective writing analytics that are based on data-driven empirical foundations.", "authors": ["Thomas Daniel Ullmann"], "session": "SESSION: Reflective writing"}, {"title": "Unravelling the dynamics of instructional practice: a longitudinal study on learning design and VLE activities", "pages": "168-177", "doi": "10.1145/3027385.3027409", "abstract": "Substantial progress has been made in understanding how teachers design for learning. However, there remains a paucity of evidence of the actual students' response towards leaning designs. Learning analytics has the power to provide just-in-time support, especially when predictive analytics is married with the way teachers have designed their course, or so-called a learning design. This study investigates how learning designs are configured over time and their impact on student activities by analyzing longitudinal data of 38 modules with a total of 43,099 registered students over 30 weeks at the Open University UK, using social network analysis and panel data analysis. Our analysis unpacked dynamic configurations of learning designs between modules over time, which allows teachers to reflect on their practice in order to anticipate problems and make informed interventions. Furthermore, by controlling for the heterogeneity between modules, our results indicated that learning designs were able to explain up to 60% of the variability in student online activities, which reinforced the importance of pedagogical context in learning analytics.", "authors": ["Quan Nguyen", "Bart Rienties", "Lisette Toetenel"], "session": "SESSION: Learning design"}, {"title": "Sequencing content in an adaptive testing system: the role of choice", "pages": "178-182", "doi": "10.1145/3027385.3027412", "abstract": "The effect of choice on student achievement and engagement has been an extensively researched area of learning analytics. Current research findings suggest a positive relationship between choice and varied outcome measures, but little has been reported to indicate whether these findings hold in the context of Intelligent Tutoring Systems (ITS). In this paper, we report the results of a randomized controlled experiment in which we investigate the effect of student choice on assignment completion and future achievement in an ITS. The experimental design uses three conditions to observe the effect of choice. In the first condition, students are able to choose the order in which to complete assignments, while in the second condition, students are prescribed an intuitive order in which to complete assignments. Those in the third condition were prescribed a counter-intuitive order in which to complete assignments. Results indicate that allowing students to choose the order in which to work on assignments leads to higher completion rates and better achievement at posttest. A post-hoc analysis also revealed that even considering students with similar completion rates, those given choice had higher posttest scores than those observed in any other condition. These results seem to support the many theories of the positive effect of choice on student achievement.", "authors": ["Seth A. Adjei", "Anthony F. Botelho", "Neil T. Heffernan"], "session": "SESSION: Learning design"}, {"title": "ATCE: an analytics tool to trace the creation and evaluation of inclusive and accessible open educational resources", "pages": "183-187", "doi": "10.1145/3027385.3027413", "abstract": "The creation of Inclusive and Accessible Open Educational Resources (IA-OERs) is a challenge for teachers because they have to invest time and effort to create learning contents considering students' learning needs and preferences. An IA-OER is characterized by its alignment with the Universal Design Learning (UDL) principles, the quality on its contents and the web accessibility as a way to address the diversity of students. Creating an IA-OER with these characteristics is not a straightforward task, especially when teachers do not have enough information/feedback to make decisions on how to improve the learning contents. In this paper we introduce ATCE - an Analytics Tool to Trace the Creation and Evaluation of IA-OERs. This tool focuses in particular on the accessibility and quality of the IA-OERs. ATCE was developed as a module within the ATutor Learning Management System (LMS). An analytics dashboard with visualizations related to the teachers' competences in the creation and evaluation of IA-OERs was included as part of the tool. This paper also presents a use case of the visualizations obtained from the creation and evaluation of one IA-OER after using our analytics tool.", "authors": ["Cecilia Avila", "Silvia Baldiris", "Ramon Fabregat", "Sabine Graf"], "session": "SESSION: Learning design"}, {"title": "Learning pulse: a machine learning approach for predicting performance in self-regulated learning using multimodal data", "pages": "188-197", "doi": "10.1145/3027385.3027447", "abstract": "Learning Pulse explores whether using a machine learning approach on multimodal data such as heart rate, step count, weather condition and learning activity can be used to predict learning performance in self-regulated learning settings. An experiment was carried out lasting eight weeks involving PhD students as participants, each of them wearing a Fitbit HR wristband and having their application on their computer recorded during their learning and working activities throughout the day. A software infrastructure for collecting multimodal learning experiences was implemented. As part of this infrastructure a Data Processing Application was developed to pre-process, analyse and generate predictions to provide feedback to the users about their learning performance. Data from different sources were stored using the xAPI standard into a cloud-based Learning Record Store. The participants of the experiment were asked to rate their learning experience through an Activity Rating Tool indicating their perceived level of productivity, stress, challenge and abilities. These self-reported performance indicators were used as markers to train a Linear Mixed Effect Model to generate learner-specific predictions of the learning performance. We discuss the advantages and the limitations of the used approach, highlighting further development points.", "authors": ["Daniele Di Mitri", "Maren Scheffel", "Hendrik Drachsler", "Dirk B\u00f6rner", "Stefaan Ternier", "Marcus Specht"], "session": "SESSION: Self-regulated learning"}, {"title": "Transitioning self-regulated learning profiles in hypermedia-learning environments", "pages": "198-202", "doi": "10.1145/3027385.3027443", "abstract": "Self-regulated learning (SRL) is a process that highly fluctuates as students actively deploy their metacognitive and cognitive processes during learning. In this paper, we apply an extension of latent profiling, latent transition analysis (LTA), which investigates the longitudinal development of students' SRL latent class memberships over time. We will briefly review the theoretical foundations of SRL and discuss the value of using LTA to investigate this multidimensional concept. This study is based on college students (n = 75) learning about the human circulatory system while using MetaTutor, an intelligent tutoring system that adaptively supports SRL and targets specific metacognitive SRL processes including judgment of learning (JOL) and content evaluation (CE). Preliminary results identify transitional probabilities of SRL profiles from four distinct events associated with the use of SRL.", "authors": ["Clarissa Lau", "Jeanne Sinclair", "Michelle Taub", "Roger Azevedo", "Eunice Eunhee Jang"], "session": "SESSION: Self-regulated learning"}, {"title": "Expanding the scope of learning analytics data: preliminary findings on attention and self-regulation using wearable technology", "pages": "203-207", "doi": "10.1145/3027385.3027427", "abstract": "The ability to pay attention and self-regulate is a fundamental skill required of learners of all ages. Learning analytics researchers have to date relied on data generated by a computing system (such as a learning management system, click stream or log data) to examine learners' self-regulatory abilities. The development of wearable computing through fitness trackers, watches, heart rate monitors, and clinical grade devices such as Empatica's E4 wristband now provides researchers with access to biometric data as students interact with learning content or software systems. This level of data collection promises to provide valuable insight into cognitive and affective experiences of individuals, especially when combined with traditional learning analytics data sources. Our study details the use of wearable technologies to assess the relationship between heart rate variability and the self-regulatory abilities of an individual. This is relevant for the field of learning analytics as methods become more complex and the assessment of learner performance becomes more nuanced and attentive to the affective factors that contribute to learner success.", "authors": ["Catherine A. Spann", "James Schaeffer", "George Siemens"], "session": "SESSION: Self-regulated learning"}, {"title": "How effective is your facilitation?: group-level analytics of MOOC forums", "pages": "208-217", "doi": "10.1145/3027385.3027404", "abstract": "The facilitation of interpersonal relationships within a respectful learning climate is an important aspect of teaching practice. However, in large-scale online contexts, such as MOOCs, the number of learners and highly asynchronous nature militates against the development of a sense of belonging and dyadic trust. Given these challenges, instead of conventional instruments that reflect learners' affective perceptions, we suggest a set of indicators that can be used to evaluate social activity in relation to the participation structure. These group-level indicators can then help teachers to gain insights into the evolution of social activity shaped by their facilitation choices. For this study, group-level indicators were derived from measuring information exchange activity between the returning MOOC posters. By conceptualizing this group as an identity-based community, we can apply exponential random graph modelling to explain the network's structure through the configurations of direct reciprocity, triadic-level exchange, and the effect of participants demonstrating super-posting behavior. The findings provide novel insights into network amplification, and highlight the differences between the courses with different facilitation strategies. Direct reciprocation was characteristic of non-facilitated groups. Exchange at the level of triads was more prominent in highly facilitated online communities with instructor's involvement. Super-posting activity was less pronounced in networks with higher triadic exchange, and more pronounced in networks with higher direct reciprocity.", "authors": ["Oleksandra Poquet", "Shane Dawson", "Nia Dowell"], "session": "SESSION: Understanding discourse II"}, {"title": "Words matter: automatic detection of teacher questions in live classroom discourse using linguistics, acoustics, and context", "pages": "218-227", "doi": "10.1145/3027385.3027417", "abstract": "We investigate automatic detection of teacher questions from audio recordings collected in live classrooms with the goal of providing automated feedback to teachers. Using a dataset of audio recordings from 11 teachers across 37 class sessions, we automatically segment the audio into individual teacher utterances and code each as containing a question or not. We train supervised machine learning models to detect the human-coded questions using high-level linguistic features extracted from automatic speech recognition (ASR) transcripts, acoustic and prosodic features from the audio recordings, as well as context features, such as timing and turn-taking dynamics. Models are trained and validated independently of the teacher to ensure generalization to new teachers. We are able to distinguish questions and non-questions with a weighted F1 score of 0.69. A comparison of the three feature sets indicates that a model using linguistic features outperforms those using acoustic-prosodic and context features for question detection, but the combination of features yields a 5% improvement in overall accuracy compared to linguistic features alone. We discuss applications for pedagogical research, teacher formative assessment, and teacher professional development.", "authors": ["Patrick J. Donnelly", "Nathaniel Blanchard", "Andrew M. Olney", "Sean Kelly", "Martin Nystrand", "Sidney K. D'Mello"], "session": "SESSION: Understanding discourse II"}, {"title": "Towards mining sequences and dispersion of rhetorical moves in student written texts", "pages": "228-232", "doi": "10.1145/3027385.3027433", "abstract": "There is an increasing interest in the analysis of both student's writing and the temporal aspects of learning data. The analysis of higher-level learning features in writing contexts requires analyses of data that could be characterised in terms of the sequences and processes of textual features present. This paper (1) discusses the extant literature on sequential and process analyses of writing; and, based on this and our own first-hand experience on sequential analysis, (2) proposes a number of approaches to both pre-process and analyse sequences in whole-texts. We illustrate how the approaches could be applied to examples drawn from our own datasets of 'rhetorical moves' in written texts, and the potential each approach holds for providing insight into that data. Work is in progress to apply this model to provide empirical insights. Although, similar sequence or process mining techniques have not yet been applied to student writing, techniques applied to event data could readily be operationalised to undercover patterns in texts.", "authors": ["Simon Knight", "Roberto Martinez-Maldonado", "Andrew Gibson", "Simon Buckingham Shum"], "session": "SESSION: Understanding discourse II"}, {"title": "Learning analytics in higher education --- challenges and policies: a review of eight learning analytics policies", "pages": "233-242", "doi": "10.1145/3027385.3027400", "abstract": "This paper presents the results of a review of eight policies for learning analytics of relevance for higher education, and discusses how these policies have tried to address prominent challenges in the adoption of learning analytics, as identified in the literature. The results show that more considerations need to be given to establishing communication channels among stakeholders and adopting pedagogy-based approaches to learning analytics. It also reveals the shortage of guidance for developing data literacy among end-users and evaluating the progress and impact of learning analytics. Moreover, the review highlights the need to establish formalised guidelines to monitor the soundness, effectiveness, and legitimacy of learning analytics. As interest in learning analytics among higher education institutions continues to grow, this review will provide insights into policy and strategic planning for the adoption of learning analytics.", "authors": ["Yi-Shan Tsai", "Dragan Gasevic"], "session": "SESSION: Learning analytics policies"}, {"title": "The influence of data protection and privacy frameworks on the design of learning analytics systems", "pages": "243-252", "doi": "10.1145/3027385.3027414", "abstract": "Learning analytics open up a complex landscape of privacy and policy issues, which, in turn, influence how learning analytics systems and practices are designed. Research and development is governed by regulations for data storage and management, and by research ethics. Consequently, when moving solutions out the research labs implementers meet constraints defined in national laws and justified in privacy frameworks. This paper explores how the OECD, APEC and EU privacy frameworks seek to regulate data privacy, with significant implications for the discourse of learning, and ultimately, an impact on the design of tools, architectures and practices that now are on the drawing board. A detailed list of requirements for learning analytics systems is developed, based on the new legal requirements defined in the European General Data Protection Regulation, which from 2018 will be enforced as European law. The paper also gives an initial account of how the privacy discourse in Europe, Japan, South-Korea and China is developing and reflects upon the possible impact of the different privacy frameworks on the design of LA privacy solutions in these countries. This research contributes to knowledge of how concerns about privacy and data protection related to educational data can drive a discourse on new approaches to privacy engineering based on the principles of Privacy by Design. For the LAK community, this study represents the first attempt to conceptualise the issues of privacy and learning analytics in a cross-cultural context. The paper concludes with a plan to follow up this research on privacy policies and learning analytics systems development with a new international study.", "authors": ["Tore Hoel", "Dai Griffiths", "Weiqin Chen"], "session": "SESSION: Learning analytics policies"}, {"title": "An information policy perspective on learning analytics", "pages": "253-256", "doi": "10.1145/3027385.3027389", "abstract": "Policy for learning analytics joins a stream of initiatives aimed at understanding the expanding world of information collection, storage, processing and dissemination that is being driven by computing technologies. This paper offers a information policy perspective on learning analytics, joining work by others on ethics and privacy in the management of learning analytics data [8], but extending to consider how issues play out across the information lifecycle and in the formation of policy. Drawing on principles from information policy both informs learning analytics and brings learning analytics into the information policy domain. The resulting combination can help inform policy development for educational institutions as they implement and manage learning analytics policy and practices. The paper begins with a brief summary of the information policy perspective, then addresses learning analytics with attention to various categories of consideration for policy development.", "authors": ["Caroline Haythornthwaite"], "session": "SESSION: Learning analytics policies"}, {"title": "Intelligent tutors as teachers' aides: exploring teacher needs for real-time analytics in blended classrooms", "pages": "257-266", "doi": "10.1145/3027385.3027451", "abstract": "Intelligent tutoring systems (ITSs) are commonly designed to enhance student learning. However, they are not typically designed to meet the needs of teachers who use them in their classrooms. ITSs generate a wealth of analytics about student learning and behavior, opening a rich design space for real-time teacher support tools such as dashboards. Whereas real-time dashboards for teachers have become popular with many learning technologies, we are not aware of projects that have designed dashboards for ITSs based on a broad investigation of teachers' needs. We conducted design interviews with ten middle school math teachers to explore their needs for on-the-spot support during blended class sessions, as a first step in a user-centered design process of a real-time dashboard. Based on multi-methods analyses of this interview data, we identify several opportunities for ITSs to better support teachers' needs, noting that the analytics commonly generated by existing teacher support tools do not strongly align with the analytics teachers expect to be most useful. We highlight key tensions and tradeoffs in the design of such real-time supports for teachers, as revealed by \"Speed Dating\" possible futures with teachers. This paper has implications for our ongoing co-design of a real-time dashboard for ITSs, as well as broader implications for the design of ITSs that can effectively collaborate with teachers in classroom settings.", "authors": ["Kenneth Holstein", "Bruce M. McLaren", "Vincent Aleven"], "session": "SESSION: Teacher support tools I"}, {"title": "Implementing predictive learning analytics on a large scale: the teacher's perspective", "pages": "267-271", "doi": "10.1145/3027385.3027397", "abstract": "In this paper, we describe a large-scale study about the use of predictive learning analytics data with 240 teachers in 10 modules at a distance learning higher education institution. The aim of the study was to illuminate teachers' uses and practices of predictive data, in particular identify how predictive data was used to support students at risk of not completing or failing a module. Data were collected from statistical analysis of 17,033 students' performance by the end of the intervention, teacher usage statistics, and five individual semi-structured interviews with teachers. Findings revealed that teachers endorse the use of predictive data to support their practice yet in diverse ways and raised the need for devising appropriate intervention strategies to support students at risk.", "authors": ["Christothea Herodotou", "Bart Rienties", "Avinash Boroowa", "Zdenek Zdrahal", "Martin Hlosta", "Galina Naydenova"], "session": "SESSION: Teacher support tools I"}, {"title": "An instructor dashboard for real-time analytics in interactive programming assignments", "pages": "272-279", "doi": "10.1145/3027385.3027441", "abstract": "Many introductory programming environments generate a large amount of log data, but making insights from these data accessible to instructors remains a challenge. This research demonstrates that student outcomes can be accurately predicted from student program states at various time points throughout the course, and integrates the resulting predictive models into an instructor dashboard. The effectiveness of the dashboard is evaluated by measuring how well the dashboard analytics correctly suggest that the instructor help students classified as most in need. Finally, we describe a method of matching low-performing students with high-performing peer tutors, and show that the inclusion of peer tutors not only increases the amount of help given, but the consistency of help availability as well.", "authors": ["Nicholas Diana", "Michael Eagle", "John Stamper", "Shuchi Grover", "Marie Bienkowski", "Satabdi Basu"], "session": "SESSION: Teacher support tools II"}, {"title": "Real-time learning analytics for C programming language courses", "pages": "280-288", "doi": "10.1145/3027385.3027407", "abstract": "Many universities choose the C programming language (C) as the first one they teach their students, early on in their program. However, students often consider programming courses difficult, and these courses often have among the highest dropout rates of computer science courses offered. It is therefore critical to provide more effective instruction to help students understand the syntax of C and prevent them losing interest in programming. In addition, homework and paper-based exams are still the main assessment methods in the majority of classrooms. It is difficult for teachers to grasp students' learning situation due to the large amount of evaluation work. To facilitate teaching and learning of C, in this article we propose a system---LAPLE (Learning Analytics in Programming Language Education)---that provides a learning dashboard to capture the behavior of students in the classroom and identify the different difficulties faced by different students looking at different knowledge. With LAPLE, teachers may better grasp students' learning situation in real time and better improve educational materials using analysis results. For their part, novice undergraduate programmers may use LAPLE to locate syntax errors in C and get recommendations from educational materials on how to fix them.", "authors": ["Xinyu Fu", "Atsushi Shimada", "Hiroaki Ogata", "Yuta Taniguchi", "Daiki Suehiro"], "session": "SESSION: Teacher support tools II"}, {"title": "Widget, widget as you lead, I am performing well indeed!: using results from an exploratory offline study to inform an empirical online study about a learning analytics widget in a collaborative learning environment", "pages": "289-298", "doi": "10.1145/3027385.3027428", "abstract": "The collaborative learning processes of students in online learning environments can be supported by providing learning analytics-based visualisations that foster awareness and reflection about an individual's as well as the team's behaviour and their learning and collaboration processes. For this empirical study we implemented an activity widget into the online learning environment of a live five-months Master course and investigated the predictive power of the widget indicators towards the students' grades and compared the results to those from an exploratory study with data collected in previous runs of the same course where the widget had not been in use. Together with information gathered from a quantitative as well as a qualitative evaluation of the activity widget during the course, the findings of this current study show that there are indeed predictive relations between the widget indicators and the grades, especially those regarding responsiveness, and indicate that some of the observed differences in the last run could be attributed to the implemented activity widget.", "authors": ["Maren Scheffel", "Hendrik Drachsler", "Karel Kreijns", "Joop de Kraker", "Marcus Specht"], "session": "SESSION: Student support tools"}, {"title": "Building a transcript of the future", "pages": "299-308", "doi": "10.1145/3027385.3027418", "abstract": "The pathways and learning outcomes of university students are the culmination of numerous experiences inside and outside of the classroom, with faculty and with other students, in both formal and casual settings. These interactions are guided by the general education requirements of the university and by the learning goals of the student. The only official record and representation of each student's education is captured by their academic transcript: typically a list of courses described by name and number, grades recorded on an A-F scale and summarized by GPA, degrees awarded, and honors received. This limited approach reflects the technological affordances of a 20th century industrial age. In recent years, scholars have begun to imagine a transcript of the future, perhaps combining a richer record of the student experience along with a portfolio of authentic products of student work. In this paper, we concentrate on first, and develop analytic methods for improving measures of both classroom performance and intellectual breadth. In each case, this is done by placing elements of individual transcripts in context using information about their peers. We frame the study by addressing basic questions. Were the courses taken by the student difficult on average? Did the individual stand out from their peers? Were the courses representative of a broad intellectual experience, or did the student delve into detail in the chosen field of study? And with whom did they take courses?", "authors": ["Benjamin P. Koester", "James Fogel", "William Murdock, III", "Galina Grom", "Timothy A. McKay"], "session": "SESSION: Student support tools"}, {"title": "Trends and issues in student-facing learning analytics reporting systems research", "pages": "309-318", "doi": "10.1145/3027385.3027403", "abstract": "We conducted a literature review on systems that track learning analytics data (e.g., resource use, time spent, assessment data, etc.) and provide a report back to students in the form of visualizations, feedback, or recommendations. This review included a rigorous article search process; 945 articles were identified in the initial search. After filtering out articles that did not meet the inclusion criteria, 94 articles were included in the final analysis. Articles were coded on five categories chosen based on previous work done in this area: functionality, data sources, design analysis, perceived effects, and actual effects. The purpose of this review is to identify trends in the current student-facing learning analytics reporting system literature and provide recommendations for learning analytics researchers and practitioners for future work.", "authors": ["Robert Bodily", "Katrien Verbert"], "session": "SESSION: Feedback systems"}, {"title": "Uncovering reviewing and reflecting behaviors from paper-based formal assessment", "pages": "319-328", "doi": "10.1145/3027385.3027415", "abstract": "In this paper, we study students' learning effectiveness through their use of a homegrown educational technology, Web Programming Grading Assistant (WPGA), which facilitates grading and feedback delivery of paper-based assessments. We designed a classroom study and collected data from a lower-division blended-instruction computer science class. We tracked and modeled students' reviewing and reflecting behaviors from WPGA. The results show that students demonstrated an effort and desire to review assessments regardless of if they were graded for academic performance or for attendance. Hardworking students achieved higher exam scores on average and were found to review their exams and the correct questions frequently. Additionally, student cohorts exhibited similar initial reviewing patterns, but different in-depth reviewing and reflecting strategies. Ultimately, this work contributes to the aggregation of multidimensional learning analytics across the physical and cybersphere.", "authors": ["I-Han Hsiao", "Po-Kai Huang", "Hannah Murphy"], "session": "SESSION: Feedback systems"}, {"title": "Scientific modeling: using learning analytics to examine student practices and classroom variation", "pages": "329-338", "doi": "10.1145/3027385.3027420", "abstract": "Modeling has a strong focus in current science learning frameworks as a critical skill for students to learn. However, understanding students' scientific models and their modeling practices at scale is a difficult task that has not been taken up by the research literature. The complex variables involved in classroom learning, such as teacher differences, increase the difficulty of understanding this problem. This work begins with an exploration of the methods used to explore students' scientific modeling in the learning sciences space and the frameworks developed to characterize student modeling practices. Learning analytics can be used to leverage these frameworks of scientific modeling practices to explore questions around students' scientific models and their modeling practices. These analyses are focused around the use of EcoSurvey, a collaborative, digital tool used in high-school biology classrooms to model the local ecosystem. This tool was deployed in ten biology classrooms and used with varying degrees of success. There are significant teacher-level differences found in the activity sequences of students using the EcoSurvey tool. The theoretical metrics around scientific modeling practices and automatically extracted feature sequences were also used in a classification task to automatically determine a particular student's teacher. These results underline the power of learning analytics methods to give insight into how modeling practices are realized in the classroom. This work also informs changes to modeling tools, associated curricula, and supporting professional development around scientific modeling.", "authors": ["David Quigley", "Jonathan Ostwald", "Tamara Sumner"], "session": "SESSION: Skill assessment"}, {"title": "Predicting math performance using natural language processing tools", "pages": "339-347", "doi": "10.1145/3027385.3027399", "abstract": "A number of studies have demonstrated links between linguistic knowledge and performance in math. Studies examining these links in first language speakers of English have traditionally relied on correlational analyses between linguistic knowledge tests and standardized math tests. For second language (L2) speakers, the majority of studies have compared math performance between proficient and non-proficient speakers of English. In this study, we take a novel approach and examine the linguistic features of student language while they are engaged in collaborative problem solving within an on-line math tutoring system. We transcribe the students' speech and use natural language processing tools to extract linguistic information related to text cohesion, lexical sophistication, and sentiment. Our criterion variables are individuals' pretest and posttest math performance scores. In addition to examining relations between linguistic features of student language production and math scores, we also control for a number of non-linguistic factors including gender, age, grade, school, and content focus (procedural versus conceptual). Linear mixed effect modeling indicates that non-linguistic factors are not predictive of math scores. However, linguistic features related to cohesion affect and lexical proficiency explained approximately 30% of the variance (R2 = .303) in the math scores.", "authors": ["Scott Crossley", "Ran Liu", "Danielle McNamara"], "session": "SESSION: Skill assessment"}, {"title": "Learning analytics in a seamless learning environment", "pages": "348-357", "doi": "10.1145/3027385.3027408", "abstract": "This paper describes seamless learning analytics methods of VASCORLL (Visualization and Analysis System for COnnecting Relationships of Learning Logs). VASCORLL is a system for visualizing and analyzing the learning logs collected by the seamless learning system, which supports language learning in the real-world. As far, several studies have been made in the seamless learning environments in order to bridge formal learning over informal learning. However, their focus was the implementation of the seamless learning environment in education. This study focuses on visualizing and analyzing learning logs collected in the seamless learning environment. This paper describes how our analytics could contribute to bridging the gap between formal and informal learning. An experiment was conducted to evaluate 1) whether our developed VASCORLL is effective in connecting the words learned in formal learning to the ones learned in informal learning, 2) which social network algorithm is effective to enhance learning in the seamless learning environment. Twenty international students participated in the evaluation experiment, and they were able to increase their learning opportunities by using VASCORLL. In addition, it was found that the betweenness centrality is useful in finding central words bridging formal and informal learning.1", "authors": ["Kousuke Mouri", "Hiroaki Ogata", "Noriko Uosaki"], "session": "SESSION: Understanding student behaviour - general"}, {"title": "SPACLE: investigating learning across virtual and physical spaces using spatial replays", "pages": "358-367", "doi": "10.1145/3027385.3027450", "abstract": "Classroom experiments that evaluate the effectiveness of educational technologies do not typically examine the effects of classroom contextual variables (e.g., out-of-software help-giving and external distractions). Yet these variables may influence students' instructional outcomes. In this paper, we introduce the Spatial Classroom Log Explorer (SPACLE): a prototype tool that facilitates the rapid discovery of relationships between within-software and out-of-software events. Unlike previous tools for retrospective analysis, SPACLE replays moment-by-moment analytics about student and teacher behaviors in their original spatial context. We present a data analysis workflow using SPACLE and demonstrate how this workflow can support causal discovery. We share the results of our initial replay analyses using SPACLE, which highlight the importance of considering spatial factors in the classroom when analyzing ITS log data. We also present the results of an investigation into the effects of student-teacher interactions on student learning in K-12 blended classrooms, using our workflow, which combines replay analysis with SPACLE and causal modeling. Our findings suggest that students' awareness of being monitored by their teachers may promote learning, and that \"gaming the system\" behaviors may extend outside of educational software use.", "authors": ["Kenneth Holstein", "Bruce M. McLaren", "Vincent Aleven"], "session": "SESSION: Understanding student behaviour - general"}, {"title": "What do students want?: towards an instrument for students' evaluation of quality of learning analytics services", "pages": "368-372", "doi": "10.1145/3027385.3027419", "abstract": "Quality assurance in any organization is important for ensuring that service users are satisfied with the service offered. For higher education institutes, the use of service quality measures allows for ideological gaps to be both identified and resolved. The learning analytic community, however, has rarely addressed the concept of service quality. A potential outcome of this is the provision of a learning analytics service that only meets the expectations of certain stakeholders (e.g., managers), whilst overlooking those who are most important (e.g., students). In order to resolve this issue, we outline a framework and our current progress towards developing a scale to assess student expectations and perceptions of learning analytics as a service.", "authors": ["Alexander Whitelock-Wainwright", "Dragan Ga\u0161evi\u0107", "Ricardo Tejeiro"], "session": "SESSION: Learning analytics adoption - recommendations"}, {"title": "What'd you say again?: recurrence quantification analysis as a method for analyzing the dynamics of discourse in a reading strategy tutor", "pages": "373-382", "doi": "10.1145/3027385.3027445", "abstract": "In this study, we investigated the degree to which the cognitive processes in which students engage during reading comprehension could be examined through dynamical analyses of their natural language responses to texts. High school students (n = 142) generated typed self-explanations while reading a science text. They then completed a comprehension test that measured their comprehension at both surface and deep levels. The recurrent patterns of the words in students' self-explanations were first visualized in recurrence plots. These visualizations allowed us to qualitatively analyze the different self-explanation processes of skilled and less skilled readers. These recurrence plots then allowed us to calculate recurrence indices, which represented the properties of these temporal word patterns. Results of correlation and regression analyses revealed that these recurrence indices were significantly related to the students' comprehension scores at both surface- and deep levels. Additionally, when combined with summative metrics of word use, these indices were able to account for 32% of the variance in students' overall text comprehension scores. Overall, our results suggest that recurrence quantification analysis can be utilized to guide both qualitative and quantitative assessments of students' comprehension.", "authors": ["Laura K. Allen", "Cecile Perret", "Aaron Likens", "Danielle S. McNamara"], "session": "SESSION: Understanding discourse III"}, {"title": "Honing in on social learning networks in MOOC forums: examining critical network definition decisions", "pages": "383-392", "doi": "10.1145/3027385.3027446", "abstract": "This study examines the impact of content-based network partitioning and tie definition on social network structures and interpretation for MOOC discussion forums. Using dynamic interrelated post and thread categorization [5] based on a previously developed natural language model [27], 817 threads containing 3124 discussion posts from 567 learners in a MOOC on the use of statistics in medicine were characterized as either related to the learning of course content or not. Content-related, non-content, and unpartitioned interaction networks were constructed based on five different tie definitions: Direct Reply, Star, Direct Reply+Star, Limited Copresence, and Total Copresence. Results showed content-related and non-content networks to have distinct characteristics at the network, community, and individual node levels, validating the usefulness of the content/non-content distinction as an analytic tool. Network properties were less sensitive to differences in tie definition with the exception of Total Copresence, which showed distinct characteristics presenting dangers for general use, but usefulness for detecting inflated social status due to \"superthread\" initiation.", "authors": ["Alyssa Friend Wise", "Yi Cui", "Wan Qi Jin"], "session": "SESSION: Understanding discourse III"}, {"title": "Using correlational topic modeling for automated topic identification in intelligent tutoring systems", "pages": "393-397", "doi": "10.1145/3027385.3027438", "abstract": "Student knowledge modeling is an important part of modern personalized learning systems, but typically relies upon valid models of the structure of the content and skill in a domain. These models are often developed through expert tagging of skills to items. However, content creators in crowdsourced personalized learning systems often lack the time (and sometimes the domain knowledge) to tag skills themselves. Fully automated approaches that rely on the covariance of correctness on items can lead to effective skill-item mappings, but the resultant mappings are often difficult to interpret. In this paper we propose an alternate approach to automatically labeling skills in a crowdsourced personalized learning system using correlated topic modeling, a natural language processing approach, to analyze the linguistic content of mathematics problems. We find a range of potentially meaningful and useful topics within the context of the ASSISTments system for mathematics problem-solving.", "authors": ["Stefan Slater", "Ryan Baker", "Ma. Victoria Almeda", "Alex Bowers", "Neil Heffernan"], "session": "SESSION: Understanding discourse III"}, {"title": "Enhancing learning through virtual reality and neurofeedback: a first step", "pages": "398-403", "doi": "10.1145/3027385.3027390", "abstract": "Virtual reality presents exciting new prospects for the delivery of educational materials to students. By combining this technology with biological sensors, a student in a virtual educational environment can be monitored for physiological markers of engagement or more cognitive states of learning. With this information, the virtual reality environment can be adaptively altered to reflect the student's state, essentially creating a closed-loop feedback system. This paper explores these concepts, and presents preliminary data on a combined EEG-VR working memory experiment as a first step toward a broader implementation of an intelligent adaptive learning system. This first-pass neural time-series and oscillatory data suggest that while an EEG-based neurofeedback system is feasible, more work on removing artifacts and identifying relevant and important features will lead to higher prediction accuracy.", "authors": ["Ryan Hubbard", "Aldis Sipolins", "Lin Zhou"], "session": "SESSION: Adaptive learning"}, {"title": "Measures for recommendations based on past students' activity", "pages": "404-408", "doi": "10.1145/3027385.3027426", "abstract": "This paper introduces two measures for the recommendation of study materials based on students' past study activity. We use records from the Virtual Learning Environment (VLE) and analyse the activity of previous students. We assume that the activity of past students represents patterns, which can be used as a basis for recommendations to current students. The measures we define are Relevance, for description of a supposed VLE activity derived from previous students of the course, and Effort, that represents the actual effort of individual current students. Based on these measures, we propose a composite measure, which we call Importance. We use data from the previous course presentations to evaluate of the consistency of students' behaviour. We use correlation of the defined measures Relevance and Average Effort to evaluate the behaviour of two different student cohorts and the Root Mean Square Error to measure the deviation of Average Effort and individual student Effort.", "authors": ["Michal Huptych", "Michal Bohuslavek", "Martin Hlosta", "Zdenek Zdrahal"], "session": "SESSION: Adaptive learning"}, {"title": "Supporting collaborative learning with tag recommendations: a real-world study in an inquiry-based classroom project", "pages": "409-418", "doi": "10.1145/3027385.3027421", "abstract": "In online social learning environments, tagging has demonstrated its potential to facilitate search, to improve recommendations and to foster reflection and learning.Studies have shown that shared understanding needs to be established in the group as a prerequisite for learning. We hypothesise that this can be fostered through tag recommendation strategies that contribute to semantic stabilization. In this study, we investigate the application of two tag recommenders that are inspired by models of human memory: (i) the base-level learning equation BLL and (ii) Minerva. BLL models the frequency and recency of tag use while Minerva is based on frequency of tag use and semantic context. We test the impact of both tag recommenders on semantic stabilization in an online study with 56 students completing a group-based inquiry learning project in school. We find that displaying tags from other group members contributes significantly to semantic stabilization in the group, as compared to a strategy where tags from the students' individual vocabularies are used. Testing for the accuracy of the different recommenders revealed that algorithms using frequency counts such as BLL performed better when individual tags were recommended. When group tags were recommended, the Minerva algorithm performed better. We conclude that tag recommenders, exposing learners to each other's tag choices by simulating search processes on learners' semantic memory structures, show potential to support semantic stabilization and thus, inquiry-based learning in groups.", "authors": ["Simone Kopeinik", "Elisabeth Lex", "Paul Seitlinger", "Dietrich Albert", "Tobias Ley"], "session": "SESSION: Understanding student behaviour - help-seeking / search"}, {"title": "Classifying help seeking behaviour in online communities", "pages": "419-423", "doi": "10.1145/3027385.3027442", "abstract": "While help seeking has been extensively studied using self report survey data and models, there is a lack of content analysis techniques that can be directly applied to classify help seeking behaviour. In this preliminary work we propose a coding scheme which is then applied to an open dataset that we have created by carefully selecting sub groups from two popular discussion sites (Reddit and StackExchange). We then explore the possibility for automatically classifying help seeking behaviour using machine learning models. A preliminary model provides good initial results, suggesting that it may indeed be possible to construct student support systems that build off of an accurate classifier.", "authors": ["Sebastian Cross", "Zak Waters", "Kirsty Kitto", "Guido Zuccon"], "session": "SESSION: Understanding student behaviour - help-seeking / search"}, {"title": "Using learning analytics to explore help-seeking learner profiles in MOOCs", "pages": "424-428", "doi": "10.1145/3027385.3027448", "abstract": "In online learning environments, learners are often required to be more autonomous in their approach to learning. In scaled online learning environments, like Massive Open Online Courses (MOOCs), there are differences in the ability of learners to access teachers and peers to get help with their study than in more traditional educational environments. This exploratory study examines the help-seeking behaviour of learners across several MOOCs with different audiences and designs. Learning analytics techniques (e.g., dimension reduction with t-sne and clustering with affinity propagation) were applied to identify clusters and determine profiles of learners on the basis of their help-seeking behaviours. Five help-seeking learner profiles were identified which provide an insight into how learners' help-seeking behaviour relates to performance. The development of a more in-depth understanding of how learners seek help in large online learning environments is important to inform the way support for learners can be incorporated into the design and facilitation of online courses delivered at scale.", "authors": ["Linda Corrin", "Paula G. de Barba", "Aneesha Bakharia"], "session": "SESSION: Understanding student behaviour - help-seeking / search"}, {"title": "EMODA: a tutor oriented multimodal and contextual emotional dashboard", "pages": "429-438", "doi": "10.1145/3027385.3027434", "abstract": "Learners' emotional state has proven to be a key factor for successful learning. Visualizing learners' emotions during synchronous on-line learning activities can help tutors in creating and maintaining socio-affective relationships with their learners. However, few dashboards offer emotional information on the learning activity. The current study focuses on synchronous interactions via a videoconferencing tool dedicated to foreign language training. We collected data on learners' emotions in real conditions during ten sessions (five sessions for two learners). We propose to adopt and combine different models of emotions (discrete and dimensional) and to use heterogeneous APIs for measuring learners' emotions from different data sources (audio, video, self-reporting and interaction traces). Based on a thorough data analysis, we propose an approach to combine different cues to infer information on learners' emotional states. We finally present the EMODA dashboard, an affective multimodal and contextual visual analytics dashboard, which allows the tutor to monitor learners' emotions and better understand their evolution during the synchronous learning activity.", "authors": ["Mohamed Ez-zaouia", "Elise Lavou\u00e9"], "session": "SESSION: Affective learning"}, {"title": "Person-centered approach to explore learner's emotionality in learning within a 3D narrative game", "pages": "439-443", "doi": "10.1145/3027385.3027432", "abstract": "Emotions form an integral part of our cognitive function. Past research has demonstrated conclusive associations between emotions and learning achievement [7, 26, 27]. This paper used a person-centered approach to explore students' (N = 65) facial behavior, emotions, learner traits and learning. An automatic facial expression recognition system was used to detect both middle school and university students' real-time facial movements while they learned scientific tasks in a 3D narrative video game. The results indicated a strong statistical relationship between three specific facial movements (i.e., outer brow raising, lip tightening and lip pressing), student self-regulatory learning strategy and learning performance. Outer brow raising (AU2) had strong predictive power when a student is confronted with obstacles and does not know how to proceed. Both lip tightening and pressing (AU23 and AU24) were predictive when a student engaged in a task that requires a deep level of incoming information processing and short memory activation. The findings also suggested a correlational relationship between student self-regulatory learning strategy use and neutral state. It is hoped that this study will provide empirical evidence for helping us develop a deeper understanding of the relationship between facial behavior and complex learning especially in educational games.", "authors": ["Zhenhua Xu", "Earl Woodruff"], "session": "SESSION: Affective learning"}, {"title": "Using data visualizations to foster emotion regulation during self-regulated learning with advanced learning technologies: a conceptual framework", "pages": "444-448", "doi": "10.1145/3027385.3027440", "abstract": "Emotions play a critical role during learning and problem solving with advanced learning technologies (ALTs). Despite their importance, relatively few attempts have been made to understand learners' emotional monitoring and regulation by using data visualizations of their own (and others') cognitive, affective, metacognitive, and motivational (CAMM) self-regulated learning (SRL) processes to potentially foster their emotion regulation (ER). We present a theoretically based and empirically driven conceptual framework that addresses ER by proposing the use of visualizations of one's own and others' CAMM SRL multichannel data to facilitate learners' monitoring and regulation of emotions during learning with ALTs. We use an example with eye-tracking data to illustrate the mapping between theoretical assumptions, ER strategies, and the types of data visualizations that can enhance learners' ER, including key processes such as emotion flexibility, emotion adaptivity, and emotion efficacy. We conclude with future directions leading to a systematic interdisciplinary research agenda that addresses outstanding ER-related issues by integrating models, theories, methods, and analytical techniques for the cognitive, learning, and affective sciences; human- computer interaction (HCI); data visualization; big data; data mining; and SRL.", "authors": ["Roger Azevedo", "Garrett C. Millar", "Michelle Taub", "Nicholas V. Mudrick", "Amanda E. Bradbury", "Megan J. Price"], "session": "SESSION: Affective learning"}, {"title": "Strategies for data and learning analytics informed national education policies: the case of Uruguay", "pages": "449-453", "doi": "10.1145/3027385.3027444", "abstract": "This work provides an overview of an education and technology monitoring system developed at Plan Ceibal, a nationwide initiative created to enable technology enhanced learning in Uruguay. Plan Ceibal currently offers one-to-one access to technology and connectivity to every student and teacher (from primary and secondary education) as well as a comprehensive set of educational software platforms. All these resources generate massive amounts of data about the progress and style of students learning. This work introduces the conceptual framework, design and preliminary results of the Big Data Center for learning analytics currently being developed at Plan Ceibal. This initiative is focused on exploiting these datasets and conducting advanced analytics to support the educational system. To this aim, a 360 degrees profile will be built including information characterizing the user's online behavior as well as a set of technology enhanced learning factors. These profiles will be studied both at user (e.g., student or teacher) and larger scale levels (e.g., per school or school system), addressing both the need of understanding how technology is being used for learning as well as to provide accurate feedback to support evidence based educational policies.", "authors": ["Cecilia Aguerrebere", "Crist\u00f3bal Cobo", "Marcela Gomez", "Mat\u00edas Mateu"], "session": "SESSION: LA adoption - experiences"}, {"title": "Follow the successful crowd: raising MOOC completion rates through social comparison at scale", "pages": "454-463", "doi": "10.1145/3027385.3027411", "abstract": "Social comparison theory asserts that we establish our social and personal worth by comparing ourselves to others. In in-person learning environments, social comparison offers students critical feedback on how to behave and be successful. By contrast, online learning environments afford fewer social cues to facilitate social comparison. Can increased availability of such cues promote effective self-regulatory behavior and achievement in Massive Open Online Courses (MOOCs)? We developed a personalized feedback system that facilitates social comparison with previously successful learners based on an interactive visualization of multiple behavioral indicators. Across four randomized controlled trials in MOOCs (overall N = 33, 726), we find: (1) the availability of social comparison cues significantly increases completion rates, (2) this type of feedback benefits highly educated learners, and (3) learners' cultural context plays a significant role in their course engagement and achievement.", "authors": ["Dan Davis", "Ioana Jivet", "Ren\u00e9 F. Kizilcec", "Guanliang Chen", "Claudia Hauff", "Geert-Jan Houben"], "session": "SESSION: Retention"}, {"title": "Planning prompts increase and forecast course completion in massive open online courses", "pages": "464-473", "doi": "10.1145/3027385.3027416", "abstract": "Among all of the learners in Massive Open Online Courses (MOOCs) who intend to complete a course, the majority fail to do so. This intention-action gap is found in many domains of human experience, and research in similar goal pursuit domains suggests that plan-making is a cheap and effective nudge to encourage follow-through. In a natural field experiment in three HarvardX courses, some students received open-ended planning prompts at the beginning of a course. These prompts increased course completion by 29%, and payment for certificates by 40%. This effect was largest for students enrolled in traditional schools. Furthermore, the contents of students' plans could predict which students were least likely to succeed - in particular, students whose plans focused on specific times were unlikely to complete the course. Our results suggest that planning prompts can help learners adopted productive frames of mind at the outset of a learning goal that encourage and forecast student success.", "authors": ["Michael Yeomans", "Justin Reich"], "session": "SESSION: Retention"}, {"title": "From prediction to impact: evaluation of a learning analytics retention program", "pages": "474-478", "doi": "10.1145/3027385.3027405", "abstract": "Learning analytics research has often been touted as a means to address concerns regarding student retention outcomes. However, few research studies to date, have examined the impact of the implemented intervention strategies designed to address such retention challenges. Moreover, the methodological rigor of some of the existing studies has been challenged. This study evaluates the impact of a pilot retention program. The study contrasts the findings obtained by the use of different methods for analysis of the effect of the intervention. The pilot study was undertaken between 2012 and 2014 resulting in a combined enrolment of 11,160 students. A model to predict attrition was developed, drawing on data from student information system, learning management system interactions, and assessment. The predictive model identified some 1868 students as academically at-risk. Early interventions were implemented involving learning and remediation support. Common statistical methods demonstrated a positive association between the intervention and student retention. However, the effect size was low. The use of more advanced statistical methods, specifically mixed-effect methods explained higher variability in the data (over 99%), yet found the intervention had no effect on the retention outcomes. The study demonstrates that more data about individual differences is required to not only explain retention but to also develop more effective intervention approaches.", "authors": ["Shane Dawson", "Jelena Jovanovic", "Dragan Ga\u0161evi\u0107", "Abelardo Pardo"], "session": "SESSION: Retention"}, {"title": "Guidance counselor reports of the ASSISTments college prediction model (ACPM)", "pages": "479-488", "doi": "10.1145/3027385.3027435", "abstract": "Advances in the learning analytics community have created opportunities to deliver early warnings that alert teachers and instructors when a student is at risk of not meeting academic goals [6], [71]. Alert systems have also been developed for school district leaders [33] and for academic advisors in higher education [39], but other professionals in the K-12 system, namely guidance counselors, have not been widely served by these systems. In this study, we use college enrollment models created for the ASSISTments learning system [55] to develop reports that target the needs of these professionals, who often work directly with students, but usually not in classroom settings. These reports are designed to facilitate guidance counselors' efforts to help students to set long term academic and career goals. As such, they provide the calculated likelihood that a student will attend college (the ASSISTments College Prediction Model or ACPM), alongside student engagement and learning measures. Using design principles from risk communication research and student feedback theories to inform a co-design process, we developed reports that can inform guidance counselor efforts to support student achievement.", "authors": ["Jaclyn Ocumpaugh", "Ryan S. Baker", "Maria O. C. Z. San Pedro", "M. Aaron Hawn", "Cristina Heffernan", "Neil Heffernan", "Stefan A. Slater"], "session": "SESSION: Students at-risk - systems"}, {"title": "Don't call it a comeback: academic recovery and the timing of educational technology adoption", "pages": "489-493", "doi": "10.1145/3027385.3027393", "abstract": "Recent research using learning analytics data to explore student performance over the course of a term suggests that a substantial percentage of students who are classified as academically struggling manage to recover. In this study, we report the result of a hazard analysis based on students' behavioral engagement with different digital instructional technologies over the course of a semester. We observe substantially different adoption and use behavior between students who did and did not experience academic difficulty in the course. Students who experienced moderate academic difficulty benefited the most from using tools that helped them plan their study behaviors. Students who experienced more severe academic difficulty benefited from tools that helped them prepare for exams. We observed that students adopted most tools and system features before they experienced academic difficulty, and students who adopted early were more likely to recover.", "authors": ["Michael Geoffrey Brown", "R. Matthew DeMonbrun", "Stephanie D. Teasley"], "session": "SESSION: Students at-risk - systems"}, {"title": "LA policy: developing an institutional policy for learning analytics using the RAPID outcome mapping approach", "pages": "494-495", "doi": "10.1145/3027385.3029424", "abstract": "This workshop aims to promote strategic planning for learning analytics in higher education through developing institutional policies. While adoption of learning analytics is predominantly seen in small-scale and bottom-up patterns, it is believed that a systemic implementation can bring the widest impact to the education system and lasting benefits to learners. However, the success of it highly depends on the adopted strategy that meets the needs of various stakeholders and systematically pushes the institution towards achieving its targets. It is imperative to develop a learning analytics policy that ensures a practice that is valid, effective and ethical. The workshop involves two components. The first component includes a set of presentations about the state of learning analytics in higher education, drawing on results from an Australian and a European project examining institutional learning analytics policy and adoption processes. The second component is an interactive session where participants are encouraged to share their motivations for adopting learning analytics and the diversity of challenges they perceive impede analytics adoption in their institution. Using the RAPID Outcome Mapping Approach (ROMA), participants will create a draft policy that articulates how the various challenges can be addressed. This workshop aims to further develop our understanding of how learning analytics operates in an organizational system and promote a cultural change in how such analytics are adopted in higher education.", "authors": ["Yi-Shan Tsai", "Dragan Gasevic", "Pedro J. Mu\u00f1oz-Merino", "Shane Dawson"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "Writing analytics literacy: bridging from research to practice", "pages": "496-497", "doi": "10.1145/3027385.3029425", "abstract": "There is untapped potential in achieving the full impact of learning analytics through the integration of tools into practical pedagogic contexts. To meet this potential, more work must be conducted to support educators in developing learning analytics literacy. The proposed workshop addresses this need by building capacity in the learning analytics community and developing an approach to resourcing for building 'writing analytics literacy'.", "authors": ["Simon Knight", "Laura Allen", "Andrew Gibson", "Danielle McNamara", "Simon Buckingham Shum"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "Developing institutional learning analytics 'communities of transformation' to support student success", "pages": "498-499", "doi": "10.1145/3027385.3029426", "abstract": "Institutional implementation of learning analytics calls for thoughtful management of cultural change. This interactive halfday workshop responds to the LA literature describing the benefits and challenges of institutional LA implementation by offering participants an opportunity to learn about and begin planning for a program to actively engage faculty as leaders of data exploration around the theme of 'student success'. This session will share experiences from five institutions actively engaged in fostering Learning Analytics Communities (LAC) by identifying key issues, sharing lessons learned, and considering structural frameworks that are transferable to other institutional contexts. Structured discussion and activities will engage participants in developing an action plan for establishing an LAC on their own campus.", "authors": ["Leah P. Macfadyen", "Dennis Groth", "George Rehrey", "Linda Shepard", "Jim Greer", "Douglas Ward", "Caroline Bennett", "Jake Kaupp", "Marco Molinaro", "Matt Steinwachs"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "Workshop on methodology in learning analytics (MLA)", "pages": "500-501", "doi": "10.1145/3027385.3029427", "abstract": "Learning analytics is an interdisciplinary and inclusive field, a fact which makes the establishment of methodological norms both challenging and important. This community-building workshop intends to convene methodology-focused researchers to discuss new and established approaches, comment on the state of current practice, author pedagogical manuscripts, and co-develop guidelines to help move the field forward with quality and rigor.", "authors": ["Yoav Bergner", "Charles Lang", "Geraldine Gray"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "Quasi-experimental design for causal inference using Python and Apache Spark: a hands-on tutorial", "pages": "502-503", "doi": "10.1145/3027385.3029428", "abstract": "Educational practitioners and policy makers require evidence supporting claims about educational efficacy. Evidence is often found using causal relationships between education inputs and student learning outcomes. Causal inference covers a wide range of topics in education research, including efficacy studies to prove if a new policy, software, curriculum or intervention is effective in improving student learning outcomes. Randomized controlled trials (RCT) are considered a gold standard method to demonstrate causality. However, these studies are expensive, timely and costly, as well as not being ethical to conduct in many educational contexts. Causality can also be deducted purely from observational data. In this tutorial, we will review methodologies for estimating the causal effects of education inputs on student learning outcomes using observational data. This is an inherently complex task due to many hidden variables and their interrelationships in educational research. In this tutorial, we discuss causal inference in the context of educational research with big data. This is the first tutorial of its kind at Learning Analytics and Knowledge Conference (LAK) that provides a hands-on experience with Python and Apache Spark as a practical tool for educational researchers to conduct causal inference. As a prerequisite, attendees are required to have familiarity with Python.", "authors": ["Shirin Mojarad", "Nicholas Lewkow", "Alfred Essa", "Jie Zhang", "Jacqueline Feild"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "Beyond failure: the 2nd LAK Failathon", "pages": "504-505", "doi": "10.1145/3027385.3029429", "abstract": "The 2nd LAK Failathon will build on the successful event in 2016 and extend the workshop beyond discussing individual experiences of failure to exploring how the field can improve, particularly regarding the creation and use of evidence. Failure in research is an increasingly hot topic, with high-profile crises of confidence in the published research literature in medicine and psychology. Among the major factors in this research crisis are the many incentives to report and publish only positive findings. These incentives prevent the field in general from learning from negative findings, and almost entirely preclude the publication of mistakes and errors. Thus providing an alternative forum for practitioners and researchers to learn from each other's failures can be very productive. The first LAK Failathon, held in 2016, provided just such an opportunity for researchers and practitioners to share their failures and negative findings in a lower-stakes environment, to help participants learn from each other's mistakes. It was very successful, and there was strong support for running it as an annual event. This workshop will build on that success, with twin objectives to provide an environment for individuals to learn from each other's failures, and also to co-develop plans for how we as a field can better build and deploy our evidence base.", "authors": ["Doug Clow", "Rebecca Ferguson", "Kirsty Kitto", "Yong-Sang Cho", "Mike Sharkey", "Cecilia Aguerrebere"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "Workshop on integrated learning analytics of MOOC post-course development", "pages": "506-507", "doi": "10.1145/3027385.3029430", "abstract": "MOOC research is typically limited to evaluations of learner behavior in the context of the learning environment. However, some research has begun to recognize that the impact of MOOCs may extend beyond the confines of the course platform or conclusion of the course time limit. This workshop aims to encourage our community of learning analytics researchers to examine the relationship between performance and engagement within the course and learner behavior and development beyond the course. This workshop intends to build awareness in the community regarding the importance of research measuring multi-platform activity and long-term success after taking a MOOC. We hope to build the community's understanding of what it takes to operationalize MOOC learner success in a novel context by employing data traces across the social web.", "authors": ["Yuan Wang", "Dan Davis", "Guanliang Chen", "Luc Paquette"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "DesignLAK17: quality metrics and indicators for analytics of assessment design at scale", "pages": "508-509", "doi": "10.1145/3027385.3029431", "abstract": "Notions of what constitutes quality in design in traditional on-campus or online teaching and learning may not always translate into scaled digital environments. The DesignLAK17 workshop builds on the DesignLAK16 workshop to explore one aspect of this theme, namely the opportunities arising from the use of analytics in scaled assessment design. New paradigms for learning design are exploiting the distinctive characteristics and potentials of analytics, trace data and newer kinds of sensory data usable on digital platforms to transform assessment. But, characteristics of quality assessment design need to be reconsidered, and new metrics for capturing quality are required. This symposium and workshop focuses on what might be appropriate quality metrics and indicators for assessment design in scaled learning. It aims to build a community of interest round the topic, to share perspectives, and to generate design and research ideas.", "authors": ["Ulla Ringtved", "Sandra Milligan", "Linda Corrin", "Allison Littlejohn", "Nancy Law"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "2nd cross-LAK: learning analytics across physical and digital spaces", "pages": "510-511", "doi": "10.1145/3027385.3029432", "abstract": "Student's learning happens where the learner is, rather than being constrained to a single physical or digital environment. It is of high relevance for the LAK community to provide analytics support in blended learning scenarios where students can interact at diverse learning spaces and with a variety of educational tools. This workshop aims to gather the sub-community of LAK researchers, learning scientists and researchers in other areas, interested in the intersection between ubiquitous, mobile and/or classroom learning analytics. The underlying concern is how to integrate and coordinate learning analytics seeking to understand the particular pedagogical needs and context constraints to provide learning analytics support across digital and physical spaces. The goals of the workshop are to consolidate the Cross-LAK sub-community and provide a forum for idea generation that can build up further collaborations. The workshop will also serve to disseminate current work in the area by both producing proceedings of research papers and working towards a journal special issue.", "authors": ["Roberto Martinez-Maldonado", "Davinia Hernandez-Leo", "Abelardo Pardo", "Hiroaki Ogata"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "FutureLearn data: what we currently have, what we are learning and how it is demonstrating learning in MOOCs", "pages": "512-513", "doi": "10.1145/3027385.3029433", "abstract": "Compared to other platforms such as Coursera and EdX, FutureLearn is a relatively new player in the MOOC arena and received limited coverage in the Learning Analytics and Educational Data Mining research. Founded by a partnership between the Open University in the UK, the BBC, The British Library and (originally) 12 universities in the UK, FutureLearn has two distinctive features relevant to the way their data is displayed and analyzed: 1) it was designed with a specific educational philosophy in mind which focuses on the social dimension of learning and 2) every learning activity provide opportunities for formal discussion and commenting. This workshop provides an opportunity to invite contributions and connect individual and groups to share their research activities on an international stage. As the first of its kind, this workshop will bring in a number of scholars and practitioners, as well as data scientists and analyst involved in the reporting, researching and developments emerging from the data offered by the platform.", "authors": ["Lorenzo Vigentini", "Manuel Le\u00f3n Urrutia", "Ben Fields"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "LAK17 hackathon: getting the right information to the right people so they can take the right action", "pages": "514-515", "doi": "10.1145/3027385.3029435", "abstract": "The hackathon is intended to be a practical hands-on workshop involving participants from academia and commercial organizations with both technical and practitioner expertise. It will consider the outstanding challenge of visualizations which are effective for the intended audience: informing action, not likely to be misinterpreted, and embodying contextual appropriacy, etc. It will surface particular issues as workshop challenges and explore responses to these challenges as visualizations resting upon interoperability standards and API-oriented open architectures.", "authors": ["Adam Cooper", "Alan Berg", "Niall Sclater", "Tanya Dorey-Elias", "Kirsty Kitto"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "Learning analytics and policy (LAP): international aspirations, achievements and constraints", "pages": "516-517", "doi": "10.1145/3027385.3029436", "abstract": "The Learning Analytics and Policy (LAP) workshop explores and documents the ways in which policies at national and regional level are shaping the development of learning analytics. It brings together representatives from around the world who report on the circumstances in their own country. The workshop is preceded by an information gathering phase, and followed by the authoring of a report. The aspirations, achievements and constraints in the different countries are contrasted and documented, providing a valuable resource for the future development of learning analytics.", "authors": ["Megan Bowe", "Weiqin Chen", "Dai Griffiths", "Tore Hoel", "Jaeho Lee", "Hiroaki Ogata", "Griff Richards", "Li Yuan", "Jingjing Zhang"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "Current and future multimodal learning analytics data challenges", "pages": "518-519", "doi": "10.1145/3027385.3029437", "abstract": "Multimodal Learning Analytics (MMLA) captures, integrates and analyzes learning traces from different sources in order to obtain a more holistic understanding of the learning process, wherever it happens. MMLA leverages the increasingly widespread availability of diverse sensors, high-frequency data collection technologies and sophisticated machine learning and artificial intelligence techniques. The aim of this workshop is twofold: first, to expose participants to, and develop, different multimodal datasets that reflect how MMLA can bring new insights and opportunities to investigate complex learning processes and environments; second, to collaboratively identify a set of grand challenges for further MMLA research, built upon the foundations of previous workshops on the topic.", "authors": ["Daniel Spikol", "Luis P. Prieto", "M. J. Rodr\u00edguez-Triana", "Marcelo Worsley", "Xavier Ochoa", "Mutlu Cukurova", "Bahtijar Vogel", "Emanuele Ruffaldi", "Ulla Lunde Ringtved"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "Building the learning analytics curriculum: workshop", "pages": "520-521", "doi": "10.1145/3027385.3029439", "abstract": "Learning Analytics courses and degree programs both on-and offline have begun to proliferate over the last three years. As a result of this growth in interest from students, university administrators, researchers and instructors we believe it is a good time to review how these educational efforts are impacting the field, how synergy between instructors might be developed to greater serve the field and what kinds of best practices could be developed.", "authors": ["Charles Lang", "Stephanie Teasley", "John Stamper"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "Connecting data with student support actions in a course: a hands-on tutorial", "pages": "522-523", "doi": "10.1145/3027385.3029441", "abstract": "The amount of data extracted from learning experiences has grown at an astonishing pace both in depth due to the increasing variety of data sources, and in breath with courses now being offered to massive student cohorts. However, in this emerging scenario instructors are now facing the challenge of connecting the knowledge emerging from data analysis with the provision of meaningful support actions to students within the context of an instructional design. The objective of this tutorial is to give attendees a set of hypothetical scenarios in which the knowledge extracted from a learning experience needs to be used to provide frequent personalized feedback to students.", "authors": ["Abelardo Pardo", "Roberto Mart\u00ednez-Maldonado", "Simon Buckingham Shum", "Jurgen Schulte", "Simon McIntyre", "Dragan Ga\u0161evi\u0107", "Jing Gao", "George Siemens"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "Community based educational data repositories and analysis tools", "pages": "524-525", "doi": "10.1145/3027385.3029442", "abstract": "This workshop will explore community based repositories for educational data and analytic tools that are used to connect researchers and reduce the barriers to data sharing. Leading innovators in the field, as well as attendees, will identify and report on bottlenecks that remain toward our goal of a unified repository. We will discuss these as well as possible solutions. We will present LearnSphere, an NSF funded system that supports collaborating on and sharing a wide variety of educational data, learning analytics methods, and visualizations while maintaining confidentiality. We will then have hands-on sessions in which attendees have the opportunity to apply existing learning analytics workflows to their choice of educational datasets in the repository (using a simple drag-and-drop interface), add their own learning analytics workflows (requires very basic coding experience), or both. Leaders and attendees will then jointly discuss the unique benefits as well as the limitations of these solutions. Our goal is to create building blocks to allow researchers to integrate their data and analysis methods with others, in order to advance the future of learning science.", "authors": ["Ken Koedinger", "Ran Liu", "John Stamper", "Candace Thille", "Phil Pavlik"], "session": "WORKSHOP SESSION: Workshops"}, {"title": "Student empowerment, awareness, and self-regulation through a quantified-self student tool", "pages": "526-527", "doi": "10.1145/3027385.3029434", "abstract": "The purpose of this paper is to examine the cross institutional use of a quantified-self application called Pattern, which is designed to promote self-regulation and reflective learning in learners. This paper provides a brief look into how learners report spending their time and react to in-app recommendations. Initial data is encouraging; however, there are limitations of Pattern, and additional research and development must be undertaken.", "authors": ["Kimberly E. Arnold", "Brandon Karcher", "Casey V. Wright", "James McKay"], "session": "POSTER SESSION: Posters"}, {"title": "A systematic review of studies on predicting student learning outcomes using learning analytics", "pages": "528-529", "doi": "10.1145/3027385.3029438", "abstract": "Predicting student learning outcomes is one of the prominent themes in Learning Analytics research. These studies varied to a significant extent in terms of the techniques being used, the contexts in which they were situated, and the consequent effectiveness of the prediction. This paper presented the preliminary results of a systematic review of studies in predictive learning analytics. With the goal to find out what methodologies work for what circumstances, this study will be able to facilitate future research in this area, contributing to relevant system developments that are of pedagogic values.", "authors": ["Xiao Hu", "Christy W. L. Cheong", "Wenwen Ding", "Michelle Woo"], "session": "POSTER SESSION: Posters"}, {"title": "A framework for hypothesis-driven approaches to support data-driven learning analytics in measuring computational thinking in block-based programming", "pages": "530-531", "doi": "10.1145/3027385.3029440", "abstract": "K-12 classrooms use block-based programming environments (BBPEs) for teaching computer science and computational thinking (CT). To support assessment of student learning in BBPEs, we propose a learning analytics framework that combines hypothesis- and data-driven approaches to discern students' programming strategies from BBPE log data. We use a principled approach to design assessment tasks to elicit evidence of specific CT skills. Piloting these tasks in high school classrooms enabled us to analyze student programs and video recordings of students as they built their programs. We discuss a priori patterns derived from this analysis to support data-driven analysis of log data in order to better assess understanding and use of CT in BBPEs.", "authors": ["Shuchi Grover", "Marie Bienkowski", "Satabdi Basu", "Michael Eagle", "Nicholas Diana", "John Stamper"], "session": "POSTER SESSION: Posters"}, {"title": "Dear learner: participatory visualisation of learning data for sensemaking", "pages": "532-533", "doi": "10.1145/3027385.3029443", "abstract": "We discuss the application of a hand-drawn self-visualization approach to learner-data, to draw attention to the space of representational possibilities, the power of representation interactions, and the performativity of information representation.", "authors": ["Simon Knight", "Theresa Anderson", "Kelly Tall"], "session": "POSTER SESSION: Posters"}, {"title": "Video annotation tool for learning job interview", "pages": "534-535", "doi": "10.1145/3027385.3029444", "abstract": "In this paper, video annotation tool for learning job interview is proposed. To visualize the difference of obtained descriptions, the proposed tool uses correspondence analysis. The results of correspondence analysis are used to give feedback to learners. By the results, the learner can understand the characteristics of his/her descriptions among the others.", "authors": ["Yoshitomo Yaginuma", "Masako Furukawa", "Tsuneo Yamada"], "session": "POSTER SESSION: Posters"}, {"title": "Reproducibility of findings from educational big data: a preliminary study", "pages": "536-537", "doi": "10.1145/3027385.3029445", "abstract": "In this paper, we examined whether previous findings on educational big data consisting of e-book logs from a given academic course can be reproduced with different data from other academic courses. The previous findings showed that (1) students who attained consistently good achievement more frequently browsed different e-books and their pages than low achievers and that (2) this difference was found only for logs of preparation for course sessions (preview), not for reviewing material (review). Preliminarily, we analyzed e-book logs from four courses. The results were reproduced in only one course and only partially, that is, (1) high achievers more frequently changed e-books than low achievers (2) for preview. This finding suggests that to allow effective usage of learning and teaching analyses, we need to carefully construct an educational environment to ensure reproducibility.", "authors": ["Misato Oi", "Masanori Yamada", "Fumiya Okubo", "Atsushi Shimada", "Hiroaki Ogata"], "session": "POSTER SESSION: Posters"}, {"title": "Large scale predictive process mining and analytics of university degree course data", "pages": "538-539", "doi": "10.1145/3027385.3029446", "abstract": "For students, in particular freshmen, the degree pathway from semester to semester is not that transparent, although students have a reasonable idea what courses are expected to be taken each semester. An often-pondered question by students is: \"what can I expect in the next semester?\" More precisely, given the commitment and engagement I presented in this particular course and the respective performance I achieved, can I expect a similar outcome in the next semester in the particular course I selected? Are the demands and expectations in this course much higher so that I need to adjust my commitment and engagement and overall workload if I expect a similar outcome? Is it better to drop a course to manage expectations rather than to (predictably) fail, and perhaps have to leave the degree altogether? Degree and course advisors and student support units find it challenging to provide evidence based advise to students. This paper presents research into educational process mining and student data analytics in a whole university scale approach with the aim of providing insight into the degree pathway questions raised above. The beta-version of our course level degree pathway tool has been used to shed light for university staff and students alike into our university's 1,300 degrees and associated 6 million course enrolments over the past 20 years.", "authors": ["Jurgen Schulte", "Pedro Fernandez de Mendonca", "Roberto Martinez-Maldonado", "Simon Buckingham Shum"], "session": "POSTER SESSION: Posters"}, {"title": "Beyond failure: the 2nd LAK Failathon poster", "pages": "540-541", "doi": "10.1145/3027385.3029447", "abstract": "This poster will be a chance for a wider LAK audience to engage with the 2nd LAK Failathon workshop. Both of these will build on the successful Failathon event in 2016 and extend beyond discussing individual experiences of failure to exploring how the field can improve, particularly regarding the creation and use of evidence. Failure in research is an increasingly hot topic, with high-profile crises of confidence in the published research literature in medicine and psychology. Among the major factors in this research crisis are the many incentives to report and publish only positive findings. These incentives prevent the field in general from learning from negative findings, and almost entirely preclude the publication of mistakes and errors. Thus providing an alternative forum for practitioners and researchers to learn from each other's failures can be very productive. The first LAK Failathon, held in 2016, provided just such an opportunity for researchers and practitioners to share their failures and negative findings in a lower-stakes environment, to help participants learn from each other's mistakes. It was very successful, and there was strong support for running it as an annual event. The 2nd LAK Failathon workshop will build on that success, with twin objectives to provide an environment for individuals to learn from each other's failures, and also to co-develop plans for how we as a field can better build and deploy our evidence base. This poster is an opportunity for wider feedback on the plans developed in the workshop, with interactive use of sticky notes to add new ideas and coloured dots to illustrate prioritisation. This broadens the participant base in this important work, which should improve the quality of the plans and the commitment of the community to delivering them.", "authors": ["Doug Clow", "Rebecca Ferguson", "Kirsty Kitto", "Yong-Sang Cho", "Mike Sharkey", "Cecilia Aguerrebere"], "session": "POSTER SESSION: Posters"}, {"title": "Examining motivations and self-regulated learning strategies of returning MOOCs learners", "pages": "542-543", "doi": "10.1145/3027385.3029448", "abstract": "The present study examines behavioral patterns, motivations, and self-regulated learning strategies of returning learners---a special learner subpopulation in massive open online courses (MOOCs). To this end, data were collected from a teacher professional development MOOC that has been offered for seven iterations during 2014--2016. Data analysis identified more than 15% of all registrants as returning learners. Findings from click log analysis identified possible motivations of re-enrollment including improving grades, refreshing theoretical understanding, and solving practical problems. Further analysis uncovered evidence of self-regulated learning strategies among returning learners. Taken together, this study contributes to ongoing inquiry into MOOCs learning pathways, informs future MOOC design, and sheds light on the exploration of MOOCs as a viable option for teacher professional development.", "authors": ["Bodong Chen", "Yizhou Fan", "Guogang Zhang", "Qiong Wang"], "session": "POSTER SESSION: Posters"}, {"title": "Learning from learning curves: discovering interpretable learning trajectories", "pages": "544-545", "doi": "10.1145/3027385.3029449", "abstract": "We propose a data driven method for decomposing population level learning curve models into mutually exclusive distinctive groups each consisting of similar learning trajectories. We validate this method on six knowledge components from the log data from an online tutoring system ASSIST-ment. Preliminary analysis reveals interpretable patterns of \"skill growth\" that correlate with students' performance in the subsequently administered state standardized tests.", "authors": ["Lujie Chen", "Artur Dubrawski"], "session": "POSTER SESSION: Posters"}, {"title": "Utilizing visualization and feature selection methods to identify important learning objectives in a course", "pages": "546-547", "doi": "10.1145/3027385.3029450", "abstract": "There have been numerous efforts to increase students' academic success. One data-driven approach is to highlight the important learning objectives in a course. In this paper, we used visualization and three feature selection methods to highlight the important learning objectives in a course. Identifying important learning objectives as well as the relation among the learning objectives have multiple educational advantages. First, it informs the instructors and students of the important topics in the course; without learning them properly students will not be successful. Second, it highlights any inconsistencies in defining the learning objective, how they are being assessed, and design of the course. Thus, this approach can be used as a course design diagnostic tool.", "authors": ["Farshid Marbouti", "Heidi Diefes-Dux", "Krishna Madhavan"], "session": "POSTER SESSION: Posters"}, {"title": "How can we accelerate dissemination of knowledge and learning?: developing an online knowledge management platform for networked improvement communities", "pages": "548-549", "doi": "10.1145/3027385.3029451", "abstract": "The Networked Improvement Learning and Support (NILS) platform is an online tool designed to accelerate the initiation and development of Networked Improvement Communities in a disciplined manner. Its main goal is to promote social, organizational learning through curation and synthesis and tacit to explicit knowledge conversion to facilitate knowledge construction and ownership by the communities regarding improvement practice in education. In this proposal we will discuss the NILS platform, a few use cases, and a plan of analytics development that advances knowledge dissemination and monitors the health status of networks.", "authors": ["Ouajdi Manai", "Hiroyuki Yamada"], "session": "POSTER SESSION: Posters"}, {"title": "Students' emotional self-labels for personalized models", "pages": "550-551", "doi": "10.1145/3027385.3029452", "abstract": "There are some implementations towards understanding students' emotional states through automated systems with machine learning models. However, generic AI models of emotions lack enough accuracy to autonomously and meaningfully trigger any interventions. Collecting self-labels from students as they assess their internal states can be a way to collect labeled subject specific data necessary to obtain personalized emotional engagement models. In this paper, we outline preliminary analysis on emotional self-labels collected from students while using a learning platform.", "authors": ["Sinem Aslan", "Eda Okur", "Nese Alyuz", "Sinem Emine Mete", "Ece Oktay", "Utku Genc", "Asli Arslan Esme"], "session": "POSTER SESSION: Posters"}, {"title": "Write-and-learn: promoting meaningful learning through concept map-based formative feedback on writing assignments", "pages": "552-553", "doi": "10.1145/3027385.3029453", "abstract": "A primary goal of higher education is to promote meaningful learning: the delivery of core academic content to students in innovative ways that allow them to learn and then apply what they have learned. As a pedagogical strategy, Writing-to-Learn (WTL) intends to use writing to improve students' understanding of course content and concepts. To improve students' meaningful learning of conceptual knowledge in WTL activities, the project proposes to develop the Write-and-Learn system to generate automated formative feedback by taking advantage of the concept maps constructed from instructors' lecture notes and individual students' writing assignments. The proposed research aims to provide insights into how to apply concept maps into WTL activities to generate effective formative feedback on the acquisition and development of conceptual knowledge, and explore how and to what extent concept map-based formative feedback can be utilized to scaffold and promote meaningful learning in WTL activities.", "authors": ["Ye Xiong", "Yi-Fang Brook Wu"], "session": "POSTER SESSION: Posters"}, {"title": "Data-assisted instructional video revision via course-level exploratory video retention analysis", "pages": "554-555", "doi": "10.1145/3027385.3029454", "abstract": "Since teachers are not physically present in an online class, instructional video is the major carrier of course contents in an online learning environment. This paper aims to investigate how course-level exploratory video retention analysis can be used for identifying moments with abnormal watching behaviors and revising videos for a higher video retention. We have empirically evaluated the effectiveness of video analysis and revisions, based on evaluating retentions of revised videos.", "authors": ["Chi-Un Lei", "Donn Gonda", "Xiangyu Hou", "Elizabeth Oh", "Xinyu Qi", "Tyrone T. O. Kwok", "Yip-Chun Au Yeung", "Ray Lau"], "session": "POSTER SESSION: Posters"}, {"title": "Using predictive analytics in a self-regulated learning university course to promote student success", "pages": "556-557", "doi": "10.1145/3027385.3029455", "abstract": "Prior research offers evidence that differing levels of student engagement are associated with different outcomes in terms of performance. In this study, we investigating the efficacy of a model of behavioural and agentic engagement to predict student performance (low, middle, high) at four timepoints in a semester. The model was significant at all four timepoints. Measures of behavioural and agentic engagement predicted membership across the three groups differently. With a few exceptions, these differences were consistent across timepoints. Looking at variations in student engagement across time can be used to target interventions to support student success at the undergraduate level.", "authors": ["Rebecca L. Edwards", "Sarah K. Davis", "Allyson F. Hadwin", "Todd M. Milford"], "session": "POSTER SESSION: Posters"}, {"title": "What are visitors up to?: helping museum facilitators know what visitors are doing", "pages": "558-559", "doi": "10.1145/3027385.3029456", "abstract": "In this paper, we describe a tablet application designed around an interactive game-based science museum exhibit. It is aimed to help provide museum docents useful information about the visitors' actions, in a way that is actionable, and enables docents to provide assistance and prompts to visitors that are more meaningful, compared to what they are typically able to do without this interface augmentation.", "authors": ["Vishesh Kumar", "Mike Tissenbaum", "Matthew Berland"], "session": "POSTER SESSION: Posters"}, {"title": "Predicting e-textbook adoption based on event segmentation of teachers' usage", "pages": "560-561", "doi": "10.1145/3027385.3029457", "abstract": "Customized content of e-textbook require teachers to spend greater efforts using authoring tools and planning activities before class, and teachers with various contexts have different demands on e-textbook. However, some teachers who lack ICT skills and dissatisfy with the features tend to give up using e-textbook. Thus we need to know the status of teachers' usage earlier before we decide to give them some technical supports. This paper describes an analysis method for predicting e-textbook adoption from usage records in early days, and an event segmentation method of teachers' usage is used in effort to provide features of predictive model.", "authors": ["Longwei Zheng", "Wei Gong", "Xiaoqing Gu"], "session": "POSTER SESSION: Posters"}, {"title": "Business intelligence (BI) for personalized student dashboards", "pages": "562-563", "doi": "10.1145/3027385.3029458", "abstract": "At Stenden University students from all over the world study together; all these different nationalities and cultures result in different ideas concerning academic success. The basis of this project was to develop a personalized dashboard for students via Microsoft Office 365 Power BI in which students can set their own personal KPI's. The raw data from the Student Information System (SIS) was transformed into clear visualizations that will help students gain better insight into their academic performance. This information can be used either independently or in consultation with their student advisor.", "authors": ["J. Sluijter", "M. Otten"], "session": "POSTER SESSION: Posters"}, {"title": "When learning is high stake", "pages": "564-565", "doi": "10.1145/3027385.3029461", "abstract": "Firefighter learning is high stake. They need to maintain certain competence levels related to physical, mental, and firefighting and rescue skills in order to provide the public with a high level of emergency service. Fire and Rescue Services need to maintain an overview of the current competences of their personnel and to react when there is a competence gap. This poster presents our approach to using competence modelling, learner models, learning analytics, and visualisations in order provide insight into competence status and development on the individual, team, and organisation level, and to provide early-alerts and automated messages to instructors responsible for planning training activities, as well as to team leaders responsible for making decisions about teams in high stakes situations.", "authors": ["Cecilie Johanne Slokvik Hansen", "Barbara Wasson", "Hans Skretting", "Grete Netteland", "Marina Hirnstein"], "session": "POSTER SESSION: Posters"}, {"title": "Mining knowledge components from many untagged questions", "pages": "566-567", "doi": "10.1145/3027385.3029462", "abstract": "An ongoing study is being run to ensure that the McGraw-Hill Education LearnSmart platform teaches students as efficiently as possible. The first step in doing so is to identify what Knowledge Components (KCs) exist in the content; while the content is tagged by experts, these tags need to be re-calibrated periodically. LearnSmart courses are organized into chapters corresponding to those found in a textbook; each chapter can have anywhere from about a hundred to a few thousand questions. The KC extraction algorithms proposed by Barnes [1] and Desmarais et al [3] are applied on a chapter-by-chapter basis. To assess the ability of each mined q matrix to describe the observed learning, the PFA model of Pavlik et al [4] is fitted to it and a cross-validated AUC is calculated. The models are assessed based on whether PFA's predictions of student correctness are accurate. Early results show that both algorithms do a reasonable job of describing student progress, but q matrices with very different numbers of KCs fit observed data similarly well. Consequently, further consideration is required before automated extraction is practical in this context.", "authors": ["Neil L. Zimmerman", "Ryan S. Baker"], "session": "POSTER SESSION: Posters"}, {"title": "Relevance of learning analytics to measure and support students' learning in adaptive educational technologies", "pages": "568-569", "doi": "10.1145/3027385.3029463", "abstract": "In this poster, we describe the aim and current activities of the EARLI-Centre for Innovative Research (E-CIR) \"Measuring and Supporting Student's Self-Regulated Learning in Adaptive Educational Technologies\" which is funded by the European Association for Research on Learning and Instruction (EARLI) from 2015 to 2019. The aim is to develop our understanding of multimodal data that unobtrusively capture cognitive, meta-cognitive, affective and motivational states of learners over time. This demands for a concerted interdisciplinary dialogue combining findings from psychology and educational sciences with advances in computer sciences and artificial intelligence. The participants in this E-CIR are leading international researchers who have articulated different emerging perspectives and methodologies to measure cognition, metacognition, motivation, and emotions during learning. The participants recognize the need for intensive collaboration to accelerate progress with new interdisciplinary methods including learning analytics to develop more powerful adaptive educational technologies.", "authors": ["Maria Bannert", "Inge Molenaar", "Roger Azevedo", "Sanna J\u00e4rvel\u00e4", "Dragan Ga\u0161evi\u0107"], "session": "POSTER SESSION: Posters"}, {"title": "Exploring the measurement of collaborative problem solving using a human-agent educational game", "pages": "570-571", "doi": "10.1145/3027385.3029464", "abstract": "Collaborative problem solving (CPS) is a process that relies on both cognitive and social skills contributions by those involved in the joint activity. If a student is matched with a problematic group of peers, then there will be no valid measurement of the CPS skills. In the human-agent settings, CPS skills are measured by pairing each individual student with a computer agent or agents that can be programmed to act as team members with varying characteristics relevant to different CPS skills and contexts. This paper describes current research on measuring CPS skills through human-agent interactions in a prototype of a collaborative educational game.", "authors": ["Kristin Stoeffler", "Yigal Rosen", "Alina von Davier"], "session": "POSTER SESSION: Posters"}, {"title": "Cooking with learning analytics recipes", "pages": "572-573", "doi": "10.1145/3027385.3029465", "abstract": "Learning Analytics is a melting pot for a multitude of research fields and origin of many developments about learning and its environment. There is a serious hype over the concepts of learning analytics, however, concrete solutions and applications are comparably scarce. Of course, data rich environments, such as MOOCs, come with statistical analytics dashboards, although the educational value is often limited. Practical solutions for scenarios in data-lean environments or for small-scale organizations are rarely adopted. The LA4S project is dedicated to gather practical solutions, provide a tool box for practitioners, and publish a cook book with concrete learning analytics recipes for everyone.", "authors": ["Roope Jaakonm\u00e4ki", "Hendrik Drachsler", "Michael Kickmeier-Rust", "Stefan Dietze", "Albrecht Fortenbacher", "Ivana Marenzi"], "session": "POSTER SESSION: Posters"}, {"title": "Using item response theory to generate an item pool for an e-learning-system", "pages": "574-575", "doi": "10.1145/3027385.3029466", "abstract": "This paper1 demonstrates how the application of item response theory yields useful item characteristics, which further can be the foundation of item pools and therefore adaptive educational software to come.", "authors": ["M. Schweighart"], "session": "POSTER SESSION: Posters"}, {"title": "Forecasting student outcomes at university-wide scale using machine learning", "pages": "576-577", "doi": "10.1145/3027385.3029467", "abstract": "Elements of applied statistics and computer science are quickly integrating and being applied to a diverse set of problems in academia and industry. Here I explore the potential value of this multi-disciplinary approach to applications in higher education by applying it to forecasting course level outcomes for individual students at all of Penn State's campuses. Utilizing hundreds of data sources on individual students, ranging from past performance to current course engagement, I demonstrate the potential accuracy of forecasting techniques at identifying high risk students early in the course term. Our preliminary results suggest that %50 of students that earned a D or F in 2015 could have been identified prior to the start of the course.", "authors": ["Drew Wham"], "session": "POSTER SESSION: Posters"}, {"title": "Buying time: enabling learners to become earners with a real-world paid task recommender system", "pages": "578-579", "doi": "10.1145/3027385.3029469", "abstract": "Massive Open Online Courses (MOOCs) aim to educate the world, especially learners from developing countries. While MOOCs are certainly available to the masses, they are not yet fully accessible. Although all course content is just clicks away, deeply engaging with a MOOC requires a substantial time commitment, which frequently becomes a barrier to success. To mitigate the time required to learn from a MOOC, we here introduce a design that enables learners to earn money by applying what they learn in the course to real-world marketplace tasks. We present a Paid Task Recommender System (Rec-$ys), which automatically recommends course-relevant tasks to learners as drawn from online freelance platforms. Rec-$ys has been deployed into a data analysis MOOC and is currently under evaluation.", "authors": ["Guanliang Chen", "Dan Davis", "Markus Krause", "Claudia Hauff", "Geert-Jan Houben"], "session": "POSTER SESSION: Posters"}, {"title": "Discourse analysis to improve the effective engagement of MOOC videos", "pages": "580-581", "doi": "10.1145/3027385.3029470", "abstract": "Lecture videos are amongst the most commonly used instructional methods in present Massive Open Online Courses (MOOCs). As the main form of instruction, students' engagement behaviour with MOOC videos directly impacts the students' success or failure. This research focuses on an in-depth analysis of 1.5 million video interactions (e.g. pause, seek video) of a Programming MOOC. Our video-by-video analysis explores the rationale behind the time-wise variation of video interactions. We aim to analyse discourse features (e.g. syntactic simplicity of text, and speaking rate) and their correlation with the video interaction patterns. This paper presents preliminary results and educational video design implications.", "authors": ["Thushari Atapattu", "Katrina Falkner"], "session": "POSTER SESSION: Posters"}, {"title": "Understanding the relationship between technology use and cognitive presence in MOOCs", "pages": "582-583", "doi": "10.1145/3027385.3029471", "abstract": "In this poster, we present the results of the study which examined the relationship between student differences in their use of the available technology and their perceived levels of cognitive presence within the MOOC context. The cognitive presence is a construct used to measure the level of practical inquiry in the Communities of Inquiry model. Our results revealed the existence of three clusters based on student technology use. The clusters significantly differed in terms of their levels of cognitive presence, most notably they differed on the levels of problem resolution.", "authors": ["Vitomir Kovanovi\u0107", "Sre\u0107ko Joksimovi\u0107", "Oleksandra Poquet", "Thieme Hennis", "Shane Dawson", "Dragan Ga\u0161evi\u0107", "Pieter de Vries", "Marek Hatala", "George Siemens"], "session": "POSTER SESSION: Posters"}, {"title": "Supporting learning analytics in computing education", "pages": "584-585", "doi": "10.1145/3027385.3029472", "abstract": "As is the case for many undergraduate STEM degree programs, computing degree programs are plagued by high attrition rates. This is especially true in early computing courses, in which failure and drop-out rates in the 35 to 50 percent range are common. By collecting learning process data as students engage in computer programming assignments, computing educators can place themselves in a position not only to better understand students' struggles, but also to better tailor instructional interventions to students' needs. We have developed OSBLE+, a learning management and analytics environment that interfaces with a computer programming environment to support the automatic collection of learners' programming process and social data as they work on programming assignments, while also providing an interactive environment for the analysis and visualization of those data. In ongoing work, we are using OSBLE+ to explore two possibilities: (a) leveraging learning and social data to strategically deliver automated learning interventions, and (b) presenting learners with visual representations of their learning data in order to prompt them to reflect on and discuss their learning processes.", "authors": ["Daniel M. Olivares", "Christopher D. Hundhausen"], "session": "POSTER SESSION: Posters"}, {"title": "Integrating syllabus data into student success models", "pages": "586-587", "doi": "10.1145/3027385.3029473", "abstract": "In this work, we present (1) a methodology for collecting, evaluating, and utilizing human-annotated data about course syllabi in predictive models of student success, and (2) an empirical analysis of the predictiveness of such features as they relate to others in modeling end-of-course grades in traditional higher education courses. We present a two-stage approach to (1) that addresses several challenges unique to the annotation task, and address (2) using variable importance metrics from a series of exploratory models. We demonstrate that the process of supplementing traditional course data with human-annotated data can potentially improve predictive models with information not contained in university records, and highlight specific features that demonstrate these potential information gains.", "authors": ["Josh Gardner", "Ogechi Onuoha", "Christopher Brooks"], "session": "POSTER SESSION: Posters"}, {"title": "Tracing physical movement during practice-based learning through multimodal learning analytics", "pages": "588-589", "doi": "10.1145/3027385.3029474", "abstract": "In this paper, we pose the question, can the tracking and analysis of the physical movements of students and teachers within a Practice-Based Learning (PBL) environment reveal information about the learning process that is relevant and informative to Learning Analytics (LA) implementations? Using the example of trials conducted in the design of a LA system, we aim to show how the analysis of physical movement from a macro level can help to enrich our understanding of what is happening in the classroom. The results suggest that Multimodal Learning Analytics (MMLA) could be used to generate valuable information about the human factors of the collaborative learning process and we propose how this information could assist in the provision of relevant supports for small group work. More research is needed to confirm the initial findings with larger sample sizes and refine the data capture and analysis methodology to allow automation.", "authors": ["Donal Healion", "Sam Russell", "Mutlu Cukurova", "Daniel Spikol"], "session": "POSTER SESSION: Posters"}, {"title": "Automating student survey reports in online education for faculty and instructional designers", "pages": "590-591", "doi": "10.1145/3027385.3029475", "abstract": "In this paper, we discuss Colorado State University Online's progress toward designing automated survey reports for student feedback data collected through our newly designed LTI survey tool. Using multiple R packages, including 'rmarkdown' and 'likert', the reporting tool imports student survey response data and generates reports for faculty and instructional designers. These reports focus on student perceptions of communication, course design, academic challenge, general satisfaction, and more. These reports display visual representations of the Likert-type response frequencies, basic descriptive statistics, and free-response comments. Surveys are administered just before half-way through the semester to provide formative feedback and just before the end of the semester to provide summative feedback. In this way, faculty and instructional designers can obtain a quick and easily digestible report to make changes and improvements to their classes with minimal effort in the back end production.", "authors": ["Sean Burns", "Kimberley Corwin"], "session": "POSTER SESSION: Posters"}, {"title": "[LISA] learning analytics for sensor-based adaptive learning", "pages": "592-593", "doi": "10.1145/3027385.3029476", "abstract": "This paper reports on research conducted in a project named LISA which aims at supporting learners through learner-centered learning analytics using physiological sensor data as well as environmental sensors. We present the concept and a prototypical realization of a mobile sensor device used in LISA.", "authors": ["Albrecht Fortenbacher", "Niels Pinkwart", "Haeseon Yun"], "session": "POSTER SESSION: Posters"}, {"title": "What does student writing tell us about their thinking on social justice?", "pages": "594-595", "doi": "10.1145/3027385.3029477", "abstract": "In this work we investigate the use of deep learning for text analysis to measure elements of student thinking related to issues of privilege, oppression, diversity and social justice. We leverage historical expert annotations as well as a large lexical model to create a more generalizable vocabulary for identifying these characteristics in short student writing. We demonstrate the feasibility of this approach, and identify further areas for research.", "authors": ["Heeryung Choi", "Christopher Brooks", "Kevyn Collins-Thompson"], "session": "POSTER SESSION: Posters"}, {"title": "MORPH: supporting the integration of learning analytics at institutional level", "pages": "596-597", "doi": "10.1145/3027385.3029478", "abstract": "While there is high potential in using learning analytics to provide educational institutions as well as teachers and learners with actionable information and improve learning experiences, currently only very few learning analytics tools are actually used in educational institutions. In this paper, we introduce MORPH, a platform that facilitates the integration of learning analytics modules and tools into institutional learning systems. MORPH provides a robust distributed architecture which combines batch, stream and real-time data processing using a parallel processing model to enable and support efficient processing of large amounts of data. Furthermore, it provides common management and administration features that enable the seamless integration of learning analytics research modules and tools into existing institutional learning systems.", "authors": ["Zoran Jeremic", "Vive Kumar", "Sabine Graf"], "session": "POSTER SESSION: Posters"}, {"title": "A neural network approach for students' performance prediction", "pages": "598-599", "doi": "10.1145/3027385.3029479", "abstract": "In this paper, we propose a method for predicting final grades of students by a Recurrent Neural Network (RNN) from the log data stored in the educational systems. We applied this method to the log data from 108 students and examined the accuracy of prediction. From the experimental results, comparing with multiple regression analysis, it is confirmed that an RNN is effective to early prediction of final grades.", "authors": ["F. Okubo", "T. Yamashita", "A. Shimada", "H. Ogata"], "session": "POSTER SESSION: Posters"}, {"title": "Challenges and opportunities facing educational discourse researchers", "pages": "600-601", "doi": "10.1145/3027385.3029480", "abstract": "The scholarly investigation of discourse in teaching and learning is multi-disciplinary, theoretically rich, and highly technical. Researchers with backgrounds in education, cognitive psychology, computer science, and the social sciences apply a diverse set of techniques to understand how student discussions affect learning. Aided by big data coming from learning content management and massive open online course systems, these researchers have an unparalleled opportunity for insight into the teaching and learning process. In this paper we summarize some of the challenges and opportunities arising out of three workshops on Educational Discourse. These workshops convened both expert and emerging scholars to discuss the (i) ethical, (ii) technical, and (iii) infrastructure barriers to building a research community focused on computer-mediated educational discourse. Of particular note is that while computational infrastructure exists for storing and manipulating educational discourse, there is a need for a sociotechnical infrastructure upon which community members can come together to engage in joint work.", "authors": ["Christopher Brooks", "Stephanie Teasley", "George Siemens"], "session": "POSTER SESSION: Posters"}, {"title": "Using learning analytics in iterative design of a digital modeling tool", "pages": "602-603", "doi": "10.1145/3027385.3029482", "abstract": "Iterative design is a powerful method for developing digital classroom tools and curricula. We explore how infusing learning analytics into this process has influenced our development of EcoSurvey, a digital modeling tool for mapping the organisms and interactions in the local ecosystem. We have found that analytic techniques can help us discover areas in which students struggle to engage with scientific modeling, and we can iteratively use learning analytics to demonstrate the impact of design changes.", "authors": ["David Quigley", "Conor McNamara", "Tamara Sumner"], "session": "POSTER SESSION: Posters"}, {"title": "An outcome-based dashboard for moodle and Open edX", "pages": "604-605", "doi": "10.1145/3027385.3029483", "abstract": "This poster presents a cross-platform learning analytics dashboard on Moodle and Open edX for monitoring outcome-based learning progress. The dashboard visualizes students' interactions with the platforms in near real-time, aiming to help teachers and students monitor students' learning progress. The dashboard has been used in four large-size general education courses in a comprehensive university in Hong Kong, undergoing evaluation and improvement.", "authors": ["Xiao Hu", "Xiangyu Hou", "Chi-Un Lei", "Chengrui Yang", "Jeremy Ng"], "session": "POSTER SESSION: Posters"}, {"title": "Automated analysis of aspects of written argumentation", "pages": "606-607", "doi": "10.1145/3027385.3029484", "abstract": "In this paper, we report on a model that uses a mathematically and cognitively augmented Latent Semantic Analysis method to automatically assess aspects of written argumentation, produced by students in a science communication course.", "authors": ["Noureddine Elouazizi", "G\u00fclnur Birol", "Eric Jandciu", "Gunilla \u00d6berg", "Ashley Welsh", "Andrea Han", "Alice Campbell"], "session": "POSTER SESSION: Posters"}, {"title": "An automatic approach for discovering skill relationship from learning data", "pages": "608-609", "doi": "10.1145/3027385.3029485", "abstract": "We have developed a method called skill2vec, which applies big data techniques to automatically analyze the learning data to discover skill relationship, leading to a more objective and data-informed decision making. Skill2vec is a neural network architecture which can transform a skill to a new vector space called embedding. The embedding can facilitate the comparison and visualization of different skills and their relationship. We conducted a pilot experiment using benchmark dataset to demonstrate the effectiveness of our method.", "authors": ["Tak-Lam Wong", "Haoran Xie", "Fu Lee Wang", "Chung Keung Poon", "Di Zou"], "session": "POSTER SESSION: Posters"}, {"title": "Topic models to support instructors in MOOC forums", "pages": "610-611", "doi": "10.1145/3027385.3029486", "abstract": "This paper explores the potential of using na\u00efve topic modeling to support instructors in navigating MOOC discussion forums. Categorizing discussion threads into topics can provide an overview of the discussion, improve navigation of the forum, and support replying to a representative sample of content related posts. We investigate four different approaches to using topic models to organize and present discussion posts, highlighting the strength and weaknesses of each approach to support instructors.", "authors": ["Jovita M. Vytasek", "Alyssa F. Wise", "Sonya Woloshen"], "session": "POSTER SESSION: Posters"}, {"title": "Best intentions: learner feedback on learning analytics visualization design", "pages": "612-613", "doi": "10.1145/3027385.3029487", "abstract": "A mixed methods approach was undertaken in this exploratory study to better understand how learners perceive and utilize learning analytics visualizations during online discussions activities. Internal conditions such as goal orientation and numeracy were measured alongside the external conditions created by the discussion structure and learning analytics. Our results emphasize key factors that should be considered when designing learning analytics tools.", "authors": ["Halimat Alabi", "Marek Hatala"], "session": "POSTER SESSION: Posters"}, {"title": "The effects of a learning analytics empowered technology on students' arithmetic skill development", "pages": "614-615", "doi": "10.1145/3027385.3029488", "abstract": "Learning analytics empowered educational technologies (LA-ET) in primary classrooms allow for blended learning scenarios with teacher-lead instructions, class-paced and individually-paced practice. This quasi-experimental study investigates the effects of a LA-ET on the development of students' arithmetic skills over one schoolyear. Children learning in a traditional paper & pencil condition were compared to learners using a LA-ET on tablet computers in grade 4. The educational technology combined teacher dashboards (extracted analytics) and class and individually paced assignments (embedded analytics). The results indicated that children in the LA-ET condition made significantly more progress on arithmetic skills in one schoolyear compared to children in the paper & pencil condition.", "authors": ["Inge Molenaar", "Carolien A. N. Knoop-van Campen", "Fred Hasselman"], "session": "POSTER SESSION: Posters"}, {"title": "New features in Wikiglass, a learning analytic tool for visualizing collaborative work on wikis", "pages": "616-617", "doi": "10.1145/3027385.3029489", "abstract": "Wikiglass is a learning analytic tool for visualizing collaborative work on Wikis built by groups of secondary or primary school students. This poster presents new features of Wikiglass developed recently based on requests from teachers, including flexible selection of date range, revision network, and thinking order detection. Currently the new features are used and evaluated in two secondary schools in Hong Kong.", "authors": ["Xiao Hu", "Chengrui Yang", "Chen Qiao", "Xiaoyu Lu", "Sam K. W. Chu"], "session": "POSTER SESSION: Posters"}]}, {"year": 2018, "papers": [{"title": "The half-life of MOOC knowledge: a randomized trial evaluating knowledge retention and retrieval practice in MOOCs", "pages": "1-10", "doi": "10.1145/3170358.3170383", "abstract": "Retrieval practice has been established in the learning sciences as one of the most effective strategies to facilitate robust learning in traditional classroom contexts. The cognitive theory underpinning the \"testing effect\" states that actively recalling information is more effective than passively revisiting materials for storing information in long-term memory. We document the design, deployment, and evaluation of an Adaptive Retrieval Practice System (ARPS) in a MOOC. This push-based system leverages the testing effect to promote learner engagement and achievement by intelligently delivering quiz questions from prior course units to learners throughout the course. We conducted an experiment in which learners were randomized to receive ARPS in a MOOC to track their performance and behavior compared to a control group. In contrast to prior literature, we find no significant effect of retrieval practice in this MOOC environment. In the treatment condition, passing learners engaged more with ARPS but exhibited similar levels of knowledge retention as non-passing learners.", "authors": ["Dan Davis", "Ren\u00e9 F. Kizilcec", "Claudia Hauff", "Geert-Jan Houben"], "session": "SESSION: Evaluation & feedback"}, {"title": "Graph-based visual topic dependency models: supporting assessment design and delivery at scale", "pages": "11-15", "doi": "10.1145/3170358.3170418", "abstract": "Educational environments continue to rapidly evolve to address the needs of diverse, growing student populations, while embracing advances in pedagogy and technology. In this changing landscape ensuring the consistency among the assessments for different offerings of a course (within or across terms), providing meaningful feedback about students' achievements, and tracking students' progression over time are all challenging tasks, particularly at scale. Here, a collection of visual Topic Dependency Models (TDMs) is proposed to help address these challenges. It visualises the required topics and their dependencies at a course level (e.g., CS 100) and assessment achievement data at the classroom level (e.g., students in CS 100 Term 1 2016 Section 001) both at one point in time (static) and over time (dynamic). The collection of TDMs share a common, two-weighted graph foundation. An algorithm is presented to create a TDM (static achievement for a cohort). An open-source, proof of concept implementation of the TDMs is under development; the current version is described briefly in terms of its support for visualising existing (historical, test) and synthetic data generated on demand.", "authors": ["Kendra Cooper", "Hassan Khosravi"], "session": "SESSION: Evaluation & feedback"}, {"title": "Data-driven generation of rubric criteria from an educational programming environment", "pages": "16-20", "doi": "10.1145/3170358.3170399", "abstract": "We demonstrate that, by using a small set of hand-graded student work, we can automatically generate rubric criteria with a high degree of validity, and that a predictive model incorporating these rubric criteria is more accurate than a previously reported model. We present this method as one approach to addressing the often challenging problem of grading assignments in programming environments. A classic solution is creating unit-tests that the student-generated program must pass, but the rigid, structured nature of unit-tests is suboptimal for assessing the more open-ended assignments students encounter in introductory programming environments like Alice. Furthermore, the creation of unit-tests requires predicting the various ways a student might correctly solve a problem - a challenging and time-intensive process. The current study proposes an alternative, semi-automated method for generating rubric criteria using low-level data from the Alice programming environment.", "authors": ["Nicholas Diana", "Michael Eagle", "John Stamper", "Shuchi Grover", "Marie Bienkowski", "Satabdi Basu"], "session": "SESSION: Evaluation & feedback"}, {"title": "Supporting teachers' intervention in students' virtual collaboration using a network based model", "pages": "21-25", "doi": "10.1145/3170358.3170394", "abstract": "This paper reports a Design-Based Research project developing a tool (the Process Tab) that supports teachers' interventions with students in virtual internships. The tool uses a networked approach and allows insights into the discourse of groups and individuals based on contributions in chat fora and assignments. In the paper, we present the tool and reports from interviews with three teachers who used the tool. The interviews provide insights about the teachers' hopes, actual use, and difficulties with the tool. The main insight is that even though the teachers genuinely liked the idea and specific representations of the Process Tab, their lack of ability to teach and look at the tool at the same time hindered their use. In the final part of the paper, we discuss how to address this issue.", "authors": ["Tiffany Herder", "Zachari Swiecki", "Simon Skov Fougt", "Andreas Lindenskov Tamborg", "Benjamin Brink Allsopp", "David Williamson Shaffer", "Morten Misfeldt"], "session": "SESSION: Evaluation & feedback"}, {"title": "Correlating affect and behavior in reasoning mind with state test achievement", "pages": "26-30", "doi": "10.1145/3170358.3170378", "abstract": "Previous studies have investigated the relationship between affect, behavior, and learning in blended learning systems. These articles have found that affect and behavior are closely linked with learning outcomes. In this paper, we attempt to replicate prior work on how affective states and behaviors relate to mathematics achievement, investigating these issues within the context of 5th-grade students in South Texas using a mathematics blended learning system, Reasoning Mind. We use automatic detectors of student behavior and affect, and correlate inferred rates of each behavior and affective state with the students' end-of-year standardized assessment score. A positive correlation between engaged concentration and test scores replicates previous studies, as does a negative correlation between boredom and test scores. However, our findings differ from previous findings relating to confusion, frustration, and off-task behavior, suggesting the importance of contextual factors for the relationship between behavior, affect, and learning. Our study represents a step in understanding how broadly findings on the relationships between affect/behavior and learning generalize across different learning platforms.", "authors": ["Victor Kostyuk", "Ma. Victoria Almeda", "Ryan S. Baker"], "session": "SESSION: Evaluation & feedback"}, {"title": "License to evaluate: preparing learning analytics dashboards for educational practice", "pages": "31-40", "doi": "10.1145/3170358.3170421", "abstract": "Learning analytics can bridge the gap between learning sciences and data analytics, leveraging the expertise of both fields in exploring the vast amount of data generated in online learning environments. A typical learning analytics intervention is the learning dashboard, a visualisation tool built with the purpose of empowering teachers and learners to make informed decisions about the learning process. Related work has investigated learning dashboards, yet none have explored the theoretical foundation that should inform the design and evaluation of such interventions. In this systematic literature review, we analyse the extent to which theories and models from learning sciences have been integrated into the development of learning dashboards aimed at learners. Our analysis revealed that very few dashboard evaluations take into account the educational concepts that were used as a theoretical foundation for their design. Furthermore, we report findings suggesting that comparison with peers, a common reference frame for contextualising information on learning analytics dashboards, was not perceived positively by all learners. We summarise the insights gathered through our literature review in a set of recommendations for the design and evaluation of learning analytics dashboards for learners.", "authors": ["Ioana Jivet", "Maren Scheffel", "Marcus Specht", "Hendrik Drachsler"], "session": "SESSION: Dashboards"}, {"title": "Open learner models and learning analytics dashboards: a systematic review", "pages": "41-50", "doi": "10.1145/3170358.3170409", "abstract": "This paper aims to link student facing Learning Analytics Dashboards (LADs) to the corpus of research on Open Learner Models (OLMs), as both have similar goals. We conducted a systematic review of literature on OLMs and compared the results with a previously conducted review of LADs for learners in terms of (i) data use and modelling, (ii) key publication venues, (iii) authors and articles, (iv) key themes, and (v) system evaluation. We highlight the similarities and differences between the research on LADs and OLMs. Our key contribution is a bridge between these two areas as a foundation for building upon the strengths of each. We report the following key results from the review: in reports of new OLMs, almost 60% are based on a single type of data; 33% use behavioral metrics; 39% support input from the user; 37% have complex models; and just 6% involve multiple applications. Key associated themes include intelligent tutoring systems, learning analytics, and self-regulated learning. Notably, compared with LADs, OLM research is more likely to be interactive (81% of papers compared with 31% for LADs), report evaluations (76% versus 59%), use assessment data (100% versus 37%), provide a comparison standard for students (52% versus 38%), but less likely to use behavioral metrics, or resource use data (33% against 75% for LADs). In OLM work, there was a heightened focus on learner control and access to their own data.", "authors": ["Robert Bodily", "Judy Kay", "Vincent Aleven", "Ioana Jivet", "Dan Davis", "Franceska Xhakaj", "Katrien Verbert"], "session": "SESSION: Dashboards"}, {"title": "Multi-institutional positioning test feedback dashboard for aspiring students: lessons learnt from a case study in flanders", "pages": "51-55", "doi": "10.1145/3170358.3170419", "abstract": "Our work focuses on a multi-institutional implementation and evaluation of a Learning Analytics Dashboards (LAD) at scale, providing feedback to N=337 aspiring STEM (science, technology, engineering and mathematics) students participating in a region-wide positioning test before entering the study program. Study advisors were closely involved in the design and evaluation of the dashboard. The multi-institutional context of our case study requires careful consideration of external stakeholders and data ownership and portability issues, which gives shape to the technical design of the LAD. Our approach confirms students as active agents with data ownership, using an anonymous feedback code to access the LAD and to enable students to share their data with institutions at their discretion. Other distinguishing features of the LAD are the support for active content contribution by study advisors and LATEX type-setting of question item feedback to enhance visual recognizability. We present our lessons learnt from a first iteration in production.", "authors": ["Tom Broos", "Katrien Verbert", "Greet Langie", "Carolien Van Soom", "Tinne De Laet"], "session": "SESSION: Dashboards"}, {"title": "A qualitative evaluation of a learning dashboard to support advisor-student dialogues", "pages": "56-60", "doi": "10.1145/3170358.3170417", "abstract": "This paper presents an evaluation of a learning dashboard that supports the dialogue between a student and a study advisor. The dashboard was designed, developed, and evaluated in collaboration with study advisers. To ensure scalability to other contexts, the dashboard uses data that is commonly available at any higher education institute. It visualizes the grades of the student, an overview of the progress through the year, his/her position in comparison with peers, sliders to plan the next years and a prediction of the length of the bachelor program for this student in years based on historic data. The dashboard was deployed at KU Leuven, Belgium and used in September 2017 to support 224 sessions between students and study advisers. We observed twenty of these conversations. We also collected feedback from 101 students with questionnaires. Results of our observations indicate that the dashboard primarily triggers insights at the beginning of a conversation. The number of insights and the level of these insights (factual, interpretative and reflective) depends on the context of the conversation. Most insights were triggered in conversations with students doubting to continue the program, indicating that our dashboard is useful to support difficult decision-making processes.", "authors": ["Martijn Millecamp", "Francisco Guti\u00e9rrez", "Sven Charleer", "Katrien Verbert", "Tinne De Laet"], "session": "SESSION: Dashboards"}, {"title": "A generalized classifier to identify online learning tool disengagement at scale", "pages": "61-70", "doi": "10.1145/3170358.3170370", "abstract": "Student success, a major focus in higher education, in part, requires students to remain actively engaged in the required coursework. Identifying student disengagement, when a student stops completing coursework, at scale has been a continuing challenge for higher education due to the heterogeneity of traditional college courses. This research uses data from Connect by McGraw-Hill Education, a widely used online learning tool, to build a classifier to identify learning tool disengagement at scale. This classifier was trained and tested on four years of historical data, representing 4.5 million students in 175,000 courses, across 256 disciplines. Results show that the classifier is effective in identifying disengagement within the online learning tool against baselines, across time, and within and across disciplines. The classifier was also effective in identifying students at risk of disengaging from Connect and then earning unsuccessful grades in a pilot course for which the assignments in Connect were worth a relatively small portion of the overall course grade. Because Connect is widely used, this classifier is positioned to be a good tool for instructors and institutions to identify students at risk for disengagement from coursework. Instructors and institutions can use this information to design and implement interventions to improve engagement and improve student success at the institution in key courses.", "authors": ["Jacqueline Feild", "Nicholas Lewkow", "Sean Burns", "Karen Gebhardt"], "session": "SESSION: Retention I"}, {"title": "Studying MOOC completion at scale using the MOOC replication framework", "pages": "71-78", "doi": "10.1145/3170358.3170369", "abstract": "Research on learner behaviors and course completion within Massive Open Online Courses (MOOCs) has been mostly confined to single courses, making the findings difficult to generalize across different data sets and to assess which contexts and types of courses these findings apply to. This paper reports on the development of the MOOC Replication Framework (MORF), a framework that facilitates the replication of previously published findings across multiple data sets and the seamless integration of new findings as new research is conducted or new hypotheses are generated. In the proof of concept presented here, we use MORF to attempt to replicate 15 previously published findings across 29 iterations of 17 MOOCs. The findings indicate that 12 of the 15 findings replicated significantly across the data sets, and that two findings replicated significantly in the opposite direction. MORF enables larger-scale analysis of MOOC research questions than previously feasible, and enables researchers around the world to conduct analyses on huge multi-MOOC data sets without having to negotiate access to data.", "authors": ["Juan Miguel L. Andres", "Ryan S. Baker", "Dragan Ga\u0161evi\u0107", "George Siemens", "Scott A. Crossley", "Sre\u0107ko Joksimovi\u0107"], "session": "SESSION: Retention I"}, {"title": "The classroom as a dashboard: co-designing wearable cognitive augmentation for K-12 teachers", "pages": "79-88", "doi": "10.1145/3170358.3170377", "abstract": "When used in classrooms, personalized learning software allows students to work at their own pace, while freeing up the teacher to spend more time working one-on-one with students. Yet such personalized classrooms also pose unique challenges for teachers, who are tasked with monitoring classes working on divergent activities, and prioritizing help-giving in the face of limited time. This paper reports on the co-design, implementation, and evaluation of a wearable classroom orchestration tool for K-12 teachers: mixed-reality smart glasses that augment teachers' realtime perceptions of their students' learning, metacognition, and behavior, while students work with personalized learning software. The main contributions are: (1) the first exploration of the use of smart glasses to support orchestration of personalized classrooms, yielding design findings that may inform future work on real-time orchestration tools; (2) Replay Enactments: a new prototyping method for real-time orchestration tools; and (3) an in-lab evaluation and classroom pilot using a prototype of teacher smart glasses (Lumilo), with early findings suggesting that Lumilo can direct teachers' time to students who may need it most.", "authors": ["Kenneth Holstein", "Gena Hong", "Mera Tegene", "Bruce M. McLaren", "Vincent Aleven"], "session": "SESSION: User-centered design I"}, {"title": "An application of participatory action research in advising-focused learning analytics", "pages": "89-96", "doi": "10.1145/3170358.3170387", "abstract": "Advisors assist students in developing successful course pathways through the curriculum. The purpose of this project is to augment advisor institutional and tacit knowledge with knowledge from predictive algorithms (i.e., Matrix Factorization and Classifiers) specifically developed to identify risk. We use a participatory action research approach that directly involves key members from both advising and research communities in the assessment and provisioning of information from the predictive analytics. The knowledge gained from predictive algorithms is evaluated using a mixed method approach. We first compare the predictive evaluations with advisors evaluations of student performance in courses and actual outcomes in those courses We next expose and classify advisor knowledge of student risk and identify ways to enhance the value of the prediction model. The results highlight the contribution that this collaborative approach can give to the constructive integration of Learning Analytics in higher education settings.", "authors": ["Stefano Fiorini", "Adrienne Sewell", "Mathew Bumbalough", "Pallavi Chauhan", "Linda Shepard", "George Rehrey", "Dennis Groth"], "session": "SESSION: User-centered design I"}, {"title": "Co-creation strategies for learning analytics", "pages": "97-101", "doi": "10.1145/3170358.3170372", "abstract": "In order to further the field of learning analytics (LA), researchers and experts may need to look beyond themselves and their own perspectives and expertise to innovate LA platforms and interventions. We suggest that by co-creating with the users of LA, such as educators and students, researchers and experts can improve the usability, usefulness, and draw greater understanding from LA interventions. Within this article we discuss the current LA issues and barriers and how co-creation strategies can help address many of these challenges. We further outline the considerations, both pre- and during interventions, which support and foster a co-created strategy for learning analytics interventions.", "authors": ["Mollie Dollinger", "Jason M. Lodge"], "session": "SESSION: User-centered design I"}, {"title": "Profiling students from their questions in a blended learning environment", "pages": "102-110", "doi": "10.1145/3170358.3170389", "abstract": "Automatic analysis of learners' questions can be used to improve their level and help teachers in addressing them. We investigated questions (N=6457) asked before the class by 1st year medicine/pharmacy students on an online platform, used by professors to prepare their on-site Q&A session. Our long-term objectives are to help professors in categorizing those questions, and to provide students with feedback on the quality of their questions. To do so, first we manually categorized students' questions, which led to a taxonomy then used for an automatic annotation of the whole corpus. We identified students' characteristics from the typology of questions they asked using K-Means algorithm over four courses. The students were clustered by the proportion of each question asked in each dimension of the taxonomy. Then, we characterized the clusters by attributes not used for clustering such as the students' grade, the attendance, the number and popularity of questions asked. Two similar clusters always appeared: a cluster (A), made of students with grades lower than average, attending less to classes, asking a low number of questions but which are popular; and a cluster (D), made of students with higher grades, high attendance, asking more questions which are less popular. This work demonstrates the validity and the usefulness of our taxonomy, and shows the relevance of this classification to identify different students' profiles.", "authors": ["Fatima Harrak", "Fran\u00e7ois Bouchet", "Vanda Luengo", "Pierre Gillois"], "session": "SESSION: Discourse I: general"}, {"title": "Recurrence quantification analysis as a method for studying text comprehension dynamics", "pages": "111-120", "doi": "10.1145/3170358.3170407", "abstract": "Self-explanations are commonly used to assess on-line reading comprehension processes. However, traditional methods of analysis ignore important temporal variations in these explanations. This study investigated how dynamical systems theory could be used to reveal linguistic patterns that are predictive of self-explanation quality. High school students (n = 232) generated self-explanations while they read a science text. Recurrence Plots were generated to show qualitative differences in students' linguistic sequences that were later quantified by indices derived by Recurrence Quantification Analysis (RQA). To predict self-explanation quality, RQA indices, along with summative measures (i.e., number of words, mean word length, and type-token ration) and general reading ability, served as predictors in a series of regression models. Regression analyses indicated that recurrence in students' self-explanations significantly predicted human rated self-explanation quality, even after controlling for summative measures of self-explanations, individual differences, and the text that was read (R2 = 0.68). These results demonstrate the utility of RQA in exposing and quantifying temporal structure in student's self-explanations. Further, they imply that dynamical systems methodology can be used to uncover important processes that occur during comprehension.", "authors": ["Aaron D. Likens", "Kathryn S. McCarthy", "Laura K. Allen", "Danielle S. McNamara"], "session": "SESSION: Discourse I: general"}, {"title": "Towards a writing analytics framework for adult english language learners", "pages": "121-125", "doi": "10.1145/3170358.3170422", "abstract": "Improving the written literacy of newcomers to English-speaking countries can lead to better education, employment, or social integration opportunities. However, this remains a challenge in traditional classrooms where providing frequent, timely, and personalized feedback is not always possible. Analytics can scaffold the writing development of English Language Learners (ELLs) by providing such feedback. To design these analytics, we conducted a field study analyzing essay samples from immigrant adult ELLs (a group often overlooked in writing analytics research) and identifying their epistemic beliefs and learning motivations. We identified common themes across individual learner differences and patterns of errors in the writing samples. The study revealed strong associations between epistemic writing beliefs and learning strategies. The results are used to develop guidelines for designing writing analytics for adult ELLs, and to propose ideas for analytics that scaffold writing development for this group.", "authors": ["Amna Liaqat", "Cosmin Munteanu"], "session": "SESSION: Discourse I: general"}, {"title": "Epistemic network analysis of students' longer written assignments as formative/summative evaluation", "pages": "126-130", "doi": "10.1145/3170358.3170414", "abstract": "This paper reports on an exploratory trial of developing pedagogical visualizations of 16 students' written assignments on literary analysis using two sets of keywords and Epistemic Network Analysis (ENA). The visualizations are aimed at summative evaluation as a tool for the professor to support assessment and understanding of subject learning. Results show that ENA can visually distinguish low, middle and high performing students, but not statistically significantly. Thus, our trial provides a tool for the professor that supports understanding of subject learning and formative assessment.", "authors": ["Simon Skov Fougt", "Amanda Siebert-Evenstone", "Brendan Eagan", "Sara Tabatabai", "Morten Misfeldt"], "session": "SESSION: Discourse I: general"}, {"title": "Driving data storytelling from learning design", "pages": "131-140", "doi": "10.1145/3170358.3170380", "abstract": "Data science is now impacting the education sector, with a growing number of commercial products and research prototypes providing learning dashboards. From a human-centred computing perspective, the end-user's interpretation of these visualisations is a critical challenge to design for, with empirical evidence already showing that `usable' visualisations are not necessarily effective from a learning perspective. Since an educator's interpretation of visualised data is essentially the construction of a narrative about student progress, we draw on the growing body of work on Data Storytelling (DS) as the inspiration for a set of enhancements that could be applied to data visualisations to improve their communicative power. We present a pilot study that explores the effectiveness of these DS elements based on educators' responses to paper prototypes. The dual purpose is understanding the contribution of each visual element for data storytelling, and the effectiveness of the enhancements when combined.", "authors": ["Vanessa Echeverria", "Roberto Martinez-Maldonado", "Roger Granda", "Katherine Chiluiza", "Cristina Conati", "Simon Buckingham Shum"], "session": "SESSION: Dashboards, learning design & video"}, {"title": "Linking students' timing of engagement to learning design and academic performance", "pages": "141-150", "doi": "10.1145/3170358.3170398", "abstract": "In recent years, the connection between Learning Design (LD) and Learning Analytics (LA) has been emphasized by many scholars as it could enhance our interpretation of LA findings and translate them to meaningful interventions. Together with numerous conceptual studies, a gradual accumulation of empirical evidence has indicated a strong connection between how instructors design for learning and student behaviour. Nonetheless, students' timing of engagement and its relation to LD and academic performance have received limited attention. Therefore, this study investigates to what extent students' timing of engagement aligned with instructor learning design, and how engagement varied across different levels of performance. The analysis was conducted over 28 weeks using trace data, on 387 students, and replicated over two semesters in 2015 and 2016. Our findings revealed a mismatch between how instructors designed for learning and how students studied in reality. In most weeks, students spent less time studying the assigned materials on the VLE compared to the number of hours recommended by instructors. The timing of engagement also varied, from in advance to catching up patterns. High-performing students spent more time studying in advance, while low-performing students spent a higher proportion of their time on catching-up activities. This study reinforced the importance of pedagogical context to transform analytics into actionable insights.", "authors": ["Quan Nguyen", "Michal Huptych", "Bart Rienties"], "session": "SESSION: Dashboards, learning design & video"}, {"title": "Video and learning: a systematic review (2007--2017)", "pages": "151-160", "doi": "10.1145/3170358.3170376", "abstract": "Video materials have become an integral part of university learning and teaching practice. While empirical research concerning the use of videos for educational purposes has increased, the literature lacks an overview of the specific effects of videos on diverse learning outcomes. To address such a gap, this paper presents preliminary results of a large-scale systematic review of peer-reviewed empirical studies published from 2007-2017. The study synthesizes the trends observed through the analysis of 178 papers selected from the screening of 2531 abstracts. The findings summarize the effects of manipulating video presentation, content and tasks on learning outcomes, such as recall, transfer, academic achievement, among others. The study points out the gap between large-scale analysis of fine-grained data on video interaction and experimental findings reliant on established psychological instruments. Narrowing this gap is suggested as the future direction for the research on video-based learning.", "authors": ["Oleksandra Poquet", "Lisa Lim", "Negin Mirriahi", "Shane Dawson"], "session": "SESSION: Dashboards, learning design & video"}, {"title": "Using embedded formative assessment to predict state summative test scores", "pages": "161-170", "doi": "10.1145/3170358.3170392", "abstract": "If we wish to embed assessment for accountability within instruction, we need to better understand the relative contribution of different types of learner data to statistical models that predict scores on assessments used for accountability purposes. The present work scales up and extends predictive models of math test scores from existing literature and specifies six categories of models that incorporate information about student prior knowledge, socio-demographics, and performance within the MATHia intelligent tutoring system. Linear regression and random forest models are learned within each category and generalized over a sample of 23,000+ learners in Grades 6, 7, and 8 over three academic years in Miami-Dade County Public Schools. After briefly exploring hierarchical models of this data, we discuss a variety of technical and practical applications, limitations, and open questions related to this work, especially concerning to the potential use of instructional platforms like MATHia as a replacement for time-consuming standardized tests.", "authors": ["Stephen E. Fancsali", "Guoguo Zheng", "Yanyan Tan", "Steven Ritter", "Susan R. Berman", "April Galyardt"], "session": "SESSION: Performance prediction"}, {"title": "The influence of students' cognitive and motivational characteristics on students' use of a 4C/ID-based online learning environment and their learning gain", "pages": "171-180", "doi": "10.1145/3170358.3170363", "abstract": "Research has revealed that the design of online learning environments can influence students' use and performance. In this study, an online learning environment for learning French as a foreign language was developed in line with the four component instructional design (4C/ID) model. While the 4C/ID-model is a well-established instructional design model, little is known about (1) factors impacting students' use of the four components, namely, learning tasks, part-task practice, supportive and procedural information during their learning process as well as about (2) the way in which students' differences in use of the 4C/ID-based online learning environment impacts course performance. The aim of this study is, therefore, twofold. Firstly, it investigates the influence of students' prior knowledge, task value and self-efficacy on students' use of the four different components of the 4C/ID-model. Secondly, it examines the influence of students' use of the components on their learning gain, taking into account their characteristics. The sample consisted of 161 students in higher education. Results, based on structural equation modelling (SEM), indicate that prior knowledge has a negative influence on students' use of learning tasks and part-task practice. Task value has a positive influence on use of learning tasks and supportive information. Additionally, results indicate that use of use of learning tasks, procedural information, controlled for students' prior knowledge significantly contribute to students' learning gain. Results suggest that students' use of the four components is based on their cognitive and motivational characteristics. Furthermore, results reveal the impact of students' use of learning tasks and procedural information on students' learning gain.", "authors": ["Charlotte Larmuseau", "Jan Elen", "Fien Depaepe"], "session": "SESSION: Performance prediction"}, {"title": "Explaining learning performance using response-time, self-regulation and satisfaction from content: an fsQCA approach", "pages": "181-190", "doi": "10.1145/3170358.3170397", "abstract": "This study focuses on compiling students' response-time allocated to answer correctly or wrongly, their self-regulation, as well as their satisfaction from content, in order to explain high or medium/low learning performance. To this end, it proposes a conceptual model in conjunction with research propositions. For the evaluation of the approach, an empirical study with 452 students was conducted. The fuzzy set qualitative comparative analysis (fsQCA) revealed five configurations driven by the admitted factors that explain students' high performance, as well as five additional patterns, interpreting students' medium/low performance. These findings advance our understanding of the relations between actual usage and latent behavioral factors, as well as their combined effect on students' test score. Limitations and potential implications of these findings are also discussed.", "authors": ["Zacharoula Papamitsiou", "Anastasios A. Economides", "Ilias O. Pappas", "Michail N. Giannakos"], "session": "SESSION: Performance prediction"}, {"title": "Finding traces of self-regulated learning in activity streams", "pages": "191-200", "doi": "10.1145/3170358.3170381", "abstract": "This paper aims to identify self-regulation strategies from students' interactions with the learning management system (LMS). We used learning analytics techniques to identify metacognitive and cognitive strategies in the data. We define three research questions that guide our studies analyzing i) self-assessments of motivation and self regulation strategies using standard methods to draw a baseline, ii) interactions with the LMS to find traces of self regulation in observable indicators, and iii) self regulation behaviours over the course duration. The results show that the observable indicators can better explain self-regulatory behaviour and its influence in performance than preliminary subjective assessments.", "authors": ["Anal\u00eda Cicchinelli", "Eduardo Veas", "Abelardo Pardo", "Viktoria Pammer-Schindler", "Angela Fessl", "Carla Barreiros", "Stefanie Lindst\u00e4dt"], "session": "SESSION: Self-regulation"}, {"title": "Investigating learning strategies in a dispositional learning analytics context: the case of worked examples", "pages": "201-205", "doi": "10.1145/3170358.3170385", "abstract": "This study aims to contribute to recent developments in empirical studies on students' learning strategies, whereby the use of trace data is combined with self-report data to distinguish profiles of learning strategy use [3--5]. We do so in the context of an application of dispositional learning analytics in a large introductory course mathematics and statistics, based on blended learning. Building on our previous work which showed marked differences in how students used worked examples as a learning strategy [7, 11], this study compares different profiles of learning strategies with learning approaches, learning outcomes, and learning dispositions. One of our key findings is that deep learners were less dependent on worked examples as a resource for learning, and that students who only sporadically used worked examples achieved higher test scores.", "authors": ["Dirk Tempelaar", "Bart Rienties", "Quan Nguyen"], "session": "SESSION: Self-regulation"}, {"title": "Discovery and temporal analysis of latent study patterns in MOOC interaction sequences", "pages": "206-215", "doi": "10.1145/3170358.3170388", "abstract": "Capturing students' behavioral patterns through analysis of sequential interaction logs is an important task in educational data mining and could enable more effective and personalized support during the learning processes. This study aims at discovery and temporal analysis of learners' study patterns in MOOC assessment periods. We propose two different methods to achieve this goal. First, following a hypothesis-driven approach, we identify learners' study patterns based on their interaction with lectures and assignments. Through clustering of study pattern sequences, we capture different longitudinal activity profiles among learners and describe their properties. Second, we propose a temporal clustering pipeline for unsupervised discovery of latent patterns in learners' interaction data. We model and cluster activity sequences at each time step and perform cluster matching to enable tracking learning behaviours over time. Our proposed pipeline is general and applicable in different learning environments such as MOOC and ITS. Moreover, it allows for modeling and temporal analysis of interaction data at different levels of actions granularity and time resolution. We demonstrate the application of this method for detecting latent study patterns in a MOOC course.", "authors": ["Mina Shirvani Boroujeni", "Pierre Dillenbourg"], "session": "SESSION: MOOCs"}, {"title": "Evaluating retrieval practice in a MOOC: how writing and reading summaries of videos affects student learning", "pages": "216-225", "doi": "10.1145/3170358.3170382", "abstract": "Videos are often the core content in open online education, such as in Massive Open Online Courses (MOOCs). Students spend most of their time in a MOOC on watching educational videos. However, merely watching a video is a relatively passive learning activity. To increase the educational benefits of online videos, students could benefit from more actively interacting with the to-be-learned material. In this paper two studies (n = 13k) are presented which examined the educational benefits of two more active learning strategies: 1) Retrieval Practice tasks which asked students to shortly summarize the content of videos, and 2) Given Summary tasks in which the students were asked to read pre-written summaries of videos. Writing, as well as reading summaries of videos were positively related to quiz grades. Both interventions seemed to help students to perform better, but there was no apparent difference between the efficacy of these interventions. These studies show how the quality of online education can be improved by adapting course design to established approaches from the learning sciences.", "authors": ["Tim van der Zee", "Dan Davis", "Nadira Saab", "Bas Giesbers", "Jasper Ginn", "Frans van der Sluis", "Fred Paas", "Wilfried Admiraal"], "session": "SESSION: MOOCs"}, {"title": "Reciprocal peer recommendation for learning purposes", "pages": "226-235", "doi": "10.1145/3170358.3170400", "abstract": "Larger student intakes by universities and the rise of education through Massive Open Online Courses has led to less direct contact time with teaching staff for each student. One potential way of addressing this contact deficit is to invite learners to engage in peer learning and peer support; however, without technological support they may be unable to discover suitable peer connections that can enhance their learning experience. Two different research subfields with ties to recommender systems provide partial solutions to this problem. Reciprocal recommender systems provide sophisticated filtering techniques that enable users to connect with one another. To date, however, the main focus of reciprocal recommender systems has been on providing recommendation in online dating sites. Recommender systems for technology enhanced learning have employed and tailored exemplary recommenders towards use in education, with a focus on recommending learning content rather than other users. In this paper, we first discuss the importance of supporting peer learning and the role recommending reciprocal peers can play in educational settings. We then introduce our open-source course-level recommendation platform called RiPPLE that has the capacity to provide reciprocal peer recommendation. The proposed reciprocal peer recommender algorithm is evaluated against key criteria such as scalability, reciprocality, coverage, and quality and shows improvement over a baseline recommender. Primary results indicate that the system can help learners connect with peers based on their knowledge gaps and reciprocal preferences, with designed flexibility to address key limitations of existing algorithms identified in the literature.", "authors": ["Boyd A. Potts", "Hassan Khosravi", "Carl Reidsema", "Aneesha Bakharia", "Mark Belonogoff", "Melanie Fleming"], "session": "SESSION: MOOCs"}, {"title": "Rethinking learning analytics adoption through complexity leadership theory", "pages": "236-244", "doi": "10.1145/3170358.3170375", "abstract": "Despite strong interest in learning analytics (LA), adoption at a large-scale organizational level continues to be problematic. This may in part be due to the lack of acknowledgement of existing conceptual LA models to operationalize how key adoption dimensions interact to inform the realities of the implementation process. This paper proposes the framing of LA adoption in complexity leadership theory (CLT) to study the overarching system dynamics. The framing is empirically validated in a study analysing interviews with senior staff in Australian universities (n=32). The results were coded for several adoption dimensions including leadership, governance, staff development, and culture. The coded data were then analysed with latent class analysis. The results identified two classes of universities that either i) followed an instrumental approach to adoption - typically top-down leadership, large scale project with high technology focus yet demonstrating limited staff uptake; or ii) were characterized as emergent innovators - bottom up, strong consultation process, but with subsequent challenges in communicating and scaling up innovations. The results suggest there is a need to broaden the focus of research in LA adoption models to move on from small-scale course/program levels to a more holistic and complex organizational level.", "authors": ["Shane Dawson", "Oleksandra Poquet", "Cassandra Colvin", "Tim Rogers", "Abelardo Pardo", "Dragan Gasevic"], "session": "SESSION: Institutional adoption"}, {"title": "Capitalisation of analysis processes: enabling reproducibility, openness and adaptability thanks to narration", "pages": "245-254", "doi": "10.1145/3170358.3170408", "abstract": "Analysis processes of learning traces, used to gain important pedagogical insights, are yet to be easily shared and reused. They face what is commonly called a reproducibility crisis. From our observations, we identify two important factors that may be the cause of this crisis: technical constraints due to runnable necessities, and context dependencies. Moreover, the meaning of the reproducibility itself is ambiguous and a source of misunderstanding. In this paper, we present an ontological framework dedicated to taking full advantage of already implemented educational analyses. This framework shifts the actual paradigm of analysis processes by representing them from a narrative point of view, instead of a technical one. This enables a formal description of analysis processes with high-level concepts. We show how this description is performed, and how it can help analysts. The goal is to empower both expert and non-expert analysis stakeholders with the possibility to be involved in the elaboration of analysis processes and their reuse in different contexts, by improving both human and machine understanding of these analyses. This possibility is known as the capitalisation of analysis processes of learning traces.", "authors": ["Alexis Lebis", "Marie Lefevre", "Vanda Luengo", "Nathalie Guin"], "session": "SESSION: Infrastructure"}, {"title": "Classroom size, activity and attendance: scaling up drivers of learning space occupation", "pages": "255-259", "doi": "10.1145/3170358.3170401", "abstract": "Teaching face-to-face is still a major education mode in many universities, yet institutions are increasingly tasked with improving efficient use of teaching spaces. This need to understand space use can be coupled with learning and teaching data to better inform student attendance and subsequently participation. Here, we analyse thermal sensor data used to monitor traffic into classrooms; these data are associated with the timetable to provide knowledge of the course and the teaching mode (such as lecture, tutorial or workshop). Further, we integrate these traffic data with student feedback data to investigate the drivers of student attendance patterns, and aim to also include online activity and behaviour to develop broad models of both room occupancy and student attendance. Combining space utilisation data with information on teaching modality and in-class and out-of-class participation can inform on how to both improve learning and design effective and efficient teaching spaces.", "authors": ["Amelia Brennan", "Christina Peace", "Pablo Munguia"], "session": "SESSION: Infrastructure"}, {"title": "Towards a data archiving solution for learning analytics", "pages": "260-264", "doi": "10.1145/3170358.3170415", "abstract": "Data solutions in the teaching and learning space are in need of pro-active innovations in data management, to ensure that systems for learning analytics can scale up to match the size of datasets now available. Here, we illustrate the scale at which a Learning Management System (LMS) accumulates data, and discuss the barriers to using this data for in-depth analyses. We illustrate the exponential growth of our LMS data to represent a single example dataset, and highlight the broader need for taking a pro-active approach to dimensional modelling in learning analytics, anticipating that common learning analytics questions will be computationally expensive, and that the most useful data structures for learning analytics will not necessarily follow those of the source dataset.", "authors": ["Sarah Taylor", "Pablo Munguia"], "session": "SESSION: Infrastructure"}, {"title": "Connecting decentralized learning records: a blockchain based learning analytics platform", "pages": "265-269", "doi": "10.1145/3170358.3170365", "abstract": "As Learners move from one learning environment to another, there is a key necessity of taking with them a proof of previous learning achievements or experiences. In most cases, this is either expressed in terms of receipt of scores or a certificate of completion. While this may be sufficient for enrollment and other administrative decisions, it poses some limitations to the depth of learning analytics and consequently a slow onboarding process. Also, with different institutions having their learning data isolated from each other, it becomes more difficult to easily access a learner's learning history for all learning activities on other systems. In this paper, we propose a blockchain based approach for connecting learning data across different Learning Management Systems (LMS), Learning Record Stores (LRS), institutions and organizations. Leveraging on unique properties of blockchain technology, we also propose solutions to ensuring learning data consistency, availability, immutability, security, privacy and access control.", "authors": ["Patrick Ocheja", "Brendan Flanagan", "Hiroaki Ogata"], "session": "SESSION: Infrastructure"}, {"title": "Running out of STEM: a comparative study across STEM majors of college students at-risk of dropping out early", "pages": "270-279", "doi": "10.1145/3170358.3170410", "abstract": "Higher education institutions in the United States and across the Western world face a critical problem of attrition of college students and this problem is particularly acute within the Science, Technology, Engineering, and Mathematics (STEM) fields. Students are especially vulnerable in the initial years of their academic programs; more than 60% of the dropouts occur in the first two years. Therefore, early identification of at-risk students is crucial for a focused intervention if institutions are to support students towards completion. In this paper we developed and evaluated a survival analysis framework for the early identification of students at the risk of dropping out. We compared the performance of survival analysis approaches to other machine learning approaches including logistic regression, decision trees and boosting. The proposed methods show good performance for early prediction of at-risk students and are also able to predict when a student will dropout with high accuracy. We performed a comparative analysis of nine different majors with varying levels of academic rigor, challenge and student body. This study enables advisors and university administrators to intervene in advance to improve student retention.", "authors": ["Yujing Chen", "Aditya Johri", "Huzefa Rangwala"], "session": "SESSION: Retention II"}, {"title": "Prospectively predicting 4-year college graduation from student applications", "pages": "280-289", "doi": "10.1145/3170358.3170395", "abstract": "We leverage a unique national dataset of 41,359 college applications to prospectively predict 4-year bachelor's graduation in a generalizable manner. Our features include sociodemographics, institutional graduation rates, academic achievement, standardized test scores, engagement in extracurricular activities, work experiences, and ratings by teachers and high-school guidance counselors. A random forest classifier successfully predicted 4-year graduation for 71.4% of the students (base rate = 44%) using all 166 of the aforementioned features and a split-half validation method. A stochastic hill-climbing feature selection procedure effectively maintained the same classification accuracy, but with a minimal set of 37 features, consisting of an approximately equal representation of sociodemographics, cognitive, and noncognitive factors. We advocate against using these results for admissions decisions, instead contemplating how they might be used to provide parents and educators with actionable information to guide students towards college success.", "authors": ["Stephen Hutt", "Margo Gardener", "Donald Kamentz", "Angela L. Duckworth", "Sidney K. D'Mello"], "session": "SESSION: Retention II"}, {"title": "\"I'll do it!\": examining the relationship between locus of control and math game retention for preschoolers", "pages": "290-294", "doi": "10.1145/3170358.3170368", "abstract": "Acquiring simple arithmetic skills at the preschool level requires repetitive practices. One method for encouraging students to spend longer time practicing is by presenting the skills in an engaging game. As student retention on the game increases, the student will be more likely to acquire the practiced skill since she will have spent more time practicing. In this paper, we examine the relationship between internal locus of control and retention in game-based learning applications for young children using Todo Math, a mobile-based math learning application for children from Pre-K to 2nd grade. We examine 345,783 users' log data to show that when children prefer \"free\" mode, which has high internal locus of control, their retention on Todo Math is higher than children who prefer \"daily\" mode, which has high external locus of control. We present three analyses that support our findings using survival analysis, post-hoc analysis, and t-test.", "authors": ["Bugeun Kim", "Jungwook Rhim", "Jihyun Rho", "Taehyun Hwang", "Gunho Lee", "Gahgene Gweon"], "session": "SESSION: Retention II"}, {"title": "Coenrollment networks and their relationship to grades in undergraduate education", "pages": "295-304", "doi": "10.1145/3170358.3170373", "abstract": "In this paper, we evaluate the complete undergraduate coenrollment network over a decade of education at a large American public university. We provide descriptive properties of the network, demonstrating that the coenrollment networks evaluated follow power-law degree distributions similar to many other large-scale networks; that they reveal strong performance-based assortativity; and that network-based features can significantly improve GPA-based student performance predictors. We then implement a network-based, multi-view classification model to predict students' final course grades. In particular, we adapt a structural modeling approach from [19, 34], whereby we model the university-wide undergraduate coenrollment network as an undirected graph. We compare the performance of our predictor to traditional methods used for grade prediction in undergraduate university courses, and demonstrate that a multi-view ensembling approach outperforms both prior \"flat\" and network-based models for grade prediction across several classification metrics. These findings demonstrate the usefulness of combining diverse approaches in models of student success, and demonstrate specific network-based modeling strategies which are likely to be most effective for grade prediction.", "authors": ["Josh Gardner", "Christopher Brooks"], "session": "SESSION: Academic analytics"}, {"title": "Conceptualizing co-enrollment: accounting for student experiences across the curriculum", "pages": "305-309", "doi": "10.1145/3170358.3170366", "abstract": "In this study, we develop and test three measures for conceptualizing the potential impact of co-enrollment in different courses on students' changing risk for academic difficulty in a focal course. Two of these measures, concurrent enrollment in at least one difficult course and academic difficulty in the prior week in courses other than the focal course, significantly increase students' odds of academic difficulty in the focal course in our models. Our results have implications for the designs of Early Warning Systems and suggest that academic planners consider the relationship between course co-enrollment and students' academic success.", "authors": ["Michael Geoffrey Brown", "R. Matthew DeMonbrun", "Stephanie D. Teasley"], "session": "SESSION: Academic analytics"}, {"title": "A framework for developing metrics of youth engagement in informal learning environments", "pages": "310-314", "doi": "10.1145/3170358.3170393", "abstract": "This paper proposes a framework which aims to leverage data from informal learning environments to provide insights about youth engagement for various stakeholders. To explore the framework, we created metrics to examine the engagement of 98 middle school-aged girls during a 20-week STEM program using attendance records and log data from an online learning platform coded to reflect 21st century learning activities. We present preliminary analyses using the metrics, focusing on how they can help stakeholders understand engagement and equity of participation.", "authors": ["Denise Nacu", "Jennifer Baltes", "Taha Hamid", "Jonathan Gemmell", "Nichole Pinkard"], "session": "SESSION: Academic analytics"}, {"title": "A diagnostic tool for competency-based program engineering", "pages": "315-319", "doi": "10.1145/3170358.3170402", "abstract": "Competency based education (CBE) is seen by many as a way to optimize learning on cost, efficiency and flexibility. However, defining the required competencies, assigning them to specific courses and building the assessments evaluating student's proficiency can be tedious. More precisely, making sure that the assessments evaluate what they are supposed to evaluate requires a fair amount of psychometrics knowledge and time that can be difficult for teachers to acquire, maintain and use. Addressing assessment validity and more specifically competency frameworks mapping adequacy, we propose a rule-based tool to ease the building and the refinement of CBE courses and curricula. After introducing the context and briefly the related work, we present our set of rules before illustrating the capacity of the proposed diagnostic tool on an engineering curriculum. Experiments show that this tool can improve mapping adequacy in term of predictive accuracy and would require more efforts towards competency parameters reliability measurement.", "authors": ["Guillaume Durand", "Cyril Goutte", "Nabil Belacel", "Yassine Bouslimani", "Serge L\u00e9ger"], "session": "SESSION: Academic analytics"}, {"title": "SHEILA policy framework: informing institutional strategies and policy processes of learning analytics", "pages": "320-329", "doi": "10.1145/3170358.3170367", "abstract": "This paper introduces a learning analytics policy development framework developed by a cross-European research project team - SHEILA (Supporting Higher Education to Integrate Learning Analytics), based on interviews with 78 senior managers from 51 European higher education institutions across 16 countries. The framework was developed using the RAPID Outcome Mapping Approach (ROMA), which is designed to develop effective strategies and evidence-based policy in complex environments. This paper presents three case studies to illustrate the development process of the SHEILA policy framework, which can be used to inform strategic planning and policy processes in real world environments, particularly for large-scale implementation in higher education contexts.", "authors": ["Yi-Shan Tsai", "Pedro Manuel Moreno-Marcos", "Kairit Tammets", "Kaire Kollom", "Dragan Ga\u0161evi\u0107"], "session": "SESSION: Policies"}, {"title": "Unpacking the relationship between discussion forum participation and learning in MOOCs: content is key", "pages": "330-339", "doi": "10.1145/3170358.3170403", "abstract": "This study examined the relationship between discussion forum contributions and course assessment results in a statistics MOOC. An important feature of the study is that it distinguished between discussions that were related to the learning of course material (\"content-related\") and those which were not (\"non-content\"). Another contribution is that the study evaluated the additional usefulness of social centrality measures in predicting course grade after the quantity of forum contributions has been accounted for. Results showed that, overall, 15% of course learners contributed to the forums and these learners had a significantly higher rate of successfully passing the course than non-contributors (64% vs 32% passing). Learners who made posts to both content-related and non-content threads had a higher passing rate than those who only contributed to one type or the other. Among learners who successfully passed the course, there were no differences in course grade when comparing discussion contributors and non-contributors overall; however those who contributed to content-related threads performed slightly better than those who did not (course grade of 87% vs 85%). A predictive model based on the number of posts made to content-related threads explained a small proportion of variance in course grades; addition of social centrality measures did not significantly improve the variance explained by the model.", "authors": ["Alyssa Friend Wise", "Yi Cui"], "session": "SESSION: Discourse II: MOOCs"}, {"title": "Are MOOC forums changing?", "pages": "340-349", "doi": "10.1145/3170358.3170416", "abstract": "There has been a growing trend in higher education towards increased use and adoption of Massive Open Online Courses (MOOCs). Despite this interest in learning at scale, limited work has compared MOOC activity across subsequent course offerings. In this study, we explore forum activity in ten iterations of the same MOOC. Our results suggest that participation in MOOC forums has changed over the past four years of delivery. First, overall participation in MOOC forums have decreased. Second, in later iterations cohorts of more committed forum users start to resemble formal online courses in size (67>n>36). However, despite the smaller groups of learners that should find it easier to form connections with one another, our analysis did not reveal the expected increase in the quality of social activity. Instead, MOOC forums evolved into smaller on-task question and answer (Q&A) spaces, not capitalizing on the opportunities for social learning. We discuss practical and research implications of such changes.", "authors": ["Oleksandra Poquet", "Nia Dowell", "Christopher Brooks", "Shane Dawson"], "session": "SESSION: Discourse II: MOOCs"}, {"title": "Gaze insights into debugging behavior using learner-centred analysis", "pages": "350-359", "doi": "10.1145/3170358.3170386", "abstract": "The presented study tries to tackle an intriguing question of how user-generated data from current technologies can be used to reinforce learners' reflections, improve teaching practices, and close the learning analytics loop. In particular, the aim of the study is to utilize users' gaze to examine the role of a mirroring tool (i.e. Exercise View in Eclipse) in orchestrating basic behavioral regulation of participants engaged in a debugging task. The results demonstrated that students who processed the information presented in the Exercise View and acted upon it, improved their performance and achieved higher level of success than those who failed to do it. The findings shed a light how to capture what constitute relevant data within a particular context using gaze patterns, that could guide collection of essential learner-centred analytics for the purpose of designing usable and modular learning environments based on data-driven approaches.", "authors": ["Katerina Mangaroska", "Kshitij Sharma", "Michail Giannakos", "Hallvard Tr\u00e6tteberg", "Pierre Dillenbourg"], "session": "SESSION: Multimodal"}, {"title": "The RAP system: automatic feedback of oral presentation skills using multimodal analysis and low-cost sensors", "pages": "360-364", "doi": "10.1145/3170358.3170406", "abstract": "Developing communication skills in higher education students could be a challenge to professors due to the time needed to provide formative feedback. This work presents RAP, a scalable system to provide automatic feedback to entry-level students to develop basic oral presentation skills. The system improves the state-of-the-art by analyzing posture, gaze, volume, filled pauses and the slides of the presenters through data captured by very low-cost sensors. The system also provides an off-line feedback report with multimodal recordings of their performance. An initial evaluation of the system indicates that the system's feedback highly agrees with human feedback and that students considered that feedback useful to develop their oral presentation skills.", "authors": ["Xavier Ochoa", "Federico Dom\u00ednguez", "Bruno Guam\u00e1n", "Ricardo Maya", "Gabriel Falcones", "Jaime Castells"], "session": "SESSION: Multimodal"}, {"title": "(Dis)engagement matters: identifying efficacious learning practices with multimodal learning analytics", "pages": "365-369", "doi": "10.1145/3170358.3170420", "abstract": "Video analysis is a staple of the education research community. For many contemporary education researchers, participation in the video coding process serves as a rite of passage. However, recent developments in multimodal learning analytics may help to accelerate and enhance this process by providing researchers with a more nuanced glimpse into a set of learning experiences. As an example of how to use multimodal learning analytics towards these ends, this paper includes a preliminary analysis from 54 college students, who completed two engineering design tasks in pairs. Gesture, speech and electro-dermal activation data were collected as students completed these tasks. The gesture data was used to learn a set of canonical clusters (N=4). A decision tree was trained based on individual students' cluster frequencies, and pre-post learning gains. The nodes in the decision tree were then used to identify a subset of video segments that were human coded based on prior work in learning analytics and engineering design. The combination of machine learning and human inference helps elucidate the practices that seem to correlate with student learning. In particular, both engagement and disengagement seem to correlate with student learning, albeit in a somewhat nuanced fashion.", "authors": ["Marcelo Worsley"], "session": "SESSION: Multimodal"}, {"title": "Analysis of interactions between lecturers and students", "pages": "370-374", "doi": "10.1145/3170358.3170360", "abstract": "In this paper, we discuss the interactions between lecturers and students. First, we detect their behaviors by extracting the face regions of lecturers and students from moving images. Thereafter, we model the interaction between the lecturers' writing and explanation behaviors and the students' note taking and listening behaviors by using multilayered neural networks. We discuss the above interactions based on the internal representations of multilayered neural networks.", "authors": ["Eiji Watanabe", "Takashi Ozeki", "Takeshi Kohama"], "session": "SESSION: Multimodal"}, {"title": "Physical learning analytics: a multimodal perspective", "pages": "375-379", "doi": "10.1145/3170358.3170379", "abstract": "The increasing progress in ubiquitous technology makes it easier and cheaper to track students' physical actions unobtrusively, making it possible to consider such data for supporting research, educator interventions, and provision of feedback to students. In this paper, we reflect on the underexplored, yet important area of learning analytics applied to physical/motor learning tasks and to the physicality aspects of `traditional' intellectual tasks that often occur in physical learning spaces. Based on Distributed Cognition theory, the concept of Internet of Things and multimodal learning analytics, this paper introduces a theoretical perspective for bringing learning analytics into physical spaces. We present three prototypes that serve to illustrate the potential of physical analytics for teaching and learning. These studies illustrate advances in proximity, motion and location analytics in collaborative learning, dance education and healthcare training.", "authors": ["Roberto Martinez-Maldonado", "Vanessa Echeverria", "Olga C. Santos", "Augusto Dias Pereira Dos Santos", "Kalina Yacef"], "session": "SESSION: Multimodal"}, {"title": "A multi-dimensional analysis of writing flexibility in an automated writing evaluation system", "pages": "380-388", "doi": "10.1145/3170358.3170404", "abstract": "The assessment of writing proficiency generally includes analyses of the specific linguistic and rhetorical features contained in the singular essays produced by students. However, researchers have recently proposed that an individual's ability to flexibly adapt the linguistic properties of their writing might more closely capture writing skill. However, the features of the task, learner, and educational context that influence this flexibility remain largely unknown. The current study extends this research by examining relations between linguistic flexibility, reading comprehension ability, and feedback in the context of an automated writing evaluation system. Students (n = 131) wrote and revised six essays in an automated writing evaluation system and were provided both summative and formative feedback on their writing. Additionally, half of the students had access to a spelling and grammar checker that provided lower-level feedback during the writing period. The results provide evidence for the fact that developing writers demonstrate linguistic flexibility across the essays that they produce. However, analyses also indicate that lower-level feedback (i.e., spelling and grammar feedback) have little to no impact on the properties of students' essays nor on their variability across prompts or drafts. Overall, the current study provides important insights into the role of flexibility in writing skill and develops a strong foundation on which to conduct future research and educational interventions.", "authors": ["Laura K. Allen", "Aaron D. Likens", "Danielle S. McNamara"], "session": "SESSION: Discourse III: writing"}, {"title": "Understand students' self-reflections through learning analytics", "pages": "389-398", "doi": "10.1145/3170358.3170374", "abstract": "Reflective writing has been widely recognized as one of the most effective activities for fostering students' reflective and critical thinking. The analysis of students' reflective writings has been the focus of many research studies. However, to date this has been typically a very labor-intensive manual process involving content analysis of student writings. With recent advancements in the field of learning analytics, there have been several attempts to use text analytics to examine student reflective writings. This paper presents the results of a study examining the use of theoretically-sound linguistic indicators of different psychological processes for the development of an analytics system for assessment of reflective writing. More precisely, we developed a random-forest classification system using linguistic indicators provided by the LIWC and Coh-Metrix tools. We also examined what particular indicators are representative of the different types of student reflective writings.", "authors": ["Vitomir Kovanovi\u0107", "Sre\u0107ko Joksimovi\u0107", "Negin Mirriahi", "Ellen Blaine", "Dragan Ga\u0161evi\u0107", "George Siemens", "Shane Dawson"], "session": "SESSION: Discourse III: writing"}, {"title": "What exactly do students learn when they practice equation solving?: refining knowledge components with the additive factors model", "pages": "399-408", "doi": "10.1145/3170358.3170411", "abstract": "Accurately modeling individual students' knowledge growth is important in many applications of learning analytics. A key step is to decompose the knowledge targeted in the instruction into detailed knowledge components (KCs). We search for an accurate KC model for basic equation solving skills, using data from an intelligent tutoring system (ITS), Lynnette. Key criteria are data fit and predictive accuracy based on a standard logistic model called the Additive Factors Model (AFM). We focus on three difficulty factors for equation solving: understanding of variables, the negative sign, and the complexity of the equation. Fine-grained KC models were found to have greater fit and predictive accuracy than an \"ideal,\" more abstract model, indicating that there is substantial under-generalization in students' equation-solving skill related to all three difficulty factors. The work enhances scientific understanding of the challenges students face in learning equation solving. It illustrates how learning analytics could inform the improvement of technology-enhanced learning environments.", "authors": ["Yanjin Long", "Kenneth Holstein", "Vincent Aleven"], "session": "SESSION: Adaptive learning"}, {"title": "Can't get more satisfaction?: game-theoretic group-recommendation of educational resources", "pages": "409-416", "doi": "10.1145/3170358.3170371", "abstract": "Students' satisfaction from educational resources is a subjective perception of how well these resources meet students' expectations for learning. Recommending educational resources to groups of students, targeting at optimizing all students' satisfaction, is a complicated task due to the lack of joint group profiles. Instead of merging individual profiles or fusing individual recommendations, this paper follows a game-theoretic perspective for solving conflict of interest among students and recommending resources to groups in online collaborative learning contexts: the group members are the players, the resources comprise the set of possible actions, and maximizing each individual member's satisfaction from the selected resources is a problem of finding the Nash Equilibrium. In case the Nash Equilibrium is Pareto efficient, none of the players can get more payoff (satisfaction) without decreasing the payoff of any other player, indicating an optimal benefit for the group as a whole. The comparative evaluation of the suggested approach to other state-of-the-art methods provided statistically significant results regarding the error in predicted group satisfaction from the recommendation and the goodness of the ranked list of recommendations.", "authors": ["Zacharoula Papamitsiou", "Anastasios A. Economides"], "session": "SESSION: Adaptive learning"}, {"title": "The teacher in the loop: customizing multimodal learning analytics for blended learning", "pages": "417-426", "doi": "10.1145/3170358.3170364", "abstract": "In blended learning scenarios, evidence needs to be gathered from digital and physical spaces to obtain a more complete view of the teaching and learning processes. However, these scenarios are highly heterogeneous, and the varying data sources available in each particular context can condition the accuracy, relevance, interpretability and actionability of the Learning Analytics (LA) solutions, affecting also the user's sense of agency and trust in such solutions. To aid stakeholders in making use of learning analytics, we propose a process to involve teachers in customizing multimodal LA (MMLA) solutions, adapting them to their particular blended learning situation (e.g., identifying relevant data sources and metrics). Since measuring the added value of adopting an LA solution is not straightforward, we also propose a concrete method for doing so. The results obtained from two case studies in authentic, blended computer-supported collaborative learning settings show an improvement in the sensitivity and F1 scores of the customized MMLA solution. Aside from these quantitative improvements, participant teachers reported both an increment in the effort involved, but also increased relevance, understanding and actionability of the results.", "authors": ["Mar\u00eda Jes\u00fcs Rodr\u00edguez-Triana", "Luis P. Prieto", "Alejandra Mart\u00ednez-Mon\u00e9s", "Juan I. Asensio-P\u00e9rez", "Yannis Dimitriadis"], "session": "SESSION: User-centered design II"}, {"title": "Analytics-enabled teaching as design: reconceptualisation and call for research", "pages": "427-435", "doi": "10.1145/3170358.3170390", "abstract": "As a human-centred educational practice and field of research, learning analytics must account for key stakeholders in teaching and learning. The focus of this paper is on the role of institutions to support teachers to incorporate learning analytics into their practice by understanding the confluence of internal and external factors that influence what they do. In this paper, we reconceptualise `teaching as design' for `analytics-enabled teaching as design' to shape this discussion to allow for the consideration of external factors, such as professional learning or ethical considerations of student data, as well as personal considerations, such as data literacy and teacher beliefs and identities. In order to address the real-world challenges of progressing teachers' efficacy and capacity toward analytics-enabled teaching as design, we have placed the teacher - as a cognitive, social, and emotional being - at the center. In so doing, we discuss potential directions towards research for practice in elucidating underpinning factors of teacher inquiry in the process of authentic design.", "authors": ["Sakinah S. J. Alhadad", "Kate Thompson", "Simon Knight", "Melinda Lewis", "Jason M. Lodge"], "session": "SESSION: User-centered design II"}, {"title": "The complexities of developing a personal code of ethics for learning analytics practitioners: implications for institutions and the field", "pages": "436-440", "doi": "10.1145/3170358.3170396", "abstract": "In this paper we explore the potential role, value and utility of a personal code of ethics (COE) for learning analytics practitioners, and in particular we consider whether such a COE might usefully mediate individual actions and choices in relation to a more abstract institutional COE. While several institutional COEs now exist, little attention has been paid to detailing the ethical responsibilities of individual practitioners. To investigate the problems associated with developing and implementing a personal COE, we drafted an LA Practitioner COE based on other professional codes, and invited feedback from a range of learning analytics stakeholders and practitioners: ethicists, students, researchers and technology executives. Three main themes emerged from their reflections: 1. A need to balance real world demands with abstract principles, 2. The limits to individual accountability within the learning analytics space, and 3. The continuing value of debate around an aspirational code of ethics within the field of learning analytics.", "authors": ["Charles Lang", "Leah P. Macfadyen", "Sharon Slade", "Paul Prinsloo", "Niall Sclater"], "session": "SESSION: User-centered design II"}, {"title": "Online change detection for monitoring individual student behavior via clickstream data on E-book system", "pages": "446-450", "doi": "10.1145/3170358.3170412", "abstract": "We propose a new change detection method using clickstream data collected through an e-Book system. Most of the prior work has focused on the batch processing of clickstream data. In contrast, the proposed method is designed for online processing, with the model parameters for change detection updated sequentially based on observations of new click events. More specifically, our method generates a model for an individual student and performs minute-by-minute change detection based on click events during a classroom lecture. We collected clickstream data from four face-to-face lectures, and conducted experiments to demonstrate how the proposed method discovered change points and how such change points correlated with the students' performances.", "authors": ["Atsushi Shimada", "Yuta Taniguchi", "Fumiya Okubo", "Shin'ichi Konomi", "Hiroaki Ogata"], "session": "SESSION: Student behaviour"}, {"title": "Embracing imperfection in learning analytics", "pages": "451-460", "doi": "10.1145/3170358.3170413", "abstract": "Learning Analytics (LA) sits at the confluence of many contributing disciplines, which brings the risk of hidden assumptions inherited from those fields. Here, we consider a hidden assumption derived from computer science, namely, that improving computational accuracy in classification is always a worthy goal. We demonstrate that this assumption is unlikely to hold in some important educational contexts, and argue that embracing computational \"imperfection\" can improve outcomes for those scenarios. Specifically, we show that learner-facing approaches aimed at \"learning how to learn\" require more holistic validation strategies. We consider what information must be provided in order to reasonably evaluate algorithmic tools in LA, to facilitate transparency and realistic performance comparisons.", "authors": ["Kirsty Kitto", "Simon Buckingham Shum", "Andrew Gibson"], "session": "SESSION: Theory"}, {"title": "The pragmatic maxim as learning analytics research method", "pages": "461-465", "doi": "10.1145/3170358.3170384", "abstract": "It is arguable that the chief aim of Learning Analytics is to use analytics for meaningful purposes in learning and teaching contexts, and that research in the field should advance this cause. However the field does not present a single clear understanding of what constitutes quality in Learning Analytics research. In this paper we present the Pragmatic Inquiry for Learning Analytics Research (PILAR) method as one approach to conducting Learning Analytics research. Rather than creating a new method, we reintroduce an old method to a new field, drawing on the Pragmatic Maxim, proposed by Charles Sanders Peirce as a principle for making ideas clear. Our instantiation of the Pragmatic Maxim requires the researcher to situate Learning Analytics research within a clearly defined learning context and to consider the analytics in terms of the practical effects on learning. We propose three essential elements and a five step process for addressing them in research. After presenting PILAR we address two potential limitations of the approach, and conclude with some implications for its future use in Learning Analytics research.", "authors": ["Andrew Gibson", "Charles Lang"], "session": "SESSION: Theory"}, {"title": "Methodological foundations for the measurement of learning in learning analytics", "pages": "466-470", "doi": "10.1145/3170358.3170391", "abstract": "Learning analysts often claim to measure learning, but their work has attracted growing concern about whether or not the measures are sufficiently accurate, fair, reliable, and valid, with utility for educators and interpretable by them. This paper considers these issues in the light of practices of scholars in more established fields, educational measurement particularly. The focus is on what really matters about methodologies for measuring learning, including foundational assumptions about the nature of learning, what is understood by the term `measured', the criteria applied when assessing quality of data, the standards of proof required to establish validity, reliability, generalizability, utility and interpretability of findings, and assumptions about learners and learning underlying data modeling techniques used to abstract meaning from the data. This paper argues that, for learning analytics to take its place as a fully-fledged member of the learning sciences, it needs seriously to consider how to measure learning. Methodology crafted at the interface of measurement science and learning analytics may be of sufficient interest to create a new subfield of scholarship - dubbed here `metrilytics' - to make a distinctive contribution to the science of learning.", "authors": ["Sandra K. Milligan"], "session": "SESSION: Theory"}]}, {"year": 2019, "papers": [{"title": "On multi-device use: Using technological modality profiles to explain differences in students' learning", "pages": "1-10", "doi": "10.1145/3303772.3303790", "abstract": "With increasing abundance and ubiquity of mobile phones, desktop PCs, and tablets in the last decade, we are seeing students intermixing these modalities to learn and regulate their learning. However, the role of these modalities in educational settings is still largely under-researched. Similarly, little attention has been paid to the research on the extension of learning analytics to analyze the learning processes of students adopting various modalities during a learning activity. Traditionally, research on how modalities affect the way in which activities are completed has mainly relied upon self-reported data or mere counts of access from each modality. We explore the use of technological modalities in regulating learning via learning management systems (LMS) in the context of blended courses. We used data mining techniques to analyze patterns in sequences of actions performed by learners (n = 120) across different modalities in order to identify technological modality profiles of sequences. These profiles were used to detect the technological modality strategies adopted by students. We found a moderate effect size (\u22082 = 0.12) of students' adopted strategies on the final course grade. Furthermore, when looking specifically at online discussion engagement and performance, students' adopted technological modality strategies explained a large amount of variance (\u03b72 = 0.68) in their engagement and quality of contributions. The result implications and further research are discussed.", "authors": ["Varshita Sher", "Marek Hatala", "Dragan Ga\u0161evi\u0107"], "session": "SESSION: Novel Devices"}, {"title": "Technologies for automated analysis of co-located, real-life, physical learning spaces: Where are we now?", "pages": "11-20", "doi": "10.1145/3303772.3303811", "abstract": "The motivation for this paper is derived from the fact that there has been increasing interest among researchers and practitioners in developing technologies that capture, model and analyze learning and teaching experiences that take place beyond computer-based learning environments. In this paper, we review case studies of tools and technologies developed to collect and analyze data in educational settings, quantify learning and teaching processes and support assessment of learning and teaching in an automated fashion. We focus on pipelines that leverage information and data harnessed from physical spaces and/or integrates collected data across physical and digital spaces. Our review reveals a promising field of physical classroom analysis. We describe some trends and suggest potential future directions. Specifically, more research should be geared towards a) deployable and sustainable data collection set-ups in physical learning environments, b) teacher assessment, c) developing feedback and visualization systems and d) promoting inclusivity and generalizability of models across populations.", "authors": ["Yi Han Victoria Chua", "Justin Dauwels", "Seng Chee Tan"], "session": "SESSION: Novel Devices"}, {"title": "\"I Spent More Time with that Team\": Making Spatial Pedagogy Visible Using Positioning Sensors", "pages": "21-25", "doi": "10.1145/3303772.3303818", "abstract": "Teachers are often encouraged to adopt different positioning strategies at various stages of a classroom lesson as each can influence learners in different ways. However, little work has been done to make evidence of the use of classrooms visible to teachers and students. As sensors drop in price, it is becoming more viable to capture traces of the use of the physical classroom space automatically. In this paper, we build on the notion of spatial pedagogy to propose an approach to visualise digital traces of teacher positioning in the classroom. We illustrate our approach through an authentic case study of a teacher enacting three distinctive learning designs. We document the teacher's and students' reactions to visual representations of positioning data to explore their potential as proxies of spatial pedagogy.", "authors": ["Roberto Martinez-Maldonado"], "session": "SESSION: Novel Devices"}, {"title": "A Study on Curriculum Planning and Its Relationship with Graduation GPA and Time To Degree", "pages": "26-35", "doi": "10.1145/3303772.3303783", "abstract": "In recent years, several data-driven methods have been developed to help undergraduate students during course selection and sequencing. These methods tend to utilize the whole set of past course registration data, regardless of the past students' graduation GPA and time to degree (TTD). Though some previous work has shown through the results of their developed models that students of different GPA tend to take courses in different sequence, the actual analysis of the degree plans and how/if they relate to the students' graduation GPA and time-to-degree has not received much attention. This study analyzes how the student's academic level when they take different courses, as well as the pairwise degree similarity between pairs of students relate to the students' graduation GPA and TTD. Our study uses a large-scale dataset that contains 25 majors from different colleges at the University of Minnesota and spans 16 years. The analysis shows that TTD is highly correlated with both the timing and ordering of courses that students follow in their degree plans, while the correlation between graduation GPA and the course timing and ordering is not as high. We also perform a case study that uses course timing and ordering features to predict whether the student at each semester will graduate on-time or overtime. The results show that careful curriculum planning is needed to improve graduation rates in universities.", "authors": ["Sara Morsy", "George Karypis"], "session": "SESSION: Curriculum"}, {"title": "Goal-based Course Recommendation", "pages": "36-45", "doi": "10.1145/3303772.3303814", "abstract": "With cross-disciplinary academic interests increasing and academic advising resources over capacity, the importance of exploring data-assisted methods to support student decision making has never been higher. We build on the findings and methodologies of a quickly developing literature around prediction and recommendation in higher education and develop a novel recurrent neural network-based recommendation system for suggesting courses to help students prepare for target courses of interest, personalized to their estimated prior knowledge background and zone of proximal development. We validate the model using tests of grade prediction and the ability to recover prerequisite relationships articulated by the university. In the third validation, we run the fully personalized recommendation for students the semester before taking a historically difficult course and observe differential overlap with our would-be suggestions. While not proof of causal effectiveness, these three evaluation perspectives on the performance of the goal-based model build confidence and bring us one step closer to deployment of this personalized course preparation affordance in the wild.", "authors": ["Weijie Jiang", "Zachary A. Pardos", "Qiang Wei"], "session": "SESSION: Curriculum"}, {"title": "Semi-Automatic Generation of Intelligent Curricula to Facilitate Learning Analytics", "pages": "46-50", "doi": "10.1145/3303772.3303834", "abstract": "Several Learning Analytics applications are limited by the cost of generating a computer understandable description of the course domain, what is called an Intelligent Curriculum. The following work contributes a novel approach to (semi-)automatically generate Intelligent Curriculum through ontologies extracted from existing learning materials such as digital books or web content. Through a series of natural language processing steps, the semi-structured information present in existing content is transformed into a concept-graph. This work also evaluates the proposed methodology by applying it to learning content for two different courses and measuring the quality of the extracted ontologies against manually generated ones. The results obtained suggest that the technique can be readily used to provide domain information to other Learning Analytics tools.", "authors": ["Angel Fiallos", "Xavier Ochoa"], "session": "SESSION: Curriculum"}, {"title": "Read Between the Lines: An Annotation Tool for Multimodal Data for Learning", "pages": "51-60", "doi": "10.1145/3303772.3303776", "abstract": "This paper introduces the Visual Inspection Tool (VIT) which supports researchers in the annotation of multimodal data as well as the processing and exploitation for learning purposes. While most of the existing Multimodal Learning Analytics (MMLA) solutions are tailor-made for specific learning tasks and sensors, the VIT addresses the data annotation for different types of learning tasks that can be captured with a customisable set of sensors in a flexible way. The VIT supports MMLA researchers in 1) triangulating multimodal data with video recordings; 2) segmenting the multimodal data into time-intervals and adding annotations to the time-intervals; 3) downloading the annotated dataset and using it for multimodal data analysis. The VIT is a crucial component that was so far missing in the available tools for MMLA research. By filling this gap we also identified an integrated workflow that characterises current MMLA research. We call this workflow the Multimodal Learning Analytics Pipeline, a toolkit for orchestration, the use and application of various MMLA tools.", "authors": ["Daniele Di Mitri", "Jan Schneider", "Roland Klemke", "Marcus Specht", "Hendrik Drachsler"], "session": "SESSION: Multimodal Analytics"}, {"title": "Multichannel data for understanding cognitive affordances during complex problem solving", "pages": "61-70", "doi": "10.1145/3303772.3303778", "abstract": "This exploratory study challenges the current practices in cognitive load measurement by using multichannel data to investigate cognitive load affordances during online complex problem solving. Moreover, it is an attempt to investigate how cognitive load is related to strategy use. Accordingly, in the current study a well- and an ill-structured problem were developed in a virtual learning environment. Online support was provided. Participants were 15 students from the teacher training program. This study incorporated subjective measurements of students' cognitive load (i.e., intrinsic, extraneous, germane load and their mental effort) combined with physiological data containing galvanic skin response (GSR) and skin temperature (ST). A first aim was to investigate whether there was a significant difference for the subjective measurements, physiological data and consultation of support between the well-and ill-structured problem. Secondly this study investigated how individual differences of subjective measurements are related to individual differences of physiological data and consultation of support. Results reveal significant differences for intrinsic load, mental effort between a well- and ill-structured problem. Moreover, when investigating individual differences, findings reveal that GSR might be related to mental effort. Additionally, results indicate that cognitive load influences strategy use. Future research with larger sample sizes should verify these findings in order to have more insight into how we can measure cognitive load and how its related to self-directed learning. These insights should allow us to provide adaptive support in virtual learning environments.", "authors": ["Charlotte Larmuseau", "Pieter Vanneste", "Piet Desmet", "Fien Depaepe"], "session": "SESSION: Multimodal Analytics"}, {"title": "Cross-Platform Analytics: A step towards Personalization and Adaptation in Education", "pages": "71-75", "doi": "10.1145/3303772.3303825", "abstract": "Learning analytics are used to track learners' progress and empower educators and learners to make well-informed data-driven decisions. However, due to the distributed nature of the learning process, analytics need to be combined to offer broader insights into learner's behavior and experiences. Consequently, this paper presents an architecture of a learning ecosystem, that integrates and utilizes cross-platform analytics. The proposed cross-platform architecture has been put into practice via a Java programming course. After a series of studies, a proof of concept was derived that shows how cross-platform analytics amplify the relevant analytics for the learning process. Such analytics could improve educators' and learners' understanding of their own actions and the environments in which learning occurs.", "authors": ["Katerina Mangaroska", "Boban Vesin", "Michail Giannakos"], "session": "SESSION: Multimodal Analytics"}, {"title": "Reliable Deep Grade Prediction with Uncertainty Estimation", "pages": "76-85", "doi": "10.1145/3303772.3303802", "abstract": "Currently, college-going students are taking longer to graduate than their parental generations. Further, in the United States, the six-year graduation rate has been 59% for decades. Improving the educational quality by training better-prepared students who can successfully graduate in a timely manner is critical. Accurately predicting students' grades in future courses has attracted much attention as it can help identify at-risk students early so that personalized feedback can be provided to them on time by advisors. Prior research on students' grade prediction include shallow linear models; however, students' learning is a highly complex process that involves the accumulation of knowledge across a sequence of courses that can not be sufficiently modeled by these linear models. In addition to that, prior approaches focus on prediction accuracy without considering prediction uncertainty, which is essential for advising and decision making. In this work, we present two types of Bayesian deep learning models for grade prediction under a course-specific framework: i)Multilayer Perceptron (MLP) and ii) Recurrent Neural Network (RNN). These course-specific models are based on the assumption that prior courses can provide students with knowledge for future courses so that grades of prior courses can be used to predict grades in a future course. The MLP ignores the temporal dynamics of students' knowledge evolution. Hence, we propose RNN for students' performance prediction. To evaluate the performance of the proposed models, we performed extensive experiments on data collected from a large public university. The experimental results show that the proposed models achieve better performance than prior state-of-the-art approaches. Besides more accurate results, Bayesian deep learning models estimate uncertainty associated with the predictions. We explore how uncertainty estimation can be applied towards developing a reliable educational early warning system. In addition to uncertainty, we also develop an approach to explain the prediction results, which is useful for advisors to provide personalized feedback to students.", "authors": ["Qian Hu", "Huzefa Rangwala"], "session": "SESSION: Machine Learning I"}, {"title": "user2code2vec: Embeddings for Profiling Students Based on Distributional Representations of Source Code", "pages": "86-95", "doi": "10.1145/3303772.3303813", "abstract": "In this work, we propose a new methodology to profile individual students of computer science based on their programming design using a technique called embeddings. We investigate different approaches to analyze user source code submissions in the Python language. We compare the performances of different source code vectorization techniques to predict the correctness of a code submission. In addition, we propose a new mechanism to represent students based on their code submissions for a given set of laboratory tasks on a particular course. This way, we can make deeper recommendations for programming solutions and pathways to support student learning and progression in computer programming modules effectively at a Higher Education Institution. Recent work using Deep Learning tends to work better when more and more data is provided. However, in Learning Analytics, the number of students in a course is an unavoidable limit. Thus we cannot simply generate more data as is done in other domains such as FinTech or Social Network Analysis. Our findings indicate there is a need to learn and develop better mechanisms to extract and learn effective data features from students so as to analyze the students' progression and performance effectively.", "authors": ["David Azcona", "Piyush Arora", "I-Han Hsiao", "Alan Smeaton"], "session": "SESSION: Machine Learning I"}, {"title": "Clustering Analysis Reveals Authentic Science Inquiry Trajectories Among Undergraduates", "pages": "96-100", "doi": "10.1145/3303772.3303831", "abstract": "Science education reforms in the United States call for an emphasis on teaching of scientific practices, such as inquiry. Previous work examined expert versus novice practices in authentic science inquiry and found although experts have fairly consistent inquiry strategies, novices exist on a continuum. In this paper, we extend our previous qualitative work to quantitatively analyze differences in inquiry practices among novices. Using clustering analysis, we found that non-science majors who performed simple investigations tended to cluster together and biology majors who performed complex investigations also tended to cluster together. We observed two additional clusters that contain both non-science majors and biology majors, but who performed distinct inquiry strategies. This raises some critical questions about how to pedagogically target students within each cluster.", "authors": ["Melanie Peffer", "David Quigley", "Mehrgan Mostowfi"], "session": "SESSION: Machine Learning I"}, {"title": "Can Background Music Facilitate Learning?: Preliminary Results on Reading Comprehension", "pages": "101-105", "doi": "10.1145/3303772.3303839", "abstract": "It is a common phenomenon for students to listen to background music while studying. However, there are mixed and inconclusive Kindings in the literature, leaving it unclear whether and in which circumstances background music can facilitate or hinder learning. This paper reports a study investigating the effects of Kive different types of background audio (four types of music and one environmental sound) on reading comprehension. An experiment was conducted with 33 graduate students, where a series of cognitive, metacognitive, affective variables and physiological signals were collected and analyzed. Preliminary results show that there were differences on these variables across different music types. This study contributes to the understanding and optimizing of background music for facilitating learning.", "authors": ["Xiao Hu", "Fanjie Li", "Runzhi Kong"], "session": "SESSION: Reading Analytics"}, {"title": "Would you?: Could you? On a tablet? Analytics of Children's eBook Reading", "pages": "106-110", "doi": "10.1145/3303772.3303833", "abstract": "It is difficult to overstate the importance of literacy for adequate functioning in society, from educational attainment and employment opportunities to health outcomes. We created a reading app with the goal of helping readers improve their reading skill while reading for meaning and pleasure, and used it to collect unique data on children's extended reading. Analysis of the data reveals the importance of a behavioral factor in understanding observed reading performance.", "authors": ["Beata Beigman Klebanov", "Anastassia Loukina", "Nitin Madnani", "John Sabatini", "Jennifer Lentini"], "session": "SESSION: Reading Analytics"}, {"title": "Comprehension Factor Analysis: Modeling student's reading behaviour: Accounting for reading practice in predicting students' learning in MOOCs", "pages": "111-115", "doi": "10.1145/3303772.3303817", "abstract": "Massive Open Online Courses (MOOCs) often incorporate lecture-based learning along with lecture notes, textbooks, and videos to students. Moreover, MOOCs also incorporate practice activities and quizzes. Student learning in MOOCs can be tracked and improved using state-of-the-art student modeling. Currently, this means employing conventional student models that are constructed around Intelligent Tutoring Systems (ITS). Traditional ITS systems only utilize students performance interactions (quiz, problem-solving or practice activities). Therefore, text interactions are entirely ignored while modeling students performance in MOOCs using these cognitive models. In this work, we propose a Comprehension Factor Analysis model (CFM) for online courses, which integrates student reading interactions in student models to track and predict learning outcomes. Our model evaluation shows that CFM outperforms state-of-the-art models in predicting students' performance in a MOOC. These models can help better student-wise adaptation in the context of MOOCs.", "authors": ["Khushboo Thaker", "Paulo Carvalho", "Kenneth Koedinger"], "session": "SESSION: Reading Analytics"}, {"title": "Are You Talking to Me?: Multi-Dimensional Language Analysis of Explanations during Reading", "pages": "116-120", "doi": "10.1145/3303772.3303835", "abstract": "This study examines the extent to which instructions to self-explain vs. other-explain a text lead readers to produce different forms of explanations. Natural language processing was used to examine the content and characteristics of the explanations produced as a function of instruction condition. Undergraduate students (n = 146) typed either self-explanations or other-explanations while reading a science text. The linguistic properties of these explanations were calculated using three automated text analysis tools. Machine learning classifiers in combination with the features were used to predict instruction condition (i.e., self- or other-explanation). The best machine learning model performed at rates above chance (kappa = .247; accuracy = 63%). Follow-up analyses indicated that students in the self-explanation condition generated explanations that were more cohesive and that contained words that were more related to social order (e.g., ethics). Overall, the results suggest that natural language processing techniques can be used to detect subtle differences in students' processing of complex texts.", "authors": ["Laura K. Allen", "Caitlin Mills", "Cecile Perret", "Danielle S. McNamara"], "session": "SESSION: Reading Analytics"}, {"title": "Exploring the Subtleties of Agency and Indirect Control in Digital Learning Games", "pages": "121-129", "doi": "10.1145/3303772.3303797", "abstract": "How do the features of a learning environment's user interface impact learners' agency and, further, their learning? We explored this question in the context of Decimal Point, a digital learning game designed to support middle school students in learning decimals. Previous studies of the game showed that giving students the ability to choose the order and number of mini-games to play did not significantly impact their learning outcomes compared to a condition without choice. In this paper we explore whether some elements of the game's interface may have inadvertently exerted indirect control over students' choice, leading to the previous effects. We conducted a classroom study using a new version of the game that varied whether students saw a visual path connecting mini-games on the game map to modulate the level of indirect control students would experience with an implied ordering. Ultimately, we found that students in the no-line condition exercised significantly more agency but did not learn any less than the line condition. These results suggest that indirect control can be a subtle but powerful way to direct student attention in digital learning games.", "authors": ["Erik Harpstead", "J. Elizabeth Richey", "Huy Nguyen", "Bruce M. McLaren"], "session": "SESSION: Games and Learning"}, {"title": "Differences in Student Trajectories via Filtered Time Series Analysis in an Immersive Virtual World", "pages": "130-134", "doi": "10.1145/3303772.3303832", "abstract": "To scaffold students' investigations of an inquiry-based immersive virtual world for science education without undercutting the affordances an open-ended activity provides, this study explores ways time-stamped log files of groups' actions may enable the automatic generation of formative supports. Groups' logged actions in the virtual world are filtered via principal component analysis to provide a time series trajectory showing the rate of their investigative activities over time. This technique functions well in open-ended environments and examines the entire course of their experience in the virtual world instead of specific subsequences. Groups' trajectories are grouped via k-means clustering to identify different typical pathways taken through the immersive virtual world. These different approaches are then correlated with learning gains across several survey constructs (affective dimensions, ecosystem science content, understanding of causality, and experimental methods) to see how various trends are associated with different outcomes. Differences by teacher and school are explored to see how best to support inclusion and success of a diverse array of learners.", "authors": ["Joseph M. Reilly", "Chris Dede"], "session": "SESSION: Games and Learning"}, {"title": "Effective Feature Learning with Unsupervised Learning for Improving the Predictive Models in Massive Open Online Courses", "pages": "135-144", "doi": "10.1145/3303772.3303795", "abstract": "The effectiveness of learning in massive open online courses (MOOCs) can be significantly enhanced by introducing personalized intervention schemes which rely on building predictive models of student learning behaviors such as some engagement or performance indicators. A major challenge that has to be addressed when building such models is to design handcrafted features that are effective for the prediction task at hand. In this paper, we make the first attempt to solve the feature learning problem by taking the unsupervised learning approach to learn a compact representation of the raw features with a large degree of redundancy. Specifically, in order to capture the underlying learning patterns in the content domain and the temporal nature of the clickstream data, we train a modified auto-encoder (AE) combined with the long short-term memory (LSTM) network to obtain a fixed-length embedding for each input sequence. When compared with the original features, the new features that correspond to the embedding obtained by the modified LSTM-AE are not only more parsimonious but also more discriminative for our prediction task. Using simple supervised learning models, the learned features can improve the prediction accuracy by up to 17% compared with the supervised neural networks and reduce overfitting to the dominant low-performing group of students, specifically in the task of predicting students' performance. Our approach is generic in the sense that it is not restricted to a specific supervised learning model nor a specific prediction task for MOOC learning analytics.", "authors": ["Mucong Ding", "Kai Yang", "Dit-Yan Yeung", "Ting-Chuen Pong"], "session": "SESSION: Machine Learning II"}, {"title": "Transfer Learning using Representation Learning in Massive Open Online Courses", "pages": "145-154", "doi": "10.1145/3303772.3303794", "abstract": "In a Massive Open Online Course (MOOC), predictive models of student behavior can support multiple aspects of learning, including instructor feedback and timely intervention. Ongoing courses, when the student outcomes are yet unknown, must rely on models trained from the historical data of previously offered courses. It is possible to transfer models, but they often have poor prediction performance. One reason is features that inadequately represent predictive attributes common to both courses. We present an automated transductive transfer learning approach that addresses this issue. It relies on problem-agnostic, temporal organization of the MOOC clickstream data, where, for each student, for multiple courses, a set of specific MOOC event types is expressed for each time unit. It consists of two alternative transfer methods based on representation learning with auto-encoders: a passive approach using transductive principal component analysis and an active approach that uses a correlation alignment loss term. With these methods, we investigate the transferability of dropout prediction across similar and dissimilar MOOCs and compare with known methods. Results show improved model transferability and suggest that the methods are capable of automatically learning a feature representation that expresses common predictive characteristics of MOOCs.", "authors": ["Mucong Ding", "Yanbang Wang", "Erik Hemberg", "Una-May O'Reilly"], "session": "SESSION: Machine Learning II"}, {"title": "Exploring Programming Semantic Analytics with Deep Learning Models", "pages": "155-159", "doi": "10.1145/3303772.3303823", "abstract": "There are numerous studies have reported the effectiveness of example-based programming learning. However, less is explored recommending code examples with advanced Machine Learning-based models. In this work, we propose a new method to explore the semantic analytics between programming codes and the annotations. We hypothesize that these semantics analytics will capture mass amount of valuable information that can be used as features to build predictive models. We evaluated the proposed semantic analytics extraction method with multiple deep learning algorithms. Results showed that deep learning models outperformed other models and baseline in most cases. Further analysis indicated that in special cases, the proposed method outperformed deep learning models by restricting false-positive classifications.", "authors": ["Yihan Lu", "I-Han Hsiao"], "session": "SESSION: Machine Learning II"}, {"title": "Social Comparison in MOOCs: Perceived SES, Opinion, and Message Formality", "pages": "160-169", "doi": "10.1145/3303772.3303773", "abstract": "There has been limited research on how perceptions of socioeconomic status (SES) and opinion difference could influence peer feedback in Massive Open Online Courses (MOOCs). Using social comparison theory [12], we investigated the influence of ability and opinion-related factors on peer feedback text in a data science MOOC. Perceived SES of peers and the formality of written responses were used as the ability-related factor, while agreement between learners represented the opinion-related factor. We focused on understanding the behaviors of those learners who are most prevalent in MOOCs; those from high socioeconomic countries. Through two studies, we found a strong and repeated influence of agreement on affect and formality in feedback to peers. While a mediation effect of perceived SES was found, a significant effect of formality was not. This work contributes to an understanding of how social comparison theory can be operationalized in online peer writing environments.", "authors": ["Heeryung Choi", "Nia Dowell", "Christopher Brooks", "Stephanie Teasley"], "session": "SESSION: Dialogue & Engagement"}, {"title": "Analysing discussion forum data: a replication study avoiding data contamination", "pages": "170-179", "doi": "10.1145/3303772.3303779", "abstract": "The widespread use of online discussion forums in educational settings provides a rich source of data for researchers interested in how collaboration and interaction can foster effective learning. Such online behaviour can be understood through the Community of Inquiry framework, and the cognitive presence construct in particular can be used to characterise the depth of a student's critical engagement with course material. Automated methods have been developed to support this task, but many studies used small data sets, and there have been few replication studies. In this work, we present findings related to the robustness and generalisability of automated classification methods for detecting cognitive presence in discussion forum transcripts. We closely examined one published state-of-the-art model, comparing different approaches to managing unbalanced classes in the data. By demonstrating how commonly-used data preprocessing practices can lead to over-optimistic results, we contribute to the development of the field so that the results of automated content analysis can be used with confidence.", "authors": ["Elaine Farrow", "Johanna Moore", "Dragan Ga\u0161evi\u0107"], "session": "SESSION: Dialogue & Engagement"}, {"title": "Exploring Learner Engagement Patterns in Teach-Outs Using Topic, Sentiment and On-topicness to Reflect on Pedagogy", "pages": "180-184", "doi": "10.1145/3303772.3303836", "abstract": "MOOCs have developed into multiple learning design models with a wide range of objectives. Teach-Outs are one such example, aiming to drive meaningful discussions around topics of pressing social urgency without the use of formal assessments. Given this approach, it is crucial to evaluate learners' engagement in the discussion forum to understand their experiences. This paper presents a pilot study that applied unsupervised natural language processing techniques to understand what and how students engage in dialogue in a Teach-Out. We used topic modeling to discover the emerging topics in the discussion forums and evaluated the on-topicness of the discussions (i.e. the degree to which discussions were relevant to the Teach-Out content). We also applied content analysis to investigate the sentiments associated with the discussions. We have taken a step toward extracting structure from students' discussions to understand learning behaviors happen in the discussion forum. This is the first study to analyze discussion forums in a Teach-Out.", "authors": ["Wenfei Yan", "Nia Dowell", "Caitlin Holman", "Stephen S. Welsh", "Heeryung Choi", "Christopher Brooks"], "session": "SESSION: Dialogue & Engagement"}, {"title": "DiAd: Domain Adaptation for Learning at Scale", "pages": "185-194", "doi": "10.1145/3303772.3303810", "abstract": "Massive online courses occupy an important place in the educational landscape of today. We study an approach to scale predictive analytic models derived from online course discussion fora--specifically that of confusion detection--onto other courses. The primary challenge here is the lack of labeled examples in a new course and this calls for unsupervised domain adaptation (DA). As a first step in exploring DA in the education domain, we propose a simple algorithm, DiAd, which adapts a classifier trained on a course with labeled data by selectively choosing instances from a new course (with no labeled data) that are most dissimilar to the course with labeled data and on which the classifier is very confident of classification. Our algorithm is empirically validated on the confusion detection task across multiple online courses. We find that DiAd outperforms other methods on the target domain, while showing a comparable performance to a popular method that uses labeled data from the target domain.", "authors": ["Ziheng Zeng", "Snigdha Chaturvedi", "Suma Bhat", "Dan Roth"], "session": "SESSION: Computational Methods"}, {"title": "The Timeliness Deviation: A novel Approach to Evaluate Educational Recommender Systems for Closed-Courses", "pages": "195-204", "doi": "10.1145/3303772.3303774", "abstract": "The decision on what item to learn next in a course can be supported by a recommender system (RS), which aims at making the learning process more efficient and effective. However, learners and learning activities frequently change over time. The question is: how are timely appropriate recommendations of learning resources actually evaluated and how can they be compared? Researchers have found that, in addition to a standardized dataset definition, there is also a lack of standardized definitions of evaluation procedures for RS in the area of Technology Enhanced Learning. This paper argues that, in a closed-course setting, a time-dependent split into the training set and test set is more appropriate than the usual cross-validation to evaluate the Top-N recommended learning resources at various points in time. Moreover, a new measure is introduced to determine the timeliness deviation between the point in time of an item recommendation and the point in time of the actual access by the user. Different recommender algorithms, including two novel ones, are evaluated with the time-dependent evaluation framework and the results, as well as the appropriateness of the framework, are discussed.", "authors": ["Christopher Krauss", "Agathe Merceron", "Stefan Arbanowski"], "session": "SESSION: Computational Methods"}, {"title": "Comparison of Ranking and Rating Scales in Online Peer Assessment: Simulation Approach", "pages": "205-209", "doi": "10.1145/3303772.3303820", "abstract": "This study examines fidelity of ranking and rating scales in the context of online peer review and assessment. Using the Monte-Carlo simulation technique, we demonstrated that rating scales outperform ranking scales in revealing the relative \"true\" latent quality of the peer-assessed artifacts via the observed aggregate peer assessment scores. Our analysis focused on a simple, single-round peer assessment process and took into account peer assessment network topology, network size, the number of assessments per artifact, and the correlation statistics used. This methodology allows to separate the effects of structural components of peer assessment from cognitive effects.", "authors": ["Dmytro Babik", "Scott Stevens", "Andrew E. Waters"], "session": "SESSION: Computational Methods"}, {"title": "Contextualizable Learning Analytics Design: A Generic Model and Writing Analytics Evaluations", "pages": "210-219", "doi": "10.1145/3303772.3303785", "abstract": "A major promise of learning analytics is that through the collection of large amounts of data we can derive insights from authentic learning environments, and impact many learners at scale. However, the context in which the learning occurs is important for educational innovations to impact student learning. In particular, for student-facing learning analytics systems like feedback tools to work effectively, they have to be integrated with pedagogical approaches and the learning design. This paper proposes a conceptual model to strike a balance between the concepts of generalizable scalable support and contextualized specific support by clarifying key elements that help to contextualize student-facing learning analytics tools. We demonstrate an implementation of the model using a writing analytics example, where the features, feedback and learning activities around the automated writing feedback tool are tuned for the pedagogical context and the assessment regime in hand, by co-designing them with the subject experts. The model can be employed for learning analytics to move from generalized support to meaningful contextualized support for enhancing learning.", "authors": ["Antonette Shibani", "Simon Knight", "Simon Buckingham Shum"], "session": "SESSION: Text Analytics I"}, {"title": "Topic Development to Support Revision Feedback", "pages": "220-224", "doi": "10.1145/3303772.3303816", "abstract": "Revision is important but challenging for novice writers, particularly in post-secondary education where opportunities for personalized feedback are limited. Inexperienced writers typically overlook revision; when they do revise, they focus on surface errors rather than global revisions that enhance meaning and coherence. Writing analytics can automate personalized prompts to guide revision. We use topic modelling LDA as grounds for an analytic to scaffold holistic revision at paragraph and essay levels. The analytic visualizes topic distribution and generates three types of prompts: Introduction, Paragraph and Conclusion. Feedback encourages revisions focusing on sequencing topics, expanding underdeveloped ideas, and making holistic revisions to improve clarity and coherence of paragraphs. Model feedback was evaluated using undergraduate student essays on various topics scored by human evaluators. Model accuracy was strong for all types of feedback. This opens new branches of research to explore generating personalized feedback at paragraph and essay levels.", "authors": ["Jovita M. Vytasek", "Alexandra Patzak", "Philip H. Winne"], "session": "SESSION: Text Analytics I"}, {"title": "Evaluating the Fairness of Predictive Student Models Through Slicing Analysis", "pages": "225-234", "doi": "10.1145/3303772.3303791", "abstract": "Predictive modeling has been a core area of learning analytics research over the past decade, with such models currently deployed in a variety of educational contexts from MOOCs to K-12. However, analyses of the differential effectiveness of these models across demographic, identity, or other groups has been scarce. In this paper, we present a method for evaluating unfairness in predictive student models. We define this in terms of differential accuracy between subgroups, and measure it using a new metric we term the Absolute Between-ROC Area (ABROCA). We demonstrate the proposed method through a gender-based \"slicing analysis\" using five different models replicated from other works and a dataset of 44 unique MOOCs and over four million learners. Our results demonstrate (1) significant differences in model fairness according to (a) statistical algorithm and (b) feature set used; (2) that the gender imbalance ratio, curricular area, and specific course used for a model all display significant association with the value of the ABROCA statistic; and (3) that there is not evidence of a strict tradeoff between performance and fairness. This work provides a framework for quantifying and understanding how predictive models might inadvertently privilege, or disparately impact, different student subgroups. Furthermore, our results suggest that learning analytics researchers and practitioners can use slicing analysis to improve model fairness without necessarily sacrificing performance.1", "authors": ["Josh Gardner", "Christopher Brooks", "Ryan Baker"], "session": "SESSION: Predictive and Privacy"}, {"title": "Learning analytics at the intersections of student trust, disclosure and benefit", "pages": "235-244", "doi": "10.1145/3303772.3303796", "abstract": "Evidence suggests that individuals are often willing to exchange personal data for (real or perceived) benefits. Such an exchange may be impacted by their trust in a particular context and their (real or perceived) control over their data. Students remain concerned about the scope and detail of surveillance of their learning behavior, their privacy, their control over what data are collected, the purpose of the collection, and the implications of any analysis. Questions arise as to the extent to which students are aware of the benefits and risks inherent in the exchange of their data, and whether they are willing to exchange personal data for more effective and supported learning experiences. This study reports on the views of entry level students at the Open University (OU) in 2018. The primary aim is to explore differences between stated attitudes to privacy and their online behaviors, and whether these same attitudes extend to their university's uses of their (personal) data. The analysis indicates, inter alia, that there is no obvious relationship between how often students are online or their awareness of/concerns about privacy issues in online contexts and what they actually do to protect themselves. Significantly though, the findings indicate that students overwhelmingly have an inherent trust in their university to use their data appropriately and ethically. Based on the findings, we outline a number of issues for consideration by higher education institutions, such as the need for transparency (of purpose and scope), the provision of some element of student control, and an acknowledgment of the exchange value of information in the nexus of the privacy calculus.", "authors": ["Sharon Slade", "Paul Prinsloo", "Mohammad Khalil"], "session": "SESSION: Predictive and Privacy"}, {"title": "Predicting the Well-functioning of Learning Groups under Privacy Restrictions", "pages": "245-249", "doi": "10.1145/3303772.3303826", "abstract": "Establishing small learning groups in online courses is a possible way to foster collaborative knowledge building in an engaging and effective learning community. To enable group activities it is not enough to design collaborative tasks and to provide collaboration tools for online scenarios. Collaboration in such learning groups is prone to fail or even not to be initiated without explicit guidance. In the target situations, interventions and guiding mechanisms have to scale with a growing number of course participants. To achieve this under privacy constraints, we aim at identifying target indicators for well-functioning group work that do not rely on any kind of information about individual learners.", "authors": ["Tobias Hecking", "Dorian Doberstein", "H. Ulrich Hoppe"], "session": "SESSION: Predictive and Privacy"}, {"title": "Exploring students' sensemaking of learning analytics dashboards: Does frame of reference make a difference?", "pages": "250-259", "doi": "10.1145/3303772.3303804", "abstract": "Learning Analytics Dashboards (LAD) are becoming an increasingly popular way to provide students with personalised feedback. Despite the number of LADs being developed, significant research gaps exist around the student perspective, especially how students make sense of graphics provided in LADs, and how they intend to act on the feedback provided therein. This study employed a randomized-controlled trial to examine students' sense-making of LADs showing four different frames of reference, and to what extent the impact of LADs was mediated by baseline self-regulation. Using a mix of quantitative and qualitative data analysis, the results revealed rather distinct patterns in students' sense-making across the four LADs. These patterns involved the intersection of visual salience and planned learning actions. However, collectively, across all four LADs a consistent theme emerged around students planned learning actions. This theme was classified as time and study environment management. A key finding of the study is that the use of LADs as a primary feedback process should be personalized and include training and support to aid student sensemaking.", "authors": ["Lisa Lim", "Shane Dawson", "Srecko Joksimovic", "Dragan Ga\u0161evi\u0107"], "session": "SESSION: Dashboards I"}, {"title": "Top Concept Networks of Professional Education Reflections", "pages": "260-264", "doi": "10.1145/3303772.3303840", "abstract": "This study explores the application of computational techniques to extract information about dental students' developing conceptions of their profession from digital reflective journal entries. Top concept networks were created for two cohorts of students at the beginning and end of their four-year program. A shift from a collection of general notions about becoming a professional to a more integrated, patient-centered conceptualization was found for both cohorts. The two groups initially differed in their perception of dental school (a mechanism for being able to work as a dentist versus a place to learn the skills to serve patients well) and subsequently in the extent of attention they paid to the feelings of their patients and themselves, as well as the continual growth of skill after graduation. Several useful linguistic markers were identified for examining these same issues in other cohorts. The results suggest that top concept networks can offer a useful window into students' developing conceptions of their profession. This kind of information can support student success on a macro level by offering feedback on existing curricula / informing learning designs to cultivate desired conceptions, and on a micro level through identifying particular ways individuals align with and diverge from the common trajectories.", "authors": ["Alyssa Friend Wise", "Yi Cui"], "session": "SESSION: Dashboards I"}, {"title": "Different Types of Response-Based Feedback in Mathematics: The case of textual and symbolic messages", "pages": "265-269", "doi": "10.1145/3303772.3303815", "abstract": "The current study compares textual and symbolic elaborated, response-based feedback in mathematics. We use a randomized experiment in Khan Academy to measure feedback effect in four different topics. Overall, we point out to the superiority of symbolic feedback.", "authors": ["Tomer Gal", "Arnon Hershkovitz"], "session": "SESSION: Feedback and Measurement"}, {"title": "Validating the Use of LMS-Derived Rubric Structural Features to Facilitate Automated Measurement of Rubric Quality", "pages": "270-274", "doi": "10.1145/3303772.3303829", "abstract": "Rubrics are widely used throughout postsecondary education as means for aiding in instruction and evaluation. However, despite their broad global adoption, very little is known about the quality of rubrics in use. We develop two measures to assess the quality of rubrics: (1) a checklist identifying criteria of high-quality rubrics based on analytic rubric design best practices and (2) a set of LMS-derived features that are hypothesized to represent structural components that are, in general, necessary but not sufficient for high quality rubrics. The validity of using the feature-generated scores as proxies for identifying rubric quality is evaluated through several means. First, the feature-generated scores are calculated for a set of external exemplary rubrics of known high quality. Second, the feature-scores for a subset of internal rubrics are compared to average human rater scores of rubric quality based on the checklist. We discuss the results, practical applications, and a larger research program surrounding the feature-generated scores.", "authors": ["Philip Arcuria", "William Morgan", "Thomas G. Fikes"], "session": "SESSION: Feedback and Measurement"}, {"title": "Measuring Knowledge Gaps in Student Responses by Mining Networked Representations of Texts", "pages": "275-279", "doi": "10.1145/3303772.3303822", "abstract": "Gaps between knowledge sources are interesting to various stakeholders: they might indicate potential misconceptions awaiting correction, complex or novel knowledge that requires careful delivery or studying. Motivated by these underlying values, this study explores the knowledge gap phenomenon in the context of student textual responses. In the method proposed in this study, discourses are first mapped into structured knowledge spaces where gaps between correct/incorrect responses and assessed knowledge are measured by network-based metrics. Empirical results demonstrate the effectiveness of the proposed method in measuring gaps in student responses. The networked representation of texts proposed in this study is novel in quantitatively framing gaps of knowledge. It also offers a set of validated metrics for analyzing student responses in research and practice.", "authors": ["Chen Qiao", "Xiao Hu"], "session": "SESSION: Feedback and Measurement"}, {"title": "Motivated Information Seeking and Graph Comprehension Among College Students", "pages": "280-289", "doi": "10.1145/3303772.3303805", "abstract": "Learning Analytics Dashboards (LADs) are predicated on the notion that access to more academic information can help students regulate their academic behaviors, but what is the association between information seeking preferences and help-seeking practices among college students? If given access to more information, what might college students do with it? We investigated these questions in a series of two studies. Study 1 validates a measure of information-seeking preferences---the Motivated Information-Seeking Questionnaire (MISQ)----using a college student sample drawn from across the country (n = 551). In a second study, we used the MISQ to measure college students' (n=210) performance-avoid (i.e., avoiding seeming incompetent in relation to one's peers) and performance-approach (i.e., wishing to outperform one's peers) information seeking preferences, their help-seeking behaviors, and their ability to comprehend line graphs and bar graphs---two common graphs types for LADs. Results point to a negative relationship between graph comprehension and help-seeking strategies, such as attending office hours, emailing one's professor for help, or visiting a study center---even after controlling for academic performance and demographic characteristics. This suggests that students more capable of readings graphs might not seek help when needed. Further results suggest a positive relationship between performance-approach information-seeking preferences, and how often students compare themselves to their peers. This study contributes to our understanding of the motivational implications of academic data visualizations in academic settings, and increases our knowledge of the way students interpret visualizations. It uncovers tensions between what students want to see, versus what it might be more motivationally appropriate for them to see. Importantly, the MISQ and graph comprehension measure can be used in future studies to better understand the role of students' information seeking tendencies with regard to their interpretation of various kinds of feedback present in LADs.", "authors": ["Stephen J. Aguilar", "Clare Baek"], "session": "SESSION: Dashboards II"}, {"title": "Using Detailed Access Trajectories for Learning Behavior Analysis", "pages": "290-299", "doi": "10.1145/3303772.3303781", "abstract": "Student learning activity in MOOCs can be viewed from multiple perspectives. We present a new organization of MOOC learner activity data at a resolution that is in between the fine granularity of the clickstream and coarse organizations that count activities, aggregate students or use long duration time units. A detailed access trajectory (DAT) consists of binary values and is two dimensional with one axis that is a time series, and the other that is a chronologically ordered list of a MOOC component type's instances, videos in instructional order, for example. Most popular MOOC platforms generate data that can be organized as detailed access trajectories (DATs). We explore the value of DATs by conducting four empirical mini-studies. Our studies suggest DATs contain rich information about students' learning behaviors and facilitate MOOC learning analyses.", "authors": ["Yanbang Wang", "Nancy Law", "Erik Hemberg", "Una-May O'Reilly"], "session": "SESSION: Logging Activity"}, {"title": "The validity and utility of activity logs as a measure of student engagement", "pages": "300-309", "doi": "10.1145/3303772.3303789", "abstract": "Learning management system (LMS) web logs provide granular, near-real-time records of student behavior as learners interact with online course materials in digital learning environments. However, it remains unclear whether LMS activity indeed reflects behavioral properties of student engagement, and it also remains unclear how to deal with variability in LMS usage across a diversity of courses. In this study, we evaluate whether instructors' subjective ratings of their students' engagement are related to features of LMS activity for 9,021 students enrolled in 473 for-credit courses. We find that estimators derived from LMS web logs are closely related to instructor ratings of engagement, however, we also observe that there is not a single generic relationship between activity and engagement, and what constitutes the behavioral components of \"engagement\" will be contingent on course structure. However, for many of these courses, modeled engagement scores are comparable to instructors' ratings in their sensitivity for predicting academic performance. As long as they are tuned to the differences between courses, activity indices from LMS web logs can provide a valid and useful proxy measure of student engagement.", "authors": ["Benjamin Motz", "Joshua Quick", "Noah Schroeder", "Jordon Zook", "Matthew Gunkel"], "session": "SESSION: Logging Activity"}, {"title": "Towards Enabling Feedback on Rhetorical Structure with Neural Sequence Models", "pages": "310-319", "doi": "10.1145/3303772.3303808", "abstract": "Analysis of student writing, both for assessment and for enabling feedback have been of interest to the field of learning analytics. While much progress can be made through detection of local cues in writing, structured prediction approaches offer capabilities that are particularly well tailored to the needs of models aiming to offer substantive feedback on rhetorical structure. We thus cast the analysis of rhetorical structure in academic writing as a structured prediction task in which we employ models that leverage both local and global cues in writing. In particular, this paper presents a hierarchical neural architecture that performs this task. The evaluation demonstrates that the architecture achieves near-human performance while significantly surpassing state-of-the-art baselines. A multifaceted approach to model interpretation offers insights into the inner workings of the model.", "authors": ["James Fiacco", "Elena Cotos", "Carolyn Ros\u00e9"], "session": "SESSION: Text Analytics II"}, {"title": "Language as Thought: Using Natural Language Processing to Model Noncognitive Traits that Predict College Success", "pages": "320-329", "doi": "10.1145/3303772.3303801", "abstract": "It is widely acknowledged that the language we use reflects numerous psychological constructs, including our thoughts, feelings, and desires. Can the so called \"noncognitive\" traits with known links to success, such as growth mindset, leadership ability, and intrinsic motivation, be similarly revealed through language? We investigated this question by analyzing students' 150-word open-ended descriptions of their own extracurricular activities or work experiences included in their college applications. We used the Common Application-National Student Clearinghouse data set, a six-year longitudinal dataset that includes college application data and graduation outcomes for 278,201 U.S. high-school students. We first developed a coding scheme from a stratified sample of 4,000 essays and used it to code seven traits: growth mindset, perseverance, goal orientation, leadership, psychological connection (intrinsic motivation), self-transcendent (prosocial) purpose, and team orientation, along with earned accolades. Then, we used standard classifiers with bag-of-n-grams as features and deep learning techniques (recurrent neural networks) with word embeddings to automate the coding. The models demonstrated convergent validity with the human coding with AUCs ranging from .770 to .925 and correlations ranging from .418 to .734. There was also evidence of discriminant validity in the pattern of inter-correlations (rs between -.206 to .306) for both human- and model-coded traits. Finally, the models demonstrated incremental predictive validity in predicting six-year graduation outcomes net of sociodemographics, intelligence, academic achievement, and institutional graduation rates. We conclude that language provides a lens into noncognitive traits important for college success, which can be captured with automated methods.", "authors": ["Cathlyn Stone", "Abigail Quirk", "Margo Gardener", "Stephen Hutt", "Angela L. Duckworth", "Sidney K. D'Mello"], "session": "SESSION: Text Analytics II"}, {"title": "Square it up!: How to model step duration when predicting student performance", "pages": "330-334", "doi": "10.1145/3303772.3303827", "abstract": "In this paper, we explore how we can model students' response times to predict student performance in Intelligent Tutoring Systems. Related research suggests that response time can provide information with respect to correctness. However, time is not consistently used when modeling students' performance. Here, we build on previous work that indicated that the relationship between response time and student performance is non-linear. Based on this concept, we compare three models: a standard Additive Factors Analysis Model (AFM), an AFM model enhanced with a linear step duration parameter and an AFM model enhanced with a quadratic, step duration parameter. The results of this comparison show that the AFM model that is enhanced with the quadratic step duration parameter outperforms the other models over four different datasets and for most of the metrics we used to evaluate the models in cross validation and prediction.", "authors": ["Irene-Angelica Chounta", "Paulo F. Carvalho"], "session": "SESSION: Intelligent Tutoring Systems I"}, {"title": "Fairer but Not Fair Enough On the Equitability of Knowledge Tracing", "pages": "335-339", "doi": "10.1145/3303772.3303838", "abstract": "Adaptive educational technologies have the capacity to meet the needs of individual students in theory, but in some cases, the degree of personalization might be less than desired, which could lead to inequitable outcomes for students. In this paper, we use simulations to demonstrate that while knowledge tracing algorithms are substantially more equitable than giving all students the same amount of practice, such algorithms can still be inequitable when they rely on inaccurate models. This can arise as a result of two factors: (1) using student models that are fit to aggregate populations of students, and (2) using student models that make incorrect assumptions about student learning. In particular, we demonstrate that both the Bayesian knowledge tracing algorithm and the N-Consecutive Correct Responses heuristic are susceptible to these concerns, but that knowledge tracing with the additive factor model may be more equitable. The broader message of this paper is that when designing learning analytics algorithms, we need to explicitly consider whether the algorithms act fairly with respect to different populations of students, and if not, how we can make our algorithms more equitable.", "authors": ["Shayan Doroudi", "Emma Brunskill"], "session": "SESSION: Intelligent Tutoring Systems I"}, {"title": "Deep Knowledge Tracing and Engagement with MOOCs", "pages": "340-342", "doi": "10.1145/3303772.3303830", "abstract": "MOOCs and online courses have notoriously high attrition [1]. One challenge is that it can be difficult to tell if students fail to complete because of disinterest or because of course difficulty. Utilizing a Deep Knowledge Tracing framework, we account for student engagement by including course interaction covariates. With these, we find that we can predict a student's next item response with over 88% accuracy. Using these predictions, targeted interventions can be offered to students and targeted improvements can be made to courses. In particular, this approach would allow for gating of content until a student has reasonable likelihood of succeeding.", "authors": ["Kritphong Mongkhonvanit", "Klint Kanopka", "David Lang"], "session": "SESSION: Intelligent Tutoring Systems I"}, {"title": "Towards Value-Sensitive Learning Analytics Design", "pages": "343-352", "doi": "10.1145/3303772.3303798", "abstract": "To support ethical considerations and system integrity in learning analytics, this paper introduces two cases of applying the Value Sensitive Design methodology to learning analytics design. The first study applied two methods of Value Sensitive Design, namely stakeholder analysis and value analysis, to a conceptual investigation of an existing learning analytics tool. This investigation uncovered a number of values and value tensions, leading to design trade-offs to be considered in future tool refinements. The second study holistically applied Value Sensitive Design to the design of a recommendation system for the Wikipedia WikiProjects. To proactively consider values among stakeholders, we derived a multi-stage design process that included literature analysis, empirical investigations, prototype development, community engagement, iterative testing and refinement, and continuous evaluation. By reporting on these two cases, this paper responds to a need of practical means to support ethical considerations and human values in learning analytics systems. These two cases demonstrate that Value Sensitive Design could be a viable approach for balancing a wide range of human values, which tend to encompass and surpass ethical issues, in learning analytics design.", "authors": ["Bodong Chen", "Haiyi Zhu"], "session": "SESSION: Design"}, {"title": "Student Centred Design of a Learning Analytics System", "pages": "353-362", "doi": "10.1145/3303772.3303793", "abstract": "Current Learning Analytics (LA) systems are primarily designed with University staff members as the target audience; very few are aimed at students, with almost none being developed with direct student involvement and undertaking a comprehensive evaluation. This paper describes a HEFCE funded project that has employed a variety of methods to engage students in the design, development and evaluation of a student facing LA dashboard. LA was integrated into the delivery of 4 undergraduate modules with 169 student sign-ups. The design of the dashboard uses a novel approach of trying to understand the reasons why students want to study at university and maps their engagement and predicted outcomes to these motivations, with weekly personalised notifications and feedback. Students are also given the choice of how to visualise the data either via a chart-based view or to be represented as themselves. A mixed-methods evaluation has shown that students' feelings of dependability and trust of the underlying analytics and data is variable. However, students were mostly positive about the usability and interface design of the system and almost all students once signed-up did interact with their LA. The majority of students could see how the LA system could support their learning and said that it would influence their behaviour. In some cases, this has had a direct impact on their levels of engagement. The main contribution of this paper is the transparent documentation of a User Centred Design approach that has produced forms of LA representation, recommendation and interaction design that go beyond those used in current similar systems and have been shown to motivate students and impact their learning behaviour.", "authors": ["Ed de Quincey", "Chris Briggs", "Theocharis Kyriacou", "Richard Waller"], "session": "SESSION: Design"}, {"title": "The Impact of an Online Tutoring Program for Algebra Readiness on Mathematics Achievements; Results of a Randomized Experiment", "pages": "363-372", "doi": "10.1145/3303772.3303777", "abstract": "We study the impact of an online tutoring program, AnimalWatch, for algebra readiness on mathematics achievements of grade 6 students. We use the data from a randomized experimental design conducted on 69 teachers and 2025 students in California in the academic years 2011-2012. After a brief description of the experimental design and the system implementation, we analyze the treatment effect of employing AnimalWatch using the popular hierarchical linear models and find a small positive effect. We further use the logged system usage data such as time spent in the system, modules completed, correct/incorrect/no-answers records of students in each login to analyze how system implementation and usage helped different students. Our results provide insights into the limitations in implementing such a study in a real world setting and suggests recommendations for future research.", "authors": ["Sahba Akhavan Niaki", "Clint P. George", "George Michailidis", "Carole R. Beal"], "session": "SESSION: Sequences"}, {"title": "UPM: Discovering Course Enrollment Sequences Associated with Success", "pages": "373-382", "doi": "10.1145/3303772.3303799", "abstract": "Identifying enrollment patterns associated with course success can help educators design better degree plans, and students make informed decisions about future enrollments. While discriminating pattern mining techniques can be used to address this problem, course enrollment patterns include sequence and quantity (grades) information. None of the existing methods were designed to account for both factors. In this work we present UPM, a Universal discriminating Pattern Mining framework that simultaneously mines various types of enrollment patterns while accounting for sequence and quantity using an expansion-specific approach. Unlike the existing methods, UPM expands a given pattern with an item by finding a minimum-entropy split over the item's quantities. We then use UPM to extract discriminating enrollment patterns from the high and the low performing student groups. These patterns can be utilized by educators for degree planning. To evaluate the quality of the extracted patterns, we adopt a supervised classification approach where we apply various classification techniques to label students according tho their performance based on the extracted patterns. Our evaluation shows that the classification accuracies obtained using the UPM extracted patterns are higher than the accuracies obtained using patterns extracted by other techniques. Accuracy improves significantly for students with larger numbers of patterns. Moreover, expansion-specific quantitative mining leads to more accurate classifications than the methods that do not account for quantities (grades).", "authors": ["Asmaa Elbadrawy", "George Karypis"], "session": "SESSION: Sequences"}, {"title": "Affect Sequences and Learning in Betty's Brain", "pages": "383-390", "doi": "10.1145/3303772.3303807", "abstract": "Education research has explored the role of students' affective states in learning, but some evidence suggests that existing models may not fully capture the meaning or frequency of how students transition between different states. In this study we examine the patterns of educationally-relevant affective states within the context of Betty's Brain, an open-ended, computer-based learning system used to teach complex scientific processes. We examine three types of affective transitions based on similarity with the theorized D'Mello and Graesser model, transition between two affective states, and the sustained instances of certain states. We correlate of the frequency of these patterns with learning outcomes and our findings suggest that boredom is a powerful indicator of students' knowledge, but not necessarily indicative of learning. We discuss our findings within the context of both research and theory on affect dynamics and the implications for pedagogical and system design.", "authors": ["Juliana Ma. Alexandra L. Andres", "Jaclyn Ocumpaugh", "Ryan S. Baker", "Stefan Slater", "Luc Paquette", "Yang Jiang", "Shamya Karumbaiah", "Nigel Bosch", "Anabil Munshi", "Allison Moore", "Gautam Biswas"], "session": "SESSION: Sequences"}, {"title": "Refusing to Try: Characterizing Early Stopout on Student Assignments", "pages": "391-400", "doi": "10.1145/3303772.3303806", "abstract": "A prominent issue faced by the education research community is that of student attrition. While large research efforts have been devoted to studying course-level attrition, widely referred to as dropout, less research has been focused on finer-grained assignment-level attrition commonly observed in K-12 classrooms. This later instantiation of attrition, referred to in this paper as \"stopout,\" is characterized by students failing to complete their assigned work, but the cause of such behavior are not often known. This becomes a large problem for educators and developers of learning platforms as students who give up on assignments early are missing opportunities to learn and practice the material which may affect future performance on related topics; similarly, it is difficult for researchers to develop, and subsequently difficult for computer-based systems to deploy interventions aimed at promoting productive persistence once a student has ceased interaction with the software. This difficulty highlights the importance to understand and identify early signs of stopout behavior in order to provide aid to students preemptively to promote productive persistence in their learning. While many cases of student stopout may be attributable to gaps in student knowledge and indicative of struggle, student attributes such as grit and persistence may be further affected by other factors. This work focuses on identifying different forms of stopout behavior in the context of middle school math by observing student behaviors at the sub-problem level. We find that students exhibit disproportionate stopout on the first problem of their assignments in comparison to stopout on subsequent problems, identifying a behavior that we call \"refusal,\" and use the emerging patterns of student activity to better understand the potential causes underlying stopout behavior early in an assignment.", "authors": ["Anthony F. Botelho", "Ashvini Varatharaj", "Eric G. Van Inwegen", "Neil T. Heffernan"], "session": "SESSION: Machine Learning III"}, {"title": "An Analysis of Student Representation, Representative Features and Classification Algorithms to Predict Degree Dropout", "pages": "401-410", "doi": "10.1145/3303772.3303800", "abstract": "Identifying and monitoring students who are likely to dropout is a vital issue for universities. Early detection allows institutions to intervene, addressing problems and retaining students. Prior research into the early detection of at-risk students has opted for the use of predictive models, but a comprehensive assessment of the suitability of different algorithms and approaches is complicated by the large number of variable features that constitute a student's educational experience. Predictive models vary in terms of their amplitude, temporality and the learning algorithms employed. While amplitude refers to the ability of the model to operate on multiple degrees, temporality is often considered due to the natural temporal aspect of the data. In the absence of a comparative framework of learning algorithms, the aim of this paper has been to provide such an analysis, based on a proposed classification of strategies for predicting dropouts in Higher Education Institutions. Three different student representations are implemented (namely Global Feature-Based, Local Feature-Based, and Time Series) in conjunction with the appropriate learning algorithms for each of them. A description of each approach, as well as its implementation process, are presented in this paper as technical contributions. An experiment based on a dataset of student information from two degrees, namely Business Administration and Architecture, acquired through an automated management system from a university in Brazil is used. Our findings can be summarized as: (i) of the three proposed student representations, the Local Feature-Based was the most suitable approach for predicting dropout. In addition to providing high quality results, the Local Feature-Based representations are simple to build, and the construction of the model is less expensive when compared to more complex ones; (ii) as a conclusion of the results obtained via Local Feature-Based, dropout can be said to be accurately predicted using grades of a few core courses, so there is no need for a complex features extraction process; (iii) considering temporal aspects of the data does not seem to contribute to the prediction performance although it increases computational costs as the model complexity increases.", "authors": ["Rub\u00e9n Manrique", "Bernardo Pereira Nunes", "Olga Marino", "Marco Antonio Casanova", "Terhi Nurmikko-Fuller"], "session": "SESSION: Machine Learning III"}, {"title": "The Impact of Student Opt-Out on Educational Predictive Models", "pages": "411-420", "doi": "10.1145/3303772.3303809", "abstract": "Privacy concerns may lead people to opt-in or opt-out of having their educational data collected. These decisions may impact the performance of educational predictive models. To understand this, we conducted a survey to determine the propensity of students to withhold or grant access to their data for the purposes of training predictive models. We simulated the effects of opt-out on the accuracy of educational predictive models by dropping a random sample of data over a range of increments, and then contextualize our findings using the survey results. We find that grade predictive models are fairly robust and that kappa scores do not decrease unless there is signiicant opt-out, but when there is, the deteriorating performance disproportionately affects certain subpopulations.", "authors": ["Warren Li", "Christopher Brooks", "Florian Schaub"], "session": "SESSION: Machine Learning III"}, {"title": "Where You Are, Not What You See: The Impact of Learning Environment on Mind Wandering and Material Retention", "pages": "421-425", "doi": "10.1145/3303772.3303824", "abstract": "Online lectures are an increasingly popular tool for learning, yet research on instructor visibility during an online lecture, and students' environmental settings, has not been well-explored. The current study addresses this gap in the literature by experimentally manipulating online display format and social learning settings to understand their influence on student learning and mind-wandering experiences. Results suggest that instructor visibility within an online lecture does not impact students' MW or retention performance. However, we found some evidence that students' social setting during viewing has an impact on MW (p = .05). Specifically, students who watched the lecture in a classroom with others reported significantly more MW than students who watched the lecture alone. Finally, social setting also moderated the negative relationship between MW and material retention. Our results demonstrate that learning experiences during online lectures can vary based on where, and with whom, the lectures are watched.", "authors": ["Trish L. Varao-Sousa", "Caitlin Mills", "Alan Kingstone"], "session": "SESSION: Classroom & Collaboration"}, {"title": "DEBE feedback for large lecture classroom analytics", "pages": "426-430", "doi": "10.1145/3303772.3303821", "abstract": "Learning Analytics (LA) research has demonstrated the potential of LA in detecting and monitoring cognitive-affective parameters and improving student success. But most of it has been applied to online and computerized learning environments whereas physical classrooms have largely remained outside the scope of such research. This paper attempts to bridge that gap by proposing a student feedback model in which they report on the difficult/easy and engaging/boring aspects of their lecture. We outline the pedagogical affordances of an aggregated time-series of such data and discuss it within the context of LA research.", "authors": ["Ritayan Mitra", "Pankaj Chavan"], "session": "SESSION: Classroom & Collaboration"}, {"title": "Modeling gender dynamics in intra and interpersonal interactions during online collaborative learning", "pages": "431-435", "doi": "10.1145/3303772.3303837", "abstract": "There has been long-standing stereotypes on men and women's communication styles, such as men using more assertive or aggressive language and women showing more agreeableness and emotions in interactions. In the context of collaborative learning, male learners often believed to be more active participants while female learners are less engaged. To further explore gender differences in learners communication behavior and whether it has changed in the context of online synchronous collaboration, we examined students interactions at a sociocognitive level with a methodology called Group Communication Analysis (GCA). We found that there were no significant differences between men and women in the degree of participation. However, women exhibited significantly higher average social impact, responsivity and internal cohesion compared to men. We also compared the proportion of learners interaction profiles, and results suggest that women are more likely to be effective and cohesive communicators. We discussed implications of these findings for pedagogical practices to promote inclusivity and equity in collaborative learning online.", "authors": ["Yiwen Lin", "Nia Dowell", "Andrew Godfrey", "Heeryung Choi", "Christopher Brooks"], "session": "SESSION: Classroom & Collaboration"}, {"title": "Predicting Student Success in Communication Skills Learning Scenarios with Virtual Humans", "pages": "436-440", "doi": "10.1145/3303772.3303828", "abstract": "Virtual humans are frequently used to help medical students practice communication skills. Here, we show that communication skills features drawn from the literature on best practices for doctor-patient communication can be used to predict student interviewers' success in a given domain skill. We also demonstrate the viability of Bayesian Rule Lists, an interpretable machine learning model, for this use case. Bayesian Rule Lists' predictive performance is comparable to that of other other commonly used algorithms, including decision trees. This suggests that Bayesian Rule Lists, which produce simple, human-readable trained binary classifiers, may be suitable for providing feedback for educational purposes.", "authors": ["Stephanie Carnell", "Benjamin Lok", "Melva T. James", "Jonathan K. Su"], "session": "SESSION: Classroom & Collaboration"}, {"title": "Challenges on implementing Learning Analytics over countrywide K-12 data", "pages": "441-445", "doi": "10.1145/3303772.3303819", "abstract": "The present work describes the challenges faced during the development of a countrywide Learning Analytics tool focused on tracking the trajectories of Uruguayan students during their first three years of secondary education. Due to the large-scale of the project, which covers an entire national educational system, several challenges and constraints (both technical and legal) were faced during its conception and development. This paper presents the design decisions and solutions found to address or mitigate the problems found, with the current state of the project. Early results point out the feasibility of finding meaningful patterns in the available data (using data mining techniques) which can be embedded into a prototype for tracking the students scholar trajectory.", "authors": ["Luiz Antonio Macarini", "Cristian Cechinel", "Henrique Lemos dos Santos", "Xavier Ochoa", "Virg\u00ednia Rod\u00e9s", "Guillermo Ettlin Alonso", "Al\u00e9n P\u00e9rez Casas", "Patricia D\u00edaz"], "session": "SESSION: Implementation"}, {"title": "Increasing the Impact of Learning Analytics", "pages": "446-455", "doi": "10.1145/3303772.3303784", "abstract": "Learning Analytics (LA) studies the learning process in order to optimize learning opportunities for students. Although LA has quickly risen to prominence, there remain questions regarding the impact LA has made to date. To evaluate the extent that LA has impacted our understanding of learning and produced insights that have been translated to mainstream practice or contributed to theory, we reviewed the research published in 2011-2018 LAK conferences and Journal of Learning Analytics. The reviewed studies were coded according to five dimensions: study focus, data types, purpose, institutional setting, and scale of research and implementation. The coding and subsequent epistemic network analysis indicates that while LA research has developed in the areas of focus and sophistication of analyses, the impact on practice, theory and frameworks have been limited. We hypothesize that this finding is due to a continuing predominance of small-scale techno-centric exploratory studies that to date have not fully accounted for the multi-disciplinarity that comprises education. For the field to reach its potential in understanding and optimizing learning and learning environments, there must be a purposeful shift to move from exploratory models to more holistic and integrative systems-level research. This necessitates greater effort applied to understanding the research cycles that emerge when multiple knowledge domains coalesce into new fields of research.", "authors": ["Shane Dawson", "Srecko Joksimovic", "Oleksandra Poquet", "George Siemens"], "session": "SESSION: Implementation"}, {"title": "Utilizing Learning Analytics to Map Students' Self-Reported Study Strategies to Click Behaviors in STEM Courses", "pages": "456-460", "doi": "10.1145/3303772.3303841", "abstract": "Informed by cognitive theories of learning, this work examined how students' self-reported study patterns (spacing vs. cramming) corresponded to their engagement with the Learning Management System (LMS) across two years in a large biology course. We specifically focused on how students accessed non-mandatory resources (lecture videos, lecture slides) and considered whether this pattern differed by underrepresented minority (URM) status. Overall, students who self-reported utilizing spacing strategies throughout the course had higher grades than students who reported cramming throughout the course. When examining LMS engagement, only a small percentage of students accessed the lecture videos and lecture slides. Applying a negative binomial regression model to daily counts of click activities, we also found that students who utilized spacing strategies accessed LMS resources more often but not earlier before major deadlines. Moreover, this finding was not different for underrepresented students. Our results provide some initial evidence showing how spacing behaviors correspond to accessing learning resources. However, given the lack of general engagement with LMS resources, our results underscore the value of encouraging students to utilize these resources when studying course material.", "authors": ["Fernando Rodriguez", "Renzhe Yu", "Jihyun Park", "Mariela Janet Rivas", "Mark Warschauer", "Brian K. Sato"], "session": "SESSION: Self-Regulated Learning"}, {"title": "Analytics of Learning Strategies: Associations with Academic Performance and Feedback", "pages": "461-470", "doi": "10.1145/3303772.3303787", "abstract": "Learning analytics has the potential to detect and explain characteristics of learning strategies through analysis of trace data and communicate the findings via feedback. However, the role of learning analytics-based feedback in selection and regulation of learning strategies is still insufficiently explored and understood. This research aims to examine the sequential and temporal characteristics of learning strategies and investigate their association with feedback. Three years of trace data were collected from online pre-class activities of a flipped classroom, where different types of feedback were employed in each year. Clustering, sequence mining, and process mining were used to detect and interpret learning tactics and strategies. Inferential statistics were used to examine the association of feedback with the learning performance and the detected learning strategies. The results suggest a positive association between the personalised feedback and the effective strategies.", "authors": ["Wannisa Matcha", "Dragan Ga\u0161evi\u0107", "Nora'Ayu Ahmad Uzir", "Jelena Jovanovi\u0107", "Abelardo Pardo"], "session": "SESSION: Self-Regulated Learning"}, {"title": "Towards Hybrid Human-System Regulation: Understanding Children' SRL Support Needs in Blended Classrooms", "pages": "471-480", "doi": "10.1145/3303772.3303780", "abstract": "This paper proposes a new approach to translate learner data into self-regulated learning support. Learning phases in blended classrooms place unique requirements on students' self-regulated learning (SRL). Learning path graphs merge moment-by-moment learning curves and learning phase data to understand student' SRL support needs. Results indicate 4 groups with different SRL support needs. Students in the self-regulated learning group are capable of learning without external regulation. In the teacher regulation group students need initial teacher regulation but rely on SRL thereafter. Students in the system regulation group require teacher and system regulation to learn. Finally, the advanced system support group is in need of support beyond the current level of system regulation. Based on these insights, the application of personalized dashboards and hybrid human-system regulation is further specified.", "authors": ["Inge Molenaar", "Anne Horvers", "Ryan S. Baker"], "session": "SESSION: Self-Regulated Learning"}, {"title": "Investigating the Usage Patterns of Algebra Nation Tutoring Platform", "pages": "481-490", "doi": "10.1145/3303772.3303788", "abstract": "We study the usage of a self-guided online tutoring platform called Algebra Nation, which is widely by middle school and high school students who take the End-of-Course Algebra I exam at the end of the school year. This article aims to study how the platform contributes to increasing students' exam scores by examining users' logs over a three year period. The platform under consideration was used by more than 36,000 students in the first year, to nearly 67,000 by the third year, thus enabling us to examine how usage patterns evolved and influenced students' performance at scale. We first identify which Algebra Nation usage factors in conjunction with math overall preparation and socioeconomic factors contribute to the students' exam performance. Subsequently, we investigate the effect of increased teacher familiarity level with the Algebra Nation on students' scores across different grades through mediation analysis. The results show that the indirect effect of teacher's familiarity with the platform through increasing student's usage dosage is more significant in higher grades.", "authors": ["Sahba Akhavan Niaki", "Clint P. George", "George Michailidis", "Carole R. Beal"], "session": "SESSION: Intelligent Tutoring Systems II"}, {"title": "Knowledge Query Network for Knowledge Tracing: How Knowledge Interacts with Skills", "pages": "491-500", "doi": "10.1145/3303772.3303786", "abstract": "Knowledge Tracing (KT) is to trace the knowledge of students as they solve a sequence of problems represented by their related skills. This involves abstract concepts of students' states of knowledge and the interactions between those states and skills. Therefore, a KT model is designed to predict whether students will give correct answers and to describe such abstract concepts. However, existing methods either give relatively low prediction accuracy or fail to explain those concepts intuitively. In this paper, we propose a new model called Knowledge Query Network (KQN) to solve these problems. KQN uses neural networks to encode student learning activities into knowledge state and skill vectors, and models the interactions between the two types of vectors with the dot product. Through this, we introduce a novel concept called probabilistic skill similarity that relates the pairwise cosine and Euclidean distances between skill vectors to the odds ratios of the corresponding skills, which makes KQN interpretable and intuitive. On four public datasets, we have carried out experiments to show the following: 1. KQN outperforms all the existing KT models based on prediction accuracy. 2. The interaction between the knowledge state and skills can be visualized for interpretation. 3. Based on probabilistic skill similarity, a skill domain can be analyzed with clustering using the distances between the skill vectors of KQN. 4. For different values of the vector space dimensionality, KQN consistently exhibits high prediction accuracy and a strong positive correlation between the distance matrices of the skill vectors.", "authors": ["Jinseok Lee", "Dit-Yan Yeung"], "session": "SESSION: Intelligent Tutoring Systems II"}, {"title": "Counting Clicks is Not Enough: Validating a Theorized Model of Engagement in Learning Analytics", "pages": "501-510", "doi": "10.1145/3303772.3303775", "abstract": "Student engagement is often considered an overarching construct in educational research and practice. Though frequently employed in the learning analytics literature, engagement has been subjected to a variety of interpretations and there is little consensus regarding the very definition of the construct. This raises grave concerns with regards to construct validity: namely, do these varied metrics measure the same thing? To address such concerns, this paper proposes, quantifies, and validates a model of engagement which is both grounded in the theoretical literature and described by common metrics drawn from the field of learning analytics. To identify a latent variable structure in our data we used exploratory factor analysis and validated the derived model on a separate sub-sample of our data using confirmatory factor analysis. To analyze the associations between our latent variables and student outcomes, a structural equation model was fitted, and the validity of this model across different course settings was assessed using MIMIC modeling. Across different domains, the broad consistency of our model with the theoretical literature suggest a mechanism that may be used to inform both interventions and course design.", "authors": ["Ed Fincham", "Alexander Whitelock-Wainwright", "Vitomir Kovanovi\u0107", "Sre\u0107ko Joksimovi\u0107", "Jan-Paul van Staalduinen", "Dragan Ga\u0161evi\u0107"], "session": "SESSION: Educational Theory"}, {"title": "Introducing meaning to clicks: Towards traced-measures of self-efficacy and cognitive load", "pages": "511-520", "doi": "10.1145/3303772.3303782", "abstract": "The use of learning trace data together with various analytical methods has proven successful in detecting patterns in learning behaviour, identifying student profiles, and clustering learning resources. However, interpretation of the findings is often difficult and uncertain due to a lack of contextual data (e.g., data on student motivation, emotion or curriculum design). In this study we explored the integration of student self-reports about cognitive load and self-efficacy into the learning process and collection of relevant students' perceptions as learning traces. Our objective was to examine the association of traced measures of relevant learning constructs (cognitive load and self-efficacy) with i) indicators of the students' learning behaviour derived from trace data, and ii) the students' academic performance. The results indicated the presence of association between some indicators of students' engagement with learning activities and traced measures of cognitive load and self-efficacy. Correlational analysis demonstrated significant positive correlation between the students' course performance and traced measures of cognitive load and self-efficacy.", "authors": ["Jelena Jovanovi\u0107", "Dragan Ga\u0161evi\u0107", "Abelardo Pardo", "Shane Dawson", "Alexander Whitelock-Wainwright"], "session": "SESSION: Educational Theory"}, {"title": "Integrated Closed-loop Learning Analytics Scheme in a First Year Experience Course", "pages": "521-530", "doi": "10.1145/3303772.3303803", "abstract": "Identifying non-thriving students and intervening to boost them are two processes that recent literature suggests should be more tightly integrated. We perform this integration over six semesters in a First Year Experience (FYE) course with the aim of boosting student success, by using an integrated closed-loop learning analytics scheme that consists of multiple steps broken into three main phases, as follows: Architecting for Collection (steps: design, build, capture), Analyzing for Action (steps: identify, notify, boost), and Assessing for Improvement (steps: evaluate, report). We close the loop by allowing later steps to inform earlier ones in real-time during a semester and iteratively year to year, thereby improving the course from data-driven insights. This process depends on the purposeful design of an integrated learning environment that facilitates data collection, storage, and analysis. Methods for evaluating the effectiveness of our analytics-based student interventions show that our criterion for identifying non-thriving students was satisfactory and that non-thriving students demonstrated more substantial changes from mid-term to final course grades than already-thriving students. Lastly, we make a case for using early performance in the FYE as an indicator of overall performance and retention of first-year students.", "authors": ["Munira Syed", "Trunojoyo Anggara", "Alison Lanski", "Xiaojing Duan", "G. Alex Ambrose", "Nitesh V. Chawla"], "session": "SESSION: Campus Experience"}, {"title": "Descriptive and Predictive Modeling of Student Achievement, Satisfaction, and Mental Health for Data-Driven Smart Connected Campus Life Service", "pages": "531-538", "doi": "10.1145/3303772.3303792", "abstract": "Yonsei University in Korea launched an educational innovation project entitled \"Data-Driven Smart-Connected Campus Life Service\", for which student-related data have been accumulated at university level since spring of 2015, and descriptive, predictive and prescriptive modeling have been conducted to offer innovative education service to students. The dataset covers not only conventional student information, student questionnaire survey, and university administrative data, but also unconventional data sets such as student location data and learning management system (LMS) log data. Based on the datasets, with respect to 4,000+ freshman students at residential college, we conducted preliminary implementation of descriptive and predictive modeling for student achievement, satisfaction, and mental health. The results were overall promising. First, descriptive and predictive modeling of GPA for student achievement presented a list of significant predictive variables from student locations and LMS activities. Second, descriptive modeling of student satisfaction revealed influential variables such as \"improvement of creativity\" and \"ability of cooperation\". Third, similar descriptive modeling was applied to students' mental health changes by semesters, and the study uncovered influential factors such as \"difficulty with relationship\" and \"time spent with friends increased' as key determinants of student mental health. Although the educational innovation project is still in its early stages, we have three strategies of the future modelling efforts: They are: (1) step-by-step improvement from descriptive, predictive, to prescriptive modelling; (2) full use of recurring data acquisition; (3) different level of segmentation.", "authors": ["Joon Heo", "Hyoungjoon Lim", "Sung Bum Yun", "Sungha Ju", "Sangyoon Park", "Rebekah Lee"], "session": "SESSION: Campus Experience"}, {"title": "Beyond A/B Testing: Sequential Randomization for Developing Interventions in Scaled Digital Learning Environments", "pages": "539-548", "doi": "10.1145/3303772.3303812", "abstract": "Randomized experiments ensure robust causal inference that is critical to effective learning analytics research and practice. However, traditional randomized experiments, like A/B tests, are limiting in large scale digital learning environments. While traditional experiments can accurately compare two treatment options, they are less able to inform how to adapt interventions to continually meet learners' diverse needs. In this work, we introduce a trial design for developing adaptive interventions in scaled digital learning environments -- the sequential randomized trial (SRT). With the goal of improving learner experience and developing interventions that benefit all learners at all times, SRTs inform how to sequence, time, and personalize interventions. In this paper, we provide an overview of SRTs, and we illustrate the advantages they hold compared to traditional experiments. We describe a novel SRT run in a large scale data science MOOC. The trial results contextualize how learner engagement can be addressed through culturally-targeted reminder emails. We also provide practical advice for researchers who aim to run their own SRTs to develop adaptive interventions in scaled digital learning environments.", "authors": ["Timothy NeCamp", "Josh Gardner", "Christopher Brooks"], "session": "SESSION: Design and Development"}]}]